Improved Anomaly Detection in Crowded Scenes via Cell-based Analysis of Foreground Speed, Size and Texture

The University of Queensland, School of ITEE, QLD 4072, Australia

Introduction

Automated detection of anomalous events in video feeds has the potential to provide more vigilant surveillance, possibly in lieu of, or as an assistance to, human operators who have limited attention spans when faced with tedious tasks [\cite=haering2008evolution]. Qualifying an event as anomalous is subjective and depends on the intended application as well as context. However, without being application or context specific, an anomalous event can be defined as any event that is different from what has been observed beforehand.

Detection of anomalous events can be hence viewed as a binary classification problem, where there are training examples only for one class, generally. Typical algorithms model the dynamics of 'normal' activity or 'expected' behaviour and compare new observations with an existing model. Any outliers are labelled as anomalous. An ideal system is expected not only to detect anomalous events accurately, but also to adapt itself to the changes witnessed in the environment over time.

Several anomaly detection techniques have been proposed in various research fields. Chandola et al. [\cite=chandola2009anomaly] discuss them in detail in their survey, while Saligrama et al. [\cite=saligrama2010video] examine video based anomaly detections approaches in the context of surveillance. Existing methods in the literature can be roughly placed into two categories: (i) analysis by tracking, where trajectories of individual objects are maintained; (ii) analysis without tracking, where other features such as motion and texture are employed to model activity patterns of a given scene.

In the first category, almost all approaches use tracking information directly to gather object speed and direction, and indirectly as an aid in determining features such as the size and aspect ratio of objects [\cite=basharat2008learning] [\cite=hu2006system] [\cite=piciarelli2008trajectory] [\cite=remagnino2001classifying] [\cite=wang2006learning]. While trajectory based approaches are suitable for cases where the scene is comprised of only a few objects, in crowded environments it is difficult to reliably maintain tracks due to occlusion and overlap of objects [\cite=kratz2009anomaly] [\cite=mahadevan2010anomaly].

In light of the above problems, in the second category the anomaly detection task is formulated while deliberately omitting the tracking of specific objects. Most approaches in this category largely rely on motion or motion-related features. For example, Mehran et al. [\cite=mehran2009abnormal] model crowd behaviour using a "social force" model, where the interaction forces are computed using optical flow. Adam et al. [\cite=adam2008robust] model optical flow at a set of fixed spatial locations using probabilistic histograms. Ermis et al. [\cite=ermis2008motion] propose using busy-idle rates of each pixel to detect abnormal behaviour.

As the above techniques solely rely on motion information, anomalies occurring due to object size or appearance may not be detected. To address this limitation, Mahadevan et al. [\cite=mahadevan2010anomaly] recently proposed to jointly model the appearance and dynamics of crowded scenes, using mixtures of dynamic textures (MDT) [\cite=Chan_MDT_2008]. The method explicitly investigates both temporal and spatial anomalies. Though the reported comparative results show improvements over earlier techniques, the method's main drawback is heavy computation. Evaluating a frame of size 240  ×  160 takes about 25 seconds (ie.  2.4 frames per minute).

In this paper, we present a robust anomaly detection algorithm with relatively low complexity, targeted primarily for crowded scenes where traditional tracking based approaches tend to fail. To suppress undesirable background dynamics, such as waving trees and illumination variations, we perform foreground segmentation and retain only foreground objects for further analysis. Each input frame is split into non-overlapping cells (small regions). Based on each frame's foreground mask, the relevant cells are analysed for the presence of an anomaly. Unlike most methods, a refined estimate of motion is achieved by computing the optical flow only for the foreground pixels. In addition to motion, the proposed method analyses the size and texture of foreground objects at each cell location.

Motion, size and texture are modelled separately. Independent analysis helps to keep computation efficient, and allows for inferring the nature of the anomaly (eg. speed violation, lack of motion, size too large, etc). Each cell is labelled as either normal or anomalous after combining the outputs of multiple classifiers (one for each feature type).

We continue the paper as follows. In Section [\ref=sec:Proposed_Algorithm] the proposed algorithm is described in detail. Performance evaluation and comparison with three recent algorithms is given in Section [\ref=sec:Experiment_Results]. The main findings and possible future directions are presented in Section [\ref=sec:conclusion].

Proposed Algorithm

The proposed method has four main components:

Feature extraction, where input images are split into non-overlapping spatial regions, termed cells, and features are extracted based on motion, size and texture of the foreground objects contained in the cells.

Model estimation, which models the normal dynamics witnessed at each cell location. There are separate models for each feature type.

Classification of each cell as anomalous or normal, where each cell is sequentially checked for normality by up to two classifiers. As soon as the first classifier deems that the cell is anomalous, the second classifier is not consulted. In order of processing, the two classifiers are:

Spatio-temporal post-processing, to minimise isolated random noise present in the generated anomaly masks.

Each of the components is explained in detail in the following sections.

Feature Extraction

Let the resolution of the greyscale image sequence I be W  ×  H. Each image is split into non-overlapping cells (regions) of size N  ×  N, with the cell located at i and j denoted by [formula]. The cell co-ordinates have the range of [formula] and [formula]. Let [formula] be the frame at time instant t and let its corresponding cells be denoted by [formula].

In order to restrict the analysis to regions of interest and to filter out distractions (eg. waving trees, illumination changes, etc), we perform foreground segmentation on each incoming frame. We have used the method proposed in [\cite=reddy2010adaptive], due to its robustness, high-quality foreground masks and the ability to estimate the background even in the presence of multiple moving foreground objects. Alternative techniques for estimating the background in crowded scenes include [\cite=Baltieri_2010] [\cite=Reddy_IVP_2011].

For each cell, we extract features based on motion, size and texture. The foreground masks are referenced while computing the features. The details of the three features are given below.

Motion

To estimate the motion associated with cell [formula], we compute the optical flow of only the foreground pixels. The iterative Lucas-Kanade algorithm [\cite=bouguet1999pyramidal] [\cite=lucas1981iterative] is employed to compute the displacement of pixels between two consecutive frames, with a fixed search window around each pixel. We first calculate the average motion associated with cell [formula] using:

where, for foreground pixel n, v(n)x and v(n)y are the optical flows in the x and y directions, respectively, while Nf is the total number of foreground pixels within the cell.

The motion feature for cell [formula] is taken to be the smoothed (noise-reduced) version of the cell's average motion, calculated using straightforward temporal averaging:

Size

Relying on motion alone for anomaly detection might be insufficient, as certain anomalies may exhibit motion that is considered as normal (eg. a slow moving vehicle on a path designated for pedestrians). Furthermore, motion estimation techniques can suffer from the aperture problem [\cite=trucco1998introductory]. To increase the sensitivity of anomaly detection, the size of foreground objects can be analysed.

A common technique to measure object size is via connected component analysis on the foreground masks. However, in crowded environments it becomes ineffective due to object overlap and occlusion. Instead, an approximate size of an object contained within a cell can be obtained by considering its foreground occupation along with that of its neighbouring cells (as the object may occupy more than one cell). An example is shown in Fig. [\ref=fig:neighbourhood].

Specifically, let us denote the foreground occupancy (number of foreground pixels) for cell [formula] by ot(i,j). We define the size feature for cell [formula] as a weighted combination of the foreground occupancy values of the cell and its immediate neighbours:

where G is a 3  ×  3 Gaussian mask [\cite=Gonzalez_2008]. The mask is used for placing prominence on the center cell and hence reducing the impact of neighbouring cells that, in crowded scenarios, may contain foreground pixels belonging to other objects (in addition to the object of interest).

Texture

While the size feature can be useful for increasing the sensitivity of anomaly detection, using it without qualification may also increase the false alarm rate. For example, in crowded environments the foreground masks of people walking close to each other could resemble a large foreground object.

To address this problem, the texture present within the cell can be used for increasing selectivity. To this end, we filter a given image using 2D Gabor wavelets [\cite=lee2002image] at four orientations: 0, 45, 90 and 135 degrees. The texture descriptor for cell [formula] is hence a 4D vector:

where mθ is the sum of the response magnitudes of the wavelet oriented at θ degrees, over the pixels contained within the cell. The texture vectors are only collected for cells that have at least one foreground pixel, in order to minimise modelling of the background.

Scalable Semi-Parametric Model Estimation

Surveillance scenarios include platforms at train/bus stations, buildings (both indoors/outdoors) as well as road/walkway traffic. In all these scenarios, even normal day-to-day events have inherent variations that are random in nature. For example, the speed of vehicles on a road can vary arbitrarily due to traffic light signals and congestion. Furthermore, the dynamics of the scene can keep changing over time. As such, parametric approaches are unlikely to be effective for modelling distributions of features in these scenarios, as the number of modes is unlikely to be reliably known beforehand. With this in mind, we employed a semi-parametric modelling approach, which can be used for modelling arbitrary distributions without using any assumptions on the forms of the underlying densities.

We model each cell by considering only the features extracted from that particular cell location, along the temporal axis. As described in Section [\ref=subsec:feature_extraction], there are three feature types: motion (a scalar), size (also a scalar) and a texture descriptor (a 4D vector). In tasks such as object detection/recognition, it is often argued that joint modelling of features yields better results than modelling them independently [\cite=bahlmann2005system] [\cite=shotton2006textonboost]. However, in our context such an approach may fail to detect outliers (ie. the anomalies) accurately, due to the implicit mutual influence exhibited by the features in the decision process. Furthermore, the dynamics of a crowded scene are inherently arbitrary in nature, which may render joint modelling ineffective. We will hence model these features separately. Independent analysis keeps computation efficient, examines each feature precisely for anomalies, which in turn allows for inferring the nature of the anomaly (eg. speed violation, lack of motion, size too large, etc).

For modelling the motion and size features, a straightforward and efficient semi-parametric approach involves constructing normalised histograms. The training data can be discarded once the histograms are built. However, a major problem with this approach is the presence of sharp discontinuities in the estimated densities due to binning, rather than that of the underlying distribution that generated the data [\cite=bishop2006pattern]. To overcome the above limitation, it is possible to use kernel density estimation techniques that result in smoother probability density functions [\cite=bishop2006pattern] [\cite=saleemi2008probabilistic]. Their training phase only involves storing of all the data samples. However, their drawback is increased computational cost and memory requirements as the dataset becomes larger [\cite=bishop2006pattern]. As such, these techniques can suffer from scalability issues.

To achieve a better trade-off between accuracy and computational requirements, we create a smoothed histogram by temporarily storing all the training samples and performing Gaussian kernel based density estimation to compute the probability of the continuous variable (ie. motion or size) only at discrete points over its entire permissible range. In effect, we assume the random variable to be discrete and compute its probability at fixed points using:

where Δx is the resolution of the step size , s  =  {0,1,2,3,...,S}, with SΔx being the valid upper limit of the variable in consideration. N is the number of samples in the training dataset and h is the bandwidth of the Gaussian kernel. The probability values are normalised to obtain a probability mass function (pmf). As in the histogram approach, the training data is discarded once the pmf is computed. The resultant pmf is denoted by p̂(  ·  ).

Adaptive Modelling of Texture Descriptors

While the above approach is effective for modelling the distribution of scalars (motion and size in our case), using it to model the distribution of the 4D texture descriptors is impractical, as the number of resulting discrete samples required to cover the entire feature space (for just one cell location) would be quite large. For example, having only 20 equally spaced points in each dimension would generate 204 points in 4D space. As there is a non-trivial number of cell locations, the total storage costs would be hence prohibitive.

Furthermore, the above density estimation approach implicitly relies on an Euclidean based distance, which will be affected by variations in texture contrasts, rather than purely measuring the differences between texture patterns. For example, the texture descriptor will exhibit low magnitude responses when the intensity of a pedestrian's clothing is similar to that of the background, and high magnitude responses when the intensity is contrasting to the background.

To address the storage problem, for each cell location we model the distribution of the texture descriptors using a codebook that is trained in an online fashion (adaptively grown), inspired by [\cite=kratz2009anomaly]. To address the distance measure problem, we employ Pearson's correlation coefficient [\cite=theodoridispattern] for measuring the similarity of two descriptors:

where [formula] is the mean of the elements of vector [formula], and [formula].

The codebook is built as follows. Initially, the first training vector is taken to be the first entry in the codebook. Each of the remaining vectors is sequentially treated as a new observation, [formula], which is compared to each entry in the codebook, [formula], using Eqn. ([\ref=eqn:correlation]). If, for the best matching [formula], [formula], the k-th entry is updated using [\cite=Chan_1979]:

where Wk is the number of texture vectors associated so far with entry k. If [formula], vector [formula] is appended to the codebook, thereby expanding it.

Cell Classification

Each cell is sequentially checked whether it is anomalous by up to two classifiers. As soon as the first classifier deems that the cell is anomalous, the second classifier is not consulted. Specifically, given a decision threshold T, cell [formula] is classified as anomalous if either of the following two conditions are satisfied:

[formula]

[formula]  and  [formula]

where [formula] and [formula] are the pmfs calculated in Section [\ref=subsec:_Model_Estimation], while [formula] [formula] [formula], ie. the correlation coefficient of the closest matching codebook entry.

Condition (a) is effectively a speed check, where speeds that are either slower or faster than 'normal' are detected (note that [formula] can define several 'normal' speeds). In condition (b) both the size and texture are checked. As the size feature alone is not be able to distinguish between a large object and a collection of small objects (eg. a crowd of people), the texture feature is in effect used to verify the presence of an anomaly indicated by the size feature.

The texture feature is only calculated for cells that contain foreground pixels, in order to avoid modelling the background (which might be dynamic). As such, the texture feature is suitable for distinguishing among foreground objects. However, as the feature may end up capturing irrelevant textures when the cell contains only thin edges of the foreground, it is used in combination with the size feature rather than being used alone.

Spatio-Temporal Post-Processing

To minimise spurious and intermittent false alarms, spatio-temporal post-processing is performed on the anomaly masks generated by the classification procedure in Section [\ref=subsec:_Classification]. If a cell at time t was initially classified as anomalous, we consider its immediate neighbours along both the spatial and temporal axes (see Fig. [\ref=fig:cubepost_proc]). If at least two cells in each plane (ie.  t1, t, t1) were classified as anomalous, we assume that the cell in question was correctly classified as anomalous. Otherwise, it is re-classified as being normal (ie. non-anomalous).

Experiments

To appraise the performance of the proposed approach, we performed experiments on the recently released UCSD Anomaly Detection dataset [\cite=mahadevan2010anomaly]. The dataset contains multiple surveillance videos of two scenes (Ped1 and Ped2), both with considerable crowds. Anomalies present in the dataset include: skateboarders, bikers, motor vehicles, people pushing carts as well as walking on the lawn. The image size in Ped1 is [formula] pixels, while on Ped2 it is [formula]. Ped1 has 34 training and 36 test image sequences, while Ped2 has 16 training and 12 test image sequences. Examples are shown in Fig. [\ref=fig:ad_sample_frames].

The UCSD dataset has a prescribed evaluation protocol [\cite=mahadevan2010anomaly], involving two types of evaluations: (i) frame-level anomaly detection, and (ii) within-frame anomaly localisation. For frame-level anomaly detection, all test sequences have annotated groundtruth at frame-level in the form of a binary flag indicating the presence or absence of anomaly in each frame. For within-frame anomaly localisation, a subset of test sequences (10 in Ped1 and 9 in Ped2) has the anomalous regions within each frame marked. If at least 40% of detected pixels (belonging to a detected anomaly) match the ground-truth pixels, it is presumed the anomaly has been localised correctly; otherwise it is treated as a 'miss'.

The proposed algorithm was compared with methods based on social force [\cite=mehran2009abnormal], MPPCA [\cite=10.1109/CVPRW.2009.5206569], and mixture of dynamic textures (MDT) [\cite=mahadevan2010anomaly]. The first two methods rely on features obtained from optical flow while the last approach employs features based on appearance and scene dynamics. The quantitative results of the above three algorithms were adapted from [\cite=mahadevan2010anomaly]. To aid the interpretation of the results, we have reported the false negative rate [\cite=bengio_icml_2005] instead of the true positive rate used in [\cite=mahadevan2010anomaly].

Based on preliminary experiments, the cell size was set to [formula], while the search window size in the optical flow computation (Sec. [\ref=subsubsec:motion]) was set to [formula] (odd-sized to ensure a symmetrical search area around a given pixel). The experiments were implemented with the aid of the Armadillo C++ library [\cite=Armadillo_2010].

The quantitative results for the frame-level evaluation are shown in Table [\ref=tab:frame_detection_results] and in Fig. [\ref=fig:ped1_roc](a)-(b). The results for the within-frame evaluation are shown in Table [\ref=tab:frame_localisation_results] and in Fig. [\ref=fig:ped1_roc](c). Some of the qualitative results obtained by the proposed method are shown in Fig. [\ref=fig:ad_sample_frames]. In Tables [\ref=tab:frame_detection_results] and [\ref=tab:frame_localisation_results], the equal error rate (EER) is the point where the false negative rate is equal to the false positive rate. At the EER, the proposed method outperforms the other methods at both the frame-level and within-frame evaluations, most notably on the anomaly localisation task.

An experimental implementation of the proposed algorithm in C++ yielded 12 fps ( 720 frames per minute) on a standard 3 GHz PC, for sequences of images with a size of 240  ×  160 (ie. processing the Ped1 subset). We note that this is several orders of magnitude faster than the MDT method, which takes 25 seconds to process each frame (ie.  2.4 frames per minute) [\cite=mahadevan2010anomaly].

The proposed method has the ability to pick up anomalies (eg. skateboarder, bike) present even at the far end of the scene (eg. 2nd and 3rd images in column (a)). However, the last image in column (a) contains a 'miss': the biker was not detected. The cyclist was riding slowly and matching the pace of the neighbouring pedestrian (bottom-left corner). The texture in this context has strong vertical gradients making the biker appear as a pedestrian. Using a more detailed texture descriptor may help in such cases.

We also note a false positive (a pedestrian being detected as anomaly) in the last image of column (b). Upon further investigation, this false positive was due to the fact that the cells in the region of the pedestrian had minimal or no activity during the training phase. Consequently any foreground object entering this zone during testing was considered as anomalous, irrespective of the observed features.

Main Findings and Future Directions

In this paper we have proposed an anomaly detection algorithm targeted towards crowded scenes. In addition to detecting anomalies based on motion, it inspects for anomalies occurring due to size and texture. Video images are initially segmented into foreground regions to confine the analysis to regions of interest, ignoring the background (which might be dynamic). Unlike most methods which compute the optical flow for all pixels or a fixed set of pixels, the flow is computed only for the foreground pixels, thereby achieving a more precise estimate of object motion.

Features based on motion, size and texture are extracted at cell level (small fixed-size regions) and are modelled independently for precise anomaly detection. Motion and size features are modelled by an approximated kernel density estimation technique, which is computationally efficient even on large training datasets. The texture features are represented by an adaptively grown codebook, which is generated in an online fashion.

Experiments on the recently published UCSD Anomaly dataset (containing annotated surveillance videos) show that the proposed method obtains better results than several recent methods: MPPCA, social force, mixture of dynamic textures (MDT). The proposed method attained considerably more accurate anomaly localisation than the next best performing method, MDT, while at the same time being several orders of magnitude faster than MDT.

As part of future work, we aim to investigate the use of more descriptive features such as the orientation of motion [\cite=10.1109/CVPRW.2009.5206569], which would allow the detection of events such as wrong-way traffic. It would also be useful to adaptively update the models over long periods of time, allowing for context changes (eg. dense traffic might be usual during the day, but it can be unusual at night).

The effect of the cell size should be analysed in the presence of object variations due to factors such as image resolution, perspective changes, as well as view angle. The optimal cell size might be scene dependant and vary across the scene. For example, in Fig [\ref=fig:ad_sample_frames](a), a larger size might be more appropriate for the bottom-left corner (where objects appear relatively large), while a smaller size might be more effective in the top-right corner (where objects appear relatively small).

Acknowledgements