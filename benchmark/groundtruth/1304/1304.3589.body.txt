Tutorial for Bayesian forensic likelihood ratio

Introduction

In the Bayesian paradigm for presenting forensic evidence to court, it is recommended that the weight of the evidence be summarized as a likelihood ratio (LR) between two opposing hypotheses of how the evidence could have been produced. Such LRs are necessarily based on probabilistic models, the parameters of which may be uncertain. It has been suggested by some authors that the value of the LR, being a function of the model parameters should therefore also be considered uncertain and that this uncertainty should be communicated to the court.

In this tutorial, we consider a simple example of a fully Bayesian solution, where model uncertainty is integrated out to produce a value for the LR which is not uncertain. We show that this solution agrees with common sense. In particular, the LR magnitude is a function of the amount of data that is available to estimate the model parameters.

Bayesian methods are often criticised because of the difficulty of choosing appropriate priors, especially when the priors are non-informative. We do not deny these difficulties, but the problem is not solved by adopting frequentist methods that effectively sweep the prior under the carpet and pretend it does not exist. In this tutorial we do need to choose a non-informative prior and we choose it by examining the effect it has on the end-result.

We shall reference the following books: E.T. Jaynes, Probability Theory: The Logic of Science, Cambridge University Press 2003, which we shall abbreviate as PTLOS; and D.J. Balding, Weight-of-evidence for Forensic DNA Profiles, Wiley 2005, abbreviated as WEFDNA.

Simplified DNA model

In this tutorial we shall derive the details of how to compute the LR with a simplified DNA-like model. The idea is not to provide a recipe that can be used in real forensic DNA analysis, but rather to choose a model that facilitates better understanding of the basic look and feel of a fully Bayesian solution. We need the model to be very simple so that we can perform the Bayesian integrals in closed form. More realistic models would require more complex methods, which would obscure the primary purpose of this tutorial.

We suppose that the DNA profile of every individual has K different binary loci the state of each of which can be either 1 or 0. Every individual is therefore categorized by K binary variables, which gives a total number of 2K states. We represent a DNA profile by a vector of the form [formula], where ak∈{0,1} represents the state of locus k.

We assume that given a DNA sample (either recovered at the crime scene where it was left by the perpetrator, or obtained from the suspect), the state of each locus may be determined without error.

The main complication is when all suspect and perpetrator loci match, that there is a non-zero probability that some person other than the suspect could have the same DNA profile. To compute this probability, we need to model profile distributions.

Profile distribution model

Here we define a generative model that is probably about as simple as it can be. Again, our goal is just to illustrate the basic principles of a fully Bayesian approach to this kind of problem. The goal of this exercise is not to reproduce a realistic DNA model--in real population genetics, the models are more complex.

Let the probability that locus k of a randomly chosen person has state 1 be qk, and the probability that it has state 0 be 1 - qk. According to this model we assume the following independencies:

The locus states are independent: knowing the state of locus k for one or more individuals, tells us nothing about the states of other loci k'.

For each locus k, the binary state for each person is sampled as an iid Bernoulli trial with parameter qk.

We can collect the locus probabilities in the vector [formula]. We refer to [formula] as the model parameter, which encodes everything there is to know (under the above modelling assumptions) about how locus states are distributed in the population. The model can be summarized by:

[formula]

which is the probability that a randomly chosen individual has DNA profile [formula] in a population characterized by the model parameter [formula]. The complication is that we are not given [formula]. Its value has to be inferred from prior assumptions and from data.

Inferring the model parameter

We do a Bayesian inference for the value of [formula], by computing a posterior distribution.

Prior

As prior for qk, we assign a beta distribution. This choice has a threefold motivation: (i) The beta distribution is a conjugate prior for this problem, which allows for closed-form Bayesian calculations. (ii) It is commonly used in forensic DNA practice. (iii) It is general enough to include various non-informative priors, which will be of special interest to us.

We assign independently for each qk a beta distribution with hyper-parameter πk  =  (αk,βk), so that:

[formula]

where we have defined [formula]. The normalization constant of the beta distribution is given by the beta function, defined as:

[formula]

where Γ is the gamma function.

For the beta distribution to be normalized, we need αk,βk > 0 and unless stated otherwise, we shall assume this condition holds for all our calculations below. In places, we will however consider the limit as [formula]. When we do this, we will follow the advice of PTLOS and complete the whole calculation under the assumption αk,βk > 0 and apply the limit only to the final result.

Non-informative priors

If we want to use a non-informative prior, we let α  =  αk  =  βk by symmetry, and we can choose some α, for example in the range [formula]. The case [formula] is called the Haldane prior, the case α = 0.5 is the Jeffreys prior and α = 1 is the Laplace prior.

The Haldane prior is flat in the sense that the probability density for [formula] is uniform, but since this reparametrization of q covers the whole real line, this prior is improper.

The Jeffreys prior is flat in the sense that the probability density for arcsin (2q - 1) is uniform between [formula] and [formula].

The Laplace prior is flat in the sense that the probability density for q is uniform between 0 and 1.

As these names show, different workers in probability theory have arrived at different conclusions about which prior should be used to encode non-informativeness about the Bernoulli model parameter. To make our calculations concrete, we will have to make a definite choice of prior. We shall solve this problem in a later section, by examining the effect of the prior on the end-result of our calculation.

Informative prior

In forensic DNA it is customary to reparametrize the beta prior as:

[formula]

where 0 < pk < 1 and 0 < θ < 1. Here θ is known as the population structure parameter. With this parametrization, [formula] has the following mean and variance:

[formula]

For small values of θ, one obtains an informative prior, with a small variance and a sharp peak near pk. In the extreme as [formula], we get a strongly informative prior, which will override contributions made by finite data and therefore asserts qk = pk.

For the case [formula] and [formula], we recover the above-mentioned non-informative priors: Laplace at [formula], Jeffreys at [formula] and in the extreme as [formula], the Haldane prior, which gives maximum weight to the data. These effects will be shown below.

Database

We make provision in our calculation to optionally use a database of examples to help us infer values for [formula]. Let [formula] be a database of DNA profiles for L different individuals, where the profile for individual [formula] is [formula] and where [formula] is the binary state of locus k of individual [formula]. We assume the DNA profiles in [formula]:

have been sampled iid from the same population as the suspect and perpetrator and are therefore relevant to inferring the parameter [formula],

but the individuals are distinct from the suspect and the perpetrator.

Our calculations will allow for the case of the empty database, where L = 0.

Likelihood

Because of our independence assumptions in the model, the likelihood for [formula], given the database [formula] is:

[formula]

where [formula] is the number of times locus k has state 1 and L - nk is the number of times it has state 0.

Posterior

We can now infer the value of [formula] by computing the posterior:

[formula]

where the integral in the denominator was solved by inspection, by recognizing the numerator as another beta distribution. This is due to the fact that the beta distribution is conjugate to the Bernoulli likelihood and therefore should result in a beta posterior. Notice that if the database is empty, then nk = L = 0 and the posterior is just the prior.

The prior parameters αk and βk play the same roles mathematically as the event counts nk and L - nk and are consequently referred to as pseudo-counts. The total pseudo count, α  +  β can be interpreted as the size of some pseudo database, which is then effectively pooled with [formula] by the additions in [\eqref=eq:qpost].

In the alternative prior parametrization, [formula] and [formula] are the pseudo counts and [formula] is the size of the pseudo database.

The posterior [formula] represents our total state of knowledge about [formula] and can be used in all calculations in place of the unknown [formula].

Forensic LR

We are given two DNA profiles: One for the suspect, [formula] and one for the perpetrator, [formula]. We work with two hypotheses and assume they are the only possible explanations for the observed data [formula]:

The prosecution hypothesis, Hp, asserts that suspect and perpetrator are the same person.

The defence hypothesis Hd, asserts that they are different individuals.

Below we compute the likelihoods under each hypothesis. For now, we assume that if they don't match, [formula], then in the absence of DNA measurement errors, this proves deductively that Hd is true and Hp is false.

In the matched case, [formula], however, we need probabilistic reasoning. The most natural way to do this would be to compute the posterior,

[formula]

where we have introduced the prior for the prosecution hypothesis,

[formula]

which is assigned by a reasoning process not involving DNA profiles. However, in the Bayesian paradigm for presenting evidence in court one equivalently considers the posterior odds for Hp against Hd, which can be separated into two factors: likelihood ratio and prior odds, respectively representing the contributions of the DNA analysis and all other evidence not related to DNA:

[formula]

where

[formula]

is referred to as the likelihood ratio. It is then recommended that the end-goal of the forensic DNA analysis is to compute [formula], which can be done independently of Π. We derive expressions for both likelihoods below and then form the ratio.

Finally, notice that if [formula], then the DNA analysis is completely non-informative about Hp versus Hd: in this case the posterior (odds) is the same as the prior (odds).

Prosecution likelihood

Under the prosecution hypothesis, [formula] and [formula] come from the same individual, so that [formula], where [formula], or [formula] if [formula]. Since we are not given [formula], but instead we are given the prior [formula] and the database [formula], we must condition on what we have and instead compute:

[formula]

where

[formula]

where Q is short-hand for the K-cube over which we are integrating. Note [formula] is called the predictive distribution for [formula], because it predicts the value of an as yet unseen profile, given that we have already seen the profiles in [formula]. Again by virtue of the conjugate prior, the predictive distribution can be found in closed form:

[formula]

Now we can expand the beta functions in terms of gamma functions and simplify the ratios of gammas with the identity Γ(x + 1) = xΓ(x), to find the predictive probability:

[formula]

For the informative prior case, notice that θ gives interpolation weights between data and the prior parameter pk. At the one extreme if [formula] (Haldane prior), we disregard the prior parameter pk and end up with just the data proportion [formula]. At the other extreme if θ = 0, we disregard the data [formula] and end up with the prior parameter pk. (If we use the non-informative Laplace prior, with αk  =  βk = 1, then [\eqref=eq:pred1n] is known as Laplace's rule of succession.) Finally, the predictive probability for the event sk = 0 is:

[formula]

Note that even for an empty database (L = nk = 0), our assumption αk,βk > 0 guarantees non-zero predictive probabilities.

Defence likelihood

Under the defence hypothesis, [formula] and [formula] come from different individuals and their probabilities are independent given [formula], so that [formula]. However, [formula] is not given, so the independence no longer holds: knowledge of one profile changes the probability for [formula], which in turn changes the probability for the other profile. This dependency is automatically taken care of by applying the rules of probability theory by integrating out the unknown [formula]:

[formula]

where we can expand and simplify again to find the predictive probability:

[formula]

Notice the similarity between the two factors in the RHS: the right factor is obtained from the left by adding 1's to the observation counts. Notice also that if [formula], then P(rk = sk = 1|πk,nk,L)  ≈  P(rk = 1|πk,nk,L)P(sk = 1|πk,nk,L), making the two events almost independent.

The probability for the other event of interest is obtained similarly as:

[formula]

LR

Forming the likelihood-ratio, we find:

[formula]

where

[formula]

More explicitly, for the mismatched cases we have

[formula]

and for the matched cases we have

[formula]

or, with the other prior parametrization:

[formula]

Notice again, that θ interpolates between data and the prior parameter pk. The minimum value (for the matched case rk = sk) is 1. This is a consequence of the error-free measurement assumption. If non-zero error probabilities were considered, values of less than 1 would be possible.

Plug-in recipe

In this section, we shall refer to:

One or more reference populations, from which one or more databases are drawn to help to estimate the parameters pk and θ for an informative prior.

The relevant population, from which the suspect and perpetrator were drawn.

In the general case, all these populations are assumed different from each other in the sense that locus state frequencies may differ between them.

For forensic DNA applications, WEFDNA motivates a plug-in recipe to compute the [formula], where values for θ and the pk are point-estimates made from one or more reference databases. In this recipe, the pk are representative of the frequencies in the reference populations, while the value of θ is chosen to reflect by how much the corresponding frequencies in the relevant population may differ. Small values of θ encode small expected differences and larger values encode larger expected differences. WEFDNA motivates for values in the range [formula] to be used for most applications.

Our database [formula], as defined in section [\ref=sec:db], is assumed to be drawn from the relevant population, but in the usual forensic scenario, additional profiles from the relevant population are not available. In our notation, this means [formula] is empty.

In summary, in the WEFDNA plug-in recipe we set L = nk = 0, the pk are generally different from [formula] and θ is smallish. This forms an informative prior for the qk. This gives, for rk = sk:

[formula]

Fully Bayesian recipe

Now we turn to the main purpose of this document, namely to explore a fully Bayesian recipe, where we start with a non-informative prior and use only the given data, [formula], to infer the model parameter.

It must be emphasized that this fully Bayesian recipe cannot be used as is to replace the plug-in recipe, because here we use the luxury of database [formula], sampled from the relevant population. As noted above, in a realistic scenario, we do not have this luxury: instead we have to make do with data sampled from some other, somewhat different, reference population. Although a fully Bayesian recipe could in principle be derived for this more realistic scenario, this would come at the cost of a considerable increase in both conceptual difficulties as well as computational complexity.

In this section, therefore we assume we do have a database, [formula], sampled from the relevant database and the only difficulty that remains is to choose the non-informative prior.

Which prior?

We are now faced with making a choice amongst the different flavours of non-informative priors. That is, we have to choose αk and βk, or equivalently pk and θ.

We concede that we are choosing a prior under the perhaps arbitrary constraint that it should be a beta distribution. A more thorough motivation for the prior should perhaps involve solving functional equations in the style of PTLOS. We feel however that the beta distribution already provides a rich enough space for the choice of prior. Moreover, as mentioned above, the non-informative Haldane, Jeffreys and Laplace priors all members of the beta family.

To start, we motivate the choice α  =  αk  =  βk, or equivalently [formula]. Before we have seen any data, all loci are on an equal footing, so that the priors for all k must be the same. Next consider a database [formula] with an equal number of 0's and 1's for some locus k, so that nk = L - nk. In this situation, there is no reason to prefer one state to the other, so that the model parameter posterior should satisfy the symmetry condition: P(qk|αk,βk,L,nk)  =  P(1 - qk|αk,βk,L,nk), which is obtained at αk  =  βk. Another way to see this is simply to require [formula] when nk = L - nk.

Now we have [formula] and we still need to choose θ. To do this, consider the case of the empty database, with L = nk = 0, for which case we still want our recipe to give a sensible answer. Now [\eqref=eq:lr11] and [\eqref=eq:lr00] give:

[formula]

When [formula] is empty, we now argue that we don't even know whether the locus state varies in the population. So we are not justified in concluding that the match at the locus modifies the probabilities for Hp vs Hd. If we maximize θ at the limit [formula], then we obtain the non-informative value of [formula], so that the DNA evidence is effectively disregarded.

Analysis

Here we analyse the behaviour of [formula], when rk = sk and θ = 1. We get:

[formula]

We make several observations:

The matched likelihood ratios are bounded: 1  ≤  LRk(s,s)  ≤  L + 1. We have already commented on the lower bound. The upper bound is determined by the database size, L. This makes intuitive sense, the larger the database, the more our maximum confidence grows. Note however, that this maximum should be a relatively rare occurrence, as shown below.

For an empty database, if L = nk = 0, then as discussed, [formula].

For a non-empty database, as long as a locus k has the same state in all of the observed data, [formula], then the [formula] is still unity: If nk = L, then [formula] and if nk = 0, then [formula].

Conversely, for a given database size L, the maximum [formula] value is reached when the locus state observed in sk = rk has never been observed in [formula]. This implies the trait shared by the suspect and perpetrator is rare. The larger the database size, L, the more we are convinced of the rarity and the more we are convinced of the identity of suspect and perpetrator.

For a large database, where both [formula] and [formula], the likelihood ratio for sk = rk is the inverse of the frequency of the corresponding event in the database: [formula] and [formula].

We can briefly compare this recipe to a very naive recipe, where we simply assign [formula], irrespective of the size of the database. This would give [formula] and [formula]. This agrees with the last case above of the Bayesian recipe, but in any other cases it could give overconfident results. In particular, if nk = 0, or nk = L, one could get infinite [formula] values, which would be ridiculous in the extreme if L = 1. The fully Bayesian recipe agrees with the naive recipe when data is plentiful, but continues to give sensible answers even when the data gets scarce to the point of vanishing.

Comment on Haldane prior

With a more realistic DNA model, where each STR locus has two independent sides (paternal and maternal), we can gain some extra insight into the nature of the Haldane prior. In this case, it can be shown (WEFDNA, section 6.2.2) that when L = 0, the LR for a locus can nevertheless reach a maximum of 3. If the paternal and maternal sides are the same, then we get LR=1, but if they are different, we get LR=3. From this fact and the third bullet above, we learn that:

The LR at locus k becomes non-informative ([formula]) under the Haldane prior, if and only if no state change has been observed at locus k in all of the data, [formula].

One may argue that loci used for forensic DNA profiling have been chosen for the purpose of giving good discrimination between individuals, precisely because they do vary appreciably between individuals and that therefore the Haldane prior is too extreme. However, we are concerned here with sub-populations, about which we cannot assume that every locus is informative--it may well be that a certain locus is constant over the whole sub-population. We therefore argue that the behaviour of the Haldane prior is appropriate: the LR for a locus remains non-informative ([formula]), until we have observed at least one state change in our data.