Introduction

Currently, the standard method for detection and tracking of Coronal Mass Ejections ( CMEs ) is by visual inspection (e.g., the CUA CDAW CME catalog, available at ). A human operator uses a sequence of images to visually locate a CME. A feature of interest is marked interactively so that it may be tracked in the sequence of images. From these manual measurements, the observer can then plot height-time profiles of the CMEs. These height measurements are used to compute velocities and accelerations (e.g., ). Although the human visual system is very sensitive, there are many problems with this technique. This methodology is inherently subjective and prone to error. Both the detection and tracking of a CME is dependent upon the experience, skill, and well being of the operator. Which object, or part of the CME to track varies, from observer to observer and is highly dependent on the quality of the data. Also, there is no way to obtain statistical uncertainties, which is particularly important for the determination of velocity and acceleration profiles. Lastly, the inability to handle large data volumes and the use of an interactive, manual analysis do not allow for a real-time data analysis required for space weather forecasting. A visual analysis of coronagraph data is a tedious and labor-intensive task. Current data rates from the Solar and Heliospheric Observatory ( SOHO ) are low enough to make an interactive analysis possible (<  1 Gigabyte/day). This will not be the case for recent missions such as the Solar TErrestrial RElations Observatory ( STEREO ) and new missions such as the Solar Dynamics Observatory ( SDO ). These missions have projected data rates that make an interactive analysis infeasible (>  1 Terabyte/day). For these reasons, it is necessary to develop an automatic, real-time CME detection and tracking system. Current digital imaging processing methods and paradigms provide the tools needed for such a system. In the next section we discuss in general, the parts needed in an automated system, as well as some of the current work on this topic.

A System for Automatic CME Detection

The general design for an automated CME detection system should basically follow the digital image-processing paradigm described by . Digital image processing as they describe can basically be broken into three parts: i) image preprocessing and segmentation; ii) image representation and description, and; iii) object recognition. Image preprocessing includes standard image preparation such as calibration, cosmic ray removal but it also includes noise reduction based on the statistics of the image (e.g., Gaussian or Poisson; ). Image segmentation is the extraction of individual features of interest in an image (e.g., edges, boundaries, and regions). Some methods used for this part include filtering, edge detection, and morphological operations. Image representation and description converts the extracted features into a form such as statistical moments or topological descriptors (e.g., areas, lengths, etc.) that are easier to store and manipulate computationally. Object recognition includes techniques such as neural networks and support vector machines ( SVMs ) to characterize and classify descriptors determined in the previous step.

Determining the complex structure of CMEs is complicated by the fact that CMEs are diffuse objects with ill-defined boundaries, making their automatic detection with many traditional image processing techniques a difficult task. To address this difficulty, new image processing methods were employed by and , who were the first to apply a wavelet-based technique to study the multiscale nature of coronal structures in LASCO and EIT data, respectively. Their methods employed a multilevel decomposition scheme via the so-called " à trous" wavelet transform.

, developed a system to autonomously detect CMEs in image sequences from LASCO. Their software, Computer Aided CME Tracking ( CACTus )(), relies on the detection of bright ridges in CME height-time maps using the Hough transform. The main limitation of this method is that the Hough transform (as implemented) imposes a linear height-time evolution, therefore forcing constant velocity profiles for each bright feature. This method is therefore not appropriate to study CME acceleration. Other autonomous CME detection systems include ARTEMIS [\cite=boursier05] (), the Solar Eruptive Event Detection Systems ( SEEDS )[\cite=olmedo05] (), and the Solar Feature Monitor [\cite=qu06] ().

In this work, a multiscale edge detector is used to objectively identify and track CME leading edges. In Section 3, Transition Region and Coronal Explorer ( TRACE;  ) and Large Angle and Spectrometric COronagraph experiment ( SOHO/LASCO;  ) observations and initial data-reduction is discussed, while the multiscale-based edge detection techniques are presented in Section 4. Our results and conclusions are then given in Sections 5 and 6.

Observations

To demonstrate the use of multiscale edge detection on CMEs in EUV imaging and white-light coronagraph, data two data sets were used. The first data set contains a CME observed on 18 April 2000 with the LASCO C2 and C3 telescopes. The data set contains six C2 images and two C3 images. The second data set of TRACE and LASCO observations contains a CME observed on 21 April 2002. The data set contains one C2 image, three C3 images, and 30 TRACE images. TRACE observed a very faint loop-like system propagating away from the initial flare brightening, which was similar in shape to a CME (or number of CMEs) observed in LASCO. The appearance of the features remained relatively constant as they passed through the TRACE 195 Å passband and LASCO fields of view.

The TRACE observations were taken during a standard 195 Å bandpass observing campaign that provides 20 second cadence and an image scale of 0.5 arcsec per pixel. Following , standard image corrections were first applied before pointing offsets were accounted for by cross-correlating and shifting each frame. The white-light LASCO images were obtained using a standard LASCO observing sequence. The C2 images were taken using the orange filter (5400 - 6400 Å) with a variable cadence between 16 and 37 minutes and an image scale of 11.9 arcsec per pixel. The C3 images were taken using the clear filter (4000 - 8500 Å) with a variable cadence between 24 and 60 minutes and an image scale of 56 arcsec per pixel. Both the C2 and C3 images were unpolarized. Table 1 summarizes the details of these two data sets.

Methodology

Edge Detection

Sharp variations or discontinuities often carry the most important information in signals and images. In images, these take the form of boundaries described by edges that can be detected by taking first and second derivatives [\cite=marr82]. The most common choice of first derivative for images is the gradient [\cite=gonzalez02]. The gradient of an image I(x,y) at a point (x,y) is the vector,

[formula]

The gradient points in the direction of maximum change of I at (x,y). The magnitude of this change is defined by the magnitude of the gradient,

[formula]

The direction of the change at (x,y) measured with respect to the x-axis is,

[formula]

The edge direction is perpendicular to the gradient's direction at (x,y).

The partial derivatives Gx and Gy are well approximated by the Sobel and Roberts gradient operators [\cite=gonzalez02], although these operators cannot easily be adapted to multiscale applications. In this work, scale is considered to be the size of the neighborhood over which the changes are calculated.

Most edges are not steep, so additional information to that returned by the gradient is needed to accurately describe edge properties. This can be achieved using multiscale techniques. First proposed by , this form of edge detection uses Gaussians of different width (σ) as a smoothing operator θσ. The Gaussians are convolved with the original image, so that Gaussians with smaller width correspond to smaller length-scales. Equation (1) for the Canny edge detector can be written as,

[formula]

The image is smoothed using a Gaussian filter with a selected σ. Then a derivative of the smoothed image is computed for the x and y-directions. The local gradient magnitude and direction are computed at each point in the image. An edge point is defined as a point whose gradient-magnitude is locally maximum in the direction defined by α. These edge points form ridges in the gradient magnitude image. The process of non-maximal suppression is performed by setting to zero all pixels not lying along the ridges. The ridge pixels are then thresholded using two thresholds (Ta and Tb with Tb  >  Ta). Ridge pixels with values between Ta and Tb are defined as weak edges. The ridge pixels with values greater than Tb are called strong edges. The edges are linked by incorporating the weak edges that are 8-connected with the strong pixels [\cite=gonzalez02]. Figure 1 shows a comparison of the Roberts, Sobel, and Canny edge detectors applied to an unprocessed LASCO C2 image of the 18 April 2000 CME from 16:54 UT. The Roberts (Figure 1(d)) and the Sobel (Figure 1(e)) detectors pick up a small piece of the CME core and noise. Using the multiscale nature of the Canny detector (Figure 1(f)), choosing a larger scale size (σ  =  5), edges corresponding to streamers and the CME front can be seen. Unfortunately, the Canny method has two main limitations: i) it is slow because it is based on a continuous transform and, ii) there is no natural way to select appropriate scales.

Multiscale Edge Detection

, showed that the maximum modulus of the continuous wavelet transform ( MMWT ) is equivalent to the multiscale Canny edge detector described in the previous section. The wavelet transform converts a 2D image into a 3D function, where two of the dimensions are position parameters and the third dimension is scale. The transform decomposes the image into translated and dilated (scaled) versions of a basic function called a wavelet: ψ(x,y). A wavelet dilated by a scale factor s is denoted as

[formula]

The wavelet is a function that satisfies a specific set of conditions, but these functions have the key characteristic that they are localized in position and scale [\cite=mallat98]. The minimum and maximum scales are determined by the wavelet transform, addressing the first problem of the Canny edge detector mentioned in the previous section.

refined the wavelet transform describe by Mallat and Hwang, creating a fast, discrete transform. This addresses the computational speed problem of the Canny edge detector making this fast transform more suited to realtime applications. As with the Canny edge detector, this wavelet starts with a smoothing function: s -  2θ(s -  1x,s -  1y). The smoothing function is a cubic spline, a discrete approximation of a Gaussian. The smoothing function is also separable, i.e. θ(x,y)  =  θ(x)θ(y). The wavelets are then the first derivative of the smoothing function. This allows the wavelets to be written as

[formula]

Another factor that adds to the speed of the wavelet transform algorithm is the choice of a dyadic scale factor (s). Dyadic means that s = 2j where [formula] or [formula], smallest scale to largest scale. The index J is determined by the largest dimension of the image, N, i.e., N = 2J. The wavelet transforms of I(x,y) with respect to x and y at scale s can then be written

[formula]

where [formula] denotes a convolution. Substituting these into Equations (2) and (3) gives the following expression for the gradient of an image at scale s in terms of the wavelets:

[formula]

The detailed steps associated with implementing Equation (6) are shown in Figure 2. The rows from top to bottom are scales one to five, respectively. Column (a) displays the horizontal wavelet components WxsI(x,y). Column (b) shows the vertical wavelet components WysI(x,y). The next two columns show the magnitude (c) of the multiscale gradient and the angle (d) of the multiscale gradient. The edges calculated from the multiscale gradient are displayed in column (e).

Edge Selection and Error Estimation

Once the gradient was found using the wavelet transform, the edges were calculated using the local maxima at each scale, as described in the end of Section 4.1. Closed or stationary edges due to features such as coronal loops, ribbons, and cosmic rays were then removed, thus leaving only moving, open edges visible. Currently not all available information is used so there were still some open spurious edges that were removed manually. Finally, only the edges from expanding, moving features were left. It was these edges that were used to characterize the temporal evolution of the CME front.

The multiscale edge detector can objectively define the CME front but it is also important to estimate the statistical uncertainty in the edges and to obtain errors in position or height. A straightforward way to do this is by using a bootstrap (). To do this we must create statistical realizations of the data, then apply the multiscale edge detection method to each realization. The realizations of the data are created by estimating a true, non-noisy image then applying a noise model to the true image. Applying the noise model means using a random number generator (random deviate) for our particular noise model to generate noise and adding to the non-noisy image estimate. In our case the noise model is well approximated by Gaussian noise. Estimation of the noise and the true image is described by . The noise model is applied 1000 times to the true image with each application creating a new realization. Doing this 1000 times, a mean and standard deviation is calculated for the edge location or in our case for each height point used. The steps for creating the estimate are i) estimate the noise in the original image, ii) compute the isotropic wavelet transform of the image ( à trous wavelet transform), iii) threshold the wavelet coefficients based on the estimated noise, and iv) reconstruct the image. The reconstructed image is the estimate of the true image. The noise estimate from the original image is used in the noise model applied to the estimated true image.

Results

The first example of application of the multiscale edge detection is illustrated in Figure 3. Figure 3(a) shows four of the original, unprocessed LASCO C2 images for the 18 April 2000 data set. The times for the frames from left to right are 16:06 UT, 16:30 UT, 16:54 UT, and 17:06 UT. Figure 3(b) shows running difference images for the sequence of C2 images. The results of the multiscale edge detection method applied to the original images are shown in Figure 3(c). The edges of the CME front are displayed as black contours over the difference images shown in Figure 3(b). Once the method is applied to the entire data set of C2 and C3 images, one point from each edge (all at the same polar angle) is selected. The distance of each point from Sun center is plotted against time to create a height-time profile. A bootstrap (described in Section  4.3) was performed for each edge calculation so that each point in the height-time profile has an associated error in height.

The resulting height-time profile is shown in Figure 4. The data plotted using + symbols are those obtained via the multiscale method. One-σ errors in height are also shown. For comparison, data from the CUA CDAW CME catalog are plotted in the figure using [formula] symbols. The points determined with the multiscale method are systematically lower in height than the points from the CUA CDAW points. This is because the CUA CDAW points are selected using difference images and, as can be seen in Figure 3(c), the true CME front (black edge) is inside of the edge in the difference images. This illustrates a drawback of using difference images to determine the CME front. The difference image height estimates from the CUA CDAW catalog are larger than the multiscale edge estimates by ≈  10%.

Figure 5 displays data from the 21 April 2002 data set. Figure 5(a) shows a TRACE difference image created by subtracting an image at 00:42:30 UT from an image at 00:43:10 UT. A very faint loop-like feature was only visible in the difference image after it was smoothed and scaled to an extremely narrow range of intensities. Both these operations were arbitrarily decided upon, and are therefore likely to lead to the object's true morphology being distorted. Figure 5(d) shows the same TRACE difference image as Figure 5(a) but overlaid with multiscale edges at scale j  =  8. The edge of the faint loop-like features is clearly visible as a result of decomposing the image using wavelets, and then searching for edges in the resulting scale maps using the gradient-based techniques described in the previous section. Figures 5(b) and 5(c) show LASCO C2 and C3 running difference images, respectively. Figures 5(e) and 5(f) show the LASCO difference images overlaid with the multiscale edges for scale j  =  8.

Figure 6 displays on the TRACE data for the 21 April 2002 data set. Figure 6(a) displays the processed difference image (same as Figure 5(a)) and Figure 6(b) is the difference image overlaid with multiscale edges at scale j = 8 (same as Figure 5(d)). The underlying TRACE image in Figure 6(c) is the original image from 00:46:34 UT. The multiscale edges at scale j = 8 were calculated for all 30 TRACE images from 00:46:34 UT to 01:05:19 UT. All 30 sets of edges were overlaid upon the original base image. Figure 6(d) contains the same set of edges but by using size and shape information, the expanding front is isolated. The leading edge, only partially visible in the original TRACE difference image in Figure 6(a), is now clearly visible and therefore more straightforward to characterize in terms of its morphology and kinematics. The multiscale edges reveal the existence of two separate moving features.

Using these edges, the expansion and motion of the CME from the sun is now clearly visible and therefore characterizing it in terms of its morphology and kinematics is more straightforward. The resulting height-time plot is show in Figure 7, together with data from , for comparison. We again find the heights determined manually are larger by ≈  10% using LASCO data and ≈  20% using TRACE data.

Following a procedure similar to that of Gallagher, Lawrence, and Dennis, the height-time curve was fitted assuming a double exponential acceleration profile of the form:

[formula]

where ar and ad are the initial accelerations and τr and τd give the e-folding times for the rise and decay phases. A best fit to the height-time curve was obtained with [formula] Mm, [formula] km s- 1, [formula] m s- 2, [formula] s, [formula] m s- 2, and [formula] s, and is shown in Figure 7.

Conclusions and Future Work

CMEs are diffuse, ill-defined features that propagate through the solar corona and inner heliosphere at large velocities (  ≥  100 km s- 1) [\cite=yashiro04], making their detection and characterization a difficult task. Multiscale methods offer a powerful technique by which CMEs can be automatically identified and characterized in terms of their shape, size, velocity, and acceleration.

Here, the entire leading edge of the 18 April 2000 and 21 April 2002 CMEs has been objectively identified and tracked using a combination of wavelet and gradient based techniques. We have shown that multiscale edge detection successfully locates the front edge for both well-defined events seen in LASCO as well as very faint structures seen in TRACE. Although height-time profiles were only calculated for one point, this method allows us to objectively calculate height-time profiles for the entire edge. This represents an advancement over previous point-and-click or difference-based methods, which only facilitate the CME apex to be tracked. Comparing height-time profiles determined using standard methods with the multiscale method shows that for these two CMEs the heights determined manually are larger by ≈  10% using LASCO data and ≈  20% using TRACE data.

Future work is needed to fully test the use of this technique in an automated system. Application of this edge detection method to a large, diverse set of events is necessary. An important improvement would be better edge selection. This will be accomplished by better incorporating scale information. By chaining the edges together as a function of scale we can distinguish false edges from true edges. This information can also be used to better distinguish better different-shaped edges. Another improvement can be made by using image enhancement. During the denoising stage, wavelet-based image enhancement (such as in ) can be performed at the same time that noise in the images is estimated and reduced. More sophisticated multiscale methods using transforms such as curvelets will be studied. In order to distinguish between edges such as those due to streamers from those due to a CME front angle information can be incorporated. This multiscale edge detection has been shown to have potential as a useful tool for studying the structure and dynamics of CMEs. With a few more improvements this method could prove to be an important part of an automated system.