Integrative genetic risk prediction using nonparametric empirical Bayes classification

Introduction

Genetic risk prediction for complex diseases is an important but difficult problem. Genome-wide association studies (GWAS) have successfully identified many SNPs associated with human disease, but it has been difficult to translate these successes into accurate risk prediction models [\citep=kraft2009genetic] [\citep=jostins2011genetic] [\citep=makowsky2011beyond]. The low accuracies can in part be attributed to the fact that much of the heritability of a complex disease is likely due to a large number of SNPs whose effect sizes are too weak to be discovered in any given GWAS [\citep=manolio2009finding] [\citep=chatterjee2013projecting] [\citep=dudbridge2013power].

To address this issue, recent research has focused on developing new prediction algorithms that aggregate information over a large number of SNPs, rather than using only those that reach genome-wide significance [\citep=chatterjee2016developing]. For example, polygenic risk scores can be constructed by taking weighted sums of all typed SNPs, or all SNPs that pass a loose significance threshold. The weights can be calculated based on univariate regression coefficients [\citep=purcell2009common] [\citep=chatterjee2013projecting] [\citep=shi2016winners], with or without accounting for linkage disequilibrium [\citep=vilhjalmsson2015modeling] [\citep=mak2016polygenic], or by using machine learning algorithms such as the lasso [\citep=wei2013large] [\citep=okser2014regularized]. The weights can also be treated as random draws from some prior distribution, and risk scores can be constructed using their posterior distributions [\citep=zhou2013polygenic] [\citep=golan2014effective] [\citep=speed2014multiblup].

These new methods are still fundamentally limited by the sample sizes of the GWAS data on which they are trained [\citep=wray2013pitfalls]. A straightforward way to increase sample size is to recruit additional study subjects, but this is time-consuming and costly. Instead, the training data can be augmented with data from previously existing studies of the disease of interest, for example by using meta-analytic methods [\citep=stahl2012bayesian] [\citep=cross2013genetic] [\citep=cross2013identification] [\citep=shi2016novel]. However, this is only feasible when developing risk prediction models for well-studied diseases. For other diseases, especially rare conditions, there may not be many existing GWAS studies, and the ones that do exist may be so small that integrating them may not be very useful.

This paper studies an alternative method of increasing effective sample size: borrowing information from auxiliary GWAS studies of diseases different from, but potentially related to, the target disease of interest. For example, recent studies of co-heritability have uncovered high degrees of genetic correlation between psychiatric disorders [\citep=lee2012estimating] [\citep=yang2013polygenic] and autoimmune diseases [\citep=li2015genetic] [\citep=li2015meta]. Genetic correlation between the target and auxiliary diseases implies that some of the SNPs that are predictive of one will simultaneously be predictive of the other. This dramatically enlarges the pool of existing studies which can be leveraged to improve the accuracy of predictions of the risk of the target disease. A major difficulty is that individual-level genotype data from these existing studies are often difficult to obtain due to privacy concerns, so prediction methods that can be trained using only GWAS summary statistics are preferable.

So far, it appears that there exist very few methods capable of this type of integrative genetic risk prediction. Given GWAS data for a target disease and auxiliary diseases, [\citet=li2014improving] and [\citet=maier2015joint] posit linear models for the effects of the SNPs, so that to each SNP there corresponds a vector of regression coefficients, one for each disease. They then assume a multivariate prior distribution on these coefficients; the degree of correlation between the coefficients quantifies the amount of information that can be borrowed across diseases. However, they require parametric assumptions on the prior distribution as well as selection or estimation of tuning parameters, e.g. those that govern the prior covariances between the coefficients, which can be computationally intensive and inaccurate. Furthermore, their methods require raw genotype data. There do not appear to exist any genetic risk prediction methods than can integrate only summary statistics from auxiliary GWAS.

This paper proposes a new approach to integrative genetic risk prediction of complex diseases with binary phenotypes. It does not require raw genotype data from either the disease of interest or the related diseases and can be trained using only summary statistics. It also uses a tuning parameter-free nonparametric empirical Bayes procedure to estimate prior distributions; this automatically learns the degree of genetic similarity between the target and auxiliary diseases. The proposed method is computationally straightforward and is implemented in the R package |ssa|.

The remainder of this paper is organized as follows. Section [\ref=sec:methods] describes the proposed method and Section [\ref=sec:results] studies its performance in simulations and in a study of pediatric autoimmune diseases conducted by Hakonarson and colleagues at the Children's Hospital of Philadelphia [\citep=li2015genetic] [\citep=li2015meta]. Section [\ref=sec:discussion] concludes with a discussion of possible extensions and future work.

Methods

Statistical formulation

Genetic risk prediction for binary disease phenotypes can be formulated as a classification problem. For a new subject whose disease status Ynew∈{0,1} is unobserved, let [formula] be the observed genotypes of d SNPs, where Xnew,j encodes the number of minor alleles of the jth SNP. The goal is to use [formula] to predict Ynew, where for example Ynew = 0 means that the subject does not have the disease.

Let [formula] denote the training data for the target disease, where [formula] is the vector of genotypes of the ith subject, n0 and n1 are the numbers of training subjects with Yi = 0 and Yi = 1, respectively, and n = n0 + n1. Also assume that summary statistics from an auxiliary GWAS study of another disease, potentially related to the one of interest, are available. Denote these statistics by [formula], where Tj is the test statistic for the marginal association between the jth SNP and the auxiliary disease. For clarity, it will be assumed that only a single auxiliary GWAS is used. It is conceptually straightforward to extend the proposed method to multiple auxiliary GWAS results; this is further discussed in Section [\ref=sec:discussion].

The integrative genetic risk prediction problem is to develop a classifier

[formula]

trained using both D and [formula], that minimizes the misclassification rate

[formula]

This differs from the standard non-integrative risk prediction problem, where the classifier δ is allowed to depend only on D and not on [formula].

Several assumptions are made throughout the remainder of this paper. First, the [formula] are assumed to be independent and identically distributed across all [formula]. Next, all SNPs in [formula] are assumed to be in linkage equilibrium. This can be approximately achieved by using linkage disequilibrium (LD) pruning. There is evidence that pruning can improve the accuracy of genetic risk prediction [\citep=shi2016winners], and even if pruning is not done, ignoring LD and treating SNPs as independent can still give accurate classification [\citep=bickel2004some] [\citep=hand2006classifier] [\citep=zhao2014menos]. A complete treatment of classification under LD is difficult and is left for future work.

Finally, all SNPs are assumed to be in Hardy-Weinberg equilibrium, so that for [formula],

[formula]

where πyj is the minor allele frequency of the jth SNP in class y. Typed SNPs that are not in Hardy-Weinberg equilibrium can be dropped from analysis. The auxiliary summary statistics Tj are assumed to arise from chi-square statistics from an existing GWAS study conducted on an independent sample of subjects, so the Tj are statistically independent of (Xnew,Ynew) and D and follow

[formula]

SNPs that are not associated with the auxiliary disease will have λj = 0. Many common association tests, such as the allelic test for association, give chi-square test statistics [\citep=evans2012power], but the approach proposed below can be easily modified if the Tj are otherwise distributed.

Review of non-integrative classification

It is well-known [\citep=devroye1996probabilistic] that the optimal classifier that minimizes the misclassification rate R(δ) [\eqref=eq:R] is given by

[formula]

Under the assumptions in Section [\ref=sec:formulation], (Xnew,Ynew) is independent of D and [formula], so the optimal classifier reduces to

[formula]

where [formula] is the prevalence of the target disease of interest and fBin(x;2,π) is the probability mass function of a Bin(2,π) random variable.

The form of [formula] [\eqref=eq:oracle] shows that optimal prediction of the target disease does not benefit from integration of the [formula]. This is one reason why standard methods for genetic risk prediction do not consider auxiliary sources of information. Of course, optimal prediction also does not benefit from the training data D either, because the optimal classifier uses the true minor allele frequencies πyj. It makes sense that if the true πyj were known, both training data and auxiliary GWAS summary statistics would be irrelevant for optimal prediction.

Clearly, the oracle [formula] cannot be implemented in practice, since the πyj are unknown. Instead, non-integrative classifiers use D is to calculate estimates of πyj, which are then plugged into [formula]. Using maximum likelihood estimates of πyj leads to the standard naive Bayes classifier. Since the total number of SNPs d is large, maximum likelihood estimation of the high-dimensional vectors [formula] for y∈{0,1} can be inaccurate. A popular alternative is to use some form of regularized estimation. A number of strategies for high-dimensional discriminant analysis have been developed in this vein, though mostly under the assumption that the Xij are normal rather than binomial random variables [\citep=fan2008high] [\citep=greenshtein2009application] [\citep=cai2012direct] [\citep=fan2012road] [\citep=mai2012direct] [\citep=fan2013optimal] [\citep=han2013coda] [\citep=dicker2016nonparametric].

Integrative classification via nonparametric empirical Bayes methods

It is not obvious how to property incorporate the auxiliary summary statistics Tj into an integrative classifier. The form of the optimal classifier [formula] [\eqref=eq:oracle] gives no indication as to how the Tj can be used, yet it is intuitively clear that the parameters λj underlying the Tj can contain information about the πyj and should be leveraged. The λj can be viewed as latent annotation information for each SNP. If the target disease is truly related to the auxiliary disease, a large value of λj provides additional evidence that the jth SNP may be useful for predicting Ynew, even if the effect size of that SNP in the target disease training data D is weak.

Properly leveraging the Tj to improve prediction of the target disease poses several methodological challenges. First, the λj are not directly observed. Second, how they should be used depends on the extend of the genetic similarity between the target and auxiliary diseases. For example, there may be some SNPs that are predictive only of the auxiliary disease but not of the target disease, or vice versa, so just because a SNP has a large λj in the auxiliary GWAS does not necessarily mean that it is useful for predicting the target disease. It is not clear how best to leverage the λj in this case. Finally, it may not always be known whether genetic correlations exist, for example if the diseases are poorly understood.

This paper proposes a new method that can address each of these challenges. The method is motivated by a Bayesian model for the (Xnew,Ynew), D, and [formula], which assumes that

[formula]

for some trivariate prior distribution G. Under this assumption, (Xnew,Ynew), D, and [formula] are no longer necessarily mutually independent, so that the misclassification rate R(δ) [\eqref=eq:R] would be minimized by the classifier

[formula]

where [formula] and fχ2(x;ν,λ) is the probability density function of a χ2ν(λ) distribution. To derive [\eqref=eq:int] it is also assumed that (π0j,π1j,λj) and [formula] are independent, which is reasonable because the parameter values can be thought of as being drawn from G before the cases and controls are drawn from the population of subjects.

The form of [\eqref=eq:int] is the key to the proposed approach. Unlike the optimal classifier [formula] [\eqref=eq:oracle], in which neither [formula] nor D appear, [\eqref=eq:int] provides a sensible way for integrating the Tj with the D. In fact, if the Bayesian assumption [\eqref=eq:G] is true, [\eqref=eq:int] is the optimal method of integrating Tj and D. Even under the present frequentist setting described in Section [\ref=sec:formulation], procedures motivated by Bayesian formalisms can still have excellent performance, for example in frequentist compound decision problems [\citep=robbins1951asymptotically] [\citep=robbins1956empirical] [\citep=zhang2003compound] [\citep=brown2009nonparametric] [\citep=jiang2009general] [\citep=gu2015problem].

The prior G implicitly encodes the additional information about (π0j,π1j) that can be borrowed from the latent annotations λj. In the extreme case when the target and auxiliary disease are not genetically correlated, G will factor into the product of a bivariate distribution on (π0j,π1j) and a univariate distribution on λj. The terms involving Tj will then cancel out in [\eqref=eq:int], resulting in a non-integrative classifier that depends only on the target training data D.

The integrals in [\eqref=eq:int] must be estimated, because the prior G is unknown. One possibility is to assume that G lies in a parametric family. However, G is a complex multivariate distribution and it is not clear what family can be used. An attractive alternative is the nonparametric maximum likelihood estimator of [\citet=kiefer1956consistency], which in the present context takes the form

[formula]

where G is the set of all trivariate distributions. The advantage of Ĝ is that it requires minimal assumptions, no tuning parameters, and is a consistent estimator of the true mixing distribution G [\citep=kiefer1956consistency]. More importantly, it uses the observed data to automatically lean the degree to which the target and auxiliary diseases are related.

The proposed classifier is obtained by replacing G in the Bayesian classifier [\eqref=eq:int] with the estimate Ĝ. This will be referred to as the nonparametric empirical Bayes classifier using latent annotations, or NEBULA. It is clear from [\eqref=eq:int] and [\eqref=eq:npmle] that NEBULA can be trained using only summary statistics Tj from the auxiliary GWAS and Syj from the target disease training data. This is a major advantage over existing integrative classifiers. NEBULA can also incorporate additional non-genetic predictors such as age or gender. Denote these by Znew,j, [formula] and let [formula] be the density of the jth predictor in class y∈{0,1}, where [formula] is a vector of parameters. Let yj be the maximum likelihood estimates of [formula] obtained from training data [formula]. NEBULA is thus defined as

[formula]

NEBULA is designed to directly predict the class Ynew of the newly observed genotype vector [formula]. The discriminant function, in other words the sum of the log terms in [\eqref=eq:int], can also be treated as a continuous score for the newly observed subject. This score can then be used to calculate area under the curve statistics or can be calibrated to provide a risk score [\citep=cook2007use].

Implementation

The Kiefer-Wolfowitz estimator Ĝ [\eqref=eq:npmle] is difficult to calculate. To mitigate the computational burden, [\citet=koenker2014convex] recently proposed a finite-dimensional approximation to Ĝ. For y∈{0,1} let Πy be a set of dy equally-spaced grid points [formula], where π̂yj = Syj / (2ny) is the maximum likelihood estimate of πyj. Similarly, let Λ be a set of d2 equally-spaced grid points [formula]. The Koenker-Mizera approximation is identical to [\eqref=eq:npmle] except that the optimization is not over the class of all trivariate distributions, but instead over all discrete trivariate distributions supported on Π0  ×  Π1  ×  Λ. The resulting estimator is the solution to a discrete convex optimization problem and can be conveniently computed [\citep=feng2016nonparametric].

Though the Koenker-Mizera estimator is an approximation to the true nonparametric maximum likelihood estimator Ĝ, it has been shown to work extremely well in many problem [\citep=koenker2014convexR] [\citep=koenker2014frailty] [\citep=koenker2014gaussian] [\citep=gu2015unobserved] [\citep=dicker2016nonparametric] [\citep=feng2016nonparametric] [\citep=jiang2016generalized]. Ideally the number of points d0, d1, and d2 used to construct the grids Π0, Π1, and Λ should be chosen to be as large as possible given constraints on computation time and memory, but in practice relatively few are needed for good performance. A theoretical characterization of a sufficient number of grid points is given by [\citet=dicker2016nonparametric].

Koenker-Mizera estimators for various problems are calculated using fast interior point methods in the R package |REBayes| [\citep=koenker2013rebayes] [\citep=koenker2014convexR]. However, for the trivariate problem [\eqref=eq:npmle] considered in this paper, |REBayes| does not contain a ready-made implementation. The expectation-maximization algorithm offers a simple alternative [\citep=feng2016nonparametric]. Specifically, let dGk(u0,u1,l) be the mass corresponding to the grid point (u0,u1,l)∈Π0  ×  Π1  ×  Λ at the kth iteration of the algorithm. Then the k + 1th update is

[formula]

This implementation has been made available in the R package |ssa|.

Results

Methods compared

In order to provide a performance baseline against which NEBULA [\eqref=eq:nebula] can be judged, the standard non-integrative polygenic risk score (PRS) classifier [\citep=purcell2009common] [\citep=shi2016novel] was implemented. Let P be the prevalence of the target disease in the population. In practice it is often known from previous epidemiological studies, or in cohort-sampling designs can be estimated from the training data. The PRS classifier is then defined as

[formula]

where

[formula]

is the maximum likelihood estimate of the log-odds ratio based on the training data D. The parameter λ is a threshold that serves to remove unimportant SNPs from the classifier. The PRS is nearly identical to the oracle classifier [formula] [\eqref=eq:oracle] after plugging in the maximum likelihood estimates of the πyj, except for the thresholding step. The optimal value of λ can be determined using cross-validation.

In addition to NEBULA, two alternative integrative genetic risk prediction algorithms were implemented for comparison. Let j denote the log-odds ratio of the jth SNP estimated from the auxiliary GWAS data. SNPs with larger Tj will also have j with larger magnitudes. There do not appear to exist any published methods that can be trained using only auxiliary GWAS summary statistics, so two new procedures were developed specifically for this comparison:

An adaptive version of the PRS: SNPs with |jj|  ≤  λ are dropped; the remaining ones are still weighted by j in the PRS. This allows SNPs with relatively weak |j| to still be included in the prediction algorithm as long as |j| is sufficiently large.

Adaptive lasso [\citep=zou2006adaptive]: logistic lasso regression [\citep=tibshirani1996regression] is implemented using the j as adaptive weights:

[formula]

where [formula] is the regression coefficient, [formula] is logistic log-likelihood of the training data D, and λ is a tuning parameter selected using cross-validation. This has the same effect as the adaptive PRS.

A potential problem with these alternative methods is that they implicitly assume that the SNPs that are significant in the auxiliary data and are the same as those that are predictive of the target disease. When this is indeed true, or approximately true, these methods should perform well, but heterogeneity in the genetic etiologies of the target and auxiliary diseases can lead to low prediction accuracy.

Simulation studies

To simulate genotype data for the target disease of interest, the total number of SNPs was d = 10,000 in all simulations. Some SNPs were set to be associated with the target disease; the number of these non-null SNPs was varied across simulation settings. The minor allele frequencies π0j in controls were randomly generated uniformly in

[formula]

Application to pediatric autoimmune disease

Hakonarson and colleagues at the Children's Hospital of Pennsylvania [\citep=li2015genetic] [\citep=li2015meta] collected genotype data for ten different pediatric autoimmune disorders from more than 5,000 cases and 10,000 shared age- and gender-matched controls of European ancestry; see Table [\ref=tab:paid]. The sizes of the case samples were relatively small, ranging from 100 to 2,000, so training genetic risk prediction models for those diseases is difficult. In this section, the proposed NEBULA classifier [\eqref=eq:nebula] and the alternative methods described in Section [\ref=sec:compared] are applied to this pediatric autoimmune data.

To apply the integrative classifiers, each of the ten autoimmune disorders was treated in turn as the target disease for genetic risk prediction, and each of the remaining nine disorders in turn was used as the auxiliary disease. Some pediatric autoimmune diseases have been found to be genetically correlated [\citep=li2015genetic] [\citep=li2015meta], so it is reasonable to integrate results from one disorder to help predict another. For each target disease, training data were comprised of 90% of the available target disease samples and the same number of subjects from the control data, all randomly selected. The other 10% of the target disease samples and an equal number of random control subjects were used as the testing data. The remaining control subjects were combined with the data for the auxiliary disease in order to calculate log-odds ratios j and summary statistics Tj. This sample splitting procedure was repeated 50 times and the misclassification errors of the different classifiers were averaged across the replications.

In addition to the autoimmune disorder data, additional auxiliary GWAS summary results were obtained from the Early Growth Genetics (EGG) Consortium; see Table [\ref=tab:egg]. The EGG Consortium conducts large GWAS meta-analyses of traits related to childhood growth in humans. It is reasonable to suspect that some of the loci that cause pediatric autoimmune disorders may also affect the early growth traits listed in Table [\ref=tab:egg]. Integrative classifiers were applied to leverage the large sample sizes in the EGG studies to potentially improve the accuracy of predicting autoimmune disease risks.

Subjects were genotyped using Illumina HumanHap550 and Human610 BeadChip arrays, and only variants on autosomal chromosomes typed on both platforms were used considered in this analysis. Similar to [\citet=shi2016novel], SNPs were pruned using the |-indep-pairwise| tool in the software PLINK [\citep=purcell2007plink] such that no SNPs within a 50 base pair window had r2 > 0.01. Pruning was performed using reference CEU genotype data from release 23 of the HapMap Project [\citep=gibbs2003international] and left 9,491 SNPs. In each of the datasets in Table [\ref=tab:paid], missing genotypes were then imputed by estimating the minor allele frequency of the corresponding SNP and then using the estimate to randomly generate genotypes assuming Hardy-Weinberg equilibrium. More sophisticated imputation strategies can also be employed. Before applying the classifiers, SNPs with minor allele frequencies below 1% and/or found not to be in Hardy-Weinberg equilibrium at a p-value threshold of 10- 3 were dropped from analysis.

Each classifier described in Section [\ref=sec:compared] was applied to all 140 possible target-auxiliary disease pairs. Gender was always included as a predictor. It was included in PRS, adaptive PRS, and NEBULA using the method described in [\eqref=eq:nebula] in Section [\ref=sec:neb], and it was not penalized in adaptive PRS or adaptive lasso. The Koenker-Mizera estimator [\eqref=eq:km] used in NEBULA was implemented using 40 equally-spaced points to construct the grids Πy,y∈{0,1} and Λ.

The average misclassification rates over the 50 replications are plotted in Figure [\ref=fig:paid]. They show that integrative classification can indeed be effective in improving prediction performance relative to the baseline PRS classifier. The most striking examples occur with Crohn's disease (CD) as the target and thyroiditis (THY) as the auxiliary, with THY as the target and CD the auxiliary, with Celiac's disease (CEL) as the target and type I diabetes (T1D) as the auxiliary. For these pairs all three integrative methods have substantially lower misclassification rates than non-integrative PRS.

Figure [\ref=fig:paid] also shows that the proposed NEBULA classifier can outperform the other two integrative procedures. For example, when predicting common variable immunodeficiency disorder (CVID) and psoriasis (PS), NEBULA had the lowest misclassification errors among all classifiers for all auxiliary diseases. Of particular interest are the results of using the EGG Consortium's childhood birth length (BL) GWAS summary statistics as auxiliary data to predict PS. Here, NEBULA outperformed adaptive PRS, and adaptive lasso and gave a nearly 10% improvement in prediction performance relative to non-integrative PRS.

In some other cases, NEBULA was cases outperformed by the other integrative classifiers, for example when predicting systematic lupus erythematosus (SLE). However, as mentioned in Sections [\ref=sec:compared] and [\ref=sec:sims], a disadvantage of adaptive PRS and adaptive lasso is that they can sometimes perform much worse than the baseline non-integrative PRS when the target and auxiliary diseases are highly genetically heterogeneous. This phenomenon was observed when predicting many of the disorders, such as THY, juvenile idiopathic arthritis (JIA), PS, and T1D. In contrast, NEBULA was never much worse than baseline in any of the analyses. In some cases, for example when predicting PS using SLE as the auxiliary disease, NEBULA could outperform the baseline while the other classifiers underperformed it.

Discussion

This paper has so far discussed the integration of auxiliary GWAS summary statistics Tj to improve genetic risk prediction, as the Tj provide latent annotation information for each SNP. However, in some cases important annotations are directly observed, for example if the SNP lies in a DNase I hypersensitive site. It is simple to extend NEBULA [\eqref=eq:nebula] to accommodate directly observed annotations. Let Ij∈{0,1} annotate the jth SNP. Then the prior assumption [\eqref=eq:G] on minor allele frequencies πyj,y∈{0,1} becomes (π0j,π1j)|Ij = 0  ~  G0 and (π0j,π1j)|Ij = 1  ~  G1. The Gy,y{0,1} can again be estimated nonparametrically using the Kiefer-Wolfowitz nonparametric maximum likelihood estimator [\eqref=eq:npmle], and a nonparametric empirical Bayes classifier similar to NEBULA can be derived. The advantage of this formulation is that it does not require perfect concordance between the SNPs predictive of the target disease and those with Ij = 1. Furthermore, it is also simple modify NEBULA to simultaneously integrate both Tj and Ij. These extended classifiers are implemented in the R package |ssa|.

In principle the NEBULA framework can be applied to multiple sources of auxiliary summary statistics Tkj, [formula]. This would necessitate a multivariate prior distribution on [formula], from which the corresponding Bayesian classifier can be derived. However, the nonparametric estimation of this multivariate prior will be both theoretically and computationally challenging. A possible solution is to develop convenient closed-form estimators, which may not be optimally adaptive to the unknown best prior but may still have good performance. This is an interesting direction of future research.

Even in the present case, nonparametric estimation of a trivariate prior distribution is computationally challenging. Faster strategies would make feasible genetic risk prediction using genome-wide SNP data without LD pruning. One approach would be to limit the support of the estimated prior. For example, the Koenker-Mizera estimator described in Section [\ref=sec:imp] supports the (π0j,π1j) on the grid Π0  ×  Π1. However, most SNPs frequencies are likely to be similar between cases and controls, such that π0j  ≈  π1j for most j. Thus most grid points in Π0  ×  Π1 should have zero mass. Enforcing this can reduce the number of grid points and speed up estimation of the prior G. Further work in this direction is necessary.

Acknowledgments

The author thanks Drs. Hakon Hakonarson, Yun Li, and Julie Kobie for providing the pediatric autoimmune disease data, and Dr. Lee Dicker for helpful discussion. Data on the birth length, birth weight, childhood obesity, and childhood BMI traits have been contributed by EGG Consortium and have been downloaded from |www.egg-consortium.org|. The research of Dave Zhao was supported in part by NSF grant DMS-1613005 and by a grant from the Simons Foundation (#SFLife 291812).