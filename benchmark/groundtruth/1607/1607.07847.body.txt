Technical Report: Giving Hints for Logic Programming Examples without Revealing Solutions

This is a slightly extended English version of [\cite=Avci2016siu] (original in Turkish). This work has been supported by Scientific and Technological Research Council of Turkey (TUBITAK) Grant 114E777.

Introduction

Answer Set Programming (ASP) [\cite=Gelfond1988] [\cite=Lifschitz2008] [\cite=Gebser2012aspbook] is a declarative logic programming and knowledge representation paradigm. Learning how to use ASP is challenging, because logic programming is very different from imperative programming (Java, C, C++) and also different from Prolog (in particular the order of rules has no influence on the evaluation algorithm).

We here consider teaching ASP by giving small real-world knowledge representation examples and partial programs to students, and ask them to complete the program. To supporting the student, examples can often be visualized and it is even possible to connect visualization and knowledge representation such that clicking the visualization can show the parts of the program that define the visualized object [\cite=Kloimullner2013]. Creating such visualization is a work-intensive task, and creating simple examples for teaching ASP is also work-intensive.

To support the student in finding the correct answer, in this work we describe a system for giving hints based on the example program, the user input, and a reference program, such that the hints do not reveal the true answer.

Consider the following example specification.

[formula]

[formula]

The expected answer to this example is as follows.

[formula]

However we might get several different kinds of answers from students, for example the following.

[formula]

Some of these answers are simply typos or missing syntactical elements such as [\eqref=syntax_err_1] and [\eqref=syntax_err_2]. Other mistakes can be processed by ASP solvers but do not yield the correct output such as [\eqref=preprocessing_err_1]-[\eqref=semantic_err_1].

In this work we propose a framework that produces a hint about the mistake from the student answer and the reference program. The hint does not reveal the correct solution.

This has the benefit, that fewer examples are sufficient for teaching ASP and fewer effort in visualization is required. Moreover student motivation is not diminished by giving away the solution.

We categorize mistakes into syntactic mistakes such as [\eqref=syntax_err_1] and [\eqref=syntax_err_2], unexpected but syntactically correct input such as [\eqref=preprocessing_err_1]-[\eqref=preprocessing_err_3], and semantic mistakes such as [\eqref=semantic_err_1]. We clearly define criteria for recognizing each class of these mistakes, and describe mathematically how to compute information necessary to give a helpful hint, including example hints for the case above.

We give preliminaries in Section [\ref=secPrelims], describe the architecture of our hint giving framework in Section [\ref=secFramework], give details about mathematical classification of mistakes and corresponding hints in Section [\ref=secLayers], briefly mention related work in Section [\ref=secRelated] and conclude in Section [\ref=secConclusion].

Preliminaries

Answer Set Programming (ASP) is a declarative logic programming paradigm [\cite=Gelfond1988] [\cite=Lifschitz2008] [\cite=Gebser2012aspbook]. An atom is form [formula] with [formula], and if [formula] we write the atom short as p. A program P consists of a set of rules, a rule r is of the form

[formula]

where αi and βi are atoms, called head and body atoms of r, respectively. We say that [formula] is the head of r, and [formula], respectively [formula] are the positive, respectively negative body of r. We call a rule a fact if [formula], disjunctive if [formula], and a constraint if [formula]. Atoms can contain constants, variables, and function terms, and a program must allow for a finite instantiation. Semantics of an ASP program P is defined based on the ground instantiation [formula] and Herbrand base [formula] of P: an interpretation [formula] satisfies a rule r iff [formula] or [formula] or [formula]; I is a model of P if it satisfies all rules in P. The reduct PI of P wrt. I is the set of rules [formula] and an interpretation I is an answer set iff it is a ⊆  -minimal model of PI. Details of syntactic restrictions, additional syntactic elements, and semantics of ASP are described in the ASP-Core-2 standard [\cite=Calimeri2012].

Hint Giving Framework

While writing programs students are making different kind of mistakes. Our methodology for giving hints is shown in Figure [\ref=figFlowchart]. The input consists of the student's answer program PU and the reference solution PR, where we assume that all parts of the example are combined into a single program. Analyzing the input and giving hints is based on three phases which address different kinds of mistakes.

In the first phase, we consider syntactical errors. If program is syntax-error free, we check if the student used the vocabulary we expected. In the third phase we evaluate the program, compare it with an evaluation of the reference program, and check if the output of both programs is the same.

In each step, we potentially find a mistake, produce a hint for the student, and abort processing at that step.

We abort processing at the first phase where we find an error, because each phase requires the previous one to complete. For example, is impossible to perform analysis of rules if the rules cannot be parsed, i.e., are syntactically incorrect.

Classification of Mistakes and Corresponding Hints

We next give details about each of the three phases.

Syntactical Check

In this phase we are checking for syntax errors in the input program. A standard ASP parser will detect syntax errors and according to the error we will give a hint. For example the ASP grounder gives the following error when parsing [\ref=syntax_err_1].

[formula]

This indicates the location of the mistake in the source code (line 3, characters 8  -  9) and allows us to display the error with additional visual support to the student, for example as the following hint.

[formula]

If student's answer passes these two checks, third step is semantical check. In this phase we already have program which is free of syntax errors and passes preprocessing check. This time we will analyse user's answer set and compare it with answer set that is correct (e.g. key answer set) and give feedback according to this.

Vocabulary Check

In this phase we parse the student's input program and check if the expected predicates with expected arities and the expected constants are used. We formalize this mathematically.

Given a set of atoms [formula] we define function [formula] which returns the set of predicates in A, the function [formula] which returns a set of tuples of predicates with their arity as occuring in A, and the function [formula] which returns the constants used in A.

[formula]

For example given the set of atoms

[formula]

We next define functions for obtaining information about predicates and their arities in heads and bodies of rules and programs.

[formula]

where P is a program -- a set of rules of form [\eqref=eqRule].

For example given rule [\eqref=preprocessing_err_1] we would have

[formula]

Given a reference solution PR and student input PU we can use the above definitions to give hints without revewaling PR.

We next use these definitions to compute what is unexpected in a student's program compared with the expected solution.

Usage of additional predicates.   We can detect if the student uses additional predicates that are not in the reference implementation by computing

[formula]

For example if [formula] and [formula] then we obtain [formula]. This allows us to easily produce the following hint.

Note that the hint does not reveal the sample solution.

Usage of predicates with wrong arity.   We can detect if the student uses a predicate with the wrong arity by computing

[formula]

For example with [formula] we obtain [formula] and we can give the following hint accordingly.

Note that if the student is unable to correct the problem after this hint, the next hint can reveal that the arity of [formula] in the sample solution is 2, without revealing the full solution.

Usage of unexpected constants.   We can detect if the student uses unexpected constants by computing

[formula]

For example with [formula] we obtain [formula] and we can give the following hint accordingly.

Note that this also shows if the student has accidentally used constants instead of variables as in [\eqref=preprocessing_err_3].

Further Hints.   Using [formula], [formula], [formula], and [formula], further hints that are more specific, can be produced, for example that a certain predicate should be used in the body of a rule in the solution.

All hints produced by this method are not revealing the solution, they are just helping students to find out their mistakes based on the vocabulary used in the program. Students should find out what to do in order to fix this mistake. When all sets are checked we can say that user's program is correct with respect to the expected vocabulary (which includes arities of predicates).

Semantical Check

The final phase is semantic verification: we evaluate the student's program and the reference solution using an ASP solver and verify if the results are the same.

If an answer set of student program includes extra or missing entities, the student program fails the check in this phase.

For example the answer [\ref=semantic_err_1] works correctly only for obstacles between Düzce and Bolu, but not between Düzce and Zonguldak. Given PR as above and [formula] we obtain one answer set [formula] and one answer set [formula] such that [formula] because the student's solution reproduces all atoms that are true in the reference solution, moreover [formula] because the student's solution additionally produces true atoms that should not be true.

The student program shows these blocked roads as open which is the mistake. By computing the difference between answer sets we can give different levels of hints to the student, for example the following generic hint.

If the student is not able to fix the problem, we can also mention the predicate.

If even this does not help, we can concretely say which true atom should not be true.

Again, these hints do not give solutions, they guide the user to finding the problematic part of the solution.

Related Work

To the best of our knowledge there is no related work focused on tools for teaching Answer Set Programming. Programming Assignment Feedback System (PABS) automatically generates feedback for programming assignments in imperative languages based on impothe Java Virtual Machine, however their feedback is based on plagiarism and failed unit tests while our work gives detailed feedback within single unit tests with additional constraint that we do not reveal the solution [\cite=Ifflander2015].

A systematic approach on teaching Prolog based on a student model that takes into account experience from earlier courses on imperative programming is presented in [\cite=Stamatis2007]. Misconceptions are separated in categories and different examples are given for each category to facilitate in-depth understanding. We use a similar approach to group mistakes and prepare hints, however our work is on ASP which is more declarative than Prolog. A didactic teaching and learning model for programming is presented in [\cite=Kaasboll1998]. Our work can be seen as a teaching model for ASP.

Several approaches for debugging answer set programs exist, and these approaches could be integrated into a teaching methodology. Early work on this topic was limited to ground programs and to explaining why an atom is present/absend in an answer set [\cite=Brain2005] using a procedural algorithm, and later a more general explanation was achieved in ground programs using declarative methods similar to diagnosis [\cite=Syrjanen2006]. Pointing out reasons for a nonground ASP program to not have a certain answer set (unsatisfied rules, violated constraints, unsupported atoms, and unfounded loops) was developed in [\cite=Gebser2008], refined in [\cite=Oetsch2010], and later extended to choice rules, cardinality, and weight constraints [\cite=Polleres2013]. These debugging methods can be used to realize a richer semantic check in our framework.

Conclusion

We have introduced a method for automatically giving hints about Answer Set Programming exercises, with the important property that the hints do not reveal solutions, but guide the student in finding the solution.

Today methods from computer science are used in many different areas and therefore it is an increasingly popular field of study. Consequently, more students are trained in basic methods of computer science and programming. These students need to solve practical programming assignments as part of their education. Feedback can help students to stay motivated and assess their progress, but giving manual feedback is a very time consuming task. Especially in large courses with beginners it is not practical due to staff limitations. As a result it is desirable to automatically generate feedback whenever possible, so that students can solve the easy problems with the help of the computer and only require human assistance for more difficult problems.

Regarding future work, our syntactic check (Section [\ref=secSyntactic]) is based on existing ASP parsers, and we augment the error message with helpful information. An interesting future work would be to create a parser that can suggest corrections or produces more detailed analyses of the parser mistake.