Multi-Objective Optimal Control with Arbitrary Additive and Multiplicative Noise

Notation

Introduction

Background

In this paper, we consider the problem of optimal control of a dynamical system with additive and multiplicative noises of arbitrary distributions. More precisely, the optimal state-feedback control problem of discrete-time dynamical system with additive and multiplicative noises is given by

[formula]

where wk and σk(i) are independent white noises with unit variance and arbitrary probability distribution functions. This is important since we would obtain a control problem whose solutions accounts for nonlinear uncertainty, which is modeled in the distribution of the stochastic noise.

The problem given by ([\ref=introproblem]) is no longer a linear quadratic control problem and the state is no longer Gaussian, not even if we assume that the noises are Gaussian. This nonlinear model is very important in many applications. For instance, multiplicative uncertainty appears on modeling link failures in networked control system ([\cite=patterson2010convergence]). Also, this models uncertainty in the state space parameters of a linear dynamical system.

Optimal control of uncertain systems is one of the corner stones of control theory. There is a vast amount of research considering optimal control of linear dynamical systems with a quadratic objective, where the uncertainty is often modeled as additive noise with a Gaussian distribution. It's well known that the optimal state feedback control problem has linear strategies μk as the optimal solution. This yields a very nice structure on the optimization problem where an optimal linear controller can be obtained by solving an optimization problem with polynomial time computational complexity. However, important variations of the linear quadratic optimal control problem are still not well understood. For instance, it's not clear whether linear controllers are optimal for the output feedback case under non Gaussian process noise assumptions and sub-optimality of linear controllers has become a folklore. Another variation of the linear quadratic control problem above is the problem given by ([\ref=introproblem]). Although very similar to the linear quadratic control problem, the problem is nonlinear and the state is no longer Gaussian even if we assume Gaussian noises in the system. Therefore, linear controllers are not necessarily optimal.

This paper will address the following questions for the above optimal state-feedback control problem:

For both a finite horizon N and an infinite time-horizon, are linear controllers optimal over the class of linear and nonlinear controllers? What is the optimal controller for arbitrary distributions of the noise variables?

What are the necessary and sufficient conditions for the optimal control problem to have a bounded solution as N  →    ∞   and that can be checked in polynomial time?

What is the optimal controller if we add the (not necessarily convex) quadratic constraints

[formula]

for both finite and infinite time horizon N?

Stability of linear systems with additive noise is well studied. For a discrete-time system given by

[formula]

a necessary and sufficient condition for stabilizability is given by the Lyapunov matrix equation. The system above is stabelizable if and only if there exists a positive definite matrix X such that

[formula]

We are interested in finding a "Lyapunov-like" stabilizability criterion to answer our second question.

The last question is important since we may have practical energy constraints on the controller of the form

[formula]

Another constraint could be the requirement of the energy of the controller to be proportional to the energy of the state:

[formula]

[formula]

[formula]

None of the quadratic forms of the constraints above form is positive definite. This justifies the generality of the weights Qj to extend to the indefinite case, implying non convex optimal control problems.

Previous Work

Linear optimal state-feedback control for scalar discrete-time systems with multiplicative noise was considered in [\cite=athans:1977] where the so called uncertainty threshold principle was introduced under Gaussian noise assumptions. It was shown that if the variance of the multiplicative noise exceeded a certain value, then stability (in the mean square sense) was not possible as the time horizon tends to infinity. Further study for a special case of multivariate systems was considered in [\cite=ku:1977]. The stabilization problem for discrete time systems with Gaussian noise was approached using linear matrix inequalities in [\cite=li:2005] where the class of linear controllers was considered. In [\cite=primbs:2009], the problem of finite horizon linear optimal control of discrete-time systems with multiplicative noise and convex quadratic constraints was approached using receding horizon control.

For continuous time stochastic systems where the noise is a standard Wiener process, stabilizability conditions in terms of linear matrix inequalities where considered in [\cite=boyd:elghaoui:1994] and optimal control with respect to various norms was considered in [\cite=elghaoui:1995] by optimizing over linear controllers using linear matrix inequalities.

Linear optimal state-feedback control of linear systems with possibly indefinite quadratic constraints over an infinite time horizon was considered in [\cite=yakubovich:1992] and its generalization to output-feedback control in [\cite=gattami:tac:10], for both finite and infinite horizons, using a covariance formulation of the optimal control problem. It was also shown in [\cite=gattami:tac:10] that linear controllers are optimal over the class of linear and nonlinear controllers.

Contributions

In this paper we answer the questions we posed in the Background section. In particular, we show that affine controllers are optimal and can be obtained by solving a semidefinite program. The solution depends solely on the the second moments of the noises affecting the system, and thus, independent of the probability distributions of the noises. This shows that the Gaussian noise assumption used, even in classical linear quadratic control theory, is unnecessary.

We also show that linear controllers are optimal if the quadratic constraints

[formula]

are convex in the control signal uk(note that the quadratic constraints maybe convex in uk without being convex in both xk and uk). The controllers are static, that is, they only depend on the current value of the state and are independent of the previously observed states. Furthermore, we show that the system is stabilizable in the mean square sense if and only if there exists a positive definite matrix [formula] such that

[formula]

where [formula] and n is the state dimension. More specifically, V is the stationary covariance matrix of the vector consisting of the state and the controller,

[formula]

Optimal State Feedback

Consider a dynamical system given by

[formula]

where {wk} and {σk(i)} are independent zero-mean white noises with arbitrary probability distributions. Without loss of generality, we will assume that [formula] and [formula] for all i and k. If [formula], then we may replace Ai with Āi  =  sk(i)  ·  Ai and again solve for the case [formula]. We want to find the optimal causal state feedback controller

[formula]

that minimizes the average variance for the sequence {zk}:

[formula]

Thus, we want to solve the optimization problem

[formula]

where [formula] and [formula].

For simplicity, we will assume that the following matrix is positive definite:

[formula]

Introduce the positive semidefinite matrix

The system dynamics and the correlation assumptions in ([\ref=lqproblem]) implicate the following recursive equation for the covariance matrices {Vk}:

[formula]

where we used that [formula], [formula], σk  =  (σk(1),...,σk(M)), [formula], [formula], [formula].

The optimal value of the optimization problem ([\ref=lqproblem]) is equal to the optimal value of the following semidefinite program:

[formula]

where [formula].

The constraints in ([\ref=lqproblem]) give rise to the equality constraint ([\ref=Xk]). For the left hand side of Equation ([\ref=Xk]), we have that

[formula]

which gives the equality constraint in ([\ref=rec]). Also, we have that Hence,

Thus, the objective to be minimized is given by

[formula]

and we are done.

Before proceeding to the next result, we need the following proposition.

Consider the dynamical systems given by

[formula]

[formula]

[formula]

Let vk be uncorrelated with wl and ul for all k and l. Also, let

[formula]

and

[formula]

for k = 0,...,N. Then, xk  =  x'k  +  x''k and

[formula]

The relation xk  =  x'k  +  x''k is easy to verify by summing up the right and left hand sides of the systems equations above for x'k and x''k . Now since vk is uncorrelated with wl and ul for all k and l, we have that [formula], [formula], and

[formula]

The above proposition clearly shows that the controller doesn't benefit from adding additional noise, uk  ↦  uk  +  vk, if the objective to be minimized is increasing in the covariance of the state and controller.

The next result shows how to obtain the optimal controller from the optimal covariance matrices.

Let

[formula]

be a solution to

[formula]

with [formula]. Then, an optimal solution to the optimization problem ([\ref=lqproblem]) is given by

[formula]

Since [formula] is positive semidefinite, the Schur complement of [formula] in [formula] is also positive semidefinite:

[formula]

Consider the controller

[formula]

where

[formula]

and vk is independent of σl(i), xl, and wl, for all i, k, and l. It's easy to verify that the controller gives the covariance sequence [formula], and thus achieves the minimal solution of ([\ref=lqproblem]) according to Theorem [\ref=stat]:

[formula]

But vk is just additional noise and by removing it from the controller we will not increase the objetive value according to Proposition [\ref=v]. Thus, an optimal controller is given by

[formula]

and the proof is complete.

The optimal value of the optimization problem ([\ref=lqproblem]) as N  →    ∞   is equal to the value of the optimization problem

[formula]

with [formula]. Furthermore, if

[formula]

is an optimal solution to ([\ref=optcon]), then [formula] and an optimal solution to the optimization problem ([\ref=lqproblem]) is given by

[formula]

as N  →    ∞  .

Theorem [\ref=stat] and the assumption that

[formula]

implies that the solution of the optimization problem ([\ref=lqproblem]) is bounded if and only if

[formula]

is bounded according to Thus, the value of ([\ref=optcon]) is finite if and only if the value of the optimization problem ([\ref=lqproblem]) is finite. The left hand side of Equation ([\ref=rec]) has the asymptotic average FVFT. The right hand side of Equation ([\ref=rec]) has the asymptotic average

[formula]

and we get the equality constraint in ([\ref=optcon]). Also, the objective to be minimized is given by

[formula]

According to Theorem [\ref=finitehorizon], an optimal sequence [formula] is obtained for the controller [formula]. Thus,

[formula]

as N  →    ∞  , which implies that

[formula]

as N  →    ∞  . This completes the proof.

As a corollary, we get a Lyapunov-like necessary and sufficient condition for mean square stabilizability of the stochastic system.

The system

[formula]

is stabilizable if and only if there exists a matrix [formula] such that

[formula]

where [formula].

Optimal State Feedback Control with Arbitrary Quadratic Constraints

In this section, we consider a linear quadratic problem given by ([\ref=lqproblem]), with additional constraints of the form

[formula]

We do not make any other assumptions about Qj except that it is symmetric, [formula].

Thus, the constrained optimal control problem we are considering in this section is given by

[formula]

The optimal control problem ([\ref=constrainedlqproblem]) is equivalent to the following semidefinite program:

[formula]

where [formula].

Note first that

[formula]

is a scalar, so

[formula]

Thus,

[formula]

Hence, we may write the quadratic constraints as the linear constraint

[formula]

for k = 0,...,N - 1, j = 1,...,J. The rest of the proof follows the same lines as Theorem [\ref=stat].

Note that the covariance constraints

[formula]

are linear in the elements of the covariance matrices {Vk}, and hence convex. This shows that the covariance formulation turns the original non convex optimal control problem into a convex one.

Let

[formula]

be a solution to

[formula]

with [formula]. Then, an optimal solution to the optimization problem ([\ref=constrainedlqproblem]) is given by

[formula]

with

[formula]

and

[formula]

Since [formula] is positive semidefinite, the Schur complement of [formula] in [formula] is nonnegative

[formula]

Consider the controller

[formula]

where

[formula]

and vk is independent of σl(i) and wl, for all i, k, and l. It's easy to verify that the controller gives the covariance sequence [formula], and thus achieves the minimal solution of ([\ref=constrainedlqproblem]) according to Theorem [\ref=constraints]. This completes the proof.

Note that the structure of the solution to the multi-objective optimal control problem ([\ref=constrainedfinitehorizon]) is a little bit different from that of the one with no constraints ([\ref=finitehorizon]) because of the additional term vk. One interpretation to this structure is that if we had the non convex constraint [formula], then the controller uk adds an offset vk in order to be above a certain energy level, although it does neither contribute to stabilization nor optimization of a convex quadratic objective.

Now suppose that all the quadratic constraints

[formula]

are convex in uk (note that they don't need to be convex in xk), then an optimal controller would still be such that vk = 0. To see this, let

[formula]

with [formula] in order for the quadratic form to be convex in uk. Then,

[formula]

Now consider the controller uk  =  RTkX- 1kxk  +  vk which has the covariance

[formula]

where vk is uncorrelated with xk and [formula]. Removing vk implies that the covariance of uk is given by

[formula]

which decreases the value of [formula] with the amount

[formula]

and the inequality [formula] would still hold.

Finally, we state the result for the infinite horizon case.

The optimal value of the optimization problem ([\ref=lqproblem]) as N  →    ∞   is equal to the value of the optimization problem

[formula]

with [formula]. Furthermore, if

[formula]

is an optimal solution to ([\ref=optcon]), then [formula] and an optimal solution to the optimization problem ([\ref=lqproblem]) is given by

[formula]

[formula]

as N  →    ∞  .

The proof follows from Theorem [\ref=constrainedfinitehorizon] using similar arguments as in Theorem [\ref=stat2], and therefore omitted here.

Numerical Example

Consider the state feedback problem

[formula]

with

[formula]

Solving the semidefinite program ([\ref=optcon2]) gives the solution

[formula]

Theorem [\ref=constraints3] gives that the optimal controller is given by

[formula]

with

[formula]

One may verify that

[formula]

which gives that vk = 0 and the optimal controller is given by

[formula]

The optimal value of the cost is 42.9116. If we remove the last quadratic constraint with respect to Q, we get the optimal cost 23.9361, which is smaller than in the constrained case as expected.

Conclusions

We have considered the problem of multi-objective optimization of a system with multiplicative and additive noises, with arbitrary probability distributions. We showed that the problem can be converted to a semidefinite program where the optimization variable has the interpretation as the covariance matrix V of the vector (xTk, ~ uTk)T.

We showed that affine controllers are optimal and depend on the optimal solution of the covariance matrix V. Furthermore, the optimal controllers are linear if all the quadratic forms in the constraints are convex in the controller.

We also showed that a necessary and sufficient condition for stabilizability is given by the solvability of a Lyapunov-like equation in the covariance matrix V.

In this paper, we assumed that the additive noise wk is independent of the multiplicative noise σk(i), for i  =  1,...,M. Also, we have assumed that the matrix B is deterministic. However these assumptions may be removed. We could impose correlation between w and σ(i) and also replace B with

[formula]

The proofs would follow readily, though giving more complicated expressions that wouldn't shed more light on the main ideas of the paper.

Acknowledgements

The author would like to thank Prof. Bassam Bamieh for suggesting the problem.