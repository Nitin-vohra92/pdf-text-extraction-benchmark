Real-Time Hand Shape Classification

Introduction

Hand gestures constitute an important source of non-verbal communication, either complementary to the speech, or the primary one for people with disabilities. The problem of hand gesture recognition has been given a considerable research attention due to a wide range of its practical applications, including human-computer interfaces [\cite=Haq2011] [\cite=CzuprynaELMAR2012], virtual reality [\cite=Shen2011], telemedicine [\cite=Tiwari2006], videoconferencing [\cite=MacLean2001], and more [\cite=GrzejszczakCORES2013] [\cite=NalepaICMMI2014]. The proposed approaches can be divided into hardware- and vision- based methods. The former utilize sensors, markers and other equipment to deliver an accurate gesture recognition, but they lack naturalness and are of a high cost. Vision-based methods are contact-free, but require designing advanced image analysis algorithms for robust classification. Thus, an additional effort is needed for applying these techniques in real-time applications.

Numerous algorithms for hand shape classification have emerged over the years. In the contour-based approaches, the shape boundary of a detected hand is considered to represent its geometric features. These methods include, among others, a very time-consuming approach based on the shape contexts analysis and estimating similarity between shapes [\cite=Belongie2002], recently optimized by reducing the search space by using the mean distances and standard deviations of shape contexts [\cite=Lin2011], and Hausdorff distance-based methods [\cite=Huttenlocher1993]. The main drawback of these contour-based approaches lies in their limited use in case of missing contour information.

In the appearance-based methods, not only is the contour utilized for shape features extraction, but also the shape's internal region is analyzed. For example, an input color or greyscale image is processed in the orientation histograms approach [\cite=Freeman213] or an entire hand mask can be fed as an input to various template matching and moment-based methods [\cite=Thippur2013]. An interesting and thorough survey on vision-based hand pose estimation methods was published by Erol et al. [\cite=Erol2007].

In this paper we discuss a fast parallel algorithm for hand shape classification. We show how the parallelization affects the classification time, and makes it possible to apply for searching large hand gesture sets in reasonable time. We present the speedup and efficiency of the parallel algorithm for various numbers of threads. Moreover, we show that combining the shape contexts with the appearance-based methods results in increasing the final classification score.

The paper is organized as follows. The hand shape classification algorithm is described in detail in Section [\ref=sec:parallel_algorithm]. The experimental study is reported in Section [\ref=sec:experimental_study] along with the description of the database of hand gestures. The paper is concluded and the directions of our future works are highlighted in Section [\ref=sec:conclusions].

Parallel Hand Shape Classification Algorithm

In this section we describe our parallel algorithm (PA) for hand shape classification [\cite=NalepaISM2013]. First, the input image Ii is subject to skin segmentation, only if necessary (Alg. [\ref=alg:parallelClassification], lines [\ref=alg:verify_if_skin_analyzed]-[\ref=alg:end_skin_detection]). This step is undertaken if the shape features are to be extracted from the skin map of Ii. There exist a number of robust skin detection and segmentation techniques [\cite=Jones2002] [\cite=Kawulok2010MTaA] [\cite=Kawulok2013ICIP] [\cite=Kawulok2013FG] [\cite=Kawulok2013]. A thorough survey on current state-of-the-art skin detection approaches has been published recently [\cite=Kawulok2013Springer]. Then, the image, either the skin mask or the original one, is normalized (line [\ref=alg:normalize_image]). The normalization procedure is presented in Fig. [\ref=fig:ex_skin_map_normal]. An input image (A) or the skin map (B) is rotated (C) based on the position of wrist points, so as the hand is oriented upwards. Pixels below the wrist line are discarded, the image is cropped and downscaled to the width wM (D).

Once the image is normalized, hand shape features are calculated in parallel (Alg. [\ref=alg:parallelClassification], lines [\ref=alg:start_calculating_features]-[\ref=alg:end_calculating_features]), and the input image Ii is compared with the gallery images, also in parallel (lines [\ref=alg:start_classification]-[\ref=alg:end_classification]). Finally, the classification result is returned (line [\ref=alg:return_final_classification]). Noteworthy, the classification procedure can be executed for a number of input images in parallel. Thus, larger databases of input hand images can be analyzed significantly faster than using a sequential approach.

In the shape features calculation and shape classification stages we utilized the following state-of-the-art methods: (1) shape contexts analysis (SC) [\cite=Belongie2002], (2) template matching (TM), (3) Hausdorff distance analysis (HD) [\cite=Huttenlocher1993], (4) comparison of the orientation histograms (HoG) [\cite=Freeman213], (5) Hu moments analysis (HM) [\cite=Hu1962], and two approaches combining the SC with the appearance-based methods: SC combined with the distance transform (SCDT) and SC enhanced by the orientation histograms analysis (SCH). In the TM algorithm we used the following summation for comparing the overlapped patches of images I1 and I2, of size w1  ×  h1 and w2  ×  h2, respectively:

[formula]

where 0  ≤  a  ≤  w2 - 1 and 0  ≤  b  ≤  h2  -  1.

Let κ and λ be two contours compared in the SC method. For each point pκi and pλi, [formula], where m is the number of contour points, belonging to κ and λ respectively, the coarse log-polar histogram hi, i.e., the shape context, is calculated. It depicts the distribution of the remaining (m - 1) points for each pi. Let Cij denote the cost of matching the points pκi and pλj, given as a chi-square distance between the corresponding shape contexts. Then, the total matching cost of two contours C is given as [formula], where π is a permutation of the contour points. Clearly, the minimization of C is an instance of the bipartite matching problem. It can be solved in O(n3) time, where n is the number of sampled contour points, using the Hungarian method [\cite=Lin2011]. To speed up the SC, we sample and analyze a subset of MSC, MSC  ≪  m, contour points of a shape. Additionally, the distance transform (DT) of the hand mask from the contour is performed. Given the DT, its histogram Hi is calculated for the image Ii. Then, the distance between the histograms H1 and H2 of two images I1 and I2 is found using the chi-square metric:

[formula]

The final cost of shapes matching of the SCDT is given as: C' = αC + βd(H1,H2), where α and β are the weights. Values of C and d(H1,H2) are normalized, therefore 0.0  ≤  C  ≤  1.0 and 0.0  ≤  d(H1,H2)  ≤  1.0. Similarly, the shape contexts are combined with the orientation histograms approach [\cite=Freeman213] using the same values of weights α and β.

Experimental Results

The PA was implemented in C++ language using the OpenMP interface. The experiments were conducted on a computer equipped with an Intel Xeon 3.2 GHz (16 GB RAM with 6 physical cores and 12 threads) processor having the following cache hierarchy: 6 ×   32 kB of L1 instruction and data cache, 6 ×   256 kB L2 cache and 12 MB of L3 cache. The settings used in both stages of the PA were tuned experimentally to the following values: α = 0.17, β = 1.0, wM = 100, MSC = 20.

Database of Hand Gestures

The experimental study was carried out using our database of 499 color hand images of 15 gestures presented by 12 individuals. Each gesture was presented n times, 27  ≤  n  ≤  39. The images are associated with ground-truth binary masks indicating skin regions along with the ground-truth hand feature points. In this study, we omitted the skin segmentation and wrist localization stages, and used the ground-truth data for fair assessment of investigated techniques applied at other algorithm steps. Examples of ground-truth binary masks are presented in Fig. [\ref=jnalepa:fig:hand_examples]. Here, each gesture (1, 2, 3, 4, H, K, N, S) was presented by five individuals (I-V). It is easy to note that the difference between masks representing the same gesture (i.e. inner-class difference) may be significant, e.g. due to the hand rotation - see e.g., Fig. [\ref=jnalepa:fig:hand_examples](N).

Classification Accuracy Analysis

The data set was split into a gallery (G) and a probe set (P) [\cite=Phillips1998]. The gallery contains exactly g, g  ≥  1, sample images per each gesture in the data set. Then, the similarities of the images from P to those in G were found using the techniques outlined in Section [\ref=sec:parallel_algorithm]. Classification effectiveness is assessed using its rank (R), [formula]. The rank is the position of the correct label on a list of gallery images sorted in the descending order by the similarity. If an image is classified correctly, then its rank is 1. The classification effectiveness for a given set is a percentage of correctly classified images. The analysis of the classification efficacy is performed based on cumulative response curves (CRCs).

The best CRCs for a single image per gesture in G are given in Fig. [\ref=fig:crc_gallery1_best]. We performed 27 classification experiments with no overlaps between the galleries. Then, the results were averaged and the best set of gallery images was determined. It is easy to see that the shape context methods, SCDT, SCH and SC, outperformed other techniques by at least ca. 15%, considering the correct classification (see rank 1). Additionally, the algorithms enhanced by the appearance-based approaches, SCDT and SCH outperformed standard SC by 2% and 3%.

Tab. [\ref=tab:avg_crc_135image] shows the average CR values for 4 initial ranks along with their standard deviations σ. In the average case for a single image per gesture in G (Tab. [\ref=tab:avg_crc_135image](A)), it is the SCDT method which turned out to be the best among the investigated techniques, resulting in the highest CR values for each rank. Clearly, the choice of the image to G has a strong impact on the later classification score, and selecting more distinctive images significantly affects the final results (see σ in Tab [\ref=tab:avg_crc_135image](A)). Although the standard deviation of the rank 1 is the smallest for the shape context based algorithms (SCDT, SCH, SC), it is still noticeable and proves the methods to be quite sensitive to the choice of the gallery images.

Fig. [\ref=fig:crc_gallery3] presents the CRCs for three (g = 3) most discriminative images, i.e. these that gave the best score for g = 1 for each method, per gesture in G. Providing multiple gallery entries improved the correct results in the initial ranks by at least 6% (SCDT, SCH and DT), up to 12% for the HD (see Fig. [\ref=fig:crc_gallery1_best] and Fig. [\ref=fig:crc_gallery3]). On the one hand, the appearance-based methods (HoG and DT) performed poorly for both g = 1 and g = 3. On the other hand, combining them with the contour-based shape contexts technique resulted in the best responses. Therefore, these methods are complementary. Noteworthy, combining the SC with other contour-based methods did not improve the classification score. Tab. [\ref=tab:avg_crc_135image](B) and Tab. [\ref=tab:avg_crc_135image](C) presents the average (out of 20 experiments) CR and its corresponding σ for g = 3 and g = 5 for SC-based methods. The enhanced approaches outperformed the SC significantly. Moreover, adding new images to the gallery (i.e. increasing g) made the algorithms more independent from the choice of gallery images (the σ values dropped).

Speedup and Efficiency Analysis

In order to assess the performance of the PA, we measured the analysis time τ(1) of the sequential algorithm and of the PA, τ(T), for various numbers of threads T, and calculated the speedup S  =  τ(1) / τ(T), along with the efficiency E = S / T [\cite=Nalepa2012] [\cite=Nalepa2013PPAM]. The analysis time τ consists of the feature extraction time τF and classification time τC, thus τ  =  τF  +  τC.

We investigated the execution time of the sequential algorithm and the PA for both g = 1 and g = 3 for each technique. Also, we measured the analysis time for g = 5 for the best approaches, i.e. giving the best CR for a smaller number of images per gesture in G (SCDT, SCH and SC). In the latter case, we run the PA 20 times, with 5 random images representing a given gesture, using each mentioned approach. The average analysis time τ, along with the speedup S and efficiency E of the PA for various number of parallel threads T, are shown in Tab. [\ref=tab:time_and_speedup]. The HD is the most time-consuming classification approach. Although we significantly reduced the number of contour points considered in the SC, SCDT and SCH techniques, their sequential analysis time is still relatively high. The HM, HoG and DT turned out to be very fast for both g = 1 and g = 3. Providing new images to G increased the sequential analysis time of the TM and HD algorithms significantly.

The experiments performed for various number of threads T showed that the sequential algorithm can be speeded up almost linearly in case of more computationally intensive approaches. It is worth to mention that we experienced the superlinear speedup [\cite=Chapman2007], i.e. S > T and E > 1.0, while executing the PA with the HD, SCDT and SCH on two parallel threads (T = 2). Our preliminary studies indicated the local core caches as the source of superlinearity, however this issue requires further investigation. Applying the PA allows for increasing the G with a very fast analysis time and analyzing larger hand gesture databases. Thus, a more accurate classification can be performed in real-time (at more than 100 frames per second rate) using the available processor resources, e.g. the execution time of the SCDT (g = 5, T = 8) is more than 3.5 times lower than for a single thread and g = 1 with a very significant increase in the classification score.

Conclusions and Future Work

In this paper we discussed our parallel algorithm for fast hand shape classification. Introducing the parallelism allowed for decreasing the execution time of the sequential algorithm significantly. Moreover, we showed that the classification score can be boosted without increasing the execution time if the available processor resources are utilized. We experienced the superlinear speedup, which indicates high efficacy of the parallelization. Furthermore, we presented how the selection of gallery images influences the classification score.

Our ongoing research includes increasing the classification accuracy of the proposed parallel algorithm. We consider using radial Chebyshev moments here as they occurred to be very effective for image retrieval purposes [\cite=Celebi2005]. Also, we plan to investigate the fusing schemes of contour-based and appearance-based techniques to enhance the final classification. Additionally, we aim at applying the proposed approach for searching the space of the parameters that control a 3D hand model [\cite=Saric2011].