Fast detection and automatic parameter estimation of a gravitational wave signal with a novel method

Introduction-While gravitational wave (GW) signals contain invaluable physical information, extracting this information from the noisy data is quite challenging. Most of the time, GW signals are weaker than the instrumental noise at any instant, but they are predictable and long lived [\cite=Sathyaprakash09]. This gives a way to build up signal-to-noise ratio (SNR) over time by tracking the signals coherently with matched filtering [\cite=Jaranowski12]. However, this requires the templates to be exactly the same as the true signal to recover the optimal SNR, or at least resemble the true signal sufficiently in order not to lose much SNR [\cite=Owen96]. Since the template waveforms depend on several parameters, one needs to match the data with a huge number of templates in the high dimensional parameter space. Therefore, a normal grid-based search is usually computationally extremely expensive, or even prohibitive. The reduction of the computational cost lies in the center of the modern GW data analysis.

There are several categories of algorithms, successfully reducing the computational cost, such as reduced bases (RB) [\cite=Field11], singular value decomposition (SVD) [\cite=Cannon10] and principal component analysis (PCA) [\cite=Heng09]. These methods make use of the fact that each template is strongly correlated with the templates in its neighbourhood in the parameter space. Therefore, its SNR can be effectively interpolated from the SNRs of the templates in its neighbourhood. In other words, the likelihood surface on the grid of the template bank has special properties (sparsity), which allows the compressed sensing [\cite=Candes06] algorithms to apply. Instead of using all the templates in the bank, one only needs to calculate the SNRs of a few so-called basis templates (which are different from the original templates), and then interpolate the SNRs of all the other templates in the bank. It is extremely fast to perform matched filtering on that few basis templates comparing to the original bank of templates. However, the interpolation (or sometimes referred to as the reconstruction) process is still computationally expensive.

We wish to design a novel method, which requires to perform matched filtering on a few templates, and in the meantime does not require any interpolation stage (or can automatically reconstruct the parameters of the GW signal). However, this method currently requires a relatively high SNR of the signal. The detailed description of the method and the preliminary simulation results are shown in the following.

GW data analysis routine-First of all, we briefly review the convention and notations of the GW data analysis. Usually, the measurement data can be expressed as s  =  Ah*  +  n, where n is the noise, A is the amplitude of the signal, h* is the normalized signal in the measurement, which satisfies 〈h*|h*〉 = 1. The inner product of two time series a(t) and b(t) is defined as follows

[formula]

where ã(f),(f) are the Fourier transforms of a(t) and b(t). Sn(f) is the so-called two-sided noise power spectral density (PSD), usually defined as [ñ * (f')ñ(f)] = Sn(f)δ(f - f').

The GW data analysis problem that we want to solve is formulated as follows. For a set of normalized candidate templates hi = h(Θi) (we choose the template index [formula] for convenience) characterized by parameters Θi, we want to determine which one is present in the measurement, hence obtaining the parameters Θ* of the signal. Notice that Θ denotes a set of waveform parameters. For clarity, we require the templates to be nearly independent 〈hi|hj〉    ≪  1,  (i  ≠  j). This is not generally true for a whole template bank. However, one can easily divide the entire template bank into a group of smaller template banks, within which the templates are nearly independent.

We assume that the true signal h* belongs to the template family, [formula]. The inner product between the measurement data and a template is denoted as

[formula]

thus the expectation and the variance are

[formula]

By identifying the largest inner product x*, we can detect the signal h* and estimate its parameters Θ*. When the inner product x* is much larger than its standard deviation [formula], the significance is high. The above shows a normal search strategy, which requires to perform 2N inner products.

The novel method-In the following, we will describe a novel search algorithm. First, we express the waveform indices i in binary, hence each index is an N-digit binary number (e.g. [formula]). Then, we define N sets Pk ([formula]) such that Pk consists of all the indices i whose k-th digit is 1. A new template family is defined based on these sets

[formula]

The inner products of these new templates with the measurement data are

[formula]

The expectation of Xk is

[formula]

The variance can be calculated as follows

[formula]

Since the templates hi are nearly independent, we have

[formula]

Suppose *  ∈Pa and *  ∉Pb, then

[formula]

When the expectation A is much larger than the standard deviation 2(N - 1) / 2, we can set some threshold T between A and 2(N - 1) / 2. Based on this threshold, a binary number can be obtained as follows: if Xk  >  T, the k-th bit of this binary number is 1, otherwise its k-th digit is set as 0. This binary number can be converted to a decimal number i0. The method identifies the waveform hi0 with parameters Θi0 to be most probably present in the data. In this new approach, we have used N templates instead of 2N templates to detect the signal and estimate its parameters. The computational cost is thus reduced from C  ·  2N to C  ·  N. Notice that, if each inner product of the data and a template provides one bit of information (above or below a certain threshold), N is the minimum required number of templates to distinguish 2N sets of candidate parameters.

Simulation-To exemplify the performance of the novel method, we consider the following chirp waveform family

[formula]

where A is the normalization constant, f and [formula] are the two intrinsic parameters to be estimated. We have simulated 100 seconds measurement data at 1  kHz with different SNRs. The parameters of the true signal are f* = 100  Hz and [formula]Hz/s. We have considered 26 candidate waveforms with the parameter mesh grid

[formula]

[formula]

The threshold is simply chosen as T  =  c  ·   max (Xk), where we have tried several values of the coefficient c. The SNR varies from 8 to 50 with a uniform spacing 3. For each combination of SNR and the threshold, we carried out a Monte Carlo simulation with 1000 different noise realizations. If the algorithm identifies the true signal and its true parameters, the detection is successful. The success rate is called the detection rate. Fig. [\ref=fig:detectionRate] shows the detection rate at different SNRs and thresholds, where the color bar indicates the value of the coefficient c. The best performance is realized by setting the coefficient c around 0.5. For signals with SNR higher than 30, the detection rate of the algorithm is above 99%. Thus, the algorithm with the least number of new templates works efficiently at relatively hight SNRs. However, at low SNRs, the detection rate is low. We will see whether we could improve the detection rate by slightly increase the computational cost.

Features of the algorithm-For the set of 2N independent templates hi, if 2N is smaller than the number of samples in the observation data, xi  =  〈s|hi〉 are also independent. To characterize the performance of the algorithms, we want to examine to what extent can the noise mimic a signal. Since the signal part of xi only contributes a DC bias to its probability distribution, we can ignore the DC part and only consider the random part of xi, which is 〈n|hi〉. It can be shown without much effort that the probability density function of the maximum of these 2N random variables xi is the following

[formula]

where the error function (x) is defined as [formula]. Similarly, the probability density function of the maximum of the N random variables Xk turns out to be the following

[formula]

For the case we considered, we have N = 6. The probability density functions and cumulative distribution functions of the random part of xi and Xk are shown in Fig. [\ref=fig:PDF], which tells us how large SNRs could be mimicked by pure noise. As expected, in case of Xk, the noise could mimic larger SNRs. This can also be seen from the larger standard deviation of Xk. In fact, this is the reason for the drop in the detection rate at low SNRs in Fig. [\ref=fig:detectionRate].

Next, let us examine the role of the threshold [formula]. In the previous simulations, we have six inner products [formula], each corresponding to an SNR achieved by Hi. Since the detection criteria only depends on the ratio between the inner products, it is convenient to look at their pie charts. In Fig. [\ref=fig:SNRpie], we show the pie charts for different SNRs, where the color bar represents the indices of the inner products. Take Fig. [\ref=fig:SNRpie] (a) for instance. The inner products X1,  X3,  X4 contribute most part of the summation [formula], while X2,  X5,  X6 are much smaller. According to the criteria we designed before, only X1,  X3,  X4 are above the threshold. Therefore, we obtain the index 1011002 = 44 of the template, which most resembles the signal in the data. Similarly, Fig. [\ref=fig:SNRpie] (b)-(e) all successfully identify the correct template in case of different SNRs. Fig. [\ref=fig:SNRpie] (f) shows a failure case. According to the previous criteria, this pie chart gives a wrong index 1010012 = 41. In fact, even if one bit of the binary is wrongly determined, we end up with a completely different template (and its corresponding parameters). This is also a main reason why the detection rate at low SNRs drops so quickly.

Improve the performance of the algorithm-Now we discuss a simple and straightforward way to improve the performance of the algorithm by slightly increasing the computational cost. Let us look at the failure case in Fig. [\ref=fig:SNRpie] (f) again. The largest inner product is X1, which contributes 30 percent of the entire SNR pie. The threshold, which was set to half of the largest inner product, turns out to be 15 percent. Therefore, among the six inner products, X1,  X3 are significantly above the threshold, X2,  X5 are significantly below, while X4,  X6 are close to the threshold. In the end, the binary bits corresponding to X4 and X6 (i.e. the 4th and 6th bits) were determined wrongly, which leads to a detection failure. However, the binary bits corresponding to X1,  X2,  X3 and X5 are correctly determined, and we are confident about that in the blind search. In fact, we are not so confident about the bits corresponding to X4 and X6, since they are just slightly above or below the threshold. If we leave these two binary bits undetermined, we end up with a binary number 10102, where we have used [formula] to denote undetermined bits. It implies that the true signal might match one of the four templates 1010002 = 40, 1011002 = 44, 1010012 = 41 and 1011012 = 45. By simply calculating the inner products of the data and these four templates, we will know which one matches the true signal.

Hence, we can modify the algorithm according to the above procedure. In the beginning, we calculate [formula] and the threshold T  =  c  ·   max (Xk). Then, we identify two Xk, which are closest to the threshold T, and leave two binary bits corresponding to these two Xk undetermined. We determine other binary bits in the same way as before. A binary number with two unknown bits is thus constructed. It corresponds to four original templates hi. In the end, we calculate the inner product between the data and these four templates, and detect the signal. Following this procedure, we carried out a similar simulation as before. The detection rate is plotted in Fig. [\ref=fig:detectionRate2] with different combinations of c values and SNRs. Comparing with Fig. [\ref=fig:detectionRate], the modified algorithm has significantly improved the performance. The detection rate is increased at all SNRs. We also observe that c = 0.5 is still the optimal choice. For the curve c = 0.5, the detection rate is 100% above SNR 30 and 96% at SNR=20. This strategy can be easily generalized by assigning a probability to each binary bit according to Xk, hence obtaining the probability of each hi present in the data. However, this is out of the scope of the current article. We will discuss it in the future work.

Conclusion and future work-We have designed a novel algorithm for GW data analysis. Instead of using 2N normal waveform templates, this new algorithm uses only N combinations of the original waveforms as the new templates. By calculating the inner products between these N new templates with the data and comparing these inner products with some threshold, we can construct a binary number with N bits. From this binary number, we can determine which normal template in the original template bank best matches the signal in the data, without any reconstruction process. Therefore, this new algorithm can greatly reduce the computational cost in certain circumstances. However, it requires relatively high SNRs. We have discussed a simple and straightforward way to improve the performance of the algorithm. By leaving two most unconfident binary bits undetermined and calculating four additional inner products, we can significantly improve the performance of the algorithm at low SNRs. The detection rate of the modified algorithm is 100% for 1000 different noise realizations for each SNR larger than 25. For SNR lower than 25, further improvements are demanded. We reserve that for future work.

One possible way to improve the algorithm is to construct additional [formula] for auxiliary use, such as to determine unconfident binary bits, to suppress the noise in Xk, etc. One can also set more sophisticated thresholds. We have used a threshold only depending on the relative values between the inner products Xk for simplicity. A threshold also depending on the absolute values of the inner products would help, since the probability distribution of the random part of Xk depends only on the absolute SNRs.

We have only carried out simulations for a bank of nearly independent templates. In the future, we will do a simulation for an entire template bank. The correlation between templates need also to be studied, since it could be used to reduce the noise in the detection statistic.