=

Research Project Anna Sikov Institute of Mathematics and Statistics University of Sao Paulo

Resume

In the case of informative sampling the sampling scheme explicitly or implicitly depends on the response variable. As a result, the sample distribution of response variable cannot be used for making inference about the population. In this research I investigate the problem of informative sampling from the Bayesian perspective. Application of the Bayesian approach permits solving the problems, which arise due to complexity of the models, being used for handling informative sampling. The main objective of the research is to combine the elements of the classical sampling theory and Bayesian analysis, for identifying and estimating the population model, and the model describing the sampling mechanism. Utilizing the fact that inclusion probabilities are generally known, the population sum of squares of the models residuals can be estimated, implementing the techniques of the sampling theory. In this research I show, how these estimates can be incorporated in the Bayesian modeling and how the Full Bayesian Significance Test (FBST), which is based on the Bayesian measure of evidence for precise null hypothesis, can be utilized as a model identification tool. The results obtained by implementation of the proposed approach to estimation and identification of the sample selection model seem promising. At this point I am working on methods of estimation and identification of the population model. An interesting extension of my approach is incorporation of known population characteristics into the estimation process. Some other directions for continuation of my research are highlighted in the sections which describe the proposed methodology.

Introduction

Inference from a sample to the whole population usually employes estimation of the model, holding in the population based only on the sample measurements. In many practical situations sample selection probabilities depend directly on the values of the variable which is being investigated (outcome variable) even after conditioning on the covariates (auxiliary variables). This typically occurs when the sample selection process uses design variables, which are correlated with the outcome variable. In this case the sampling design is informative and the distribution of the measurements corresponding to the units belonging to the selected sample is different from the distribution of the measurements corresponding to the units in the population. If the sampling design is informative, the use of standard methods of estimation that ignore sample selection process may result in large biases. Hence, one of the most important problems, facing the analyst is selection an appropriate model underlying the sample selection process, and testing ignorability of the sampling selection process. The approaches to handling informative sampling, which are proposed in the literature generally focus on estimation of unknown parameters, leaving the two defined problems almost unaddressed. The methods proposed in the literature, typically use either classical inference procedures, such as maximum likelihood estimation, based on the approximation of the model holding for the sample measurements (Pfeffermann et al., (1998), Pfeffermann and Sverchkov (2003)), or weighting procedures, which use either reciprocals of sampling probabilities (Binder (1983), Skinner et al. (1989), Pfeffermann (1993, 1996)), or their modifications, which are designed to reduce the variances (Pfeffermann and Sverchkov(1999), Beaumont (2008), Kim and Skinner (2013)). The sampling probabilities are generally assumed to be known for the sampled units. Application of the maximum likelihood approach requires modeling of the population distribution and specification of the parametric form of the conditional expectations of the sample selection probabilities, given the outcome variable and the covariates. Two these models define the model, holding in the sample. In this case hypothesis testing can be carried out by application of the log-likelihood test statistics, the score test or the Wald test, however, these tests generally unstable, or computationally complicated. In the second case one can utilize the tests, proposed by Pfeffermann and Sverchkov (1999) or by Pfeffermann (1993).

In this article we apply a Bayesian approach to estimation of unknown parameters and hypothesis testing. In principle, the likelihood, based on the sample distribution, can be imbedded within a Bayesian model, and inference can be drawn using the MCMC techniques. The problem with this approach is that prior information on unknown parameters is generally unavailable. On the other hand, if improper priors are imposed, the resulting posterior distributions may likewise be improper. In addition, the resulting models are generally very complicated, which results in an extremely slow convergence of the MCMC process even for the models, containing a small number of unknown parameters. Another restriction of utilizing the sample likelihood is that in some cases the model may be unidentifiable (see Section 3.1). As with the case of the methods, based on the sample likelihood, we assume in this article a parametric model on the population distribution, which models the process generating the population measurements, and a parametric form of the expectations of the sample selection probabilities, given the outcome variable and covariates. Assuming that both processes are independent, and that the sampling probabilities are observed for all the sampled units, we propose to estimate the population model and the expectations of the sample selection probabilities, based on the Hovitz-Tompson estimators for the population sums of squares of the residuals of the models. The derivatives of Hovitz-Tompson estimators with respect to unknown parameters provide statistics for the Bayesian inference. Conditional distribution of these statistics, given unknown parameters, can be approximated as multivariate normals, since they constitute sums of random variables. Imposing a flat multivariate normal prior on the vector of unknown parameters permits application of the MCMC techniques and therefore, estimation of unknown parameters. The main advantage of application of the Bayesian approach is that it permits solving the problems of hypothesis testing and model identification. For hypothesis testing we utilize the Full Bayesian Significance Test (FBST), introduced by Pereira and Stern (1999). The FBST is based on the Bayesian measure of evidence, favoring the null hypothesis. This measure is computed using the draws from the posterior distribution. The evidence value estimates the probability of tangential set of points having posterior density values higher than the supremum of the posterior density under the null hypothesis. The proposed test rejects the null hypothesis if this probability is high. The other important problem is identification of a model, describing the sample selection process, since statistical inference in this case typically requires modeling the expectations of the sampling probabilities given the covariates and the outcomes, the forms of which are seldomly known (Pfeffermann et al (1998), Pfeffermann and Sverchkov (1999)).

Summary of the Proposed Approaches

Estimation Methods

In this section we provide a brief description of the problem of informative sampling and present the main findings in this area. Let Yi denote the value of the outcome variable Y, associated with unit i, belonging to a sample S, drawn from a finite population U, and let X and V denote the vectors of auxiliary variables, associated with unit i, such that dim(Xi) = p and dim(Vi) = q. We assume that the population values are independent realizations from a distribution with probability density function fp(yi|xi,θ), where θ is an unknown parameter, and that the sample selection mechanism employed a design variable Z, so that the probability of the units to be selected is proportional to the value of this variable (or to some function of this variable). Throughout this paper we assume that the model holding in the population is the normal linear regression model,

[formula]

where θ = (β,σ2).

Let πi denote the sample inclusion probability of unit i, and Ii denote the sampling indicator, which takes the value 1 if unit i was selected to the sample and 0 othervise. Therefore, the distribution, holding in the sample for the unit i is a conditional distribution, fs(yi|xi,vi) = f(yi|xi,vi,Ii = 1), which, following Pfeffermann et al., (1998), can be presented as

[formula]

where [formula] Noting that [formula], the relationship (2) can be also written in the form:

[formula]

where the index p of the expectation indicates that it is computed with respect to the population distribution fp(yi|xi). If the inclusion probabilities are proportional to the values of the design variable Z, the equation (2) takes the form

[formula]

Note that the model, holding in the sample, fs(yi|xi,vi) is fully determined by the population model, fp(yi|xi) and by Ep(πi|yi,xi). Note also that if selection probabilities do not depend on the value of the outcome variable yi, then the distributions in the population and in the sample coincide. Utilizing the result obtained by Pfeffermann et al., (1998), which states that under common sampling designs with unequal sampling probabilities, when the population measurements are independently drawn from some distribution, the sample measurements are asymptotically independent as the population size increases, a sample likelihood can be specifies as

[formula]

where the unknown parameters θ and γ are indexing the sample model and a model underlying a sample selection mechanism correspondingly. The authors note that the functional form of the expectations, Ep(πi|yi,xi) is not necessarily known, and therefore, must be approximated. They propose two possible approximations:

[formula]

where [formula] and [formula] and [formula] are unknown parameters, and

[formula]

The authors point out that under approximation (6) the resulting sample distribution may be not identifiable. For example, if the population distribution is normal, Yi|xi  ~  N(β0 + xtiβ,σ2) and Ep(πi|yi,xi) =  exp (A1yi + g(xi)) for some function g(x) then, by (3) it follows that the distribution of Yi|xi, holding in the sample is N((β0 + A1σ2) + xtiβ,σ2), which is not identifiable. In order to avoid identification problems the authors propose to split the estimation process into two steps, where in the first step the parameters [formula] and [formula] are estimated from the observed probabilities πi, and in the second step the parameters, indexing the population model are estimated from the likelihood, defined by (4) ,with the parameters [formula] and [formula] substituted by their estimates. Apart from solving identifiability problem, when using the approximaion (6), this approach is designed to ease the computation process, which can be cumbersome for both approximations, (5) and (6), if the number of parameters, indexing the resulting sample model is large. In order to test sampling ignorability one can use the log-likelihood test statistic, obtained by application of the generalized likelihood ratio test, however this test is applicable if all the parameters, θ and γ are estimated from the likelihood (4). If parameters γ are estimated from the observed probabilities πi, one can use a Score or a Wald test. The described two step procedure was applied by Pfeffermann and Sverchkov (1999) for estimation of the parameters of linear regression model with normal error terms. Noting that, [formula], where [formula], the authors propose at the first step to identify and to estimate the unknown parameters [formula] and [formula] by regressing wi against (xi,yi). If the assumptions of normality is dropped then the parameters β can alternatively be estimated as a solution of

[formula]

where Ês(wi|xi,vi) denote the estimates of the expectations,Es(wi|xi,vi), obtained by regressing wi against (xi,yi) (see Pfeffermann and Sverchkov, 1999 for details). For extension of the approach to the generalized linear models see Pfeffermann and Sverchkov (2003). The approach based on minimization of (7) can be viewed as a modification of probability weighting methods, which use census estimating equations for deriving unknown parameters θ:

[formula]

Since the measurements outside of the sample are unobserved, the left handside of (8) is replaced by its Horvitz-Thompson estimator

[formula]

If [formula] then the estimation method is known in the literature as pseudo likelihood estimation method, which was introduced by Skinner et al (1989). Under the model (1) the estimators [formula] are the solutions of the equations

[formula]

In order to test ignorability of the sampling mechanism, one can use the test proposed by Pfeffermann and Sverchkov (1999). Their test employes the relationship,

[formula]

(see Skinner, 1994). Denoting by εi  =  yi - Ep(Yi|xi) the regression residuals associated with the unit i, one can test the hypothesis of the form Ep(εki) = Es(εki),  k = 1,2..., which by (11) is equivalent to testing the hypothesis Corrs(εki,wi) = 0,  k = 1,2..., where Corrs denotes the correlation under the sample distribution. The authors point out that it generally suffices to test the first 2-3 correlations. This approach can be applied to testing ignorability of the sampling mechanism, however, it does not permit identification of the model, underlying the sample selection mechanism. There exist a few other approaches to testing ignorability of the smpling mechanism. These approaches are generally based on the difference between the estimators of the regression coefficients under the assumed model and the model under ignorable sampling design. See Pfeffermann (1993) for discussion.

The FBST

As said previously, implementation of the Bayesian approach permits application of the FBST for solving the problem of hypothesis testing and model identification. This can be carried out by determining whether the fitted model contains non-significant parameters. In our application this reduces to testing nested models, where the more complex model is tested versus the model under the null hypothesis, obtained by setting the coefficients of some group of variables to zero. Therefore, the FBST can be used as an identification tool for selecting the model in the family of the nested models which best fits the data.

Let us consider a standard parametric statistical model, i.e., for an integer m, [formula] is the parameter, g(θ) a prior probability density over Θ, x is the observation (a scalar or a vector), and Lx(θ) is the likelihood generated by the data x. After the data x have been observed, the sole relevant entity for the evaluation of the Bayesian evidence value, ev, is the posterior probability (density) for θ given x, denoted by

[formula]

We are restricted to the case where the posterior probability distribution over Θ is absolutely continuous, that is gx(θ) is a density over Θ. We are focusing on testing of sharp hypothesis, which state that θ belongs to a sub-manifold ΘH of smaller dimension than Θ. For simplicity we use H for ΘH in sequel. Let r(θ) be a reference density on Θ such that the function s(θ) = gx(θ)  /  r(θ) is called the “relative surprise”. Now consider a sharp hypothesis H:θ∈ΘH. Let [formula] and [formula]. The Bayesian evidence value agains H tis defined as the posterior probability of the tangential set, i.e.,

[formula]

Note that the evidence value, supporting H, [formula], is not an evidence against the alternative hypothesis A. Equivalently, ev does not constitute an evidence in favor of A, although it is against H. The FBST rejects H whenever ev is small.

Proposed Approach

Estimation Equations and Bayesian Model

As noted by Pfeffermann et al., (1998), the situation, often occurring in practice is where the only design information, available to the analyst is the vector of sample inclusion probabilities of the sample units, and possible, also the sample values of Z. In this research we assume that we observe both, sample inclusion probabilities and the values of the design variables, and that sampling probabilities are proportional to the corresponding values of the design variable. Let the population outcomes follow the model defined by (1) and assume for simplicity that

[formula]

We also assume that the population realizations of Z are independent between the units.

The defined sample selection model is a special case of a model (5) where J = 1 and h() is a linear function of the covariates. However our approach can be easily extended to the situations where J > 1 and h() is a polynomial of an order m, for some m > 1. The method presented below can also be utilized if conditional expectation of the sample selection probabilities is given by (6).

In this research we differentiate between randomization based inference over all possible sample selections, and inference, based on both, randomization and model distributions. The former distribution is underlying classical survey sampling inference, while the later distribution takes also into account the process of generating the values of the finite population. The randomization distribution accounts only for the process of sample selection, holding the population values fixed, therefore inference based on this distribution is restricted to the populations, which are similar to the population of the study (see Pfeffermann, 2011 for discussion). On the other hand, inference, based on both, randomization and model distributions requires strong assumptions on the design variables. For example, in our case assuming a parametric form only for the conditional expectation of πi given the values yi and vi will not be sufficient. In this research we focus on a randomization based inference.

Let W(γ) define the population sum of squares of the regression residuals of the model for the design variable,

[formula]

where γ  =  (γv,γy) and γv  =  (γ1,...,γq). If all population measurements were available, the value of γ could be obtained as a solution of the estimation equations,

[formula]

In real situation statistical inference can only be based on the available sample measurements. Denote by [formula] the Horvitz-Thompson estimator of W(γ), based on the observed sample S. Then

[formula]

Let

[formula]

and

[formula]

Note that the equations specified above, can be alternatively expressed as

[formula]

and

[formula]

where Ii denotes the sampling indicator. Note that in the specified equations the observed values of the variables Z, Y and V are held fixed and the only source of randomness is expressed by the sampling indicators I1,...,IN, which can take the values 0 and 1.

Denote

[formula]

[formula]

Note that

[formula]

where 0(q + 1)  ×  1 denotes a vector of zeros of dimension q + 1, ED denotes the expectation over all possible sample selections, for the fixed population values, and [formula] denote the vector of inclusion probabilities and the vectors of the population realizations of the variables Yand Vcorrespondingly. Therefore, the following equations can be specified:

[formula]

where ν = (ν1,ν2,...,νq + 1)t is a q + 1-variate random variable. Implication of the equations (20) is that even were γ known, it is unlikely that the components of [formula] would be equal to zero for any selected sample S due to sampling variability, although we expect them to be close to zero. Noting that [formula] are defined by sums of random variables, we assume that given the vector of unknown parameters γ, the vector of random variables ν can be approximated by a q + 1-variate normal distribution, that is

[formula]

where [formula], [formula] and [formula] denote the observed parts of the vectors [formula], [formula] and [formula] correspondingly. A well known result of a classical sampling theory states that under the randomization distribution, the components of the matrix Σ(γ) can be derived as follows:

[formula]

where [formula] Then, based on the sample measurements, (22) can be estimated as

[formula]

Calculation of the components of the variance matrix Σ(γ), generally requires knowledge of the joint sampling probabilities for the units k and l, where k,l = 1,...,N. These probabilities are generally not specified, however, if they are proportional to a design variable, it can be shown that the estimator (23) can be rewritten as

[formula] where [formula] If sampling probabilities are proportional to some function of the design variable, calculation of Σ(γ) will require knowledge of the design variable value for all sample units.

In order to apply a Bayesian approach we use the model (21) and a noninformative prior on γ, h(γ). Then

[formula]

where φ0(q  +  1)   ×   1,(γ) denotes a q + 1-variate normal density function with the expectation vector, 0(q + 1)  ×  1 and the variance matrix equal to (γ).

Application of the proposed method to the situations where the sample selection mechanism follows model (6) is straightforward. In my research I would like to extend the proposed methodology to the cases, where the selection models have more complex forms.

The regression parameters β, indexing the population model, can be estimated by implementation of the same approach, by defining the population sums of squares of the residuals as [formula] and their Horvitz-Tompson estimators,

[formula]

.

The methods of estimation of unknown parameters β, hypothesis testing and identification of the model, holding in the population are being developed by the author at present. The author is also working on extending the proposed methodology to the situations, where the population model belongs to the family of GLM.

An additional interesting extension of the proposed methodology is incorporation of constraints in the estimation process. This is also one of the direction of my future work.

As previously mentioned, we assume a flat prior on all unknown parameters. It is generally known that the posterior distributions may be heavily influenced by the priors. In this research I also intend to investigate and to implement various methods of sensitivity analysis.

Application of the FBST

In this section we consider a simple case of hypothesis testing under the model defined by (14), H:γy = 0, where rejection of H implies that the sample selection mechanism is ignorable. Extension to testing hypothesis of the form [formula], where [formula] for more complex sample selection models is straightforward. Denote by [formula] the random draws from the posterior distribution [formula], obtained by application of the MCMC to the full model, and let [formula]. Denote by γ0 the vector of unknown parameters, indexing the sampling selection model under H. Let

[formula]

and

[formula]

It follows (see Reference) then that derivation of the value [formula], requires computation of the probability [formula]. This probability can be estimated, using the posterior draws, as follows [formula].

[formula]

where

[formula]

and

[formula]

Therefore, application of the FBST requires two following steps:

A maximization step (25).

Computation of the ratio of the integrals, defined in (29).

The first step constitutes a standard maximization problem, which can usually be carried out by application of a standard multivariate Newton-Raphson algorithm, and therefore does not require intensive computations. The second step involves more complex computations, however, it can be carried out by application of an importance sampling, using Monte Carlo techniques, as described by Zacks and Stern (2003). The authors also derive the sample size, which is required for attaining the desired precision of the integrals ratio.

One of the objectives of my research at this point is to approximate the value of [formula] in order to avoid computation of the integrals in (29). This will significantly simplify the process of calculation of the evidence value.

Simulation Study

In order to test the proposed approach and to compare its performance to some other approaches, described in a literature review section, we performed a small simulation study, which consisted of a few experiments. For each experiment we generated M = 200 populations of size N = 500, and for each generated population we selected one sample of size n = 50, such that the units were randomly selected with the inclusion probabilities proportional to the values of the design variable Z. We used the following population and sample selection models.

[formula]

where εi  ~  N(0,1.5) and the auxiliary variables X and V were generated from Gamma(1,1) and Poisson(3) distributions correspondingly. The true model for the design variable, Z is:

[formula]

where νi  ~  N(0,2.5). The primary objective of the simulation study is to identify the model, holding for E(Zi|vi,yi) by testing the following hypotheses. For each experiment, j = 1,2,3 and each sample i,i = 1,...,M we compute the value of the Bayesian evidence value in favour of H, evji as presented in Section 4.2, using a normal flat prior. As mentioned above the FBST rejects H whenever ev is small. In order to define a rejection region, we utilize the asymptotic distribution of the evidence value under H, provided by Pereira et al. (2008). The tables below summarize proportions of the samples, where the hypothesis H was rejected for various significance level. We illustrate the results for the proposed test and the classical Likelihood Ratio test (LR), based on the model (21). For the first experiment we also applied the test proposed by Pfeffermann and Sverchkov (1999), which is based on the identity in (11). As mentioned above this test can only be implemented to testing informativeness of the sampling selection mechanism and is not applicable if both tested models are informative. We denote by PS(1) and by PS(2) the tests based on the correlations between the sampling weights and the first and the second powers of the residuals, as described in the end of the Section 3.1.

The table above illustrates that the FBST prsents very good power properties for the first and the third experiments. The high probability of rejection of H in the first experiment implies that our method succeeds in revealing that the sampling mechanism is indeed informative (recall that the true model for the sampling selection process included the quadratic term of the value of outcome variable). In the third experiment both specified models are informative. In this case the proposed method shows good performance in revealing the correct model. For the second experiment, both models are not correct. The results indicate in this case, that both methods generally do not reject the model with a smaller number of coefficients.

In order to validate the proposed methods, we carried out an additional experiment. For this experiment the tested models are the same as in the first experiment, however the values of the design variable Z were generated under the model under the hypothesis H of this experiment. We expect that the proportion of the samples where the hypothesis H is rejected will be close to the significance level.

In general, the empirical distribution of all the statistics is sufficiently close to the nominal values, thus validating the use of all the discussed methods.