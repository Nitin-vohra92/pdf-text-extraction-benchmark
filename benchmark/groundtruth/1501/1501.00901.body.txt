=1500

Learning to Recognize Pedestrian Attribute

Introduction

to recognize pedestrian attributes, such as gender, age, clothing style, has received growing attention in computer vision research, due to its high application potential in areas such as video-based business intelligence [\cite=VideoBased] and visual surveillance [\cite=GongChallenge2013]. In real-world video surveillance scenarios, clear close-shots of face and body regions are seldom available. Thus, attribute recognition has to be performed at far distance using pedestrian body appearance (which can be partially occluded) in the absence of critical face/close-shot body visual information.

Pedestrian attribute recognition at far distance is non-trivial due to: 1) Appearance diversity - owing to diverse appearances of pedestrian clothing and uncontrollable multi-factor variations such as illumination and camera viewing angle, there exist large intra-class variations among different images for the same attribute; 2) Appearance ambiguity - far-view attribute recognition is a remarkably difficult task due to limited image resolution, inherent visual ambiguity, and poor quality of visual features obtained from far view field (Fig. [\ref=fig:figParsed]).

Related work: Cao et al. [\cite=cao2008gender] are among the first to study human attribute recognition from full body images. In their study, HOG features extracted from overlapping patches are used along with Adaboost classifier for recognizing the gender attribute. Bourdev et al. propose the use of poselets [\cite=bourdev2011describing] to attribute recognition. In particular, HOG features, color histogram, and skin-specific features are extracted on local poses for poselet-level attribute classification. Zhu et al. [\cite=Zhu] extract dense color, LBP, and HOG features to train Adaboost and weighted kNN classifiers for attributes classification. Although these approaches have all tried to train a robust attribute detection model, they either relied on a small-size dataset or selected not enough attributes for analysis. In view of the growing research interest in the field of human re-identification [\cite=GongChallenge2013] [\cite=zheng2013reidentification] [\cite=liu2014semi], which aims at detecting the same person across spatial and temporal distance, the role of pedestrian attributes has become vital, as mid-level features are shown to be exceptional for aiding the human re-identification task [\cite=liu2012person]. In particular, Layne et al. [\cite=layne2012towards] [\cite=Layne] propose intersection kernel SVM with a mixture of colour (RGB, HSV and YCbCr) and texture histograms (8 Gabor filters and 13 Schmid filters) for learning a selection of pedestrian attributes as a form of mid-level features to describe people. The use of attributes has shown remarkable re-identification performance compared to employing low-level features alone, but the attribute recognition performance in [\cite=layne2012towards] [\cite=Layne] has yet to be improved.

Contributions: As discussed above, most existing pedestrian attribute studies focus either on feature engineering or classifier learning. To better mitigate the appearance diversity and ambiguity issues, we explore some new perspectives of exploiting neighborhood and background contexts in this study: 1) We view multiple pedestrian images as forming an Markov Random Field (MRF) graph in order to exploit the hidden neighborhood information for better attribute recognition performance. The underlying graph topology is automatically inferred, with node associations weighted by pairwise similarity between pedestrian images. The similarity can be estimated as the conventional Euclidean distance or the more elaborated decision forest-based similarity with feature selection [\cite=ZhuICCV2013] [\cite=ZhuCVPR2014]. By carrying out inference on the graph, we jointly reason and estimate the attribute probability of all images in the graph. 2) We extract foreground segments of pedestrian through deep learning-based parsing and extensively evaluate the integration of foreground segments with background context for improved pedestrian representation. All experiments are systematically conducted on the largest pedestrian attribute dataset introduced by us.

Methodology

From Pedestrian Parsing to Representation

The goal of pedestrian attribute recognition is to quantify an attribute with value, [formula], given the d-dimensional feature vector, denoted by [formula], of a pedestrian image. Conventionally the features are extracted from the whole pedestrian image defined by the detection bounding box [\cite=cao2008gender] [\cite=layne2012towards] [\cite=Layne] [\cite=Zhu], denoted as [formula].

However, it is more intuitive to use only the features from foreground for attribute recognition. Would background regions play any role? We wish to examine if discarding the background region would facilitate more accurate recognition of pedestrian attributes. To this end, we train a Deep Decompositional Network (DDN) [\cite=LuoParsing] to parse a pedestrian image into different body regions. Such a deep network is an unified architecture that combines occlusion estimation, data completion, and data transformation for pedestrian segmentation and parsing, with each layer being fully connected to the next upper layer. We refer readers to [\cite=LuoParsing] for the network structure and training details of the DDN due to page limits. At test time, the DDN parses the input image into multiple pedestrian regions. As depicted in Fig. [\ref=fig:figParsed], we define regions such as hair, face, body, arms, and legs of the pedestrian to be the foreground and we consider the remaining regions to be the background. Utilizing the binary masks (Fig. [\ref=fig:figParsed]) produced by the DDN, we investigate the following combinations of features extracted from foreground [formula], background [formula], and the whole image [formula], namely [formula] alone, [formula] alone, foreground and background feature concatenation [formula], and foreground and whole image feature concatenation [formula].

Recognition of Attributes using Neighborhood Context

To improve attribute recognition, we further propose to exploit the context of neighboring images by Markov Random Field (MRF), which is an undirected graph, where each node represents a random variable and each edge represents the relation between two connected nodes. Traditionally, the neighborhood information in MRF is defined by using the nearby pixels in a single image, such as in the application of smoothing [\cite=Smoothing] in image segmentation [\cite=CoSegmentation]. In the context of attribute recognition, we hypothesize that neighboring images share natural invariance in their feature space, which could be treated as a form of regularization. As such, attribute inference of an image can be locally constrained by its neighbors to obtain a more reliable prediction. Hence in this work, we define the energy function of MRF over a graph G as follows

[formula]

where [formula] are two random variables in the graph and [formula] denotes the state of [formula]. [formula] and [formula] signify the unary cost and pairwise cost functions, respectively. More precisely, they indicate the cost of assigning state [formula] to variable [formula] as well as the cost of assigning states to neighboring nodes [formula], which is determined based on the graph structure (e.g., assigning different states to nodes that are similar is penalized). [formula] is a set of variables that are the neighbors of [formula].

Each random variable corresponds to an image and the relation between two variables corresponds to the similarity between images. The variable states [formula] are the values of the image attribute. The unary function is modeled by

[formula]

where [formula] is the probability of predicting the attribute value of image [formula] as [formula]. This probability can be conveniently mapped by the output scores of ikSVM.

Now we consider the definition of the pairwise function. To define affinity between nodes, a simple way widely adopted by existing methods, such as [\cite=Zha], is the Gaussian kernel, [formula], in which [formula] indicate the feature vectors of two images and σ is a coefficient that needs to be tuned. The graph built on this kernel function can model the global smoothness among images. However, when large variations are presented, one may consider modeling the local smoothness and discovering the intrinsic manifold of the data. Thus, an alternative is to employ the random forest (RF) [\cite=Breiman] to learn the pairwise function [\cite=ZhuICCV2013] [\cite=ZhuCVPR2014]. The RF we adopted is unsupervised, with pairwise sample similarity derived from the data partitioning discovered at the leaf nodes of RF as output. The unsupervised RF can be learned using the pseudo two-class method as in [\cite=ZhuICCV2013], [\cite=ZhuCVPR2014] and [\cite=liu]. The pairwise function in our MRF model can hence be expressed as

[formula]

Here, [formula] if [formula] fall into the same leaf node and [formula] =  +   ∞   otherwise, where t is the index of tree. Since the graph is dense, the inference of MRF is difficult. Thus, we build a k-NN sparse graph by limiting the number of neighbors for each node. We set k = 5 in our experiment. Eq.([\ref=eq:mrf]) can be efficiently solved by the min-cut/max-flow algorithm introduced in [\cite=min].

Experiments

Settings

Feature representation: Low-level color and texture features have been proven robust in describing pedestrian images [\cite=Layne], including 8 color channels such as RGB, HSV, and YCbCr, and 21 texture channels obtained by the Gabor and Schmid filters on the luminance channel. The setting of the parameters of the Gabor and Schmid filters are given in [\cite=Layne]. We horizontally partitioned the image region into six strips and then extracted the above feature channels, each of which is described by a bin-size of 16. To obtain [formula] and [formula], we apply the binary mask (Fig.[\ref=fig:figParsed]) to extract features separately from the foreground and background.

Dataset: We present benchmark results on the PEdesTrian Attribute (PETA) dataset (Fig. [\ref=fig:pieComposition]), introduced by us. This dataset is the largest and most diverse pedestrian attribute dataset to date. There are 61 binary attributes covering an exhaustive set of characteristics of interest, including demographics (e.g. gender and age range), appearance (e.g. hair style), upper and lower body clothing style (e.g. casual or formal), and accessories. There are another four multi-class attributes that encompass 11 basic color namings [\cite=ColorName], respectively for footwear, hair, upper-body clothing, and lower-body clothing. We selected 35 attributes for our study, consisting of the 15 most important attributes in video surveillance proposed by human experts [\cite=Layne] [\cite=HomeOfficeUK] and 20 difficult yet interesting attributes chosen by us, covering all body parts of the pedestrian and different prevalence of the attributes. For example, the attributes 'sunglasses' and 'v-neck' have a limited number of positive examples (Table [\ref=tb:table1]). We randomly partitioned the dataset images into 9,500 for training, 1,900 for verification and 7,600 for testing.

Comparisons: We compare the performance of intersection kernel SVM (ikSVM) [\cite=Layne], MRF with Gaussian kernel (MRFg), and MRF with random forest (MRFr), as discussed in Sec.[\ref=sec:mrf]. For the attributes with unbalanced positives and negatives samples, we trained ikSVM for each attribute by augmenting the positive training examples to the same size as negative examples with small variations in scale and orientation. This is to avoid bias due to imbalanced data distribution. For MRFg and MRFr, we built the graphs using two different schemes. The first scheme, symbolized by MRFg1 and MRFr1, is to construct the graphs with only the testing images. The second one, symbolized by MRFg2 and MRFr2, is to include both training and testing samples in the graphs.

Results

Evaluating the informativeness of the parsed regions: To investigate the usefulness of foreground and background regions for attribute recognition, we first follow the previous study [\cite=layne2012towards] [\cite=Layne] that applies intersection kernel SVM (ikSVM) [\cite=Maji]. Given the extracted foreground and background regions by DDN, we evaluate different representation schemes as discussed in Sec. [\ref=sec:parsing], i.e. [formula] alone, [formula] alone, foreground and background feature concatenation [formula], and foreground and whole image feature concatenation [formula].

As shown in Table [\ref=tb:table1], we observe that simply extracting the foreground features ([formula]) results in an inferior performance than that resulted from using the whole image. It suggests that background information is critical in facilitating the detection of attributes. If we inspect the recognition results of each attribute in detail, we observe that background plays a pivotal role for recognizing 'Backpack', 'CarryingOther', 'Plastic bag', and 'No carrying' attributes. This is reasonable since the visual evidence that corresponds to these attributes is not solely captured by the pedestrian foreground region. Moreover, slight drops of accuracy are observed on cloth-style related attributes, e.g. 'Jeans' and 'Trousers', if features are only extracted from the foreground. These results all suggest that background region could provide context for better attribute recognition performance.

Extracting and concatenating features from the foreground and background ([formula]) sees a slight improvement for easy-to-spot attributes such as 'AgeAbove60', 'Casual upper wear', 'Formal upper wear', 'Hat', 'Jeans', 'Long hair', 'Male', 'Shorts', 'Skirt'; however, the performance deteriorates for other attributes due to the inevitable noise contained in the features extracted from the background. Finally, when [formula] is adopted, a significant boost in the performance is observed, even for hard-to-spot attributes like 'Leather Shoes' and 'Plastic bag'. The [formula] scheme seems to a better way to exploit the information provided by the background.

Evaluating the importance of neighborhood context: We choose the best three of the four feature extraction schemes, namely the [formula], [formula], and [formula], and evaluate our proposed MRF methodology for detecting pedestrian attributes. We report the attribute detection accuracy in Table [\ref=tb:table2] and list some further observations as follows.

Firstly, the MRF-based methods outperform ikSVM on most of the attributes (comparing Table [\ref=tb:table2] with Table [\ref=tb:table1]). For instance, MRFr2 achieves an average of 3.4% improvement over ikSVM for the 'age' attributes shown on top of the tables. This is significant in a dataset with large appearance diversity and ambiguity and it demonstrates that graph regularization can improve attribute inference. In addition, an about 5% boost of performance is observed for attributes such as 'MessengerBag', 'No accessory', 'No carrying', and 'Trousers' and we observe a near 10% boost over ikSVM for 'carryingOther' and 'Shoes'. Secondly, the MRF graphs built with the second scheme (graph constructed by both train and test samples) is superior compared to the first scheme (graph constructed by test samples only), which is reasonable as using both the training and testing data can better cover the image space. Thirdly, for many important attributes, such as 'Trousers' and 'Shoes', random forest works much better than Gaussian kernel to measure the neighborhood context.

Moreover, we observed that for our proposed MRF methods, the importance of background information as context is best exploited when using [formula] (Table [\ref=tb:table2]). This observation corresponds with the detection performance using ikSVMs (Table [\ref=tb:table1]) and we show that the best result is obtained when we use MRFr2 with [formula], which on average outperforms the [formula] scheme in our earlier preliminary result [\cite=deng2014pedestrian] by 4.4%. Fig. [\ref=fig:plot] shows some attribute recognition results using the forest MRF. The detection performance is satisfactory for most attributes. False negative samples typically result from occlusion (e.g. backpack), color ambiguity (long hair) and background noise (male). All methods perform poorly on attributes with imbalanced positive-negative distribution (see Table [\ref=tb:table1]) such as 'logo', 'stripes', 'v-neck' and 'sunglasses', which are also hard to spot by human observers.

Conclusions

In this work, a novel approach to exploit the neighborhood information among image samples with emphasis on the foreground attribute regions has been investigated and the automatically inferred pairwise graph topology has led to better performance of attribute recognition. Using the latest large-scale pedestrian attribute dataset (PETA) as the benchmark, we showed that our new MRF model with the proposed feature representation scheme is more capable to accurately detect pedestrian attributes.