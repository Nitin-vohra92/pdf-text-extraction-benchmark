LATCH: Learned Arrangements of Three Patch Codes

Introduction

The ability to effectively represent local visual information is key to a very wide range of computer vision applications. These applications range from image alignment, which requires that local image descriptors be accurately matched between different views of the same scene, to image classification and retrieval, where massive descriptor collections are frequently scanned in order to locate the ones most relevant to those of a query image. Consequently, computer vision research has devoted substantial efforts to develop and fine-tune these representations.

At the core of the problem is the challenge of extracting local representations at keypoints, typically distributed sparsely over an image, in a manner which is both discriminative and invariant to various image transformations. Additional requirements, often as important if not more, are that a representation be efficient, in terms of the computational costs required to produce it, the space required to store it, and the time required to search for matching descriptors in large descriptor repositories.

Over the past two decades, several distinct approaches for designing such descriptors have emerged. Two noteworthy designs are the distribution-based representations and the binary descriptors. Distribution-based descriptors, which include the successful SIFT [\cite=lowe2004distinctive] and HOG [\cite=dalal2005histograms] representations, represent visual information using distributions of image measurements (e.g., gradients, gradient orientations, etc.). Though proven highly effective in an ever widening range of applications, their main drawbacks are their size, the time required to produce them, and the challenges associated with efficiently searching through large numbers of such descriptors [\cite=heinly2012comparative].

Binary descriptors, on the other hand, were designed with an emphasis on minimizing computational and storage costs [\cite=alahi2012freak] [\cite=calonder2010brief] [\cite=lepetit2013boosting] [\cite=leutenegger2011brisk] [\cite=rublee2011orb] [\cite=strecha2012ldahash] [\cite=trzcinski2013learning] [\cite=trzcinski2012efficient]. These methods represent image patches using a (typically short) binary string, commonly computed by sampling and comparing pixels in the patch; different methods advocating different sampling strategies or other methods for increasing the descriptors discriminate power (e.g. boosting, discriminant projections). Though binary representations may not be as descriptive as their histogram counterparts, they make up for this shortcoming in their compact size, efficient computation, and the ability to quickly compare descriptor pairs using few processor-level instructions.

The representation presented here belongs to the latter family of descriptors. Our work is motivated by the longstanding observation that the act of sampling pixel pairs in order to compute each binary value in the representation is sensitive to noise and other changes in local appearances. Previous representations have addressed this problem by offering a number of alternative smoothing operations, which should be performed before the pixel values are sampled. Though this alleviated some of the problem, the unfortunate side effect of smoothing is, of course, the loss of information. This is particularly crucial in high-frequency regions of the image - precisely where key points are detected, and where these representations are applied.

We offer an alternative approach based on the simple notion of comparing pixel patches rather than individual pixel values (illustrated in Fig. [\ref=fig:overview]). By comparing patches, visual information with more spatial support is considered for each of the descriptor's bits, and their values are therefore less sensitive to noise. We describe a patch-triplet based approach, in which triplets of patches are compared in order to set the binary values of the representation. Informative triplet arrangements are learned beforehand using labeled training data. Thus, triplet arrangements are ordered by their contribution to the successful classification of patches as being either similar or not while refraining from selecting highly correlated triplets. The most effective arrangements of patch triplets are then used to sample and compare patches whenever the descriptor is computed.

The resulting representation, appropriately dubbed LATCH (Learned Arrangements of Three patCH codes), is evaluated extensively and shown to outperform existing alternatives by a wide margin, at the cost of a minor increase in the run-time computational requirements of extracting the descriptor. To summarize, this paper makes the following contributions.

We propose a novel binary descriptor design, intended to provide improved stability and robustness than existing related descriptors.

We show how effective descriptors can be generated by off-line, supervised learning of discriminative patch arrangements.

Extensive quantitative results and qualitative applications compare the capabilities of our LATCH representation with existing descriptors. These show LATCH to outperform other representations of its kind, significantly narrowing the performance gap between binary descriptors and histogram based methods.

In order to promote reproducibility, as well as to allow easy use of our LATCH descriptors, our implementation is available online as part of the OpenCV library. Please see  for further details.

Related Work

The development of local image descriptors has been the subject of immense research, and a comprehensive review of related methods is beyond the scope of this work. For a recent survey and evaluation of alternative binary interest point descriptors, we refer the reader to [\cite=heinly2012comparative]. Here, we only briefly review these and other related representations.

Binary descriptors. Binary key-point descriptors were recently introduced in answer to the rapidly expanding sizes of image data sets and the pressing need for compact representations which can be efficiently matched. One of the first of this family of descriptors was the Binary Robust Independent Elementary Features (BRIEF) [\cite=calonder2010brief]. BRIEF is based on intensity comparisons of random pixel pairs in a patch centered around a detected image key point. These comparisons result in binary strings that can be matched very quickly using a simple XOR operation. As BRIEF is based on intensity comparisons, instead of image gradient computations and histogram pooling of values, it is much faster to extract than SIFT-like descriptors [\cite=lowe2004distinctive]. Furthermore, by using no more than 512 bits, a single BRIEF descriptor requires far less memory than its floating point alternatives.

Building upon BRIEF's design and matching method, the Oriented fast and Rotated BRIEF (ORB) descriptor [\cite=rublee2011orb] adds rotation invariance by estimating a patch orientation based on local first order moments within the patch. Another innovation proposed by [\cite=rublee2011orb] is the use of a unsupervised learning in order to select pixel pairs, rather than the random sampling of BRIEF.

Rather than random sampling or unsupervised learning of pairs, the Binary Robust Invariant Scalable Keypoints (BRISK) [\cite=leutenegger2011brisk] use hand-crafted, concentric ring-based sampling patterns. BRISK uses pixel pairs with large distances between them to compute the patch orientation, and pixel pairs separated by short distances to compute the values of the descriptor itself, again, by performing binary intensity comparisons on pixel pairs. More recently, inspired by the retinal patterns of the human eye, the Fast REtinA Keypoint descriptor (FREAK) was proposed. Similarly to BRISK, FREAK also uses a concentric rings arrangement, but unlike it, FREAK samples exponentially more points in the inner rings. Of all the possible pairs which may be sampled under these guidelines, FREAK, following ORB, uses unsupervised learning to choose an optimal set of point pairs.

Similar to BRIEF, the Local Difference Binary (LDB) descriptor was proposed in [\cite=yang2012ldb] [\cite=yang2014ldb] where instead of comparing smoothed intensities, mean intensities in grids of [formula], [formula] or [formula] were compared. Also, in addition to the mean intensity values, LDB also compares the mean values of horizontal and vertical derivatives, amounting to 3 bits per comparison. Building upon LDB, the Accelerated-KAZE (A-KAZE) descriptor was suggested in [\cite=Alcantarilla13bmvc] where in addition to presenting a feature detector, the authors also suggest the Modified Local Difference Binary (M-LDB) descriptor. M-LDB uses the A-KAZE detector estimation of orientation for rotating the LDB grid to achieve rotation invariance and uses the A-KAZE detector's estimation of feature scale to sub-sample the grid in steps that are a function of the feature scale.

A somewhat different descriptor design approach was proposed by [\cite=strecha2012ldahash]. Their LDA-Hash representation extracts SIFT descriptors from the image, projects them to a more discriminant space and then thresholds the projected descriptors to obtain binary representations. Though the final representation is a binary descriptor, producing it requires extracting SIFT descriptors, making the representation slower than its pure binary alternatives. To alleviate some of this computational cost, the DBRIEF [\cite=trzcinski2012efficient] representation projects patch intensities directly. The projections are further computed as a linear combination of a small number of simple filters from a given dictionary. Finally, the BinBoost representation of [\cite=lepetit2013boosting] [\cite=trzcinski2013learning] also learns a set of hash functions that correspond to each bit in the final descriptor. Hash functions are learned using boosting and implemented as a sign operation on a linear combination of non linear week classifiers which are gradient based image features.

These last three representations, LDA-Hash, DBRIEF, and BinBoost, all obtain binary representations following application of filter combinations or floating-point descriptor extraction. Thus, though they claim improved performance over the original binary descriptors, they are all substantially more expensive computationally and so may therefore be unsuitable in many practical applications.

Unlike these methods, our own uses efficient patch comparisons directly. Unlike the earlier representations (i.e. BRIEF,ORB,BRISK and FREAK), rather than comparing pairs of pixels, we compare triplets of pixel patches thereby providing more spatial support for each comparison. This provides more information at each comparison, making the binary values more robust to various sources of noise. Doing so also requires redesigning the descriptor itself. Finally, in contrast to the unsupervised learning of arrangements proposed by ORB, we use supervised learning to obtain efficient patch combinations.

Local binary patterns. In a separate line of work, the Local Binary Patterns (LBP) were proposed as global (whole image) representation by [\cite=LBP2] [\cite=ojala2002multiresolution]. Since their original release, they have been successfully applied to many image classification problems, most notably of texture and face images (e.g., [\cite=ahonen2006face] and [\cite=nanni2012survey]).

LBP produces for each pixel in the image a (typically very short) binary string representation. In fact, to our knowledge, in all reports of the use of LBP 8-bit strings or less were employed. These bits, similarly to the binary descriptors, are set following binary comparisons between image pixel intensities. In the original LBP implementation, these bits were computed by using a pixel's value as a threshold, applied to its eight immediate spatial neighbors, and taking the resulting zero/one values as the 8-bit string. By using only 8-bits, each pixel is thus represented by a code in the range of

[formula]

Method

We begin with a review of binary descriptor design. Let W be a detection window, an image portion of fixed, pre-determined size, centered on a detected image key point. A binary descriptor [formula] is formed by considering an ordered set [formula] of T pairs of sampling coordinates, [formula] and [formula], given in W's coordinate frame. The selection of values for S is performed beforehand, either randomly (e.g., BRIEF [\cite=calonder2010brief]), manually (BRISK [\cite=leutenegger2011brisk]), or is automatically learned from training data (ORB [\cite=rublee2011orb] and FREAK [\cite=alahi2012freak]).

Each index t is typically associated not only with a pair of coordinates in W, but also with a pair of Gaussian smoothing kernels, [formula]. These are applied separately to W, in the pixel coordinates given by [formula], before being sampled. Thus, for each sampling pair [formula], the smoothed intensities at the two sampling points [formula] and [formula], are compared and a single bit is set according to:

[formula]

where [formula] (similarly [formula]) is the value of the image window W at coordinates [formula] ([formula]) smoothed by a Gaussian filter with standard deviation σt,1 (σt,2). The final binary string [formula], produced for image window W, is defined by

[formula]

From pixel pairs to patch triplets

As previously mentioned, the pixel pairs sampling strategy presented above, though efficient, can be susceptible to noise as each bit relies on the values of two specific pixels. Though pre-smoothing can alleviate some of this problem, it can also result in the loss of information particularly at high frequency regions where key points are often detected. As a means of ameliorating this, we propose comparing pixel patches rather than pixels. Doing so, however, requires changing how each bit's value is set and in particular, defining a binary relation between pixel patches. This is achieved by using three-way patch comparisons.

Specifically, we consider [formula] pixel patch triplets, adding the location of an "anchor" patch and redefining S as [formula]. Each of the pixel coordinates, [formula], [formula], and [formula] provides the location of the central pixel in patches of size k  ×  k pixels, denoted by [formula], for the anchor patch, and [formula], and [formula] for its "companion" patches. We then evaluate the similarity of the anchor patch [formula] to its two companions, by computing their Frobenious norm. Thus, the single binary value is produced by revising function f as follows:

[formula]

Learning patch triplet arrangements

Even small detection windows W give rise to a huge number of possible triplet arrangements. Considering that only a small number T of bits is typically required (in practice, no more than 256), we must therefore consider which of the many possible triplet arrangements should be employed. Here, rather than taking one of the three approaches described by existing binary descriptors (Sec. [\ref=sec:related]), we propose our own selection criteria.

Specifically, we use the data-set introduced in [\cite=brown2011discriminative]. It consists of three separate collections: Liberty, Notre Dame, and Yosemite. Each of these contains over 400k local image windows that were extracted around multi-scale Harris corner detections [\cite=harris1988combined]. Pairs of these windows, extracted from different images in each collection, were labeled as being "same" (the two windows present the same physical scene point, viewed from different viewpoints or viewing conditions) or "not-same". These labels were obtained by employing multi-view stereo to form correspondences between different images in each collection. These windows were then partitioned into 500k pairs of which half are labeled as same and half not-same.

We form 56k patch triplet arrangements, by random selection of the pixel coordinates [formula] of the anchor patch, and the coordinates [formula] and [formula] of its two companion patches ([formula]). We then evaluate each of these T arrangements over all the window pairs in the benchmark, giving us 500k bits per arrangement. We define the quality of an arrangement by summing the number of times it correctly yielded the same binary value for "same" labeled pairs and different values for "not-same" labeled pairs.

Arrangement selection based on this criteria may result in highly correlated arrangements being selected. To prevent this, following [\cite=alahi2012freak] [\cite=rublee2011orb], we add arrangements incrementally, skipping over those with responses highly correlated to previously selected arrangements. Specifically, a candidate arrangement is selected if its absolute correlation with all previously selected arrangements is smaller than a threshold τ. In our experiments, this value was set to τ = 0.2 and left unchanged.

We note that others have also used the data-set from [\cite=brown2011discriminative] for the purpose of learning binary descriptors (e.g. [\cite=lepetit2013boosting] [\cite=strecha2012ldahash] [\cite=trzcinski2013learning] [\cite=trzcinski2012efficient]). However, those methods differ from the one proposed here as they do not learn optimal arrangements for pixel comparison, but instead learn optimal projections or linear/non-linear filters to apply to these patches. The method presented here is simpler, yet provides comparative, or even better performance, as we later show.

Experimental results

Our LATCH extraction routine is implemented in C+  +  using OpenCV 2.0 for image processing operations. Unless otherwise noted, we used 32-byte LATCH descriptors with 7  ×  7 patches. Detection windows are 48  ×  48 pixels centered on key-points. Our tests use the efficient C+  +  descriptor implementations available from OpenCV or from their various authors, with parameter values left unchanged.

Empirical results

Comparisons are provided using a wide range of relevant alternative methods. These include the "pure"-binary descriptors: BRIEF [\cite=calonder2010brief], ORB [\cite=rublee2011orb], BRISK [\cite=leutenegger2011brisk], FREAK [\cite=alahi2012freak] and A-KAZE [\cite=Alcantarilla13bmvc]. We additionally provide results comparing LATCH to the more computationally expensive LDA-Hash [\cite=strecha2012ldahash], DBRIEF [\cite=trzcinski2012efficient] and BinBoost [\cite=lepetit2013boosting] [\cite=trzcinski2013learning] representations. Finally, the performances of SIFT [\cite=lowe2004distinctive] and SURF [\cite=bay2006surf] are also provided.

We used two standard benchmarks for our tests: the Oxford [\cite=mikolajczyk2005performance] [\cite=mikolajczyk2005comparison] and the Learning Local Image Descriptors [\cite=brown2011discriminative] benchmarks. Our tests employ the test protocols associated with these benchmarks. We additionally provide a range of tests designed to evaluate the contribution and effect of various design aspects of our LATCH descriptor.

Run times. We begin by comparing the computational costs associated with extracting the various descriptors used in our experiments. The time (ms) required to extract a single descriptor were averaged over 250K patches of different scale and orientation, taken from various images. Measurements were performed on an Intel Core i7 laptop with 16.0 GB of memory, running 64-bit Microsoft Windows 8.1.

Table [\ref=tab:RunningTimes] summarizes the measured running times. The substantial difference between the time required to extract the pure binary descriptors, including our own LATCH, and descriptors based on floating point values is clearly evident. In particular, LATCH requires an order of magnitude less time than some of these alternatives.

Oxford data-set. Originally described by [\cite=mikolajczyk2005performance] [\cite=mikolajczyk2005comparison] this set has since become the standard for evaluating descriptor design capabilities, and in particular, the capabilities of the binary descriptors discussed here (see, e.g., [\cite=alahi2012freak] [\cite=Alcantarilla13bmvc] [\cite=calonder2010brief] [\cite=leutenegger2011brisk]).

The Oxford data-set comprises of eight image sets, each with six images presenting increasing appearance variations. The appearance variations modeled by the benchmark sets are: zoom and rotation (the Boat and Bark sets), planar perspective transformations (view-point changes in the Graffiti and Wall sets), lightning changes (the Leuven set), JPEG compression (the UBC set), and increasing degrees of blur (the sets Bikes and Trees).

For each set, we compare the first image against each of the remaining five and check for correspondences. Performance is measured using the code from [\cite=mikolajczyk2005performance] [\cite=mikolajczyk2005comparison], which computes recall and 1-precision using known ground truth homographies between the images. We also provide the area under the recall vs. 1-precision curve, averaged over all five image pairs in each set.

Following the test protocol employed in, e.g., [\cite=alahi2012freak] [\cite=Alcantarilla13bmvc] [\cite=bay2006surf] [\cite=calonder2010brief] [\cite=leutenegger2011brisk] [\cite=rublee2011orb] each descriptor was extracted at image locations detected using its own original key-point detector. Our own LATCH descriptor was applied to key-points returned by the multi-scale Harris based detector used by the original SIFT implementation [\cite=lowe2004distinctive]. As some of the sets in the Oxford benchmark depict rotation changes and some do not, we implement rotation invariance by using the detected orientation, or the descriptors' own estimates when available.

Table [\ref=tab:MikolajczykResults] summarizes our results. Fig. [\ref=fig:MikolajczykGraphs] additionally provides recall vs. 1-precision curves for the datasets Bikes and Leauven. Aside from LDA-HASH and LDA-DIF which extract binary descriptors by first extracting SIFT descriptors and thus are much slower, LATCH outperforms the other binary descriptors on most of the sets and in some cases even the much larger, histogram representations, SIFT and SURF.

Learning Local Image Descriptors data-set. We next report tests on the data-set described by [\cite=brown2011discriminative]. It provides a large number of detection windows along with same/not-same labels signifying whether two windows from two separate images correspond to the same physical point or not.

The test protocol used here is designed to evaluate the discriminative power of different image descriptors. Given two windows, a descriptor is extracted for each one and the distance between the two descriptors is measured. A scalar threshold is then applied to this distance in order to determine if the two descriptors are similar enough to imply that the windows should be labeled "same" or not. We use the Yosemite dataset in order to learn an optimal threshold by using linear support vector machines (SVM) [\cite=svm]. Yosemite images were also used to learn patch triplet arrangements for the LATCH descriptor (Section [\ref=subsec:LearningTheTriplets]). Testing is performed on the Liberty and Notre-Dame sets.

Table [\ref=tab:sameNotSameResults] summarizes the results in terms of accuracy, area under the ROC curve and 95% error-rate (the percent of incorrect matches obtained when 95% of the true matches are found). ROC curves for the different methods tested are presented in Fig [\ref=fig:SameNotSameGraphs]. Our results show the clear advantage of the proposed LATCH descriptor over other binary descriptor designs, with LATCH outperforming the other representations, in both tests, by noticeable margins. Although BinBoost and LDA-HASH/DIF perform better than LATCH on these tests, as previously noted, this added performance comes at substantial computational costs.

Analysis: Varying descriptor size. In the tests reported above, we used a LATCH descriptor of 32 bytes. Here, we revisit the tests on the Oxford benchmark in order to evaluate the effect descriptor size has on its performance. We test varying descriptor sizes (the number of arrangements used) using 4, 8, 16, 32, and 64 bytes for the representation. Table [\ref=tab:analysis] (a) summarizes our results, providing the area under the recall vs. 1-precision curve. Clearly, the performance of LATCH improves as its size grows. These results can be compared with those of Table [\ref=tab:MikolajczykResults].

Analysis: Varying patch size. One of the key components of the LATCH descriptor is the use of pixel patches compared to sampling single pixels. We next evaluate the effect of larger pixel patches on the performance of LATCH. Here, we use a 32 byte LATCH representation, testing it with patches of sizes 3  ×  3, 5  ×  5, 7  ×  7, 9  ×  9, 11  ×  11, 13  ×  13 and 15  ×  15.

We report also the performance of a simpler LATCH variant, which is computed by comparing pixel triplets, rather than patch triplets (LATCH 1  ×  1). Similarly to ORB, in order to handle noise pixel values are sampled following the same local smoothing. Extracting larger-patch LATCH descriptors following smoothing brought performance further down, and so we do not report these results.

Our results, summarized in Table [\ref=tab:analysis] (b) demonstrate that larger patches provide more accuracy. In nearly all cases, the bigger the patches used, the higher the performance gain. The relative improvement in performance, however, decays with patches larger than 9  ×  9 or 11  ×  11. Here too, these results may be compared with those presented in Table [\ref=tab:MikolajczykResults], where LATCH was computed using 7  ×  7 patches.

It is worthwhile to consider the performance of LATCH 1  ×  1. Evidently, this approach almost always provides inferior results even to LATCH extracted using 3  ×  3 patches. With the default 7  ×  7 patches, LATCH performance is significantly better than sampling single pixels.

Analysis: Comparing learning methods. As discussed in [\ref=subsec:LearningTheTriplets], we propose supervised learning of optimal patch arrangements. The same approach can of course be applied to learning optimal pairs. We compare the proposed approach to that of ORB [\cite=alahi2012freak] [\cite=rublee2011orb] and also present the performance of the combined method in which the quality of the triplets is measure by their score on the "same"/"not-same" dataset, filtering out correlated triplets.

Table [\ref=tab:analysis] (c) presents results on the Oxford benchamark and Table [\ref=tab:LearningMethodBrown] on the Learning Local Descriptors set. Evidently, overall, the proposed learning method outperforms the learning method of [\cite=alahi2012freak] [\cite=rublee2011orb], and the combined method outperforms both. Unsurprisingly, random selection of patch triplets performs much worse than either of these.

Application to multi-view 3D reconstruction

One of the more challenging uses of local descriptors lies in structure from motion (SfM) applications. In order to produce accurate results, local appearances must be matched across images of the same scene, taken from possibly widely different views. Additionally, SfM methods often compare many comparisons between many interest points, and hence the efficiency of matching descriptors is also a matter of concern.

We test the use of our proposed LATCH descriptor in a SfM framework, comparing it to the SIFT descriptor often used for this purpose. To this end, we have incorporated LATCH into the OpenMVG library [\cite=moulon2013adaptive] using their incremental structure from motion chain method. We ran SfM twice, changing only the local image representations from their default SIFT to our own LATCH descriptors.

In order to isolate the effect of using LATCH rather than SIFT, both use the same key-points, recovered by the SIFT detector implemented in the VLFeat library [\cite=vedaldi08vlfeat]. All OpenMVG parameters were kept at their default values apart from the ratio threshold which was 0.6 for SIFT (the default), and raised to 0.99 for LATCH (binary descriptors in general are known to be more sensitive to this value).

Reconstruction results for standard test image sequences [\cite=moulon2013adaptive] are provided in Fig. [\ref=fig:SFM] and the time required to match the descriptors in each scene is provided in Table [\ref=tab:SFMruntime]. We note that denser surfaces could conceivably be produced by running a multi-view stereo algorithm, e.g. the Patch-based Multi-View Stereo (PMVS) method of [\cite=furukawa2010accurate], following the initial reconstructions. Doing so, however, may correct errors due mismatching descriptors. We focus on the quality of the descriptors, not the final reconstruction, and so this step was not performed here.

Evidently, 3D reconstructions obtained by using both descriptors are qualitatively comparable. The time required to match our LATCH descriptors, however, is consistently an order of magnitude faster than SIFT.

Conclusions

Over the years, the computer vision community has invested immense efforts in a continuing effort to improve the performance of local descriptors, including the requirements they make on storage, extraction and matching time. As part of this effort, we propose a new variant to the binary descriptors representation family. Our LATCH representation enjoys the same fast matching time and small storage requirements of binary descriptors. Our tests, however, demonstrate that it outperforms other binary descriptors by wide margins, closing the gap between their performance and the performance reported by the much larger, more expensive histogram based representations.

At the heart of our representation lies the observation that by sampling individual pixel pairs, previous descriptors may be at risk of being too sensitive to noise and other local changes in appearance. Instead, we consider comparisons of pixel patches. In order to provide meaningful comparisons, we propose comparing patch triplets, rather than pixel pairs, and provide a means for selecting triplets which provide the most discriminative capabilities. We test this representation extensively and provide a comprehensive comparison with other similar representations.