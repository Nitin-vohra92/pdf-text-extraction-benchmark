Identifying the Spectral Representation of Hilbertian Time Series

Introduction

In this paper, we provide theoretical results regarding estimation of the spectral representation of the covariance operator of stationary Hilbertian time series. This is a generalization of the method developed in [\cite=bathia2010identifying] to a setting of random elements in a separable Hilbert space. The approach taken in [\cite=bathia2010identifying] relates to functional pca and, similarly to the latter, relies strongly on the Karhunen-Loève (K-L) Theorem. The authors develop the theory in the context of curve time series, with each random curve in the sequence satisfying the conditions of the K-L Theorem which, together with a stationarity assumption, ensures that the curves can all be expanded in the same basis - namely, the basis induced by their zero-lag covariance function. The idea is to identify the dimension of the space M spanned by this basis (finite by assumption), and to estimate M, when the curves are observed with some degree of error. Specifically, it is assumed that the statistician can only observe the curve time series [formula], where whereas the curve time series of interest is actually [formula]. Here Yt, Xt and εt are random functions (curves) defined on [formula]. Estimation of M in this framework was previously addressed in [\cite=hall2006assessing] assuming the curves are iid (in t), a setting in which the problem is indeed unsolvable in the sense that one cannot separate Xt from εt. [\cite=hall2006assessing] propose a Deus ex machina solution which consists in assuming that εt goes to 0 as the sample size grows. [\cite=bathia2010identifying] in turn resolve this issue by imposing a dependence structure in the evolution of [formula]. Their key assumption is that, at some lag k, the k-th lag autocovariance matrix of the random vector composed by the Fourier coefficients of Xt in M, is full rank. In our setting this corresponds to Assumption [\ref=thm:bathia-thm-1-A1] (see below).

In [\cite=bathia2010identifying] it is assumed that each of the stochastic processes [formula] satisfy the conditions of the K-L Theorem (and similarly for εt), and as a consequence the curves are in fact random elements with values in the Hilbert space [formula]. Therefore, since every separable Hilbert space is isomorphic to [formula], the idea of a generalization to separable Hilbert spaces of the aforementioned methodology might seem, at first, rather dull. The issue is that in applications transforming the data (that is, applying the isomorphism) may not be feasible nor desirable. For instance, the isomorphism may involve calculating the Fourier coefficients in some 'rule-of-thumb' basis which might yield infinite series even when the curves are actually finite dimensional.

The approach that we take here relies instead on the key feature that a centered Hilbertian random element of strong second order, lies almost surely in the closed linear span of its corresponding covariance operator. This result allows one to dispense with considerations of 'sample path properties' of a random curve by addressing the spectral representation of a Hilbertian random element directly. In other words, the Karhunen-Loève Theorem is just a special case of a more general phenomena. The result below (which motivates - and for that matter, justifies - our approach) is not a new one: it appears, for example, in a slightly different guise as an exercise in [\cite=vakhania1987probability]. However, it is in our opinion rather overlooked in the literature. The proof that we give is straightforward and, to our knowledge, a new one. In this paper H is always assumed to be a real Hilbert space, but with minor adaptations all stated results hold for complex H.

Let H be a separable Hilbert space, and assume ξ is a centered random element in H of strong second order, with covariance operator R. Then [formula] almost surely.

In the conditions of Theorem [\ref=thm:xi-orthogonal-ker], let [formula] be the (possibly finite) non-increasing sequence of nonzero eigenvalues of R, repeated according to multiplicity, and let [formula] denote the orthonormal set of associated eigenvectors. Then

[formula] in H, almost surely;

[formula] in [formula].

Moreover, the scalar random variables 〈ξ,φi〉 and 〈ξ,φj〉 are uncorrelated if i  ≠  j, with [formula].

Proofs to the above and subsequent statements are given in Appendix [\ref=sec:proof]. We can now adapt the methodology of [\cite=bathia2010identifying] to a more general setting.

The model

In what follows [formula] is a fixed complete probability space. Consider a stationary process [formula] of random elements with values in a separable Hilbert space H. Here [formula] is either [formula] or [formula]. We assume throughout that ξ0 is a centered random element in H of strong second order. Of course, the stationarity assumption ensures that these properties are shared by all the ξt. Now let denote the k-th lag autocovariance operator of [formula], and let [formula] be the (possibly finite) non-increasing sequence of nonzero eigenvalues of R0, repeated according to multiplicity. Here either [formula] or, whenever R0 is of rank d <   ∞  , [formula]. Now for j∈J, let φj∈H be defined by and assume the set [formula] is orthonormal in H. Corollary [\ref=thm:hilbert-representations] and the stationarity assumption ensure that the spectral representation holds almost surely in H, for all t, where the Ztj: = 〈ξt,φj〉 are centered scalar random variables satisfying [formula] for all t, and [formula] if i  ≠  j. In applications, an important case is that in which the above sum has only finitely many terms: that is, the case in which R0 is a finite rank operator. In this setting, the stochastic evolution of [formula] is driven by a vector process [formula], where [formula], in [formula] (here d is the rank of R0). The condition that R0 is of finite rank models the situation where the data lie (in principle) in an infinite dimensional space, but it is reasonable to assume that they in fact lie in a finite dimensional subspace which must be identified inferentially.

We are interested in modeling the situation where the statistician observes a process [formula] of H-valued random elements, and we shall consider two settings; the simplest one occurs when

[formula]

This is to be interpreted as meaning that perfect measurements of a 'quantity of interest' ξt are attainable. A more realistic scenario would admit that associated to every measurement there is an intrinsic error - due to rounding, imprecise instruments, etc. In that case observations would be of the form

[formula]

In fact, the latter model nests the 'no noise' one if we allow the εt to be degenerate. Equation [\eqref=eq:noisy-measurement] is analogous to the model considered in [\cite=hall2006assessing] and in [\cite=bathia2010identifying]. Here [formula] is assumed to be noise, in the following sense:

In the above setting, for h,f∈H one has [formula] and thus estimation of R0 via a sample [formula] is spoiled (unless the εt are degenerate). This undesirable property has been addressed by [\cite=hall2006assessing] and [\cite=bathia2010identifying] respectively in the iid scenario and in the time series (with dependence) setting. The clever approach by [\cite=bathia2010identifying] relies on the fact that [formula] (lagging filters the noise) and therefore R1 can be estimated using the data [formula]. Now an easy check shows that [formula]. The key assumption in [\cite=bathia2010identifying] is asking that this relation hold with equality:

[formula].

Consider the operator [formula], where *   denotes adjoining. It is certainly positive, and compact (indeed nuclear) since [formula]. Let [formula] be the (possibly finite) non-increasing sequence of nonzero eigenvalues of S, repeated according to multiplicity, and denote by [formula] the orthonormal set of associated eigenvectors. Under Assumption [\ref=thm:bathia-thm-1-A1] we have J' = J, and the representation is seen to hold, for all t, almost surely in H for centered scalar random variables Wtj  =  〈ξt,ψj〉. Again, when R0 is finite rank, say [formula], then the stochastic evolution of ξt is driven by the finite-dimensional vector process [formula], where [formula].

Main results

Before stating our result, let us establish some notation. Define the estimator [formula], where R̂1 is given by Notice that R̂1 is almost surely a finite rank operator, say of rank q, with q  ≤  n - 1 almost surely, and thus Ŝ is also of finite rank q. Let [formula] denote the non-increasing sequence of eigenvalues of Ŝ, repeated according to multiplicity. Clearly j  =  0 if j  >  n - 1. Denote by [formula] the orthonormal basis of associated eigenfunctions. Also, for a closed subspace V  ⊂  H, let ΠV denote the orthogonal projector onto V. Let [formula], and for conformable k put [formula].

Let [\ref=thm:bathia-thm-1-A1] and the following conditions hold.

[formula] is strictly stationary and ψ-mixing, with the mixing coefficient satisfying the condition [formula];

[formula], for all t;

εt and ξs are strongly orthogonal, for all t and s.

Then,

[formula];

[formula].

Moreover, if

[formula] is one-dimensional, for each nonzero eigenvalue θj of S,

holds, then

[formula].

If additionally S is of rank d  <    ∞  , then

[formula], for all j  >  d;

[formula], for all j  >  d.

Let Assumptions [\ref=thm:bathia-thm-1-A1]-[\ref=thm:bathia-thm-1-A4] hold. Let [formula] and [formula]. Then,

[formula], for all j such that Nj is one-dimensional;

if S is of rank d  <    ∞  , then [formula];

if S is of rank d  <    ∞  , there exists a metric ρ on the collection of finite-dimensional subspaces of H such that [formula].

Concluding remarks

In this paper we have provided consistency results regarding estimation of the spectral representation of Hilbertian time series, in a setting with imperfect measurements. This generalizes a result from [\cite=bathia2010identifying]. The generalization relies on an important property of centered random elements in a separable Hilbert space - see Theorem [\ref=thm:xi-orthogonal-ker]. Further work should be directed at obtaining a Central Limit Theorem for the operator Ŝ, which would have the important consequence of providing Central Limit Theorems for its eigenvalues (via Theorem 1.2 in [\cite=mas2003perturbation]), potentially allowing one to propose statistical tests for these parameters. The term 'spectral' in the title of this work refers, of course, to the spectral representation of the operator S and not to the spectral representation of the time series [formula] in the usual sense.

Notation and mathematical background

As in the main text we let [formula] denote a complete probability space, i.e. a probability space with the additional requirement that subsets N  ⊂  Ω with outer probability zero are elements of [formula]. Let H be a separable Hilbert space with inner-product 〈  ·  ,  ·  〉 and norm ||  ·  ||. A Borel measurable map ξ:Ω  →  H is called a random element with values in H (also: Hilbertian random element). For q  ≥  1, if [formula] we say that ξ is of strong order q and write [formula]. In this case, there is a unique element hξ∈H satisfying the identity [formula] for all f∈H. The element hξ is called the expectation of ξ and is denoted be [formula]. If [formula] we say that ξ is centered. If ξ and η are centered random elements in H of strong order 2, they are said to be (mutually) strongly orthogonal if, for each h,f∈H, it holds that [formula].

Denote by [formula] the Banach space of bounded linear operators acting on H. Let [formula]. If for some (and hence, all) orthonormal basis [formula] of H one has [formula], we say that A is a Hilbert-Schmidt operator. The set [formula] of Hilbert-Schmidt operators is itself a separable Hilbert space with inner-product [formula], with [formula] being the induced norm. An operator [formula] is said to be nuclear, or trace-class, if T  =  AB for some Hilbert-Schmidt operators A and B. If [formula], its covariance operator is the nuclear operator [formula], h∈H. More generally, if [formula], their cross-covariance operator is defined, for h∈H, by [formula]. In the main text we denote by Rk the cross-covariance operator of ξ0 and ξk.

For a survey on strong mixing processes, including the definition of ψ-mixing in Assumption [\ref=thm:bathia-thm-1-A2], we refer the reader to [\cite=bradley2005basic].

Proofs

Let (ej) be a basis of ker (R). It suffices to show that [formula] for each j. Indeed, this implies that there exist sets Ej, [formula] and 〈ξ(ω),ej〉 = 0 for ω∉Ej. Thus 〈ξ(ω),ej〉 = 0 for all j as long as [formula] with [formula]. But [formula].

Item [\ref=theorem-lemma-hilbert-representations-item-1] is just another way of stating the Lemma. For item [\ref=theorem-lemma-hilbert-representations-item-2], first notice that the functions ω  ↦  〈ξ(ω),φj〉φj, j∈J, form an orthogonal set in [formula] (although not orthonormal). We must show that [formula]. Let [formula]. By item [\ref=theorem-lemma-hilbert-representations-item-1] gn(ω)  →  0 almost surely. Also, [formula]. So g2n(ω)  →  0 and [formula]. Now apply Lebesgue's Dominated Convergence Theorem.

One only has to consider an isomorphism [formula]. The proof is the same as in [\cite=bathia2010identifying].

See the proof of Theorem 2 in [\cite=bathia2010identifying].

The hypothesis that ξ is centered in Theorem [\ref=thm:xi-orthogonal-ker] cannot be weakened, as the following simple example shows. Let [formula] and let ξ = (ξ1,ξ2) where ξ1 is a (real valued) standard normal and ξ2 = 1 almost surely. Then [formula] is the matrix with all entries equal to zero except for R11 which is equal to 1, and obviously one has [formula].