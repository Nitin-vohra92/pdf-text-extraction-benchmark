=1

Proposition

Unit-free and robust detection of differential expression from RNA-Seq data

Introduction

Ultra high-throughput sequencing of transcriptomes (RNA-Seq) is a widely used method for quantifying gene expression levels due to its low cost, high accuracy and wide dynamic range for detection [\citep=Mortazavi2008]. As of today, modern ultra high-throughput sequencing platforms can generate hundreds of millions of sequencing reads from each biological sample in a single day. RNA-Seq also facilitates the detection of novel transcripts [\citep=Trapnell2010] and the quantification of transcripts on isoform level [\citep=Jiang2009] [\citep=Salzman2011]. For these reasons, RNA-Seq has become the method of choice for assaying transcriptomes [\citep=Wang2009].

In a typical RNA-Seq experiment, mRNA transcripts are extracted from biological samples, reverse transcribed into cDNA molecules, randomly fragmented into pieces, filtered based on fragment lengths (size selection), linked with sequencing adapters and finally processed by a sequencer. The data output by the sequencer are sequenced reads (or reads for short), from either one end (i.e., single-end sequencing) or both ends (i.e., paired-end sequencing) of the fragments. These reads are usually aligned to reference transcripts or genomes and the data are then summarized as read counts for each transcript in each sample. Complications may occur when reads cannot be uniquely aligned to reference transcripts or genomes, either due to sequence homology among genes, or due to multiple transcripts (isoforms) sharing commons regions (exons) within a single gene. In this paper, we will ignore these complications and assume that each gene has only one transcript and therefore we will use terms "gene" and "transcript" interchangeably. We will also assume that each read can be uniquely aligned to a single gene, and we take read counts for each gene in each sample as our data. However, our approach can work with estimated read counts or gene expression levels from methods developed to handle these complications such as [\citet=Jiang2009] and [\citet=Li2010a]. An overview of these methods is given in [\citet=Pachter2011].

One major limitation of RNA-Seq is that it only provides relative measurements of transcript abundances. Because reads are sequenced from a random sample of transcript fragments, changing the total amount of transcripts in a sample will have little effect on the distribution of finally sequenced reads. Furthermore, longer transcripts will generate more fragments which will subsequently result in more reads, and sequencing with higher depth will also lead to more reads for every transcript. To account for these factors, several data summarization units (a.k.a. within-sample normalization methods) for transcript quantification have been proposed in the past to account for different sequencing depths across samples and possibly also for different transcript lengths across genes, which include CPM/RPM (counts/reads per million) [\citep=Robinson2010a], RPKM/FPKM (reads/fragments per kilobase of exon per million mapped reads) [\citep=Mortazavi2008] [\citep=Trapnell2010] and TPM (transcript per million) [\citep=Li2010a]. Since a "read" can refer to either a single-end read or a paired-end read, depending on the sequencing experiment conducted, we will use the term RPKM to represent both RPKM and FPKM in this paper. Suppose that there are a total of m genes in the sample. For [formula], let li be the length (often measured as the effective length after adjusted for edge effects) of gene i and let ci be the observed read count for gene i in the sample. CPM (denoted as cpmi), RPKM (denoted as rpkmi) and TPM (denoted as tpmi) values for gene i are defined as follows, respectively

[formula]

In the past, all these methods have been used (with RPKM being the most widely used one) for quantifying gene expression levels from RNA-Seq data. It has been argued that TPM should be used instead of RPKM since TPM estimates the relative molar concentration of transcripts in a sample [\citep=Wagner2012]. However, none of these methods can be used directly to detect differentially expressed (DE) genes reliably without a further between-sample normalization step, which is necessary to make gene expression measurements comparable across samples. Different between-sample normalization methods make different assumptions on the distribution of gene expression levels across samples. For instance, quantile normalization [\citep=Bolstad2003] assumes that the overall distributions of gene expression levels are the same for all the samples. In this sense, both RPKM and TPM can be considered as between-sample normalization methods when they are used directly to detect DE genes without additional normalization - TPM assumes that the total numbers of transcripts (i.e., total molar amount) are the same for all the samples and RPKM assumes that the total numbers of nucleotides in all the transcripts (i.e., total physical mass) are the same for all the samples, both of which are strong but arguably reasonable assumptions.

To understand the limitation of between-sample normalization, consider a simple hypothetical example of comparing gene expression profiles of two samples A and B. If 60% of the genes were up-regulated by 2-fold in sample B while the other 40% of the genes stayed stable in both samples, due to the relative nature of RNA-Seq measurements, it is impossible to distinguish it from the scenario where the first group of 60% genes actually stayed stable but the second group of 40% gene were down-regulated by 2-fold in sample B. Since the problem is non-identifiable in such cases, the normalization approach has to rule out the ambiguities based on its assumptions. One commonly used assumption is that the majority (i.e., > 50%) of the genes are non-DE. The median-based approach [\citep=Anders2010] and TMM (trimmed mean of M values) [\citep=Robinson2010a] are two normalization methods based on this assumption. Furthermore, between-sample normalization and detection of DE gene are two problems that are always tangled together, since ideally normalization should be based on non-DE genes only. The iterative normalization approach [\citep=Li2012] utilizes this idea and iterates between normalization and detection of DE genes. However, it is unclear what objective function is optimized in such an approach, and the final solution often depends on the initial guess which is undesirable. For an overview of between-sample normalization approaches and comparison of their performance for detection of DE genes, please refer to [\citet=Dillies2013] [\citet=Rapaport2013].

Fortunately, the example described above is rather extreme and unrealistic, because in practice genes rarely change at the same pace - it is unlikely that all the DE genes are up-regulated by the same amount (2-fold in the above example). Therefore, a practical assumption is that among DE genes, the degrees at which genes change have an unknown but spreaded distribution. This assumption, while largely ignored by most existing approaches, will be exploited in this paper.

In this paper, we will propose a unified statistical model for joint detection of differential gene expression and between-sample normalization. We will introduce the model and an efficient algorithm for model fitting in Section [\ref=sec:model]. Comparisons with existing methods will be given in Section [\ref=sec:experiments], followed by discussions in Section [\ref=sec:discussion].

A penalized likelihood approach

The model

Suppose there are a total of m genes measured in S groups of experiments with [formula] samples, respectively. Let [formula] be log-transformed gene expression measurements (a small positive number is usually added before taking logarithm) for the i-th gene from the j-th sample in the s-th group. The following statistical model is assumed

[formula]

where μsi is the mean of log-transformed expression levels of gene i in group s, dsj is a scaling factor (e.g., log () or log ()) for sample j in group s and σ2i is the variance of log-transformed expression levels of gene i across all S groups. Here we assume that the log-transformation stabilizes the variances and makes them roughly the same across groups (yet can still be different across genes). Nevertheless, our model can be extended to accommodate heteroscedastic variances across groups.

Our main interest is in detecting differentially expressed (DE) genes across the S groups. Let τi be the indicator of differential expression for gene i such that τi = 1 if gene i is differentially expressed across the S groups and τi = 0 otherwise, i.e., [formula] where 1(  ·  ) is the indicator function. The parameters of major interest are {τi}mi = 1, while μsi,dsj and σ2i might be of interest too, because they denote biologically meaningful quantities.

It can be easily shown that due to the log-transformation on the data, our method is independent of the unit (i.e., counts, CPM/RPM, RPKM/FPKM or TPM) in which gene expression levels are summarized, which is a desirable property in practice.

Penalized likelihood

For now, we assume that {σ2i}mi = 1 are known. In practice, we solve for σ2i using an ad hoc approach, which will be described later.

To fit model ([\ref=model]), we reparametrize μsi as [formula]. Then the model becomes

[formula]

To fit model ([\ref=model2]), we minimize its negative log-likelihood

[formula]

where the term [formula] is discarded as it does not contain any unknown parameter when σ2i is known. Model ([formula]) is non-identifiable because we can simply add any constant to all the dsj's and subtract the same constant from all the μi's, while having the same fit for l(  ·  ). To resolve this issue, we fix d11 = 0. Furthermore, we introduce a penalty p(γ) on all the γsi's and formulate a penalized likelihood

[formula]

Commonly used penalty functions for p(γ) are L1 (a.k.a. lasso) [\citep=Tibshirani1996], L0, SCAD [\citep=Fan2001] and etc. The penalty function will force some γsi's to become zero, which will in turn facilitate the detection of DE genes since by definition [formula].

Let [formula] be the total sample size. There are mn observations and mS + n - 1 free parameters in the model, and typically we can have n in tens or hundreds and m in tens of thousands. Using an L1 penalty, it will be computationally intensive if we fit the model using a lasso solver such as Glmnet [\citep=Friedman2010], and typically it will be computationally even more challenging to fit the model with a non-convex penalty such as L0 or SCAD. Fortunately, we can take advantage of the structure in model ([\ref=model2]) and solve it efficiently. In this paper we work with the L0 penalty due to its robustness in estimation and variable selection

[formula]

where [formula] are tuning parameters. The approach to choose {αi}mi = 1 will be described later. Our model fitting approach can also be adapted to accommodate other penalty functions.

Model fitting

It can be shown that the solution to ([\ref=penalized_likelihood]) with penalty ([\ref=L0]) can be obtained as follows (see Appendix for details).

Model ([\ref=penalized_likelihood]) with penalty ([\ref=L0]) can be solved as follows

[formula]

γ = { .

[formula]

(1/n)n(μ-d)

[formula]

The only computationally intensive step in Proposition [\ref=solution] is to solve for [formula], for which the following function is minimized

[formula]

Typically, function G(  ·  ) is non-convex and non-differentiable, and therefore very difficult to minimize. However, in low-dimensional cases, function G(  ·  ) can be minimized efficiently using exhaustive search. Examples with S = 2 and S = 3 are given in Figure [\ref=two-min-d] (where [formula], a variation of G(  ·  ) is shown; see Section [\ref=subsec:twogroup] for details) and Figure [\ref=three-min-d], respectively.

Choosing αi

Choosing the tuning parameters in a penalized regression model is usually very tricky because it involves the bias-variance tradeoff [\citep=Hastie2009]. In practice, cross-validation can often achieve reasonable performance, at the cost of additional computation and less robustness. Fortunately, there is a simple way to choose the tuning parameters in our model, which is based on the property of the solution in Proposition [\ref=solution]. Let ysij = xsij - dsj denote the normalized data. Then

[formula]

is the mean of ysij for gene i in group s. The condition for γsi = 0 in Proposition [\ref=solution] can be rewritten as

[formula]

whose LHS mimics the form of the F-statistic for one-way ANOVA models, which suggests we choose αi as ((S - 1) / 2)F*1 - q(S - 1,n - S), where F*1 - q(  ·  ) is the critical value for one-sided level q tests with the F-distribution. We set q = 0.01 in our experiments.

Simplification for two-group comparison

Here we study the simplest case of two-group comparison, which is the most widely used experimental design for differential gene expression study. For S = 2, the condition for γ2i = 0 is

[formula]

which can be rewritten as

[formula]

where

[formula]

is a tuning parameter that is alternative to and more convenient than αi. Therefore, the solutions for d2 (denoted as d for simplicity), γ2i (denoted as γi for simplicity) and μi in Proposition [\ref=solution] can be simplified as

[formula]

[formula]

[formula]

Similarly, the condition for γi = 0 can be rewritten as

[formula]

whose LHS mimics the form of the t-statistic for two-sample comparison with pooled variance, which suggests we choose λi as [formula], where [formula] is the critical value for two-sided level q tests with the t-distribution. The corresponding value for αi is [formula] which is the same as ((S - 1) / 2)F*1 - q(S - 1,n - S) suggested in Section [\ref=subsec:alpha].

Solving for {σ2i}mi = 1

To solve for {σ2i}mi = 1, consider the negative log-likelihood function (with {σ2i}mi = 1 being unknown parameters as well) for model ([\ref=model]) restricted to group s

[formula]

Taking partial derivatives of ls(  ·  ) with respect to μsi,dsj and σ2i respectively and setting the partial derivatives to be zero, we have

[formula]

[formula]

[formula]

Estimates for μsi,dsj and σ2i can then be iteratively updated using the above three equations until converge, which is similar to the method of iteratively reweighted least squares for two-way ANOVA models with heteroscedastic errors. In our implementation, we use the following modified equation for updating σ2i to reduce the estimation bias.

[formula]

Same as before, we fix ds1 = 0 and adjust the remaining dsj's and μsi's accordingly after each iteration to resolve the non-identifiability issue. Note that μsi and dsj estimated here are for group s only and therefore will be discarded. They should be be confused with the parameters estimated from model ([\ref=model]) based on the data from all the groups.

Denote the variance estimated using the above iterative algorithm for gene i in group s as s2si. We take a weighted average of {s2si}Ss = 1 to pool information from all the groups

[formula]

Then we take another weighted average of s2i and the estimated mean variance across all the genes to obtain a robust estimate for σ2i. That is

[formula]

where [formula], and the weight w is calculated using the following formula as suggested in [\citet=Ji2005] which is based on an empirical Bayes approach

[formula]

This kind of variance estimation approach is widely used in differential gene expression analysis with small sample sizes [\citep=Ji2010] [\citep=Smyth2004]. Using the estimated variances [formula], we can then solve for ds, γsi and μi as described in Proposition [\ref=solution].

Experiments

Simulation of two-group data

We simulate RNA-Seq data with a total of m = 1000 genes (700 non-DE genes, 300 DE genes) in two-group as follows

[formula]

We use log csij as data to fit our model. The fitted {γi}mi = 1 are plotted in Figure [\ref=gamma]a. Using CPM, RPKM or TPM values computed with formulas in ([\ref=units]) yield the same result. To demonstrate the robustness of our method, we also simulate with 300 non-DE genes and 700 DE genes. Furthermore, for DE genes we simulate with μ2i  =  μ1i + N(1,1), which means that the average log-fold change is 1. Our method still robustly estimates the γi's (Figure [\ref=gamma]b). We further simulate with 100 non-DE genes and 900 DE genes, for which our method still achieves robust estimates when we simulate with μ2i  =  μ1i + N(1,1) (Figure [\ref=gamma]c). Only when we simulate with 900 DE genes and with μ2i  =  μ1i + N(3,1), our method fails to achieve robust estimates (Figure [\ref=gamma]d).

Comparison with existing methods

We compare our method (named rSeqRobust) with edgeR-robust [\citep=edgeR] [\citep=edgeR-robust], DESeq2 [\citep=DESeq2], and limma-voom [\citep=limma] [\citep=limma-voom], all of which are state-of-the-art methods for detecting differential gene expression from RNA-Seq data. We use two-group RNA-Seq data with a total of m = 1000 genes, and n1 = n2 = 4 samples in each group. We simulate both log-normally distributed read counts, which is the model assumptions of limma-voom and rSeqRobust, as well as negative-binomially distributed read counts, which is the underlying assumption of edgeR-robust and DESeq2. The distributions of gene expression levels and the distributions of library sizes for both simulations, as well as the distributions of read count dispersions for the negative-binomial simulation, are based on a real RNA-Seq dataset [\citep=Pickrell2010]. In the log-normal simulation, log read counts are assumed to be normally distributed with σ = 0.5.

The read counts are simulated using the simulator described in [\citep=edgeR-robust]. We slightly modify the simulator to allow log-normally distributed data, as well as variable fold changes. We simulate data sets with 30% or 70% DE genes, as well as 50%, 70% or 90% up-regulated genes among all the DE genes. The log-fold change for DE genes (when measured as up-regulation from one group to the other) are assumed to be distributed as [formula]. We calculate AUCs for DE gene detection using all four methods, and summarize the results in Tables [\ref=tab:LN] and [\ref=tab:NB], respectively. For each parameter setting, the highest AUC value is shown in bold font. We can see that rSeqRobust is the best in log-normal simulations, and rSeqRobust and edgeR-robust are the best in negative-binomial simulations, which are expected. In particular, when rSeqRobust is outperformed by other methods, it is usually by only a small margin (i.e., with in one standard error) and only in relatively easier cases. In the most difficult cases, rSeqRobust outperform other methods by a relatively larger margin.

Discussion

It is shown in our simulations that our proposed approach is able to reliably normalize the data and detect differential expression in some cases when more than half of the genes are differentially expressed in an asymmetric manner. This is hard to achieve with other robust methods such as the median or trimmed mean based normalization approaches [\citep=Anders2010] [\citep=Robinson2010a]. This is attributed to the L0-penalized likelihood used by our model. Typically L0-penalized models are difficult to fit due to their non-convexity. However in our case it is easily manageable once we reduce the model fitting to a univariate or bivariate optimization problem. Adding an L0 penalty p(γ) results in hard thresholding on γ, which has been shown to be a general case in [\citet=She2011]. The hard thresholding facilitates the inference on indicators {τi}mi = 1 for differential gene expression.

The R program for generating the results in this paper is available at .

Appendix

We have

[formula]

Therefore

[formula]

which gives

[formula]

Consequently

[formula]

Since we fix d11 = 0, we have [formula]. Similarly, we have

[formula]

Denote ds1 as ds, [formula], we have d1 = d11 = 0 and [formula]. Now we have

[formula]

which can be written as

[formula]

where the μi's and the γsi's can all be considered as functions of [formula]. Here we first work out these functions, i.e., solutions for the μi's and the γsi's when the ds's are considered fixed. Fixing [formula], f can be minimized by minimizing each hi separately. When [formula], hi is easily minimized by

[formula]

and

[formula]

Similarly, when [formula], i.e., [formula], we have

[formula]

Changing from [formula] to [formula], the increase in the maximum achievable value of hi is

[formula]

which is a quadratic function of [formula]. Therefore

[formula]

Now we only need to solve for [formula]. We have

[formula]

which can be simplified as

[formula]

since [formula] is actually not a function of [formula]. Therefore,

[formula]