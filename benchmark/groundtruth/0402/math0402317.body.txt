Lemma Proposition Definition Corollary

Elements of harmonic analysis, 2

These informal notes are based on a course given at Rice University in the spring semester of 2004, and much more information can be found in the references.

Preliminaries

Let n be a positive integer, and let [formula], [formula] denote the usual real and complex vector spaces consisting of n-tuples of real and complex numbers, using coordinatewise addition and scalar multiplication. Of course any real linear transformation from [formula] into itself can be extended to a complex-linear transformation from [formula] to itself in a simple way. Similarly, a real-linear mapping from [formula] into [formula] or [formula] can be extended to a complex-linear mapping into [formula].

If a is a complex number, then a can be written as a1  +  i  a2, where a1, a2 are real numbers. We call a1, a2 the real and imaginary parts of a, which may be written as [formula], [formula]. The complex conjugate of a is the complex number defined by

[formula]

One can easily verify that

[formula]

for all [formula].

The absolute value of a real number x is denoted |x| and defined to be equal to x when x  ≥  0 and to - x when x  ≤  0. This is extended to complex numbers by setting

[formula]

for [formula], which is equivalent to saying that |a| is a nonnegative real number and that

[formula]

The triangle inequality for real or complex numbers states that

[formula]

Also,

[formula]

for all [formula].

If [formula], then their inner product is defined by

[formula]

For [formula], their inner product is defined by

[formula]

Let us also put

[formula]

which is the same as 〈z,w〉 when [formula].

The standard Euclidean norm on [formula], [formula] can be written as

[formula]

This is equivalent to saying that |w| is a nonnegative real number and that

[formula]

The Cauchy-Schwarz inequality states that

[formula]

for all [formula], and in particular when [formula], and it can be shown using the fact that

[formula]

is a nonnegative real number for all scalars s. The triangle inequality states that

[formula]

for all [formula], and it can be shown using the Cauchy-Schwarz inequality.

By a multi-index we mean an n-tuple [formula] of nonnegative integers. The degree of α is defined by

[formula]

We also get the associated monomials on [formula], [formula] given by

[formula]

i.e., the product of the corresponding powers of xj or zj, as apprpriate. If αj  =  0 for some j, then we interpret that factor as being equal to 1.

A polynomial on [formula] or [formula] means a complex linear combination of monomials. In particular, a polynomial on [formula] extends to a polynomial on [formula] in a natural way. To be precise, by a polynomial on [formula] we mean a complex polynomial or holomorphic polynomial, as opposed to a real polynomial which might also use complex conjugates.

Suppose that f(x) is a smooth complex-valued function on [formula]. We write

[formula]

for the usual partial derivative of f in the jth direction. If α is a multi-index, then we put

[formula]

In other words, this is the mixed partial derivative of f of order equal to the degree of α with αj derivatives in the jth direction for each j.

Now suppose that that f(z) is a smooth complex-valued function on [formula], and let us write xj, yj for the real and imaginary parts of zj. We can think of f(z) as a smooth function of the 2n real variables xj, yj, and define partial derivatives accordingly. We define complex first-order partial derivatives by

[formula]

and

[formula]

We say that f(z) is holomorphic if

[formula]

for [formula].

Constants and complex-linear functions on [formula] are clearly holomorphic. The sum and product of two holomorphic functions on [formula] are again holomorphic. As a result, (complex) polynomials on [formula] are holomorphic.

Nice functions

Recall that a linear transformation [formula] is said to be symmetric if

[formula]

for all [formula]. If also

[formula]

when x  ≠  0, then A is said to be positive-definite. The principal axis theorem states that if A is a symmetric linear transformation on [formula], then there is an orthonormal basis for [formula] consisting of eigenvectors for A. Of course the corresponding eigenvalues are positive real numbers if A is also positive-definite.

If z is a complex number, then the exponential of z is defined by

[formula]

As usual zj is interpreted as being equal to 1 when j  =  0, and j! is j factorial, the product of the positive integers from 1 to j, which is also interpreted as being equal to 1 when j  =  0. By standard results this power series converges absolutely for all [formula], and converges uniformly on bounded subsets of [formula].

One can check that

[formula]

for all complex numbers z, w. Specifically, one can formally multiply the two series on the right and rearrange terms to get the series on the left, using the binomial theorem, and absolute convergence of the series is adequate to ensure that the formal computation is correct. As a special case,

[formula]

for all complex numbers z, and in particular exp (z)  ≠  0 for all z.

One can also check that

[formula]

i.e., the complex conjugate of the exponential is the exponential of the complex conjugate. If x is a real number, exp (x) is a real number, and in fact exp (x)  >  0 because this is clear when x  ≥  0 and when x  <  0 we have that exp (x) is the reciprocal of exp ( - x)  >  0. Furthermore,

[formula]

for all complex numbers z.

Let us say that a complex-valued function on [formula] is a nice function if it is a complex linear combination of functions of the form

[formula]

where α is a multi-index, A is a positive-definite symmetric linear transformation on [formula], and [formula]. In fact a nice function automatically has a holomorphic extension to [formula], just using the same formula.

Fourier transforms

If f(x) is a nice function on [formula], then we can define the Fourier transform of f by

[formula]

For [formula] we have that

[formula]

The Fourier transform (ξ) of a nice function f(x) makes sense for all [formula], and defines a holomorphic function on [formula], because of the rapid decay of nice functions as |x|  →    ∞  , and one might refer to this holomorphic function on [formula] as the Fourier-Laplace transform of f. When [formula] we have that

[formula]

and this is not true in general when [formula], so that we do not have the same kind of uniform bound for |(ξ)| for [formula] as for [formula].

Suppose that n  =  1, and consider the nice function

[formula]

It is well known that

[formula]

Clearly the integral is a positive real number, and to determine its value one can use the well-known trick that the square of the integral is equal to the analogous integral over [formula], and that can be converted to an elementary 1-dimensional integral via polar coordinates.

If z is a real number, then

[formula]

Actually, the conclusion

[formula]

also works if z is a complex number, because both sides of the equation define holomorphic functions of z which are equal when z is real. As a result, if f(x)  =   exp ( - πx2), then its Fourier transform is given by

[formula]

and this works for all complex numbers ξ. If we take f(x) to be the nice function on [formula] given by f(x)  =   exp ( - πx  ·  x), then we have that

[formula]

for all [formula], because the n-dimensional integral in the Fourier transform reduces to a product of n 1-dimensional integrals just computed.

Suppose that T is a linear transformation on [formula], which we can also view as a complex linear transformation on [formula] which takes [formula] to itself. There is a unique linear transformation Tt on [formula], called the transpose of T, which maps [formula] to itself and satisfies

[formula]

for all [formula]. As usual the standard matrix associated to Tt is the transpose of the standard matrix associated to T, which is to say that one interchanges the indices of the matrix.

If T is an invertible linear transformation on [formula] and f(x) is a nice function on [formula], then the composition f(T(x)) is also a nice function on [formula], as one can verify directly from the definition. Making a change of variables in the integral defining the Fourier transform one can also check that the Fourier transform of f(T(x)) is equal to

[formula]

where det T denotes the determinant of T and [formula] is the inverse of the transpose of T, which is the same as the transpose of the inverse of T. Note that T is an orthogonal transformation on [formula] if and only if [formula], in which case | det T|  =  1 and the Fourier transform of f(T(x)) is equal to (T(ξ)).

Suppose that A is a positive-definite symmetric linear transformation on [formula], and that

[formula]

In this case the Fourier transform of f is given by

[formula]

To see this one can use the fact that A is diagonalized in an orthonormal basis to reduce the n-dimensional integral to a product of n 1-dimensional integrals. Alternatively, one can derive this from the change of variables formula discussed in the previous paragraph, with [formula].

Let f(x) be a nice function on [formula], and let b be an element of [formula]. Thus f(x) exp ( - 2πix  ·  b) is also a nice function on [formula], and it is easy to see that the Fourier transform of this function is equal to (ξ  +  b). This extends to [formula], because both functions are holomorphic in b and agree when [formula].

Let f(x) be a nice function on [formula], and let α be a multi-index. By differentiating under the integral sign we have that

[formula]

is equal to the Fourier transform of

[formula]

which is also a nice function on [formula]. To be a bit more precise, one can think of (ξ) as a function on [formula], in which case we are taking real derivatives of it, or as a holomorphic function on [formula], in which case we are taking complex derivatives.

By combining these various properties of the Fourier transform of a nice function we see that the Fourier transforms of the building blocks for nice functions can be computed explicitly, and that the Fourier transform of a nice function is a nice function.

Fourier transforms, continued

Nice functions on [formula] are defined as linear combinations of the building blocks

[formula]

where α is a multi-index, A is a positive-definite symmetric linear transformation on [formula], and [formula]. One might instead consider the building blocks

[formula]

where α, A, and b are as in the previous case. It is easy to see that every building block of the second type can be expressed as a linear combination of building blocks of the first type, simply by direct computation.

Conversely, every building block of the first type can be expressed as a linear combination of building blocks of the second type. One can approach this by approximating a building block of the first type using derivatives of exp ( - A(x)  ·  x  +  b  ·  x), with error terms given by this exponential times monomials of lower degree. The two types of building blocks agree when α  =  0, and using induction on the degree of α one can show that building blocks of the first type can be expressed as linear combinations of building blocks of the second type.

Thus nice functions on [formula] can be defined either as linear combinations of the first kind of building block or of the second kind of building block, and in particular derivatives of nice functions are nice functions. Let f(x) be a nice function on [formula], let α be a multi-index, and consider

[formula]

The Fourier transform of this nice function is given by

[formula]

by integration by parts.

If f(x) is a nice function on [formula] and [formula], then f(x  -  a) is a nice function on [formula] too. The Fourier transform of this nice function is equal to

[formula]

by a simple change of variables. This also works for [formula], using the holomorphic extensions of f, [formula].

A corollary of the equivalence of the two kinds of building blocks for nice functions is that the Fourier transform is a linear mapping from the vector space of nice functions on [formula] onto the vector space of nice functions on [formula]. If φ(ξ) is a nice function on [formula], consider

[formula]

which makes sense as a holomorphic function on [formula], and as a function on [formula] in particular. This transform behaves in practically the same way as the Fourier transform, and it takes nice functions to nice functions in particular. One can check that this is the inverse of the Fourier transform, which is to say that [formula] when φ  =   and conversely. In this regard note that both transforms take exp ( - πz  ·  z) to itself, and that the computation of either transform applied to a nice function can be reduced to this case using linearity and the various properties of the transforms.

Suppose that f(x), φ(ξ) are nice functions on [formula]. It is easy to see that

[formula]

Specifically, both sides of the equation can be expanded into double integrals. The two double integrals are equal by interchanging the order of integration.

Because the two transforms are inverses of each other, it follows that

[formula]

for all nice functions f1, f2 on [formula]. This is known as Plancherel's theorem. Specifically, it follows from the previous identity with φ  =  1 and f  =  f2. As a result

[formula]

for all nice functions f on [formula].

If f1, f2 are nice functions on [formula], then the convolution of f1 and f2 is the function on [formula] defined by

[formula]

Clearly this is linear in f1, f2, and one can check that the convolution of two nice functions is again a nice function. Moreover,

[formula]

and

[formula]

when f1, f2, f3 are nice functions on [formula].

The convolution of two nice functions f1, f2 on [formula] is also characterized by the property that the Fourier transform of f1  *  f2 is equal to the product of the Fourier transforms of f1, f2. Similarly, if φ1, φ2 are nice functions on [formula] and φ  =  φ1  *  φ2, then [formula].