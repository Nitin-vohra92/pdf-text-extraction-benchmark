=1

Long-term degradation of optical devices on the moon

Introduction

Long-term NASA plans [\citep=nasa-plan] for placing scientific equipment on the moon face uncertainty regarding the environmental impact on such devices as hard information about the lunar environmental effect on scientific instruments has not been available. From a quantitative analysis of the performance of the laser reflectors, we find clear evidence for degradation of the retroreflectors, and note that degradation began within one decade of placement on the lunar surface.

From 1969-1985, the McDonald Observatory 2.7 m Smith Telescope [\citep=bender] dominated lunar laser ranging (LLR), using a 634 nm ruby laser. Starting around 1985, the McDonald operation moved away from the competitively-scheduled MST to a dedicated 0.76 m telescope designed to perform both satellite and lunar laser ranging, becoming the McDonald Laser Ranging System [\citep=mlrs]. In 1984, other LLR operations began at the Observatoire de la CÃ´te d'Azur [\citep=oca] in France and at the Haleakala site in Hawaii, that used 1.5 m and 1.74 m telescopes, respectively. These systems all operate Nd:YAG lasers at 532 nm.

In 2006, the Apache Point Observatory Lunar Laser-ranging Operation [\citep=apollo] began science operations using the 3.5 m telescope and a 532 nm laser at the Apache Point Observatory in New Mexico. Primarily geared toward improving tests of gravity, APOLLO is designed to reach a range precision of one millimeter via a substantial increase in the rate of return photons. The large telescope aperture and good image quality at the site, when coupled with a [formula] single-photon detector array, produces return photon rates from all three Apollo reflectors that are about 70 times higher than the best rates experienced by the previous LLR record-holder (OCA). Consequently, APOLLO is able to obtain ranges through the full moon phase for the first time since MST LLR measurements ceased around 1985.

We find that the performance of the reflectors themselves degrades during the period surrounding full moon. In this paper we describe the full-moon deficit, report its statistical significance, and eliminate the possibility that it results from reduced system sensitivity at full moon. We show that this deficit began in the 1970's, and examine the significance of successful total-eclipse observations by OCA and MLRS. We see an additional factor-of-ten signal deficit that applies at all lunar phases, but this observation requires a detailed technical evaluation of the link, and is deferred to a later publication. We briefly discuss possible mechanisms that might account for the observed deficits.

Degradation at full moon

APOLLO observing sessions typically last less than one hour, with a cadence of one observing session every 2-3 nights. For a variety of practical reasons, APOLLO observations are confined to 75% of the lunar phase distribution, from [formula] to [formula], where D is the synodic phase relative to new moon at D = 0. Within an observing session, multiple short "runs" are carried out, where a run is defined as a contiguous sequence of laser shots to a specific reflector. Typical runs last 250 or 500 seconds, consisting of 5000 or 10000 shots at a 20 Hz repetition rate. Each shot sends about 1017 photons toward the moon, and in good conditions we detect about one return photon per shot. If the signal level acquired on the larger Apollo 15 reflector is adequate, we cycle to the other two Apollo reflectors in turn, sometimes completing multiple cycles among the reflectors in the allotted time. When the Lunokhod 2 reflector is in the dark, we range to it as well. Its design leads to substantial signal degradation from thermal gradients, rendering it effectively unobservable during the lunar day.

Figure [\ref=fig:APOLLO-rate] displays APOLLO's return rates, in return photons per shot, for the Apollo 15 reflector as a function of lunar phase, with 338 data points spanning 2006-10-03 to 2009-06-15. Signal rate is highly dependent on atmospheric seeing (turbulence-related image quality). When the seeing is greater than 2 arcsec, the signal rate scales like the inverse fourth power of the seeing scale [\citep=apollo]. Variability in seeing and transparency dominate the observed spread of signal strength, resulting in at least two orders-of-magnitude of variation.

Below about 0.001 photons per shot (pps), we have difficulty identifying the signal against photon background and detector dark rate. A typical peak rate across phases is [formula] pps, with the best runs reaching [formula] pps. The key observation is the order-of-magnitude dip in signal rate in the vicinity of full moon, at [formula]. The best return rates at full moon were associated with pristine observing conditions that would have been expected to deliver [formula] photon per shot at other phases, but only delivered 0.063 pps at full moon. Thus the deficit is approximately a factor of 15. The deficit appears to be confined to a relatively narrow range of [formula] around the full moon, and is not due to uncharacteristically poor observing conditions during this period.

A Kolmogorov-Smirnov (K-S) test confirms the improbability that random chance could produce a full-moon dip as large as that seen in Fig. [\ref=fig:APOLLO-rate]. There is < 0.03% chance that the measurements within [formula] of full moon were drawn from the same distribution as the out-of-window points. Similar tests using [formula]-wide windows centered away from full moon do not produce comparably low probabilities.

Additional evidence for the full-moon deficit is provided by the instances of failure to acquire a signal. Failure can occur for a variety of reasons not related to the health of the lunar arrays: poor seeing; poor atmospheric transparency; inaccurate telescope pointing; optical misalignment between transmit and receive beams; time-of-flight prediction error; instrumental component failure. But none of these causes depend on the phase of the moon. We therefore plot a histogram of Apollo 15 acquisition failures as a function of lunar phase in Fig. [\ref=fig:failure]. Failures due to known instrumental problems were removed from this analysis, as were failures due to causes such as pointing errors that were ultimately remedied within the session. The bars are shaded to reflect observing conditions: light gray indicates poor conditions (seeing or transparency); medium gray indicates medium conditions; and black indicates excellent observing conditions, for which the lack of signal is especially puzzling. Note the cluster of failures centered around full moon. The phase distribution of run attempts is roughly uniform.

The other Apollo reflectors are similarly impacted at full moon. On the few occasions when the full-moon Apollo 15 signal was strong enough to encourage attempts on the other reflectors, we found that the expected 1:1:3 ratio between the Apollo 11, 14, and 15 rates is approximately preserved. In no case have we been able to raise a signal on other reflectors after repeated failures to acquire signal from Apollo 15.

Could the full-moon deficit be explained by paralysis of our single-photon avalanche photodiode (APD) detectors in response to the increased background at full moon? Figure [\ref=fig:background] indicates that APOLLO sees a maximum background rate at full moon of [formula] avalanche events per 100 ns detection gate across the [formula] APD array--in agreement with throughput calculations. Therefore, a typical gate-opening has a ~  30% chance that one of the 11 consistently-functioning avalanche photodiode elements (out of 16) will be rendered blind prior to the arrival of a lunar photon halfway into the 100 ns gate. The sensitivity for the entire array to signal return photons therefore remains above 97% even at full moon. The background rates presented here are extrapolated from a 20 ns window in the early part of the gate, before any lunar return signal.

The Apollo 15 site is near the lunar prime meridian, so that its illumination curve is roughly symmetric about full moon. Small-aperture photometry measurements by [\citet=peacock]--and more recently by [\citet=kieffer]--show that the surface brightness increases roughly linearly on approach to full moon, with an additional [formula]% enhancement very near full moon [\citep=opposition]. A linear illumination curve is provided in Fig. [\ref=fig:background] for reference. APOLLO clearly sees the expected background enhancement at full moon. If any phenomenon suppressed APD sensitivity to laser returns from the reflector array, it would likewise suppress sensitivity to the background photons, as suggested by the dashed curve in Fig. [\ref=fig:background]. There is no hint of detector suppression in the background counts, so we conclude that the diminished return rate observed near full moon constitutes a genuine reduction in signal returning from the reflector.

It is natural to ask if we can determine the timescale over which the full-moon deficit developed. MST LLR data [\citep=cddis] [\citep=ilrs] reveal that from 1973 to 1976 there was no indication of a full-moon deficit. Figure [\ref=fig:old_mcd] shows the photon count per run for two periods of the MST operation, where a run typically consisted of 150-200 shots at a rate of 20 shots per minute. A full-moon deficit began to develop in the period from 1977-1978 (not shown), and is markedly evident in the period from 1979-1984--but it appears somewhat narrower than the deficit now observed by APOLLO. K-S tests indicate that the probability that the distribution of photon counts between [formula] is the same as that outside the window is 18%, 0.9%, and 0.03% for the three periods indicated above, in time-order. In the last period, roughly one decade after placement of the Apollo 15 array in 1971, the deficit was approximately a factor of three. The MST apparatus did not change in a substantial way between 1973 to 1984.

By 1985, LLR was performed only on smaller telescopes, and attempts at full moon ranging subsided--except during four total lunar eclipses. The 35 eclipse range measurements by OCA and MLRS add an interesting twist: the return strength during eclipse is statistically indistinguishable from that at other phases and not compatible with an order-of-magnitude signal deficit. Existing data do not probe the time evolution of reflector efficiency into and out of the total eclipse, but it appears that the arrays perform normally as soon as 15 minutes into the totality. APOLLO could not observe the eclipses of 2007 August 28 and 2008 February 21 because of bad weather, but will have a chance to follow a complete total eclipse on 2010 December 21.

Other evidence for degradation

In addition to the full-moon deficit, analysis of APOLLO's return rate reveals an overall factor-of-ten signal deficit at all lunar phases. Supporting evidence requires more analysis than can be covered here. In brief, the dominant contributors to the [formula] photon throughput loss arise from beam divergence on both the uplink and downlink. We can measure the former by deliberately scanning the beam across the reflector on the moon, confirming a seeing-limited beam profile. We additionally measure the atmospheric seeing via the spatial distribution of the return point source on the [formula] detector array. The downlink divergence is set by diffraction from the corner cubes, verified by measurements of the actual flight cubes. Receiver throughput losses, which constitute a small fraction of the total loss, were measured by imaging stars or the bright lunar surface on the APD, and agree well with a model of the optical and detector system. Careful analysis does not account for APOLLO's missing factor of ten in signal return, while early ranging data from MST do agree with the anticipated return rate [\citep=llr-1970].

Further evidence for the damaging effects of the lunar environment comes from the Lunokhod 2 reflector. In the first six months of Lunokhod 2 observations in 1973, its signal was 25% stronger than that from the Apollo 15 array. Today, we find that it is 10 times weaker. The Lunokhod corner cubes are more exposed than the recessed Apollo cubes, and unlike the Apollo cubes, have a silver coating on the rear surfaces. Both factors may contribute to the accelerated degradation of the Lunokhod array relative to the Apollo arrays.

Discussion

The full-moon deficit, the overall signal shortfall experienced by APOLLO, and the relative decline in performance of the Lunokhod array all show that the lunar reflectors have degraded with time. It may be possible to explain these observations with a single mechanism that causes both an optical impairment at all phases, and a thermal influence near full moon that abates during eclipse. One possibility is alteration of the corner-cube prisms' front surfaces either via dust deposition or surface abrasion from high-velocity impact ejecta or micrometeorites. Alternatively, any material coating on the back of the corner cubes--perhaps originating from the teflon mounting rings--could impact performance of the Apollo reflectors via frustration of total internal reflection (TIR) and absorption of solar energy. Bulk absorption in the glass could also produce the observed effects.

The impact on reflection efficiency at all phases from each of these possibilities is obvious. The full-moon effect would arise from an enhancement of solar energy absorption by the corner-cube prisms and their housings--defeating the careful thermal design intended to keep the prisms nearly isothermal. Because the uncoated Apollo corner cubes work via TIR, their rejection of solar flux should be complete when sunlight arrives within 17[formula] of normal incidence. But the temperature uniformity within the corner cubes is upset either by absorption of energy at the cube surfaces, or by defeat of TIR via scattering--which results in energy deposition in the pocket behind the cubes, heating the cubes from the rear. Temperature gradients in a corner-cube prism produce refractive index gradients, generating wavefront distortion within the prism. A 4 K gradient between the vertex and front face of the Apollo corner cubes reduces the peak intensity in their far-field diffraction pattern by a factor of ten [\citep=adl]. Apollo corner cubes are recessed by half their diameter in a tray oriented toward the earth. Near full moon, the weathered corner cubes are most fully exposed to solar illumination, maximizing the degradation. During eclipses, the reflector response may be expected to recover on a short timescale, governed by the [formula] minute thermal diffusion timescale for 38 mm diameter fused silica corner-cube prisms.

While any of the proposed mechanisms could account for the observations, objections can be raised to each of them. Bulk absorption is not expected in the Suprasil fused silica used for the Apollo cubes after 40 years of exposure. Micrometeorite rates on the lunar surface gleaned from study of return samples, and summarized in [\citet=surveyor], suggest the fill-factor of craters on an exposed surface to be ~  10- 4 after 40 years, dominated by craters in the 10-100 Î¼m range. Opportunities for a contaminant coating on the rear surfaces of the corner cubes are limited given that the only substance within the closed aluminum pocket besides the glass corner cube is the teflon support ring. Moreover, the Lunokhod array would not be subject to the same rear-surface phenomena as the Apollo cubes, yet shows an even more marked degradation.

Dust is perhaps the most likely candidate for the observed degradation. Astronaut accounts from the surface and from lunar orbit, as well as a horizon glow seen by Surveyor 7, suggest the presence of levitated dust--possibly to altitudes in excess of 100 km, for which a lofting mechanism has been suggested by [\citet=stubbs-dust]. The dust monitor placed on the lunar surface by the Apollo 17 mission measured large fluxes of dust in the east-west direction around the time of lunar sunrise and sunset--consistent with the electrostatic charging mechanisms described by [\citet=farrell-terminator]. The main difficulty with the dust explanation is that electrostatic charging alone is not strong enough to liberate dust grains from surface adhesion. But mechanical disturbance seeded by micrometeorite and impact ejecta activity may be enough to free the already-charged grains. Whether or not dust is responsible, the supposed health of the reflector arrays has been used to argue that dust dynamics on the surface of the moon are of minimal importance. Our observations of the reduced reflector performance invalidate the invocation of reflector health in this argument.

The only other relevant data for the environmental impact on optical devices on the lunar surface comes from the Surveyor 3 camera lens, retrieved by the Apollo 12 mission. After 945 days on the surface, the glass cover of the camera lens had dust obscuring an estimated 25% of its surface--though it is suspected that much of this was due to Surveyor and Apollo 12 landing and surface activities [\citep=surveyor]. Clearly, the ascent of the lunar modules could result in dust deposition on the nearby reflectors. But the effect reported here became established after several years on the lunar surface (e.g., Fig. [\ref=fig:old_mcd]), and is therefore not related to liftoff of the lunar modules.

The evidence for substantially worsened performance of the lunar reflectors over time makes it important to consider the long-term usefulness of next-generation devices proposed for the lunar surface. Finding the mechanism responsible for the observed deficits is a high priority. Thermal simulations or testing deliberately altered corner-cube prisms in a simulated lunar environment would likely expose the nature of the problem with the Apollo arrays. Especially important would be to differentiate between permanent abrasion versus removable dust. The results could impact the designs of a wide variety of space hardware--especially next-generation laser ranging reflectors, telescopes, optical communication devices, or equipment dependent on passive thermal control.