On the volume of the polytope of doubly stochastic matrices

David P. Robbins

Introduction

We study the calculation of the volume of the polytope Bn of n  ×  n doubly stochastic matrices; that is, the set of real nonnegative matrices with all row and column sums equal to one. This polytope is sometimes known as the Birkhoff polytope or the assignment polytope. We will describe and evaluate two methods for computing the volume of Bn.

In the first method we decompose Bn into a disjoint union of simplices all of the same volume and count the simplices. The fact that this can be done appears in [\cite=St1]. This method applies to any face of Bn as well.

In the second method we count the number of n  ×  n nonnegative integer matrices with all row and column sums equal to t (sometimes called magic squares) for suitable values of t. These numbers allow us to compute the Ehrhart polynomial of Bn, which (essentially) has the volume of Bn as its leading coefficient. It appears that this has been the most common method of computing the volume of Bn. Sturmfels reports in [\cite=Stu] on other work in which the volume of Bn has been computed for n up to 7. We have also used this method to compute the volume when n = 8.

This study is largely expository since the two methods are not new. However, the details about how we carry out these methods may be of interest. We are not aware of any reports of others who have carried out the simplicial decomposition method.

As a byproduct of our program for carrying out the simplicial decomposition method, we are easily able to compute the volume of any face (of any dimension) of Bn provided that n is not too large. This allowed us to discover that a certain special face of Bn has a volume which appears to be given by a simple product formula. This formula is given in Conjecture [\ref=conj:1].

Our study resulted from a question [\cite=Mi] of Victor Miller, who asked how one could generate a doubly stochastic matrix uniformly at random. It is not hard to see that it would be easy to generate a random doubly stochastic matrix if one could easily calculate the volume of any face of Bn. However the method described here for calculating face volumes is practical only for small n.

In what follows we will make use of some well known properties of the face structure of Bn: the vertices of Bn are precisely the n! n  ×  n permutation matrices; on the other hand, for each pair (i,j) with 1  ≤  i,j  ≤  n, the doubly stochastic matrices with (i,j) entry equal to 0 form a facet (maximal proper face) of Bn and all facets arise in this way. See [\cite=BS] for further properties and references.

In general, it is convenient to identify the faces of Bn with certain n  ×  n matrices of 0's and 1's, as follows.

First we identify a 0-1 matrix with the set of entries in the matrix that are 1's. Thus, for two 0-1 matrices A and B of the same size, we can define their union [formula] as the 0-1 matrix whose set of 1's is the union of the sets of 1's of A and B. e.g.,

[formula]

Similarly we can speak of one 0-1 matrix containing another and so forth.

Now to each face F of Bn, we associate the matrix M which is the union of the vertices (permutation matrices) in F. The facets of Bn containing F are precisely those associated with the zero entries of M. Since any face is the intersection of the facets containing it, any permutation matrix contained in M must be a vertex of F. Thus the vertices of F are precisely the permutation matrices contained in M, so we can recover F from M. In this way we identify the faces of Bn with the set of 0-1 matrices which are unions of permutation matrices. Note that not every 0-1 matrix corresponds to a face of Bn. For example

[formula]

is not a union of permutation matrices, hence not a face of B2.

Volume

It is easy to see that the dimension of Bn is (n - 1)2. Strictly speaking, the volume we wish to compute is the (n - 1)2-volume of Bn regarded as a subset of n2-dimensional Euclidean space. Thus, for example, the polytope B2 consists of the line segment joining the matrices

[formula]

and hence its volume is 2.

An n  ×  n doubly stochastic matrix is determined by its upper left (n - 1)  ×  (n - 1) submatrix. The set of (n - 1)  ×  (n - 1) matrices obtained this way is the set An of all nonnegative (n - 1)  ×  (n - 1) matrices with row and column sums ≤  1 such that the sum of all the entries is at least n - 2. This is affinely isomorphic to Bn. In the Appendix we show that the ratio of the volume of Bn to the volume of An, regarded as a subset of Euclidean (n - 1)2 space, is nn - 1. In some ways the volume of An is easier to understand since its dimension is equal to the dimension of its ambient space.

James Maiorana [\cite=Ma] (and probably others) noted a Monte Carlo method for approximating the volume of An. Consider the set Cn of (n - 1)  ×  (n - 1) nonnegative matrices with row sums (but not necessarily column sums) ≤  1. This is the Cartesian product of n - 1 unit simplices in Euclidean (n - 1)-space so its volume is [formula]. It is easy to choose points in Cn uniformly at random. The probability αn that such a point is in An is the ratio of the volume of An to that of Cn. Thus we can run Monte-Carlo trials to estimate αn and hence the volume of An.

For large n, this Monte Carlo method is impractical since αn is too small. However, it is useful for checking computations for small n. A lower bound for αn is given by Bona in [\cite=Bo].

There is a more natural unit for the volume of Bn and its faces. This is based on the fact that the vertices of Bn are integer matrices. Suppose that F is a d-dimensional face of Bn. Since its vertices have integer coordinates, the integer points in the affine span of F comprise a d-dimensional affine lattice L. Given such a lattice there is a minimum volume of any d-simplex with vertices in L. Lattice points [formula] are the vertices of one of these minimum volume simplices if and only if every point of L is uniquely expressible in the form [formula], where the ki's are integers whose sum is 1. The relative volume of a face F is the volume of F expressed in units equal to the volume of a minimal simplex in L. The relative volume of a face is the same whether regarded as a face of Bn or as a face of An, since the mapping from Bn to An (by taking the upper left (n - 1)  ×  (n - 1) minor) preserves integrality of points.

Here are the currently known relative volumes of Bn.

[formula]

To convert relative volumes to true volumes, we need to know the volume of a minimal simplex of An.

But the affine span of An is all of (n - 1)2-dimensional space. Hence the volume of a minimal simplex in An is [formula], and the volume of a minimal simplex in Bn is [formula].

Triangulations

We call the first method for computing the volume of Bn the triangulation method.  The method applies to the calculation of the volume of any polytope. The essence is that we decompose the polytope into simplices and sum the volumes of the simplices.

For Bn we have used a standard method of decomposing a polytope P into simplices. See for example [\cite=St1]. To decompose P into simplices, we choose an arbitrary vertex v and form the collection of facets of P opposite v (facets of P not containing v.) We then recursively triangulate each facet. The triangulation of P is then formed by adding our chosen vertex to each simplex in the triangulation of each of the facets.

The standard triangulations of Bn and its faces have an unusual property, given in [\cite=St1], for which we provide a self-contained proof below.

In any standard triangulation of a face F of Bn, every simplex has minimal volume in the affine lattice determined by F.

Proof: Let F be a d-dimensional face of Bn, v0 any vertex in F, and G a facet of F opposite v0. Suppose that a simplex in a standard triangulation of G has vertices [formula]. We need to prove that the set of integer points of the affine space determined by F is the same as the set of points [formula], where the ki are integers whose sum is 1.

Of course all the integer combinations are in the affine span. The question is whether there are any other points.

Any integral point of the affine span can be uniquely expressed in the form [formula], where the ri's are real numbers with sum 1.

Since v0 is not in the face G, there is a facet of Bn containing G but not v0. Thus v0 must have at least one entry equal to 1 in the same position where all vi, i  ≥  1, have zeroes. Thus, in the hypothetical combination above, r0 must be an integer. If we add r0(v1 - v0) to the combination above, we obtain another integral point in the affine span of G. It follows, using induction, that r1 + r0, and [formula] are integers and therefore all the r's are integers, as desired.

Note that, as a corollary, in any standard triangulation of a face of the Bn, the number of simplices in the triangulation is equal to the relative volume.

We also obtain an important computational principle. Given a face F of Bn and a vertex v of F, the relative volume of F is the sum of the relative volumes of facets of F opposite v.

The Triangulation Method for Bn

We now describe the triangulation method for computing the volume of Bn. This is simply an elaboration of the principle that the relative volume of a face is the sum of the relative volumes of the faces opposite any vertex.

We apply this principle recursively. To get started we use the fact that the relative volume of any zero-dimensional face of Bn is 1.

In the most naive plan we calculate the relative volumes of all faces. We first produce a list of all faces of each dimension. For dimension 0, we know all the relative volumes are 1. Then, for each face F of dimension d we select a vertex and find the opposite facets (of dimension d - 1). Assuming recursively that their relative volumes have already been computed, we now find the relative volume of F by summing the relative volumes of the facets.

There are two serious drawbacks to the naive plan.

Perhaps the most pressing problem is that we need to compute the volumes of an extremely large number of faces, since quite a few of the 2n2 possible 0-1 matrices are actually faces of Bn. Here we have recourse to a single important trick. If we permute the rows and columns of the matrix representing a face, we obtain the matrix of another face with the same volume. Also if we transpose a matrix representing a face, we obtain another face of the same volume. We regard matrices which can be obtained from each other by these operations as equivalent. We can cut down on the cost of our algorithm if we compute the volume only for a single "canonical" face in each equivalence class.

The next most difficult problem is to produce the lists of faces. The most practical method that we found for producing faces is to start with the single (n - 1)2-dimensional face, Bn itself, and successively produce faces of lower dimension by intersecting with a facet of Bn. While producing the faces we save the subface information so that we can look up the volumes when we are done. Unfortunately we need to construct a very large partially ordered set of faces before we can calculate any volumes since the only volumes we know are those of the zero-dimensional faces. While the cost in memory is not so bad for n less than 8, when we reach n = 8, we seem to need about 200 gigabytes of intermediate storage. If the memory were available, the computation of the volumes would be relatively easy. In fact we are able to carry out a substantial fraction of the work before running out of memory.

There are two phases to our algorithm. In the first phase we construct a collection of faces together with information about which ones are facets of which others. In particular, we successively compute, for [formula], a collection Fd of d-dimensional faces of Bn. We begin by setting F(n - 1)2  =  {Bn}, i.e., consisting of just the all 1's matrix representing Bn itself.

Given Fd we produce Fd - 1 as follows. Start with [formula]. For each face F∈Fd we select a vertex v∈F. We then find the facets of F opposite v, canonicalize these faces, and add them to Fd - 1. Having done this for all F∈Fd, we sort Fd - 1 and remove the duplicates. Then, for each face f∈Fd - 1, we save a list of pointers to the faces in Fd from which f arose. (Equivalent faces can appear several times as opposite faces of the same face. When this happens, we include the pointer in the list of pointers multiple times.)

This completes the first phase. In the second phase we start with F0 and work up to higher dimensions, calculating the relative volume of every saved face until we obtain the volume of Bn itself. This is quite fast, requiring just one addition for each saved pointer.

Note that once the pointers are constructed we do not need the faces themselves, unless we want to know which face has each of the intermediate volumes we are computing.

For larger values of n, the accumulators used for calculating the volumes will overflow. But we can get around this problem by using multiple precision arithmetic or by performing the volume calculation several times modulo various primes and combining the results with the Chinese Remainder Theorem.

The main computational work of our algorithm takes place in three steps.

for each face F∈Fd, find a vertex v∈F.

determine the facets of F opposite v.

put these opposite facets into canonical form.

We now describe how each of these steps is done.

One important decision is the data structure for storing faces. We identify each face with the 0-1 matrix which is the union of its vertices (regarded as permutation matrices). For n  ≤  8 it is convenient to represent each face as n2 bits of a single word, where the words of a (64-bit) computer are regarded as 64-long arrays of bits.

In Step 1 we are given a face f represented by a 0-1 matrix and we are looking for a permutation matrix π contained in f. This could be done with the assignment algorithm or one of the methods for finding maximum matchings, but for the small values of n that we were using, it was quicker to use a backtracking search method, as follows. The matrix f has at least one 1 in its first row. We guess one of these as the location of the 1 in the first row of π. We then guess the location of the 1 in the second row of π, bearing in mind that it cannot be in the same column as the 1 in the first row. We continue this way searching for the location of the 1 in subsequent rows. We backtrack if we reach a row in which there are no feasible choices.

Now we consider Step 2. Given a face f and a vertex π we need to find the facets of f opposite π.

For a moment let us ignore π and consider the general problem of constructing the facets of f. The main principle is that each facet of f can be obtained by intersecting f with a facet of Bn that does not contain f. Consider the facet corresponding to the pair (i,j). The facet does not contain f if fij = 1. To intersect f with this facet we start by replacing fij with 0, obtaining a 0-1 matrix g. The face which is the intersection of f with the facet (i,j) is then the largest face h contained in g. The matrix h, which is the union of the permutation matrices contained in g, can be strictly contained in g. Given one of the 1's in g, to test whether it is in h, we search for a permutation matrix in g which uses the 1 in question. This can be done with our backtracking search algorithm. The 1 in question is in h precisely when this search succeeds. When the position of a 1 in g is zero in h we say it is forced to zero.

For example if n = 3 and f is the 3-dimensional face with matrix

[formula]

then the intersection of f with the facet corresponding to the middle entry of the top row is one-dimensional, with matrix

[formula]

In this example two zeroes in the last column are forced. This example also shows that although every facet of f is the intersection of f with a facet of Bn, the converse is not true and the dimension of the intersection can be too small to be a facet of f.

There are some additional simplifications when we search for the facets of f opposite a given vertex π of f. If g is a facet of f not containing π, then g must contain a 0 in place of one of the 1's of π. Thus there are at most n facets of f opposite π. Observe that if g is a facet of f not containing π, then [formula] is a union of permutation matrices and therefore a face of Bn containing g and π. Thus [formula]. This implies an important and helpful principle. When we introduce a 0 at a 1 of π and this results in a facet of f, then the only other positions that might be forced to zero are those of the other 1's of π. Thus we can loop through the n 1's of π one at a time and, for each of these, introduce a 0 and determine what other 1's of π are forced to be 0 and produce accordingly a matrix, which we call a candidate. We obtain a set of n candidates among which all the facets opposite π must occur. (This list can have duplicates which we remove.) Of these candidates the facets are those which are maximal under inclusion. Indeed, it is clear that every candidate contains a face that has the same intersection with π. But this face is contained in a facet which has an intersection with π that is at least as large. Thus every candidate is contained in at least one facet, and the facets are precisely the maximal candidates.

Finally we describe Step 3, which we call "canonicalization".

The most straightforward way to choose a canonical form for a face f is to apply every element of our group of symmetries to f and choose the image of f with the least value (where the bit pattern f is regarded as an integer.) But this is prohibitively slow.

Instead we make use of certain special functions, which we call scores, which assign integers to every row and column of a 0-1 matrix. The scores have the special property that when rows are permuted, the row scores are permuted the same way leaving the column scores unchanged, whereas, when columns are permuted, the column scores are permuted the same way leaving the row scores unchanged. An example of an allowable score is to assign to each row its row sum and to each column its column sum.

Given such scores we say that a matrix is in standard form if it satisfies the following three properties:

the column scores are weakly increasing.

the row scores are weakly increasing.

in the case of tied row scores the rows are ordered lexicographically as bit strings.

For a given 0-1 matrix, once its row and column scores have been computed it is easy to put a matrix and its transpose into standard form by forcing each of the three conditions above in the listed order.

For each face constructed, we put both the face and its transpose into standard form and finally choose the smaller of these two, regarded as integers, as the "canonical" form that is saved.

Note that we are abusing terminology a little here since although the method always replaces a face by an equivalent face, it is conceivable that equivalent faces will canonicalize to distinct faces. When this happens, we still obtain correct volumes, but we end up doing work which could be avoided if the equivalence were recognized. However, if this event is rare, we obtain almost all the savings of true canonicalization as described above (but without the excessive cost).

It turns out that just using row and column sums as the score functions fails to recognize a substantial number of equivalences. What we need are scores that tend to assign different values to different rows and columns. Slightly more complicated scores do better. Given a column score, we can produce a more complicated row score by assigning to each row the sum (or any symmetric function) of the values of the column scores of those columns for which 1's occur in the given row. Similarly a row score can be used to produce a more complicated column score. We can also add two row scores to obtain another row score or two column scores to obtain another column score. By combining steps like this we produced scores that were better at distinguishing rows (and columns) without being much more expensive to compute.

This concludes our description of the triangulation method. As mentioned earlier it is reasonably practical for n  <  8. The times required on a 500mhz DEC alpha were as follows:

[formula]

Although the volumes of Bn do not seem to follow a recognizable pattern, it seemed conceivable that there would be faces of Bn for which the relative volumes had interesting properties. One fairly natural class is the set of matrices for which the set of of zeroes of the matrix form a Young tableau in a corner of the matrix.

Since our triangulation method applies to any face of Bn, we were able to check some natural classes of faces. It turned out that for the simplest non-trivial Young tableau faces the volumes apparently obey a simple rule, although we have not been able to supply a proof. More precisely, suppose that n  ≥  2 and that Fn is the n  ×  n matrix whose (i,j) entry is 1 when j  ≤  i + 1 and 0 otherwise. Then Fn is a union of permutation matrices corresponding to a face of Bn of dimension [formula] with 2n - 1 vertices and we have the following

The relative volume of Fn is the product

[formula]

of the first n - 1 Catalan numbers.

We have verified this for n  ≤  12.

Finally, we give some miscellaneous observations which may be useful but do not actually enter our algorithm.

In our method, we never needed to calculate the dimension of a face since the way they were produced guaranteed their dimension. However one may wonder how one can efficiently calculate the dimension of a face. One of the most efficient methods makes use of the fact, discussed in [\cite=BS], that the dimension is equal to e + k - 2n, where e is the number of 1's in the matrix of F and k the number of components in the graph corresponding to F. (i.e., the bipartite graph on 2n letters in which i is joined to j when the (i,j) entry of the matrix of F is 1.)

The relative volume of any d-face F can be computed in several different ways since it is the sum of the relative volumes of the facets opposite any vertex of F. This yields linear relations on the volumes of (d - 1)-faces of Bn. It seems conceivable that these linear relations could be strong enough to yield useful information about the volumes. However from our limited investigation this does not appear to save anything in our computations.

Since our standard triangulations all involve minimum volume simplices, one might wonder whether all minimum volume simplices with vertices from the vertex set of Bn belong to one of these triangulations. For n = 4, we found that there are 658584 minimum volume simplices whose vertices are vertices of B4. Of these, only 641112 belong to some standard triangulation.

The Magic Squares Method

In the next two sections we describe the magic squares method for calculating the volume of Bn. We have no reason to believe that our implementation is substantially different from those used by others. (See [\cite=DG], [\cite=Mo],[\cite=SS], and [\cite=Stu].) The only apparent novelty is that we have carried out the computation when n = 8.

We briefly explain here the connection between magic squares and the volume of Bn.

It is known that for a d-dimensional polytope P with integer vertices, for any nonnegative integer t, the number e(P,t) of lattice points contained in t  ·  P is a polynomial of degree d in t. This polynomial is called the Ehrhart polynomial of P. Its leading coefficient is the volume of P in units equal to the volume of the fundamental domain of the affine lattice spanned by P. Thus if we know the values of e(P,t) for values of t from 0 to d, we can find the Ehrhart polynomial by interpolation and in that way determine the volume of P.

For P = Bn, this method is particularly attractive since the polynomial is known to have certain symmetries, which make it necessary to calculate the values of e(Bn,t) for t only up to and including [formula] rather than (n - 1)2.

Note that e(Bn,t) is exactly the number of n  ×  n matrices with nonnegative integer entries and all row and column sums equal to t, i.e., the number of n  ×  n magic squares with sum t. In the next section we will describe how to count magic squares relatively efficiently.

To see that we need only find e(Bn,t) for values of t up to and including [formula] we refer to the following identities:

e(Bn,t) = 0 for - n + 1  ≤  t  ≤   - 1.

e(Bn, - n - t) = ( - 1)n - 1e(Bn,t) for all t.

These identities (conjectured in [\cite=ADG]) are easy consequences of Ehrhart's Law of Reciprocity, which states that, for a d-dimensional polytope P with integer vertices, and t > 0,

[formula]

where e*(P,t) denotes the number of integer points in the interior of P. See [\cite=H], and [\cite=E] for proof and references.

Proof of 1: e*(Bn,t) is the number of n  ×  n matrices with positive integer entries and all row and column sums equal to t. Since all the entries are ≥  1, each row and column sum must be ≥  n, so e*(Bn,t) = 0 for 1  ≤  t  ≤  n - 1. By Ehrhart's Law of Reciprocity this implies e(Bn,t) = 0 for - n + 1  ≤  t  ≤   - 1.

Proof of 2: There is a one-to-one correspondence between n  ×  n matrices with nonnegative integer entries and row and column sums t and n  ×  n matrices with positive integer entries and row and column sums n + t. (Simply add 1 to each entry in matrices of the first type.) Thus e(Bn,t) = e*(Bn,n + t). Applying Ehrhart's Law of Reciprocity, the right-hand-side equals ( - 1)(n - 1)2e(Bn, - n - t), which simplifies to ( - 1)n - 1e(Bn, - n - t).

The effect of the first identity is that we know n - 1 zeroes of e(Bn,t). We also have e(Bn,0) = 1. For each t > 0, if we calculate the value of e(Bn,t), by the second identity we obtain also the value of e(Bn, - n - t). Thus if we calculate e(Bn,t) for t up to [formula], we have a total of [formula] values of the e(Bn,t) so we have enough data to find the polynomial e(Bn,t) by interpolation.

Counting Magic Squares

We now describe the method we used for counting the number of n  ×  n magic squares of row and column sum t for [formula]. This seems no different from the methods used by others [\cite=DG] to carry out the smaller cases.

Given an m-tuple [formula] and an n-tuple [formula] of nonnegative integers, we denote by N(r,c) the number of nonnegative integer matrices with row sums [formula] and column sums [formula].

There are a few computational principles. The first is that N(r,c) = 0 unless [formula]. Next note that N(r,c) is invariant under permutation of either the r's or the c's. Finally the principle that leads to substantial computational savings is that, for any integer k (usually near m / 2)

[formula]

where the sum is over all nonnegative n-tuples x such that [formula] and xi  ≤  ci, [formula]. This formula results from classifying the matrices counted by N(r,c) according to the column sums of the submatrix formed from the first k rows. For fixed column sums [formula], the column sums of the submatrix formed by the remaining rows must be ci - xi. The total number of matrices in the class corresponding to x is the number of ways of choosing the top submatrix multiplied by the number of ways of choosing the bottom.

The counting of magic squares amounts to the calculation of N(r,c) with the "constant" n-tuples [formula]. For this special case there are a few simplifications. We discuss the case when n is even. The same ideas apply with slight modification when n is odd.

Suppose that n = 2m and we wish to calculate e(Bn,t). From our general principle we have

[formula]

where R is the m-tuple of all t's, T is the n-tuple of all t's, and y runs over all nonnegative n-tuples satisfying |y| = mt, and yi  ≤  t for all i. For a k-tuple [formula], let us denote by M(y) the number of distinct k-tuples which arise by permuting the yi's. So, if [formula] are distinct, and y is a k-tuple consisting of k1 z1's, k2 z2's, etc., then [formula]. In terms of this notation a more computationally efficient version of the preceding equation is

[formula]

where now we further restrict y to weakly increasing n-tuples.

We can apply this principle again to the calculation of N(R,y) and N(R,T - y) that appear in the last formula. We find that

[formula]

where now x runs over all weakly increasing nonnegative m-tuples with [formula] and xi  ≤  t for all i.

We can save an additional factor of 2 by noting that the quantities N(R,y) are the same as N(R,T - y) except in a different order. Thus if we save the former in a suitable array, we can look up the latter ones in the array rather than computing them.

Notice that the ingredients for calculating the sums N(R,y) and N(R,T - y) are the quantities N(x,y) where x and y vary over weakly increasing nonnegative m-tuples with [formula]. Thus it is sensible to precompute these quantities and save the results before forming the sums for N(R,y) or the sum for e(Bn,t).

For example, for n = 8 we need to precompute the quantities N(x,y) where x and y have length 4. Again it is easier to calculate

[formula]

where the sum is over all 4-long vectors z with |z| = x1 + x2 and zi  ≤  yi for all i. However we do not have available the additional simplification to a sum over increasing sequences z. Thus on the right side we require the values N(x,y), for pairs (x,y) where x has length 2 and y has length 4, not necessarily weakly increasing, where the components of x and y vary up to 21. It would be possible to precompute all the needed values and save these as well for later use. This might be advantageous since these results are used several times each. However, for simplicity, we use a subroutine to compute these, in effect repeating the calculation of any N(x,y) whenever needed. This subroutine in turn calls a subroutine for counting 2  ×  2 matrices with prescribed row and column sums which calculates N((x1,x2),(y1,y2)) =  min (x1,x2,y1,y2) + 1 whenever |x| = |y|.

The precalculation for n = 8 requires about 20 minutes on a 500Mhz DEC alpha. The remaining calculation also takes about 20 minutes. The first part can be calculated in single precision. In the remaining parts we need some sort of multiple precision method. We perform the calculation modulo several primes and combine the results with the Chinese Remainder Theorem. A similar program for n = 7 requires 38 seconds.

Here are the Ehrhart polynomials e(Bn,t), for [formula]. For each n, the coefficient of the last binomial coefficient in the expression for e(Bn,t) is the relative volume of Bn. We express the Ehrhart polynomial of Bn as an integer combination of binomial coefficients [formula], [formula], because they are a basis for the polynomials satisfying p( - n - t) = ( - 1)n - 1p(t).

[formula]

[formula]

Comparison

We now compare the two methods described above.

The main advantage of the first method seems to be that it applies just as well to any face of Bn as it does to Bn itself. To apply the algorithm to a face F of Bn, we simply start at the top level with the 0-1 matrix associated to F and produce lists of canonical subfaces as before.

In the second method it is not obvious how well one could do in computing the volume of an arbitrary face F of Bn. This would amount to counting the number of magic squares with prescribed zeros and row and column sums t for possibly as many as dim (F) values of t. We would not have e*(F,t) = 0 for 1  ≤  t  ≤  n - 1, nor would we have e(F,t) = e*(F,n + t), because of the prescribed zeros in F. For certain F (e.g., those with the same number of prescribed zeros in every row) we would have an analogous identity, and some automatic roots, but in general we cannot guarantee any cutdown in the number of values of e(F,t) needed to determine the polynomial. Furthermore in the actual counting of magic squares with certain prescribed zeros, we would not be able to exploit the symmetries used in our algorithm above.

The second method however has the advantage that, for computing volumes of Bn itself, it is much more feasible in terms of memory.

The second method also computes the Ehrhart polynomial. It seems possible that the first method could be modified to compute Ehrhart polynomials of the faces as well as just their volumes. We would need to keep track of the numbers of simplices of each dimension in a standard triangulation instead of just the simplices of the largest dimension.

Appendix: Ratio of Volumes of Bn and An

Consider the linear mapping L from (n - 1)  ×  (n - 1) matrices to n  ×  n matrices which sends matrix Ei,j which is all zero except for a 1 at (i,j) to the matrix Fi,j which is all zero except for 1's at (i,j) and (n,n) and - 1's at (i,n) and (n,j). If we follow L by the addition of the n  ×  n matrix that has the block form

[formula]

where Jk,l is the all k  ×  l matrix of all 1's, then we obtain the affine mapping which sends An to Bn. Thus if we denote the ratio we seek by R, we find that R2 is the determinant of the (n - 1)2  ×  (n - 1)2 matrix of dot products of Fi,j  ·  Fk,l = 2δik2δjl.

But in general if xik and yjl are two m  ×  m matrices and z is the m2  ×  m2 tensor product matrix indexed by pairs ij and kl given by zij,kl = xikyjl then det z  =  ( det x det y)m.

Our case is the special case that x = y = Jn - 1,n - 1 + In - 1. Since the characteristic polynomial of - Jm is λm - 1(λ + m), the determinant of Jn - 1 + In - 1 is n. It follows that R = nn - 1.