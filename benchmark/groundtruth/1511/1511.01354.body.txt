Model-Based, Coverage-Driven Verification and Validation of Code for Robots in Human-Robot Interactions

INTRODUCTION

Robotic assistants are designed to interact and collaborate closely with humans. These robots are increasingly being developed for industrial and domestic applications. Due to ethical and legal implications of the Human-Robot Interaction (HRI), the safety and functional soundness of such technologies needs to be demonstrated, for them to become viable commercial products [\cite=ROMAN14]. Currently, limits for speed and force according to interaction zones are enforced for safety, as mentioned in the standard ISO 13482:2014 for robotic assistants, and in the standard ISO 10218 (parts I and II) for industrial robotics, along with physical separation between robots and humans. Such limits can restrict the scope of the interactions, ruling out some of the envisaged applications for collaborative robots. To minimise the need for such restrictions, the software running in these robotic platforms must be subjected to rigorous verification and validation (V&V) processes.

According to the standard IEEE P1012, verification seeks to demonstrate the correctness of a robot's code, with respect to safety, liveness and functional requirements. Validation is the process used to determine if the implementation is fit for purpose when placed in its target environment, i.e. the requirements correctly embody the objectives of the implementation. In practice, similar procedures are employed for both. Whether we speak about Validation or Verification, depends largely on where we draw the boundary between the design and the environment in which that design operates.

V&V is challenging in the HRI domain. The requirements to be accounted for typically include a wide range of considerations relating to safety as well as the intended function of the robot. Furthermore, the robot's environment (which includes the human agent) is multifaceted and highly unpredictable, regardless of whether the intended interaction is structured or not. Another challenge is achieving a satisfactory degree of realism (detail) in V&V processes, while exploring all the possible environmental conditions, within resource bounds.

Real-life HRI experiments or simulation-based testing are V&V methods that allow realism, and thus exploring a large set of detailed requirements. However, neither of these can exhaustively explore all possible scenarios, due to constraints on time and other resources. As an alternative, 'formal verification' methods have been employed to verify HRI in the past [\cite=BFS09:HRIshort] [\cite=Cowley2011] [\cite=Kouskoulas2013] [\cite=Mohammed2010] [\cite=Muradore2011] [\cite=webster14formalshort]. Formal methods can exhaustively examine highly abstracted models of the HRI, making them valuable techniques for maximising the breadth of the V&V process. However, computational constraints limit the level of detail that may be included in a tractable formal model. Hence, more realistic testing remains a necessity. We require a systematic approach that maximises the thoroughness of such testing with the available resources.

To meet this need, we propose the use of Coverage-Driven Verification (CDV) for V&V of robotic assistants' high-level control code. 'Coverage' is a measure of the extent to which a system's design has been explored during V&V. Various coverage metrics may be used as V&V completion criteria. CDV is the systematic pursuit of satisfactory coverage according to a predefined verification plan [\cite=Piziali2004]. It promotes efficiency in the generation of effective tests, the collection and analysis of coverage metrics to guide test generation, and automatic checking of the response from the System Under Test (SUT).

CDV has been used successfully for more than a decade in the microelectronics design industry to verify designs with billions of transistors. Language constructs to implement functional coverage models have been incorporated into the popular hardware description language (HDL), SystemVerilog [\cite=Piziali2004], and packages have been developed to support such efforts in other HDLs, such as VHDL; indicating the maturity and acceptance of this approach. Microelectronics designs are characterised by a high level of concurrency. Similarly, robot control software typically includes multiple modules for concurrent systems, such as the top-level control, separate sensor systems, path planning and actuation. Are V&V approaches from microelectronics suitable for the robotics domain?

Currently, simulation-based testing of robots is often implemented using a small set of directed (manually constructed) tests. Because this approach may overlook unexpected scenarios, a larger set of randomly generated (Monte Carlo) tests is a commonly used alternative. However, the number of tests required to expose rare scenarios of critical interest may be intractably large. A key aspect of CDV is the use of constraints to bias testing towards rare events, providing a more thorough examination of the system without sacrificing the ability to expose unforeseen scenarios. In this paper we compare different methods for constraining pseudorandom test generation, and demonstrate the added value of model-based techniques in the HRI domain.

We illustrate the methodology and merits of CDV on a case study, where we apply CDV to an object-handover task, a critical component of a cooperative manufacture scenario. To do this, we developed a CDV testbench specifically for HRI. This implementation utilizes Robot Operating System (ROS), Gazebo, and available testing and custom Python modules. Through ROS and Gazebo, the testbench allows the verification of the real robot's code. Additionally, the testbench allows generating a diverse set of human input behaviours, to explore robot's code and consequent behaviours in testing. We verified and validated selected safety and functional requirements of the handover task. The results demonstrate the feasibility of CDV in simulation-based testing and its potential benefits in the HRI domain.

The paper is structured as follows. We present the handover scenario in Section [\ref=sc:casestudy]. Our CDV testbench, along with an explanation of the general CDV methodology, are presented in Section [\ref=sc:CDV]. A discussion of the V&V and coverage results is presented in Section [\ref=sc:results]. Section [\ref=sc:conclusions] presents the conclusions and future work.

CASE STUDY: ROBOT TO HUMAN OBJECT HANDOVER TASK

The handover of an object is a critical component of many interaction scenarios, including those between a robot and a person. This case study was chosen to demonstrate CDV in simulation-based testing for robotic code within the HRI domain. Our CDV testbench, described in detail in Section [\ref=sc:CDV], is based on open-source tools. Here, we provide the details of the actual robot to human handover task.

The robot, BERT2 [\cite=lenz2010bert2], starts in a reset state. The handover starts with an activation signal from the person to the robot. The robot then picks up an object, holds it out to the human, and signals for the human to take it. The human sends another signal back, indicating readiness to take the object. Then, the robot makes a decision, within a time threshold, based on a combination of three sensors: "pressure," indicating whether the human is holding the object (applying force against the robot's hold of the object); "location," visually tracking whether the person's hand is close to the object; and "gaze," visually tracking whether the person's head is directed towards the object. The sensing combination is the cross-product, more formally the Cartesian product, of "gaze", "pressure" and "location" readings (GPL for short), i.e. (G,P,L)∈G  ×  P  ×  L. Each sensor reading is classified into G,P,L = {,1}, where 1 represents a value within range indicating the human being ready to receive the object, and [formula] is any other value, including null. The robot does not release the object if the human is not deemed ready, i.e. +GPL +∈{(, * , * ),( * ,, * ),( * , * ,)}, where *  ∈{1,}. If, given the sensor readings, the human is deemed ready, i.e. +GPL += (1,1,1), the robot decides to release the object. The person may disengage from the task after signalling readiness to take the object. The robot may disengage whilst sensing, or while waiting for a signal over a longer time threshold. The sensors are considered perfect.

A robot ROS 'node' was developed to implement the handover interaction protocol, comprising 212 code statements in Python. The code was structured as a FSM using the SMACH modules [\cite=SMACH]. The ROS node's code is depicted as a flow chart in Figure [\ref=BERT2handover].

Requirements List

Safety and functional requirements were derived from the standard ISO 13482:2014 and the work in [\cite=Grigore2011], respectively:

If the gaze, pressure and location are sensed as correct, then the object shall be released.

If the gaze, pressure or location are sensed as incorrect, then the object shall not be released.

The robot shall make a decision before a threshold of time.

The robot shall always either time out, decide to release the object, or decide not to release the object.

The robot shall not close the gripper when the human is too close.

The robot shall start in restricted speed.

The robot shall not collide with itself at high speeds.

The robot shall operate within allowable maximum values to avoid dangerous unintentional collisions with humans and other safety-related objects.

The last of these requirements was implemented as four speed requirements, to more clearly classify the risks associated with the robot. The speed threshold of 250 mm/s is based on the recommendations of the standard ISO 120218-1:2011.

=

The robot hand speed is always less than 250 mm/s.

If the robot is within 10 cm of the human, the robot's hand speed is less than 250 mm/s.

If the robot collides with anything, the robot's hand speed is less than 250 mm/s.

If the robot collides with the human, the robot's hand speed is less than 250 mm/s.

A CDV TESTBENCH FOR HRI

A simulator for the handover interaction was developed in ROS and Gazebo. ROS is an open-source platform for the development and deployment of robotics code, using C++ and/or Python. Gazebo is a robot simulation tool, compatible with ROS, that emulates our world's physics. The person in the handover interaction was embodied as a floating head and hand for simplicity, and a physical model of the robot was developed for Gazebo. These models are shown in Fig. [\ref=Simulatorphoto], contrasted with a real-life handover scenario.

A CDV process starts with a plan. The verification plan is formed by a requirements list including the aspects of the SUT that need to be verified, such as the one presented Section [\ref=sc:casestudy], and a coverage strategy indicating how to achieve effective exploration of the SUT (the robot's code) and advancement of the verification progress [\cite=Piziali2004]. The coverage strategy specifies the design of the testbench components, along with coverage models (how to measure coverage).

The SUT is placed into a testbench for testing. The testbench represents (a model of) the target environment. A fundamental feature of the CDV testbench is automation to facilitate other processes that require manual input, such as effective test generation, bug detection, reliable progress tracking and timely V&V completion. The testbench is formed from four core components: the Test Generator, the Driver, the Checker and the Coverage Collector.

Figure [\ref=simstructure] shows the structure of our CDV testbench implementation, within the simulator, incorporating the robot's high-level control code and the four CDV testbench components. The Driver incorporates Gazebo and other modules interfacing the human components with the robot's components. The design of our simulator ensures the access of these interfaces, internal parameters in the robot's code, and the physical models in Gazebo, to facilitate the work of the Checker and the Coverage Collector. The dotted line indicates a feedback loop that may require human input.

Test Generator

The test generator aims to produce effective and efficient tests to exercise the SUT (the robot's code) towards uncovering bugs while achieving its full coverage. Effective tests address the exploration of scenarios of interest as per the requirements as well as unexpected conditions. Efficient tests maximise coverage (according to models and metrics) and V&V progress, with the minimum number possible. The generated tests must be valid and realistic (e.g., sensors within range of all their possible values).

A first test generation option is pseudorandom (as opposed to random, for repeatability of the test generation), which is, in principle, unconstrained with respect to any assumptions for the environment or the HRI protocol. To generate interesting tests, pseudorandom test generation can be biased using constraints, which may be derived from the requirements list or from the verification engineer's judgement. The implementation of these constraints requires significant engineering skill and application knowledge to be effective. Model-based test generation techniques [\cite=Haedicke2012] [\cite=Lakhotia2009] can target specific use cases or requirements far more efficiently and effectively. In model-based test generation, a model of the system is explored or traversed to obtain test templates. These templates are at the same level of abstraction as the model, and refinement might be needed. The templates can be considered as constraints [\cite=Lackner2012] [\cite=Nielsen2003], to which further constraints may optionally be added to increase the effectiveness of test generation.

For model-based test generation, a model capturing the envisioned HRI behaviours, comprising both the robot and the human/environment, is necessary. The model can be constructed through formalisms such as process algebras and automata. Model checking techniques [\cite=ClarkeMC] can be used to traverse these models to obtain information (witness traces) for test generation. Commonly, a model in such formalisms abstracts from much of the detail of the real HRI and the simulation, e.g. in [\cite=webster14formalshort] the path planning and actuation control have been abstracted from. Process algebras' relation theories can be employed to assess the correctness of an abstract model with respect to the robot's code [\cite=CCSbook].

The test generation methods discussed above were implemented for the handover simulator. Pseudorandomly, high-level action sequences for the simulated human were assembled, from a set of actions, and relevant parameters were instantiated, to form each test. These pseudorandom sequences model a human with freedom within the allowed set of actions, unconstrained with respect to the handover protocol. These tests allow the exploration of the SUT, the robot's code, under many unexpected, or unintended, yet possible human behaviours. The pseudorandom test generator allows constraints to be added to bias tests according to the engineer's judgement. For example, constraints can enforce action sequences that ensure the activation of the robot in the simulations, until the decision making point.

Model-based test generation was implemented, as a more efficient mechanism to effectively bias the test generation towards exploring some of the requirements. A model comprising six Probabilistic-Timed Automata (PTA) [\cite=Hartmanns2009] formalized the handover interaction protocol. Each automaton models an aspect of the interaction: the robot, the human, the human's gaze, location and pressure, and the robot's sensors. The model abstracts the handover protocol, in terms of high-level actions. We applied model checking using UPPAAL, to the PTA model and temporal logic [\cite=ClarkeMC] properties derived from Requirements 1 to 4. These requirements, as opposed to 5 to 8, can be verified at the level of abstraction in the PTA model, after their translation into a suitable temporal logic, e.g., Computation Tree Logic (CTL). The model checking process produced witness traces (examples) for the satisfied properties. These witnesses contain combined sequences of states from the different automata, and thus the robot and the human. By removing the robot's and sensors states from the witness traces via projections, we formed test templates from the human and its gaze, pressure and location actions. Based on these test templates, acting as constraints, tests were generated pseudorandomly.

The use of model checking in model-based test generation has an added benefit in that the verification results complement those of simulation-based testing. Any requirements that can be meaningfully represented at the abstraction level of the formal model can be verified exhaustively with respect to that model, while simulations can verify those same requirements in a more realistic model. Agreement between the results increases confidence in the verification, while discrepancies can expose problems with how the requirements have been expressed, or issues in the simulation models. Although model checking can be applied to code (e.g. using the tool CBMC for a limited subset of C), the properties that are verified at the code level typically focus on runtime errors, such as arrays out of bounds or unbounded loop executions, rather than on high-level functional requirements.

A test for the simulator is formed from high-level human actions with pseudorandomly instantiated parameters constrained within defined ranges. Constraints can be applied, separately or together, to the action sequences and the parameter instantiation. An example is shown in Fig. [\ref=exampletest].

ACKNOWLEDGMENT

This work is part of the EPSRC-funded project "Trustworthy Robotic Assistants" (refs. EP/K006320/1 and EP/K006223/1).