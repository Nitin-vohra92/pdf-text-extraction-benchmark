Similarity-based text recognition by Deeply Supervised Siamese Network

Electrical and Computer Engineering University of Louisville Louisville, KY 40292, USA ehsan.hosseiniasl@louisville.edu Angshuman Guha Captricity, Inc. Oakland, CA 94612 USA angshumang@captricity.com

Introduction

Optical Character Recognition (OCR) is traditionally used to convert images of machine printed text into textual content. Intelligent Character Recognition (ICR) is used to do the same for images of handwritten text. State-of-the-art OCR engines can work well, but only for clean data and where the OCR engine can be adjusted to deal with a single font or a small set of fonts. State-of-the-art ICR engines are significantly worse.

For a real-life application of high-accuracy character recognition involving both machine print and handwriting, one has to develop one's own OCR/ICR engine. This typically requires plenty of character-segmented data, as well as labeling at the character level. This is a very expensive proposition in most real-world situations, if not an impossible one. To avoid the character segmentation cost, [\cite=keeler1991self] proposed learning character segmentation and recognition simultaneously from un-segmented data. This does not work well in practice beyond numeric characters and for large vocabularies. There has been some work at limited-vocabulary whole word recognition, see, for example,  [\cite=lavrenko2004holistic]. To avoid character segmentation, [\cite=lecun1998gradient] proposed a graph transformer network with Viterbi search. These kinds of models cannot compete in performance (training time) with modern deep neural nets that afford efficient implementations, for example, using GPU. [\cite=bunke2004offline] handled the segmentation problem using HMM-based recognition using the Viterbi algorithm. The present authors have experienced (convolutional) neural nets consistently out-performing HMMs in at least two domains, both with large quantities of industrial data: online handwriting recognition and speech recognition. Recently there also has been work involving innovative models where nth characters are predicted for an input word of a fixed-size input image. For instance, one model might predict the first character, another model might predict the second character, and so on. See for example, [\cite=jaderberg2014synthetic].

Our goal is for a practical system that organically incorporates human labeling with machine learning in an active learning paradigm, to achieve very low error rates ([formula]) while minimizing the amount of necessary human labeling.

Siamese Network (SN) is a type of end-to-end metric learning approach, consisting of a neural network that learns a discriminative function. SNs are trained by learning a similarity metric between pairs of data. SN models are applied to signature verification [\cite=bromley1993signature], digit recognition [\cite=hadsell2006dimensionality], face recognition [\cite=chopra2005learning], Speech feature extraction [\cite=chen2011extracting], and Speech keyword detection [\cite=grangier2007learning]. In this paper, we propose and discuss a novel method of text recognition that does not require character-segmented data. by predicting the content of a text using similar labeled texts. We use a Siamese Convolutional Network to learn the similarity between text images in a low-dimensional Euclidean space. To account for similar machine-printed and handwritten text, the SN is regularized by supervision in hidden layers [\cite=weston2012deep] [\cite=lee2014deeply]. Then a k-nearest neighbor algorithm is employed to predict the label based on most similar labeled texts. To account for unseen labels in test data, an interactive k-nearest neighbor algorithm with human annotation is employed for label prediction, and reducing the error. See Fig. [\ref=fig:similar-text] for examples of “similar” images i.e. with the same text content.

Proposed Model

In this section, we propose a model of text recognition based on learning similarity of images. In section [\ref=sec:model], a Siamese network is proposed for learning similarity of text, and section [\ref=sec:framework] describes a text recognition framework.

Learning Text Similarity

To train a model to be able to learn the similarity between texts, a Siamese network is used as in [\cite=chopra2005learning] [\cite=hadsell2006dimensionality]. The Siamese network is trained to project the images into a feature space, where similar images are projected with short mutual Euclidean distance, and dissimilar images are projected with large mutual Euclidean distances. Training of the Siamese network is based on minimizing the contrastive loss of a pair of images,

[formula]

where W = {{w1,...,wn},wo} are the weights of the hidden layers and output layer of the Siamese network, Y is the label of paired images, i.e. 0 if similar and 1 if dissimilar, Dw is the Euclidean distance between a pair of images, and m is the desired Euclidean distance between a pair of dissimilar images. Siamese networks have shown promising results in learning similarity of the handwritten digits dataset, MNIST. However, in complicated cases of long text, capturing similarities between two texts is infeasible using a single loss function in the output layer of Siamese network. The performance of contrastive loss L is dependent on feature extraction of the hidden layers, where it should capture the similarities in a hierarchical way, to enable the output layer to extract features which can clearly represent the similarities of long and complex text. In order to boost the performance of the Siamese network for learning similarity of long text, we used the method of deep supervision proposed in [\cite=lee2014deeply], where several contrastive loss functions are used for hidden and output layers, to improve the discriminativeness of feature learning, as shown in Fig. [\ref=fig:model]. Therefore, the proposed method is called Deeply Supervised Siamese Network (DSSN) and it is trained using the combined contrastive loss,

[formula]

where l indicates the index for hidden layer, o is the output layer. Eq. [\ref=eq:d-loss] indicates that the loss Ll of each hidden layer is only the function of weights of that layer, i.e. l. The DSSN network generates a Similarity Manifold, where similar texts are projected with short mutual Euclidean distances. The next section describes the text recognition model based on the Similarity Manifold. The ADADELTA method of gradient descent ([\cite=zeiler2012adadelta]) is used to update the parameters of DSSN.

Text Recognition by Text Similarity

This section describes a text recognition framework to predict the label of text using the DSSN model developed in the previous section. The text recognition model is based on feature extraction of text using proposed DSSN network. We use a K-nearest neighbor algorithm to predict the label of text images in test data, based on similarity distance to the labeled text in train data. The predicted label is compared with human estimation as shown in Fig. [\ref=fig:framework](a).

Our human-based model for text label prediction is based on voting of two humans on a text image. The proposed framework in Fig. [\ref=fig:framework] (a) is motivated by our goal of reducing the cost of human estimations while maintaining a low error rate. As shown in Fig. [\ref=fig:framework](a), the predicted label of DSSN-KNN is accompanied by a confidence value. We choose two parameters, θ1 and θ2, such that the confidence value can be classified as highly confident, confident and not confident. If the model's prediction confidence is high, we omit the required two human estimations. However, if the prediction is only confident, we validate the predicted label of DSSN-KNN with one human estimation. The parameters θ1 and θ2 are chosen by tuning the model's performance on the training set (or one can use a validation set).

To measure the performance of DSSN-KNN in reducing the human estimation, we define an efficiency metric as shown in Fig. [\ref=fig:framework](b),

[formula]

where T is the total number of text samples, A1 and B1 are the number of confidently wrong and confidently correct predictions, and A2 and B2 are the number of high-confident wrong and high-confident correct predictions, respectively.

Note that the efficiency metric definition implicitly assumes a low rate of disagreement between two humans labeling the same image or between a human and the DSSN-KNN model. If this rate is 1% (which is what we see in practice, see AC column in Table [\ref=tab:thresholds]), the metric will overcount the reduction in the required number of human estimates by [formula]. In the case of disagreement, extra human estimates will be needed to resolve conflicts.

The DSSN-KNN model can be used in one of two modes: ROBOTIC and ASSISTIVE.

ROBOTIC mode is suggested by Fig. [\ref=fig:framework] - (i) for high confidence predictions, we skip human labeling, (ii) for medium confidence predictions, we ask for human confirmation and (iii) for low confidence predictions, we discard the prediction and ask for at least two human estimates.

ASSISTIVE mode is to ignore θ2 (high confidence threshold) - (i) for high and medium confidence predictions, we ask for human confirmation and (ii) for low confidence predictions, we discard the prediction and ask for at least two human estimates.

By definition, ASSISTIVE mode results in zero error from the DSSN-KNN model. But efficiency is lower because {A,B}2 are folded into {A,B}1 in the numerator of Fig. [\ref=fig:framework](b). On the other hand, ROBOTIC mode has higher efficiency at the cost of some DSSN-KNN errors unchecked by humans. We want this error to be under 0.5%. The detail of ASSISTIVE and ROBOTIC mode is explained in Algorithm [\ref=alg:_prediction].

Experiments

In this section, we design several experiments to evaluate the performance of our proposed model of text recognition. First, the DSSN-KNN model is pretrained on MNIST data with same same number of layers and filters. The MNIST pretraining is employed to extract edge-like filters to capture complex variation in handwritten text. Then the trained filters are used to initialize the DSSN for each dataset, and then fine-tuned based on similarity within each datasets, by minimizing the loss function of Eq. [\ref=eq:d-loss]. We have chosen 80% for training and 20% for testing. We select minibatch size of 10 paired texts, containing 5 similar pairs and 5 dissimilar pairs, to train the Similarity manifold. Then based on Algorithm [\ref=alg:_prediction], in an online paradigm, data are read from test set one by one, and the predicted label is compared to truth label (as human) based on the confidence measure. The dataset is collected from form digitization. Then gussian blurring and laplacian are used to remove noise and enhance the contrast before training the model. We used Caffe,  [\cite=jia2014caffe], and Theano,  [\cite=Bastien-Theano-2012], on Amazon EC2 g2.8xlarge instances with GPU GRID K520 for our experiments. First we apply some metrics to evaluate the performance of DSSN in learning the similarity manifold in section [\ref=sec:exp-sim]. Then the performance of DSSN-KNN is evaluated for text recognition of three hand-written text datasets in section [\ref=sec:exp-rec].

Similarity Manifold Evaluation

In order to evaluate the performance of proposed DSSN for text recognition, we evaluated the trained similarity manifold for detecting similar and dissimilar texts. For this purpose, we implemented two separate experiments for non-numeric and numeric texts.

The non-numeric dataset contains 8 classes, where two major classes dominate in sample count. We found that most of the human-labeled 'blanks' are actually not blank, and contain some text from the two major classes. This misclassified text in training data hurts the performance of DSSN. The numeric dataset contains 9 classes, including 'blank' and numbers. The dominant classes are 'blank, '2016', '2018', '2014', and '2020'.

To investigate the distribution of text in the similarity manifold, the feature spaces of hidden layers and output layer are visualized in Fig. [\ref=fig:mp-manifold] and Fig. [\ref=fig:mp-numeric-manifold]. Fig.[\ref=fig:mp-manifold] shows the visualization of texts based on the 50- and 20-dimensional features extracted in 'conv2' and 'ReLu' layers, respectively. (Visualization of multidimensional data is done using a technique called t-SNE. See [\cite=van2008visualizing].) It demonstrates that the three major classes are well-separated e.g. 'LEER, "BECKLEY' and 'Mountain Laurel'. Fig. [\ref=fig:mp-numeric-manifold] depicts the distribution of all texts in 'feat' layer, where each region is expanded for better visualization. Fig. [\ref=fig:mp-numeric-manifold] demosntrates the effect of deep supervision in forming natural clusters of texts with same label in hidden embedding. Accordingly, some boxes contain texts belonging to only one class, e.g. 2, 3, 5, 8, 9, 10, 11. The '2014' class is mixed with other classes of '2018' and '2016', as shown in boxes 1, 4, 6, 7, 13. The 'blank' shreds in box 12 which are combined with '2016' texts are mis-labeled texts - reducing the clustering performance of the DSSN model.

In order to evaluate the similarity manifold, several random pairs of images are selected from the test set and feed-forwarded through the DSSN. Then, the Euclidean distance between the paired images is computed based on the output of 'feat' layer. We choose a decision threshold, θ, such that 0.9 * FN + 0.1 * FP is minimized over the training set. Here FP is the false positive rate (similar images predicted as dissimilar) and FN is the false negative rate (dissimilar images predicted as similar). We weigh FN more than FP because the former increases efficiency at the cost of accuracy while the latter does not hurt accuracy. Table [\ref=tab:sim-error] shows the results for the model initialized by MNIST data, and after fine-tuning on the training dataset.

To further evaluate the similarity manifold, a clustering algorithm is applied on texts and the clustered texts are evaluated based on truth labels in Table [\ref=tab:sim-clust]. For this test, we don't need parallel networks of DSSN. We use the extracted features from hidden and output layers for clustering of the text. Several clustering algorithms were implemented: K-means, spectral clustering, DBSCAN and agglomerative clustering. To have a better evaluation of features in each layer, we applied clustering algorithms on the features of the 'ReLu', 'ip', and 'feat' layers. The number of clusters for K-means and spectral clustering were set to 8. For DBSCAN and Agglomerative algorithms, the number of clusters was based on the similarity distance between text samples. The clustering performance is measured using Adjusted Rand Index ([\cite=hubert1985comparing], [\cite=rand1971objective]), which measures the similarity between clustered text and truth clusters formed by the truth labels. Table [\ref=tab:sim-clust] shows the best clustering algorithm performance, which was agglomerative clustering on 3 layers of DSSN network.

Text Recognition Evaluation

In section [\ref=sec:exp-sim], the similarity manifold learned by DSSN was evaluated for clustering and similarity prediction. This section focuses on performance of the proposed DSSN-KNN framework, as shown in Fig. [\ref=fig:framework] for text recognition. The trained DSSN model was tested on three difficult hand-written datasets. These datasets included hand-written and machine printed text with many variations of translation, scale and image patterns for each class. The number of texts and unique classes in each dataset are listed in Table [\ref=tab:datasets].

The text recognition performance of DSSN-KNN on the three datasets is listed in Table [\ref=tab:final], where the reduction in human estimation is computed. The performance of DSSN-KNN is measured by Accuracy (AC), Accuracy of DSSN-KNN High-Confidence predicted labels (HCAC), Accuracy of medium-confident predicted labels validated by a human (HVAC), False Negative labels (FN), and High-Confidence False Negatives (HCFN). In order to select the confidence and high-confidence thresholds (θ1 and θ2) for each dataset, we did a grid search over the two thresholds to minimize High Confidence False Negative (HCFN). The chosen thresholds for each dataset and the error values are shown in Table [\ref=tab:thresholds].

Some of the text images where DSSN-KNN produces high confidence errors are shown in Fig. [\ref=fig:exp-err]. It is evident that most of the example pairs are, in fact, mutually visually similar, and the "errors" can be attributed to human errors in ground truth. Interestingly, DSSN-KNN sometimes predicts better-than-human labels, for example, spelling corrections.

Conclusion

In this paper, we proposed a new text recognition model based on visual similarity of text images. A Deeply Supervised Siamese Network is trained along with a K-nearest neighbor classifier, to predict labels of text images. The performance of the proposed model is evaluated for accuracy and reduction of human cost of labeling. The results show that the average value of human-less efficiency on successful field is: ~ 25 - 45% in ASSISTIVE mode with NO error, and ~ 50 - 85% in ROBOTIC mode with < 0.5% error. Observed errors are explainable. Predicted labels are sometimes better than human labels e.g. spell corrections. Some of the false negative errors we count are in whitespace and irrelevant punctuation (the "real" error is lower than reported here).