A Computational Model for Amodal Completion

Introduction

Visual completion is a pervasive process in our daily life that works by hallucinating contours and surfaces in the scene when there is not a physical magnitude for them. Whenever we look at an image, our brain unconsciously reconstructs the 3D scene by completing partially occluded objects while inferring their relative depth order into the scene (see Figure [\ref=fig:examples]). In Figure [\ref=subfig:exSintetic], for instance, our brain prefers to interpret the scene as four discs partially occluded by four rectangles instead of, e.g., the more straightforward description of eight quarters of a disc and four rectangles fitting together.

In this paper, we are interested in computationally modeling this perceptual phenomenon, recovering what the brain infers about the structure and the relative depth of the objects composing the scene from a planar image. To simplify the analysis of our approach, we focus on scenes where objects appear at two different depths, ones occluding the others. The current approach can handle scenes with both partially occluded and fully visible objects. Our contribution is twofold: firstly, we propose a computational method relying on perceptual findings related to amodal visual completion to compute the disoccluded objects that form the possible 3D interpretations or configurations that arise from a planar image; and secondly, we propose a Bayesian probabilistic model which chooses between these possible interpretations of a planar image the most plausible one, justifying the visual completion human experience. The disocclusion method works by minimizing the Euler's elastica and incorporates the concepts of relatability of the occluded contours and convexity of the disoccluded objects. Roughly speaking, two contours are relatable if they can be connected with a smooth contour without inflection points [\cite=KellmanShipley] (see Figure [\ref=subfig:relatable]-)) . An equivalent and more precise definition is given in Section [\ref=sec:theModel] (see Def. [\ref=defRel]) but let us now notice that the relatability property implies that two contours can be relatable no matter how far away their corresponding ending points are. Once the objects conforming the scene are disoccluded, we follow a Bayesian approach and give definitions for the prior probability and the likelihood, measured, respectively, by the object complexities and an elastica-based quantity. As a consequence, our probability model takes into account the shape of the objects in the hypothesized scenes as well as the effort of bringing these objects in their relative positions in the visual image.

The structure of the paper is as follows. In Section [\ref=sec:relatedwork] we review the related work and the fundamentals of visual completion. Section [\ref=sec:theModel] is devoted to present the proposed approach: in particular, Subsection [\ref=sec:binaryinpainting] presents the object disocclusion method, while Subsection [\ref=sec:approach] details the probabilistic model. Section [\ref=sec:algorithm] explains the numerical algorithm while Section [\ref=sec:experimentalresults] provides experimental results. Finally, we present our conclusions in Section [\ref=sec:conclusions].

Related research

The visual completion phenomenon has been intensively investigated during the past fifty years and it is still an active area of research [\cite=kanizsa1972amodal] [\cite=kanizsa1985seeing] [\cite=michotte1991amodal] [\cite=gerbino1987effect] [\cite=ringach1996spatial] [\cite=murray2004setting] [\cite=froyen2015modal] [\cite=carrigan2015differentiating]. Nowadays, it is well acknowledged that occlusion patterns evoke both local and global completion processes, but how the final perception outcome is conveyed is still not well understood. Local completion has been related to the good continuation of visible contours [\cite=Wertheimer1923], while global completion is driven by the simplicity principle [\cite=koffka1935] [\cite=Kanizsa1979]: The assumption that the visual system favours interpretations characterised by phenomenal simplicity, such as symmetry, repetition, familiarity or context properties [\cite=Sekuler], and regularity, and typically leads towards the simplest completed shape, even though the good continuation principle may be violated. Figure [\ref=subfig:divergent] shows an example where two different amodal completions occur depending on whether a global cue as symmetry is incorporated or only more local cues, while in Figure [\ref=subfig:convergent], both interpretations coincide. Some authors (e.g., [\cite=moravec86] and references therein) have noticed that features favoring completion through good continuation are read out more quickly (in the very first second) than are features favoring completion through symmetry (which are incorporated in the following 9 seconds). The incorporation of different cues was also studied by Rubin [\cite=rubin2001role] who experimentally proved that local and global occlusion cues affect the perception of amodal completion at different stages of visual processing. As for global cues, the author focused in relatability and surface similarity, being cues that seem to be instantaneously used at first stages of occlusion perception. Relatability (see Figure [\ref=fig:relatability]) was first introduced by Kellman and Shipley [\cite=KellmanShipley], who noticed that it is a necessary global condition for completion to occur. Then, for the perception of amodal completion, Rubin proposed that the detection of local cues such as T-junctions (see Figure [\ref=fig:t-junction]) generates a local pattern of activation which launches a process of propagation of the contour which is either enhanced or stopped depending on whether or not other global cues such as relatability or surface similarity hold.

The evidence that the visual system generates multiple interpretations and that visual completion is the result of a competition between them, was discussed by van Lier et al. [\cite=van1995competing] [\cite=van1995multiple]. In Figure[\ref=subfig:divergent] is shown that sometimes global and local processes may diverge, and since it is not always the same process which is prevalent, a theory based on either local or global principles alone cannot hold. Later, van Lier et al. [\cite=VanDerHelm1] proposed an integrative model of global and local aspects of occlusion.

In computer vision, the computational translation of the visual completion phenomenon is commonly referred to as disocclusion or inpainting. A pioneering contribution to the recovery of image plane geometry was given by Nitzberg, Mumford and Shiota [\cite=NitzbergMumfordShiota]. The authors proposed a variational model for segmenting the image into objects which should be ordered according to their depth in the scene, providing the so-called image 2.1 sketch. The minimization of the functional should be able to find the occluding and the occluded objects, while finding the occluded boundaries. The energy functional is defined in terms of region simplification and completion of occluded contours. Contours completion is achieved by linking signatures of occlusion, the T-junctions (see Figure [\ref=fig:t-junction]), with the Euler's elastica, so that the completion tends to respect the principle of good continuation [\cite=Kanizsa1979] [\cite=Kanizsa1991]. Despite its theoretical importance, the complexity of minimizing this energy makes the approach far from practical applications. On the other hand, it was one of the main sources of inspiration for the first inpainting algorithms. A first formulation was proposed by Masnou and Morel [\cite=masnoumorel1998], who tried to interpolate the data into the uncomplete region by minimizing an energy functional based on the Elastica. A similar approach was followed in [\cite=BBCSV-01] and in the work of Chan and Shen [\cite=ChanShen]. Those methods belong to the so-called geometry-oriented methods where the images are modeled as functions with some degree of smoothness, expressed, for instance, in terms of the curvature of the level lines [\cite=masnoumorel1998] [\cite=BBCSV-01] [\cite=ChanShen] [\cite=masnou2002disocclusion] [\cite=inpaintingCao2011] or the total variation of the image [\cite=inpaintingTVchan2001]. Binary inpainting tools for images are also used to disocclude shapes and thus can be considered as geometry-oriented methods. Binary inpainting can be based on diffusion processes followed by thresholding, named as thresholding dynamics (e.g. [\cite=MBO]). Thresholding dynamic interpolations also usually minimize a geometric functional, based either on the length, area, or curvature of the shape contours [\cite=MBO] [\cite=ERT-05] [\cite=GH-03].

This work is focused on a computational model that, given an image of a 3D scene, it automatically outputs the preferred - according to human perception - interpretation of the scene in terms of depth configuration of the scene objects together with their completion in case of occlusions. A related and inspiring work in the literature is the proposal of van Lier et al. [\cite=VanDerHelm1]. They proposed to choose the preferred scene interpretation based on the minimum complexity or description code, taking into account local and global aspects of occlusion. Their model assumes that the most likely interpretation is the one that minimizes the sum of the complexity of three components of the visual pattern: (i) The internal structure, related to each of the visible shapes separately, (ii) the external structure, related to the positional relation between these shapes, and (iii) the virtual structure, related to the occluded parts of the shapes. The perceptual complexity of each of these three components is expressed in terms of structural information theory (SIT) [\cite=SIT], a formal coding model that encodes complexity in terms of descriptive parameters. However, van Lier et al. do not automatically complete the occluded objects and the complexities are manually estimated from line drawings; thus their approach can not be directly applied to images in a computer vision task. The same authors noticed in [\cite=van2011bayesian] that the global minimum principle can be settled in a Bayesian framework (see [\cite=knill1996] and references therein) by properly defining prior and conditional probabilities. In this paper, based on a Bayesian framework, we propose a fully automatic method that can be applied to any image decomposed in shapes.

The model

Our model is grounded in two elements: a disocclusion method that computes the different objects conforming different potential scenes that are compatible with the given planar image, and a probabilistic model that quantitatively justifies which scene configuration is the preferred. As we are considering two-depth images, the possible interpretations or hypothesis of the real 3D scene are three, namely: object A occluding object B, B occluding A, or A and B fitting together forming a mosaic (see Figure [\ref=fig:nHypothesis]). We will denote them by H1, H2, and H3. Let us remark that sometimes the objects in the third interpretation H3 (i.e., A and B fitting together) coincide with one of the others, both perceptually and using our algorithm (an example is shown in Figure [\ref=subfig:2hyp]), or even the objects in all three hypothesis coincide (an example is shown in Table [\ref=tab:alltogether3]). Even if the objects forming the scene coincide in different hypothesis, the depth ordering is not the same in each hypothesis. In Section [\ref=sec:experimentalresults] we will provide some experiments analyzing this phenomenon which is related to the well-known optical illusion of relative size perception (see Figure [\ref=fig:illusions]). In the Perception community, the observed image is often called the proximal stimulus (e.g., the left image in Figure [\ref=subfig:3hyp] and ), and each of the hypothesized interpretations Hi is called the distal stimulus.

Our method first computes several distal interpretations of the scene which are compatible with the proximal planar image. Rubin [\cite=rubin2001role] studied the role of T-junctions, relatability and surface-similarity in the amodal completion phenomenon and illusory contour perception. The author proposed that T-junctions, being a local cue for occlusion, are used to launch the completion process when contours are relatable [\cite=KellmanShipley]. Then, the Gestalt law of good continuation plays an important role. This motivates us to use the Euler's elastica in order to smoothly continue the contours. Let us recall that, given two T-junctions at points x1 and x2, with tangents τx1 and τx2 to the respective terminating stems (also called T-stems, see Figure [\ref=fig:t-junction]), Euler solved in 1744 [\cite=Mumford] the problem of joining them with a smooth continuation curve minimizing

[formula]

where the minimum is taken among all the curves [formula] joining x1 and x2 with tangents τx1 and τx2, respectively, κ denotes the curvature of [formula], [formula] its arc length, and β is a positive constant. The parameter β plays a geometric role by settling the expected underlying a priory regularity. In this sense, with a larger β, the energy favours the completion with straight lines (minimal length). Otherwise, smooth curves of low curvature are favoured (Figure [\ref=fig:beta-parameter] illustrates the effect of the parameter β on the underlying regularity of the disoccluded shape). This energy has been frequently used to solve different computer vision problems (e.g. [\cite=NitzbergMumfordShiota] [\cite=Mumford] [\cite=masnoumorel1998] [\cite=ThornberWilliams] [\cite=LeungMalik] among others). In a recent work that proposes a computational method for modal completion [\cite=kang2014illusory], the elastica is a key ingredient to obtain illusory contours. We propose in Section [\ref=sec:binaryinpainting] an elastica-based object disoclusion method which incorporates the relatability of partially occluded contours and the convexity of the disoccluded objects. On the other hand, the elastica is also used in Section [\ref=sec:approach] to select the most probable disoccluded scene.

Elastica-based object disocclusion

For disoccluding the objects, we focus on the completion that takes place in the first time instants of observation [\cite=moravec86] or when the local processes dominate due to limited regularities in the object or low saliency of the symmetry cues versus the good continuation [\cite=Sekuler]. In the perception community, this completion is usually called local completion. The disocclusion method we propose integrates global and local cues: Global cues such as relatability and convexity are incorporated in the inititial step of our algorithm, followed by local ones such as smooth continuation.

We propose to disocclude partially occluded objects by a binary inpainting algorithm that simulates the minimization of the elastica [\eqref=eq:Elastica]. Disocclusion, also known as image completion or inpainting, is the recovery of missing or corrupted parts of an image in a given region so that the reconstructed image looks natural. Most available methods for inpainting can be divided into two groups: geometry [\cite=masnoumorel1998] [\cite=BBCSV-01] [\cite=ChanShen] [\cite=inpaintingTVchan2001] [\cite=masnou2002disocclusion] [\cite=ERT-05] [\cite=inpaintingCao2011] and texture-oriented methods [\cite=inpainting_demanet_2003] [\cite=inpainting_criminisi_2004] [\cite=inpainting_wexler_irani_2007] [\cite=inpainting_kawai_2009] [\cite=inpainting_aujol_2010] [\cite=inpainting_arias_2011] [\cite=mansfield_2011]. The synthesis of methods of these two types is still an open question [\cite=inpaintingCao2011]. Since we are interested in recovering objects or shapes, we will focus on geometry-oriented methods, where images are usually modeled as functions with some degree of smoothness, expressed, for instance, in terms of the curvature of the level lines or the total variation of the image. Taking advantage of this structure, these methods interpolate the inpainting domain by continuing the geometric structure of the image (its level lines or edges), usually as the solution of a (geometric) variational problem or by means of a partial differential equation.

In this paper, we are concerned solely by the shape of the objects. Thus, we work with segmented objects and we perform a geometric inpainting of the binary images that represent these objects. More precisely, we disocclude each object in each hypothesis by separate considering the hypothesized occluding object as the inpainting mask. The object is automatically completed in such a way that its boundary minimizes the elastica [\eqref=eq:Elastica]. For that, the object to be completed is represented in a binary image (given by the object segmentation) and the minimization of [\eqref=eq:Elastica] is performed through a threshold dynamics algorithm which mainly consists in a diffusion process followed by a thresholding. In our case, the minimization algorithm iteratively alternates one step of the Grzibovskis-Heintz scheme [\cite=GH-03] that decreases [formula], one step of the standard Merriman-Bence-Osher scheme [\cite=MBO] that decreases [formula], and a thresholding step, as proposed by Esedoglu et al. in [\cite=ERT-05]. Figure [\ref=fig:beta-parameter] shows an example illustrating how the parameter β affects the disoccluded shape: larger values of β give more strength to the length than to the curvature, so the completion is closer to a straight line than to a circular one. On the other hand, depending on the resolution of the proximal stimulus, the parameter β needs to be adapted to obtain the same underlying shape regularity. An example is shown in Figure [\ref=fig:b_vs_r]: circles with larger radius need a larger value of β in order to obtain the same regularity. The reason is the following: the curvature of smooth plane curves is defined as the inverse of the radius of the osculating circle (the unique circle which most closely approximates the curve near the point). Therefore, there is a relationship between the numerical curvature of the disoccluded objects and the a priori regularity imposed through the parameter β: the larger the β, the larger the expected radius of the osculating circle.

In Section [\ref=sec:approach] we define prior probabilities and likelihoods which take into account global and local properties of the shape. As a consecuence, the Bayesian approach is able to choose the more likely amodal completion not only between the different hypothesis on the scene configuration for a fixed disocclusion parameter β (as shown in Sect. [\ref=sec:approach]), but also between several disocclusions associated to different parameters β, and therefore to integrate some global completion properties such as symmetry or repetitions. For instance, Figure [\ref=fig:beta-parameter] presents the different hypothesis certainty, denoted by p̃ in Sect [\ref=sec:approach], for different values of β.

Initialization of the inpainting mask

Since the elastica energy [\eqref=eq:Elastica] is not convex, the inpainting result depends on the initial condition inside the inpainting mask. Let us illustrate it with a simple example. In Figure [\ref=fig:initializations] we show the inpainting results (shown in the second row) obtained by minimizing the elastica with different initializations, namely, initializating the mask with white, black, random (black and white choosed randomly from a uniform distribution) or with our proposal, which is explained in the remainder of this section.

In order to automatically compute an initialization of the inpainting problem sufficiently close to what humans perceive as disoccluded objects by amodal completion, we incorporate perceptual cues such as relatability of object contours [\cite=KellmanShipley] and convexity of the disoccluded objects.

The notion of relatability (see Figure [\ref=fig:relatability]) was introduced by Kellman and Shipley [\cite=KellmanShipley] in the attempt of defining under which conditions visual completion occurs. Let us recall the definition of relatability.

Let E1 and E2 be two (non-closed) edges and let x1 and x2 be one of their respective end-points. Let τx1 and τx2 be the tangents at these points, pointing to the direction along which the interpolated contour must continue. Consider the semi-lines s1  =  {x1  +  λτx1,  λ  ≥  0} and s2  =  {x2  +  λτx2,  λ  ≥  0}. Then, E1 and E2 are relatable if: (a) s1 and s2 intersect, and (b) their outer angle of intersection (i.e. from τx1 to -  τx2) is acute or [formula].

In [\cite=SinghHoffman], the authors showed that this definition is equivalent to the existence of a smooth contour without inflection points connecting x1 and x2, and that the interpolating curve doesn't turn through a total angle of more than [formula].

Since (non-occluded) objects in the world tend to be convex [\cite=burge2010natural], we favour the convexity of the disoccluded object by taking advantage of the following well-known property of convex sets.

Every closed convex set in Rn is the intersection of the closed half-spaces that contain it.

The automatic initialization of the binary image inside the inpainting mask is illustrated in Figure [\ref=fig:iniMask1]. In practice, our algorithm considers all the end-points of the object contours (given in this case by the level lines) arriving to the inpainting mask together with their tangents (illustrated in Figure [\ref=subfig:tangents1] by a line passing through them), and computes all the possible pairs of relatable contours (shown in Figures [\ref=subfig:rel1] and [\ref=subfig:rel2]). In order to compute these tangents we use the Line Segment Detector [\cite=lsd]. Then, for each pair of relatable contours, for the end-point xi and tangent τxi we consider the half-space [formula] (or ≤  0, depending on which half-space the object is), and we assign a vote to the half-space on which the known object is. Figure [\ref=subfig:lema1] and Figure [\ref=subfig:lema2] display the image gathering these votes in the inpainting mask, for the shapes shown in Figure [\ref=subfig:ps1] and Figure [\ref=subfig:ps2], respectively (the shape to disocclude is shown in white and the inpainting mask is shown in gray, respectively). Let us remark that, in order to better illustrate our perceptually inspired initialization, in Figure [\ref=subfig:lema1] and Figure [\ref=subfig:iniMask1] (respectively, in Figure [\ref=subfig:lema2] and Figure [\ref=subfig:iniMask2]) we only show the computed values inside the inpainting mask. Finally, we binarize the image containing the votes with a threshold based on a rank order filter of these votes. We order the votes in increasing order and start with a threshold with the value ranked at percentile 75th. If no new connected components appear in the initialization with this threshold we keep it. Otherwise we decrease the threshold (taking the preceding ordered value) and repeat the process until no new connected components appear. Two different examples of this binary image are shown in Figure [\ref=subfig:iniMask1] and [\ref=subfig:iniMask2], they are the initialization of the binary inpainting algorithm. Figure [\ref=subfig:iniMask1] shows an example where the threshold on the votes correspond to the 75th percentile while in Figure [\ref=subfig:iniMask2] the threshold was automatically decreased to the 65th percentile in order to obtain an initialization with a single connected component.

Elastica-based probabilistic model

In this section, we follow a Bayesian approach [\cite=knill1996] in order to choose among all possible interpretations of the scene, the most plausible one. We propose definitions for the prior and the conditional probabilities which take into account the global complexity of the objects in the hypothesized scenes as well as the effort of bringing these objects in their relative positions in the visual image. As a consequence, the result of this probability model indicates that the most simple interpretation is the one that more likely results from the amodal completion process, which was also suggested by [\cite=van2011bayesian].

Inspired by the work of van Lier et al. [\cite=VanDerHelm1], our probabilistic model takes into account the complexity of the objects. Each hypothesized scene is formed both by completely visible objects and disoccluded objects (computed using the method described in previous Section [\ref=sec:binaryinpainting]); their respective global complexities are taken into account to define the prior probability of the hypothesized scene under analysis. The likelihood, i.e. the conditional probability of the given image (proximal stimulus) given a certain hypothesis (distal stimulus) is defined through an Euler's elastica-based quantity that measures two attributes: the effort of bringing these objects in their relative positions given in the image and the smoothness of the disoccluded boundaries. Our probabilistic model provides a formalization allowing to computationally verify directly on images the proposal of van der Helm [\cite=VanDerHelm1] [\cite=van2011bayesian] (based on manually estimating complexity from line drawings) giving a probabilistic interpretation of the visual completion process.

We propose to predict and justify the preferred interpretation by maximizing the responsibility or a posterior probability, given by the Bayes' rule as

[formula]

over the hypothesized interpretations Hi, where I is the proximal stimulus or given image. As the quotient p(I) remains the same for all hypothesis Hi in the maximization process, we propose to select the preferred hypothesis [formula] by

[formula]

Given the underlying hypothesis Hi and the proximal image I, we define the conditional probability p(I / Hi) as

[formula]

where Bci and Bdi stand for common and disoccluded boundaries, respectively (see Figure [\ref=fig:boundaries] for an example with two hypothesis) and ω1 is a normalization constant. Formula [\eqref=condPr] measures the responsibility that hypothesis Hi takes for explaining the proximal stimulus I as well as the deviation of I from Hi.

With the first integral in [\eqref=condPr] we compute the difficulty of bringing the two objects together in order to get the perceived image taking into account only the known boundary of the objects; for example, it is easier to obtain configuration [\ref=subfig:b_dc] than [\ref=subfig:b_c] as in the first case only two points need to coincide, independently of the two coinciding points we will perceive the same image, and in the other case, H2, a larger boundary needs to coincide in order to to perceive exactly that configuration. The second integral takes into account the regularity of the occluded boundary of the shape to define the probability of obtaining a particular stimulus; for example in Figure [\ref=subfig:facil] we can move the disc at many different positions behind the square to obtain the same image we are observing, but in Figure [\ref=subfig:dificil] the movements we can do are more limited, as the perceived image will change drastically. Let us remark that due to the way we disocclude the objects the resulting disoccluded boundaries are always smooth; if we had different models of disocclusion this term would help to distinguish among them (in addition to the prior term). For instance, with our disocclusion model based on the elastica we are not able to recover the occluded object in Figure [\ref=fig:probs](b) or the objects A in Figure [\ref=subfig:divergent].

The prior probabilities are defined as

[formula]

where ω2 is a normalizing constant, and O1i and O2i are the (disoccluded) objects in the hypothesized interpretation Hi. The factor [formula] denotes the complexity of the object or shape Oji at depth j. In the case that the object at one depth is formed by more than one connected component the complexity is computed separately for each connected component and their sum constitutes the complexity of Oji. We use the definition of complexity of a shape defined by Chen and Sundaram in [\cite=complexity] which takes into account global properties of the shape such as entropy measures of global distance and local angle, and a measure of shape randomness (global distance is defined as in [\cite=complexity] as the distance of boundary points to the centroid of the shape). Therefore, the defined prior probability considers global properties such as shape contour symmetries and repetitions.

Let us notice that with these definitions our whole model for amodal completion is able to choose, not only between the different hypothesis for a fixed disocclusion parameter β but also between several disocclusions associated to different parameters β, and therefore to take into account global completion properties such as symmetry or repetitions. In Figure [\ref=fig:beta-parameter] there is an example illustrating this computational ability, where the different probabilities associated to the different disocclusion results depending on β are given. Both normalization constants, ω1 and ω2, are defined, respectively, by the inverse of the maximum value, over all the hypothesis Hi, of the elastica and the object complexity.

Let us comment on the term [formula] in our definition [\eqref=condPr]. When visual completion occurs while propagating the stem, (e.g., hypothesis H1 in Figure [\ref=subfig:2hyp]), the common boundaries Bc between the objects are reduced to the T-junctions. In this case: [formula] and [formula]. Let us notice that in the distal stimulus, since we are considering closed objects, Bc belongs to both objects, and if the objects are interpreted as being fit-together (e.g., hypothesis H2 in Figure [\ref=subfig:2hyp]), a disoccluded boundary Bd  =  Bc appears. Let us also comment on the effect of the regularity of Bc. Figure [\ref=fig:3discandsquares] presents three different proximal stimuli or images. The numerical computation of the term [formula] associated to each of the three images will decrease from left to right in the fit-together (or mosaic) interpretation, the same behaviour applies to the complexity-related terms [formula] and [formula]. Therefore, the visual completion will become more and more evident and the interpretation of two complex pieces fitting together will become perceptually less favourable.

Let us finally remark that we are not considering all possibles configurations [\cite=von2009toward] but only the ones favoured by relatability, convexity, and good continuation. On the other hand, even if global cues such as symmetry or repetitions are taken into account in our probability model, we do not incorporate them in the disocclusion algorithm. In the future, we plan to integrate it with other disocclusion strategies (such as, e.g., exemplar-based methods [\cite=inpainting_aujol_2010] [\cite=inpainting_arias_2011] or [\cite=HayashiSasaki]) allowing to model these global properties and obtain, e.g., the objects A in Figure [\ref=subfig:divergent].

Algorithm and Implementation details

Algorithm [\ref=algoSummary], shows the steps of the whole numerical algorithm. Let us detail it: Our algorithm needs a decomposition of the given image into objects and object parts which are interpreted as projections of real 3D objects on the image plane. This decomposition can be given either from the classical decomposition in level sets, in bi-level sets or segmenting the image from a criterion. In this paper, for the synthetic images, we use the decomposition in bi-level sets, which are defined as usual by X(λn,λn + 1)I = {x∈Ω:λn  ≤  I(x) < λn + 1}, where Ω is the image domain and {λn}  ⊂  R is a finite strictly increasing sequence; and for the real images, we use the segmented shapes from the Berkeley segmentation dataset [\cite=MartinFTM01]. In this way we obtain the objects that appear in the image; these objects will be denoted by X1 and X2. From X1 and X2 the three hypothesis will be considered by the algorithm: X1 occluding the distal object D2 (corresponding to the proximal X2), X2 occluding the distal object D1 (corresponding to the proximal X1), and X1 and X2 fit together. Now, by applying the disocclusion method of Section [\ref=sec:binaryinpainting] where X1 and X2 are, respectively, the inpainting mask, we compute the complete hypothesis [formula] and [formula], respectively. Then, to this two hypothesis, we always add the additional hypothesis [formula] of the mosaic interpretation (which is obtained when we do not apply the disoccluding algorithm). For each Hi we compute the probabilities p̃(I / Hi) and p̃(Hi) from the definitions in Sect. [\ref=sec:approach]. Finally, we compute the perceptually preferred hypothesis HP by ([\ref=max]).

Experimental results

The proposed method has been tested with both synthetic and real images. The only parameter of our method is β, which sets the underlying a priori regularity (see comments on its role in Section [\ref=sec:binaryinpainting]). It has been fixed to 0.6 for all the experiments, with two exceptions, namely, Proximal 2 of Table [\ref=tab:alltogether1] and Proximal 15 of Table [\ref=tab:alltogether2], where β is fixed to 1.2 and 1.7, respectively, due to the biggest size of the circular shapes. As explained in Section [\ref=sec:binaryinpainting], there is a relationship between the numerical curvature of the disoccluded objects and the a priori regularity imposed through the parameter β: the larger the β, the larger the expected radius of the osculating circle locally approximating the curve.

The experiments of this Section are organized as follows: The synthetic experiments, which are described in the following Section [\ref=sec:synthetic], are shown in Tables [\ref=tab:alltogether1], [\ref=tab:alltogether2] and [\ref=tab:alltogether3] while the experiments on real images (described in Section [\ref=sec:real]) are shown in Tables [\ref=2segs], [\ref=tab:alltogether7], [\ref=tab:alltogether5] and [\ref=tab:alltogether6]. Table [\ref=tab:alltogether7] shows our results on images of the Berkeley dataset with provided figure-ground ground-truth labeling [\cite=figuregroundBerkeley]. Finally, Table [\ref=tab:alltogether8] in Section [\ref=subsec:fig-ground] shows the ability of our method to also decide on (perceptually) fully visible objects over a background. For each row in each table we show a complete experiment.

Let us recall that our method assumes the proximal stimulus to be decomposed into objects and object parts (which can be interpreted as projections of real 3D objects on the image plane). As in the synthetic experiments, the images are formed by objects with a single and unique color, this already gives a segmentation and we apply our algorithm directly. For the real experiments, we use a segmentation of the image. In particular, we have taken segmented images from the Berkeley segmentation dataset [\cite=MartinFTM01] and from [\cite=SemanticBenchmark].

Synthetic images

Tables [\ref=tab:alltogether1], [\ref=tab:alltogether2] and [\ref=tab:alltogether3] show some experiments on synthetic images. For each row in each table, a complete experiment is shown. We first present the proximal image (piecewise constant) I on the left, followed by the three hypothesis Hi (each one separated by a gray box), together with the values p̃(I / Hi) and p̃(Hi) proportional to the conditional probability and the prior probability, respectively, and the probability value p(Hi|I). Let us remark that we have normalized the probabilities in such a way that p(H1 / I) + p(H2 / I) + p(H3 / I) = 1. The probability value of the preferred hypothesis HP is highlighted in boldface. For the first two hypothesis, H1 and H2, we display the objects at depth 1 on the left, and the disoccluded objects (at depth 2) on the right. Let us recall that the objects at depth 1 are considered the inpainting mask for disoccluding the objects at depth 2. Finally the last column is the hypothesis H3 where the two objects are fitting together at the same depth.

Let us comment on the results in Tables [\ref=tab:alltogether2] and [\ref=tab:alltogether3]. In Table [\ref=tab:alltogether2], the third hypothesis is not shown because it coincides with H2 due to the fact that the disocclusion algorithm does not change the objects being disoccluded. Besides, in Table [\ref=tab:alltogether3] there is shown a synthetic experiment where the three hypothesis coincide on account of the obtained disoccluded objects: The disocclusion algorithm applied in the first two hypothesis does not change the objects and thus H1  =  H2  =  H3, and the posterior probability is the same for all three hypothesis. Let us remark that, even if the objects forming the scene coincide in different hypothesis, the depth ordering is not the same in each hypothesis. Let us singularize and explain one example in Figure [\ref=subfig:2hyp], where our method produces H3 = H2. However, as for depth order, H3 is interpreted as two objects at the same depth (and having the real relative size which is observed in the proximal image) while H2 can be interpreted as three quarters of a disc which is closer to the observer, plus a square which can be of bigger size but farther away from the three-quarters-of-a-disc shape and whose boundary partially coincides with part of the boundary of the three-quarters-of-a-disc shape. Notice that this situation is related to the well-known ambiguity in size of some proximal stimulus, sometimes causing optical illusion of relative size perception as the one displayed in Figure [\ref=fig:illusions].

In all experiments except for three (proximals 6, 9 and 15), our method agrees with human perception. The perception literature acknowledges that, in a T-junction, the occluder is the surface on the T-head side while the surfaces on the T-stem side continue behind the occluder [\cite=rubin2001role]. This phenomenon is validated by our method: The preferred hypothesis, highlighted in boldface, is the one that is obtained by continuation of the T-stems. Let us comment on the results corresponding to Proximal 6, 7, 8, and 9 of Table [\ref=tab:alltogether1], which include quite similar shapes but with different occlusion signatures and different common boundaries among the shapes. In Proximal 7 and 8 (and also in Proximal 11 of Table [\ref=tab:alltogether2]), the local perception cue at the T-junctions indicates that there is an occluded disc which continues behind an incomplete square (the occluder). Our method is able to choose the corresponding preferred hypothesis as is shown by the probability values p(H1 / I). On the contrary, in Proximal 6 and 9, the local occlusion signatures given by the T-junctions indicate that there is an occluded square which continues behind an incomplete disc (the occluder). Taking this into account, our method fails to give the hypothesis that agrees with the T-junction cues (which should be H2). In Proximal 6, the likelihood of the hypothesis H1 and H2 are similar but the global complexity of the shapes in H1 is smaller (thus higher prior) than the global complexity of the shape in H2. In particular, any of the two shapes present in H1 is simpler that any of the two shapes in H2. Regarding Proximal 9, the highly irregular contour of the shapes makes difficult a straightforward analysis and the final chosen hypothesis is due to a balance among the corresponding complexities and likelihoods. In Proximal 15 of Table [\ref=tab:alltogether2], according to the local cues given by the T-junctions, the preferred option should be H1. However, our method obtains H2; although a higher prior due to a smaller complexity of the objects in H1, the likelihood of H2 is higher due to smaller elastica values in H2. On the contrary, in Proximal 16 on Table [\ref=tab:alltogether2], according to the T-junctions we should prefer H1 (as the method chooses), but for symmetries most of us perceptually prefer H2. In this case, according to the prior H2 should be preferred (as symmetries are valued positively), but as the disoccluded and common boundary are so large in H2, the value p̃(I / H1) is much bigger, and H1 is selected as preferred. Finally, let us comment on Proximal 4 which is a well-known and perceptually controversial example. The preferred hypothesis for Proximal 4 is the one that agrees with the T-junction cues and the one reported in [\cite=VanDerHelm1] to be the most preferred by the subjects participating in their psychophysics experiments. However, in this case the posterior probabilities for H2 and H1 are quite close and, according to our personal experience (e.g., by incorporating our knowledge about the world and objects of similar shapes), some people prefer the interpretation according to H2. Both experiments, Proximal 4 and 16, are examples where hypothesis H1 and H2 correspond, respectively, to a local and global completion of the occluded object. In both cases, our algorithm favours local completion, that is, a completion that produces good continuation instead of the global one which produces a more symmetric object (notice that the local completion in both cases produces a symmetric object with respect to one axis). As commented in Section [\ref=sec:relatedwork], both kind of completions interplay and the prevalence of one of them depends on the observation time [\cite=moravec86] and on the saliency of the good-continuation versus symmetry in the completion [\cite=Sekuler].

Summarizing, our method fails in 3 out of 15 synthetic images, giving a success rate of 80%. Let us notice that we do not include in the statistics the ambiguous cases Proximal 4 and 16.

Real images

In this section we show some results on real images from the Berkeley dataset [\cite=MartinFTM01] and the dataset provided in [\cite=SemanticBenchmark]. For all experiments, we present the real image, the proximal stimulus I which is a segmentation of the real image (one of the segmentations provided in the databases), followed by the three hypothesis Hi (each one separated by a gray box), together with the values p̃(I / Hi) and p̃(Hi) proportional to the conditional probability and the prior probability, respectively, and the probability value p(Hi|I). The probability value of the preferred hypothesis HP is highlighted in boldface. For the first two hypothesis, H1 and H2, we display the objects at depth 1 on the left, and the disoccluded objects (at depth 2) on the right. Let us recall that the objects at depth 1 are considered the inpainting mask for disoccluding the objects at depth 2. Finally the last column is the hypothesis H3 where the two objects are fitting together at the same depth.

We start illustrating that our method is robust to different segmentations of the same image. Table [\ref=2segs] shows a real image with a bear holding a branch and two different segmentations (representing the proximal stimuli). Both segmentations are from the ground truth available in [\cite=MartinFTM01]. Segmentation 1 reflects that some flowers are partially occluding the bear and increasing the complexity of the bear shape; the flowers do not appear in segmentation 2 and thus the bear shape has a lower complexity (its complexity is 0.53, while in the previous case, Segmentation 1, was 1.34) Notice that the values p̃ are not comparable among the two experiments (only among different hypothesis within the same experiment) because they use a different normalizing constant ω2 (see Section [\ref=sec:approach] for further details). Finally, the most preferred interpretation of the image coincides using the two different segmentations, i.e., it is a branch partially occluding a bear for both stimulus.

In Table [\ref=tab:alltogether7] we present results on images of the Berkeley dataset with provided figure-ground ground-truth labeled by humans. Then, Table [\ref=tab:alltogether5] shows experimental results on real images from [\cite=SemanticBenchmark] and Table [\ref=tab:alltogether6] shows results on images from the Berkeley Segmentation database [\cite=MartinFTM01]. Each row shows a different experiment: the two left-most images are, respectively, the original image and a segmentation of it, they are followed by the three different hypothesis (each one separated by a gray box). For the images in Table [\ref=tab:alltogether7], superimposed on the original image, we display the provided figure-ground ground-truth [\cite=figuregroundBerkeley] as a boundary in two colors, namely, black and white. The black side of the border indicates the object that is behind, while the white region indicates the frontal object. In the experiments of Table [\ref=tab:alltogether7] the method fails in Images 14, 15, and 16. Image 14 and 15 reflect the same situation; the inpainting method is unable to recover the leg of the older horse or sheep. In any case, the difference among the posterior probabilities of the first two hypothesis is very small. On the other hand, in Image 16, although according to the likelihood the preferred hypothesis is the correct one (two ladybugs in front of two flowers), the complexity of the objects in the second hypothesis (flowers in front of ladybugs) is smaller (higher prior) because of the simplified completed object and this second hypothesis wins. In the experiments of Table [\ref=tab:alltogether5] and [\ref=tab:alltogether6], the method fails in images 21, 28, and 29, according to our perception. For Images 21 and 29 the explanation is the same as the previous one, the likelihood agrees with the correct hypothesis but the prior is much higher in the hypothesis with the wrong depth order because of the simplification of the disoccluded objects. In Image 28 the two first hypothesis have very close probabilities, only slightly higher (third decimal) in the wrong hypothesis (H2) compared to the correct one (H1). Summarizing, our method fails in 6 out of 31 real images, giving a success rate of 81%.

We present in Table [\ref=controvertides] two experiments with real images from [\cite=MartinFTM01] where there is an ambiguity in the depth ordering (there are conflicting local depth cues). This situation can appear when the proximal image is made of objects that are not fronto-parallel to the camera or when their relative order changes due to, for example, mutual occlusions as in these examples. In other words, an object does not appear at a single depth layer. In this situation our algorithm chooses the object that is more occluded as being behind but let us remark how the posterior probabilities of the two first hypothesis are very close; in fact, these two hypothesis correspond to the two different depth orderings indicated by the local depth cues and figure/ground ground-truth labels superimposed on the original image.

Shapes in front of a background

Finally, we present some results showing the ability of our method to also decide on (perceptually) fully visible objects over a background. Table [\ref=tab:alltogether8] displays several synthetic images of this type, where there are no T-junctions present and, according to human perception, the depth ordering is established by convexity cues [\cite=Kanizsa1991] (in the perception literature, they are also called figure-ground images). For each row, the proximal stimulus is shown in the first column, and the following columns are the different hypothesis separated by a gray box. For hypothesis H1 and H2, the object which is supposed to be at depth 1, i.e, the occluding object, is displayed in blue. In H3, where both objects are fitted together, the objects are presented with its original color. In these experiments, our method fails in Results 3, 4 and 5; in all of them the convexity cue is a stronger depth cue than symmetry, while the algorithm we are using for computing shape complexity favours symmetries. Let us also remark that Result 9 allows both interpretations: black in front of white and white in front of black, as they form the same shape but with different orientation. In this case our algorithm prefers H1 but with a small difference with respect to H2.

Conclusions

We have proposed a computational model of amodal completion that allows to compute the most preferred structure of a scene given a still image of it. As we are considering scenes where objects appear at two different depths, we take into account the three different hypothesis: Object A occluding object B, B occluding A, or A and B fitting together forming a mosaic. Our main contribution is a Bayesian probabilistic model based on the elastica and the global complexity of the hypothesized objects in order to choose the most preferred explanation of the image. This explanation includes both the disoccluded objects that form the scene and their ordering according to depth. Furthermore, we have proposed a disocclusion method, to compute the hypothesized objects, based on human visual completion, which is modeled by a binary inpainting method based on the Euler's elastica and that takes into account perceptual findings related to amodal completion, such as relatability, convexity, and good continuation. Finally, we have shown the capability of our method with numerical experiments, both with real and synthetic images.

As future work, we plan to extend the approach to scenes with more than two depth layers. Furthermore, we plan to incorporate other disocclusion strategies (such as, e.g., exemplar-based methods [\cite=inpainting_aujol_2010] [\cite=inpainting_arias_2011] or [\cite=HayashiSasaki]) allowing to model global completions taking into account properties such as symmetries or repetitions. Last but not least, we are also interested in the extension of the model to video sequences.