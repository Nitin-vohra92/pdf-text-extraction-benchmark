Sampling from a couple of negatively correlated gamma variates

Introduction

To fix notation, if X follows a gamma distribution with parameters λ and α, that is X  ~  G(λ,  α), then the density is

[formula]

Johnson and Kotz [\cite=kotz] define a multivariate gamma distribution in the following way. We have m + 1 independent standard (that is, each with λ = 1), gamma variates (in general with different α's) [formula]. Define

[formula]

Then the [formula] are distributed according a m-variate gamma variable. We can see that each marginal Yj is a standard gamma variable with α  =  α0  +  αj and

[formula]

and so all the marginals are positively correlated.

We follow this suggestion, with m = 2, but we exploit the preserving monotonicity property of the inverse transform method, see Fishman [\cite=fishman] to generate a couple of gamma variates, X1 and X2, with a rigid amount of negative correlation and then generate X0 to allow for some flexibility.

First Method

Let X1  ~  G(1,  r) and X2  ~  G(1,  s), with r and s integers. Assume, without loss of generality, r < s. Let Ui be s independent uniforms on the unit interval, that is [formula]. Then we can write, using properties of the gamma variate and the inverse transform method,

[formula]

[formula]

It follows that

[formula]

Now define, with X0  ~  G(1,  α0) independent of X1 and X2,

[formula]

[formula]

It follows Y1  ~  G(1,  α0 + r) and Y2  ~  G(1,  α0 + s). Furthermore

[formula]

Because

[formula]

we can see that varying r and α0 we have some freedom in modelling a negative covariance.

The correlation coefficient between Y1 and Y2 is given by

[formula]

For α0 + rc < 0, which guarantees a negative correlation, we see that

[formula]

and so when the correlation is negative, it is an increasing function of α0. The lower bound for ρ is given by

[formula]

When r = s and assuming that α0 = 0 means that X0 = 0 with probability 1 we reach the most negative correlation possible between two gamma variates.

If we are given α0 + r = m, α0 + s = n and ρ  =  ρ0 then from Equation [\ref=eq:correl] we get

[formula]

which can be solved for r and subsequently obtaining α0 and s. The drawback is that r and s are required to be integers, so we cannot arbitrarily choose m, n and ρ. To give an idea of the situation we present some tables, assuming for simplicity that both m and n are integers. It follows that also α0 has to be an integer. Because we want a negative correlation and because α0  ≥  0 we have the restriction

[formula]

Using Equation [\ref=eq:correla] we obtain

Nothing essentially changes if we require gamma's with the first parameter different from 1: it is enough to multiply Y1 and Y2 by, say, a constant β. The correlation coefficient is of course not affected.

Joint Density

Obtaining the joint density of Y1 and Y2 in the general case is cumbersome. To give an idea we consider the simplest case, r = s = 1, and we set α  <   - c that is α  <  0.644934, to guarantee a negative correlation. So we have

[formula]

[formula]

with independence of X0 and U. It turns out that marginally Y1 and Y2 are both G(1,  1 + α0). Setting

[formula]

we get

[formula]

Because X0  ≥  0 we have the inequality

[formula]

The solution to the equation

[formula]

is given by

[formula]

It follows that we have x0  ≥  0 if

[formula]

For the Jacobian of this transformation we have

[formula]

The joint density of X0 and U is given by

[formula]

The quantity e- x0J simplifies to

[formula]

and consequently we get for the joint density of Y1 and Y2

[formula]

We see that for α = 1 this simplifies to

[formula]

but in this case the correlation is positive:

[formula]

In this last situation the marginals are G(1,  2). This can be checked using the fact that

[formula]

Second Method

Again looking for flexibility we analyze another method where we start generating s samples (U1i,  U2i) from a bivariate distribution with density

[formula]

This density is of the form studied by Long and Krzysztofowicw [\cite=long]. For - 1  ≤  θ  ≤  1 this function is a proper density. It turns out that marginally U1i and U2i are uniforms over the unit interval and the correlation coefficient is given by

[formula]

Now define

[formula]

[formula]

Now

[formula]

It follows that

[formula]

Proceeding as in the other method we define, with X0  ~  G(1,  α0) independent of X1 and X2,

[formula]

[formula]

and we get

[formula]

Now we have a negative correlation if 4α0 + rθ < 0. Because of this inequality the admissible range for θ is - 1  ≤  θ < 0. The lower bound for ρ is

[formula]

so we cannot hope to do better than

[formula]

Repeating the same reasoning that led us to Equation [\ref=eq:correla] now we have

[formula]

The restrictions are now

[formula]

Solving for r we get

[formula]

Other restrictions on the minimum value admissible for ρ0 arise from Equation [\ref=eq:restr] and the fact that r must be integer. The minimum value of r as given by Equation [\ref=eq:erre] is obtained for θ =  - 1. Then

[formula]

which implies

[formula]

Under the condition m  ≥  6 this attainable lower bound is an increasing function of n and because n  ≥  m it is a decreasing function of m: in particular if m = n the limit for m going to infinity is - 0.25.

Once observed the conditions on m and ρ we have the following algorithm.

Set [formula].

Obtain [formula].

Set r = ⌈a⌉, that is the lowest integer not lower than a. Because of the construction such an r exists and r < m.

Obtain θ  =  4 - y  /  r.

As an example, imagine m = 7,  n = 10. The attainable lower bound is - 0.0597. Set for example ρ0 =  - 0.05. Then [formula]. Take r = 6, so that θ = 4 - 4.38778 =  - 0.38778.

Once θ is obtained, the next step is to evaluate α0 = m - r and s = n - α0. Then we generate s samples from the density given in Equation [\ref=eq:density2]: this can be done for instance with the acceptance-rejection method. And then we follow the final construction to obtain Y1 and Y2.

We can note that in this second method the attainable lower bound for ρ is sensibly greater than in the first method, but for the admissible values we have a complete flexibility. The other negative point is that we have to generate samples from a bivariate density, whose covariance scaler θ (as termed by Long and Krzysztofowicw) has to be preliminarily obtained, instead of generations from univariate densities.