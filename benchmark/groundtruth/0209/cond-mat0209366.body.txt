A Growth-based Optimization Algorithm for Lattice Heteropolymers

Lattice polymers have been studied intensively to understand protein folding, one of the central problems of computational biology. A popular model used in these studies is the so-called HP model [\cite=Dill85] [\cite=Lau89] where only two types of monomers, H (hydrophobic) and P (polar) ones, are considered. Hydrophobic monomers tend to avoid water which they can only by mutually attracting themselves. The polymer is modeled as a self-avoiding chain on a regular (square or simple cubic) lattice with interactions (εHH,εHP,εPP) =  - (1,0,0) between neighboring non-bonded monomers.

This model might be too simple to represent finer details of real protein folding [\cite=Chan00], but this is not our concern. We use the search for its ground states as a paradigmatic example for combinatorial optimization, with a large body of existing benchmarks.

A wide variety of computational strategies have been employed to simulate and analyze these models, including conventional (Metropolis) Monte Carlo schemes with various types of moves [\cite=yue95] [\cite=rrp97] [\cite=deutsch97], chain growth algorithms without [\cite=tp92] and with re-sampling [\cite=g98] [\cite=bast98] [\cite=zhang02] (see also [\cite=bd96]), genetic algorithms [\cite=um93] [\cite=kd01], parallel tempering [\cite=irbaeck] and generalizations thereof [\cite=chikenji] [\cite=chikenji2], an 'evolutionary Monte Carlo' algorithm [\cite=lw01], and others [\cite=tt96]. In addition, Yue and Dill [\cite=yd93_95] also devised an exact branch-and-bound algorithm specific for HP sequences on cubic lattices, which gives all low energy states by exact enumeration and typically works for [formula].

It is the purpose of the present letter to present a new variant of the Pruned-Enriched Rosenbluth Method (PERM) [\cite=g97] and to apply it to lattice proteins. PERM is a biased chain growth algorithm with re-sampling ("population control") and depth-first implementation. It is built on the old idea of Rosenbluth and Rosenbluth (RR) [\cite=rr55] to use a biased growth algorithm for polymers, where the bias is corrected by means of giving a weight to each sample configuration. While the chain grows by adding monomers, this weight (which also includes the Boltzmann weight if the system is thermal) will fluctuate. PERM suppresses these fluctuations by "pruning" configurations with too low weight, and by "enriching" the sample with copies of high-weight configurations [\cite=g97]. These copies are made while the chain is growing, and continue to grow independently of each other. PERM can be viewed as a special realization of a "go with the winners" strategy [\cite=aldous] and indeed dates back to the beginning of the Monte Carlo simulation era, when it was called "Russian roulette and splitting" [\cite=kahn]. Among statisticians, this approach is also known as sequential importance sampling (SIS) with re-sampling [\cite=liu].

Pruning and enrichment are done by choosing thresholds W<n and W>n depending on the estimate of the partition sums of n-monomer chains (see below for their actual determination). If the current weight Wn of an n-monomer chain is less than W<n, the chain is discarded with probability 1/2, otherwise it is kept and its weight is doubled. Many alternatives to this simple choice are discussed in [\cite=liu], but we found that more sophisticated strategies had little influence on the efficiency, and thus we kept the above in the present work. On the contrary, we found that different strategies in biasing and, most of all, in enrichment had a big effect, and it is here the present variant differs from those in [\cite=g98] [\cite=bast98]. There, high-weight configurations were simply cloned and the weight was uniformly shared between the clones. For relatively high temperatures this is very efficient [\cite=g97], since each clone has so many possibilities to continue that different clones very quickly become independent from each other. This is no longer the case for very low temperatures. There we found that clones often evolved in the same direction, since one continuation has a much higher Boltzmann weight than all others. Thus, cloning is no longer efficient in creating configurational diversity, which was the main reason why it was introduced.

The main modification made in the present paper is thus that we no longer make identical clones. Rather, when we have a configuration with n - 1 monomers, we first estimate a predicted weight Wpredn for the next step, and we count the number kfree of free sites where the n-th monomer can be placed. If kfree > 1 and Wpredn  >  W>n, we choose 2  ≤  k  ≤  kfree different sites among the free ones and continue with k configurations which are forced to be different. Thus we avoid the loss of diversity which limited the success of old PERM. Typically, we used k  =   min {kfree,⌈Wpredn / W>n⌉}.

When selecting a k-tuple [formula] of mutually different continuations αj with probability pA, the corresponding weights [formula] are

[formula]

where the importance qαj  =   exp ( - βEn,αj) of choice αj is the Boltzmann-Gibbs factor associated with the energy En,αj of the newly placed monomer in the potential created by all previous monomers. The other terms arise from correcting bias and normalization, see [\cite=hmng] for a more thorough discussion. Choosing

[formula]

would result in usual importance sampling [\cite=hmng]. However, instead of qα we use the modified importances α  =  (k(α)free  +  1 / 2)qα in Eq. ([\ref=nis]), k(α)free being the number of free neighbors when the n-th monomer is placed at α. This replacement is made since we anticipate that continuations with less free neighbours will contribute less on the long run than continuations with more free neighbours. This is similar to "Markovian anticipation" [\cite=cylinder] within the framework of old PERM, where a bias different from the short-sighted optimal importance sampling was found to be preferable. Consequently, the predicted weight is [formula],

A noteworthy feature of new PERM is that it crosses over to complete enumeration when W<n and W>n tend to zero. In this limit, all possible branches are followed and none is pruned as long as its weight is not strictly zero. In contrast to this, old PERM would have made infinitely many copies of the same configuration. This suggests already that we can be more lenient in choosing W<n and W>n. For the first configuration hitting length n we used W<n = 0 and W>n  =    ∞  , i.e. we neither pruned nor branched. For the following configurations we used W>n = Zn / Z0(cn / c0)2 and W<n = 0.2  W>n. Here, cn is the total number of configurations of length n already created during the run, and Zn is the partition sum estimated from these configurations.

In PERM we work at a fixed temperature (no annealing), and successive "tours" [\cite=g97] are independent except for the thresholds W< , >n which use partially the same partition sum estimates. Results are less sensitive to the precise choice of temperature than they were for old PERM. In general all temperatures in the range 0.25  <  T  <  0.35 gave good results for ground state search. In the following, when we quote numbers of ground state hits or CPU times between such hits, these are always independent hits. The actual numbers of (dependent) hits are much larger.

We now present our results. Special comparison is made with the Core-directed Growth Method (CG) of Beutler and Dill [\cite=bd96], the only method we found to be still competitive with ours. We emphasize, however, that the CG method works only for the HP model and relies heavily on heuristics, in contrast to our fully blind general purpose approach.

(a) We first tested the ten 48-mers from [\cite=yue95]. As with old PERM, we could reach lowest energy states for all of them, but within much shorter CPU times. For all 10 chains we used the same temperature, exp (1 / T)  =  18, although we could have optimized CPU times by using different temperatures for each chain.

The CPU times for new PERM in Table [\ref=table1] are typically one order of magnitude smaller than those in [\cite=bd96], except for sequence #9 whose lowest energy was not hit in [\cite=bd96]. Since in [\cite=bd96] a SPARC 1 machine was used which is slower by a factor ≈  10 than the 167 MHz Sun ULTRA I used here, this means that our algorithms have comparable speeds. We note that introducing a simple configurational bias in new PERM [\cite=footnote] can already give a considerable speedup; in this contribution, however, we want to concentrate on blind search.

(b) Next we studied the two 2-d HP-sequences of length N = 100 of Ref. [\cite=rrp97]. They were originally thought to have ground states fitting into a 10  ×  10 square with energies -44 and -46 [\cite=rrp97], but in [\cite=bast98] configurations fitting into this square were found with lower energies. Moreover, when configurations were allowed to have arbitrary shape, even lower energies were found [\cite=bast98] [\cite=chikenji] [\cite=zhang02]. In the present work we studied only configurations of the latter type. The lowest energies known by now are -48 [\cite=zhang02] resp. -50 [\cite=chikenji]. The CPU times needed to find them were 48 min resp. 50h, on machines with ≈  500 MHz. In contrast, new PERM needed in average 2.6 min resp. 5.8h on a 667 MHz DEC Alpha 21264 between any two hits.

(c) Several 2-d HP-sequences were introduced in [\cite=um93], where the authors tried to fold them using a genetic algorithm. Except for the shortest chains they were not successful, but putative ground states for all of them were found in [\cite=bast98] [\cite=irbaeck] [\cite=chikenji]. But for the longest of these chains (N = 64), the ground state energy E min =  - 42 was found in [\cite=bast98] only by means of special tricks which amount to non-blind search. With blind search, the lowest energy reached by PERM was -39. We should stress that PERM as used in [\cite=bast98] was blind for all cases except this 64-mer (and when it found E =  - 49 for the second N = 100 chain of [\cite=rrp97]), in contrast to statements to the contrary made in [\cite=lw01].

We now found putative ground states for all chains of [\cite=um93] with blind search. For the 64-mer the average CPU time per hit was ca. 30h on the DEC 21264, which seems to be roughly comparable to the CPU times needed in [\cite=chikenji] [\cite=irbaeck], but considerably slower than [\cite=bd96]. This sequence is particularly difficult for any growth algorithm, and the fact that we now found it is particularly noteworthy.

On the other hand, new PERM was much faster than [\cite=bd96] for the sequence with N = 60 of [\cite=um93]. It needed ≈  10 seconds on the DEC 21264 to hit E min =  - 36, and ≈  0.1 second to hit E =  - 35. In contrast, E =  - 36 was never hit in [\cite=bd96], while it took 97 minutes to hit E =  - 35.

(d) A 85-mer 2-d HP sequence was given in [\cite=konig], where it was claimed to have E min =  - 52. Using a genetic algorithm, the authors could find only conformations with E  ≥   - 47. In Ref. [\cite=lw01], using a newly developed evolutionary Monte Carlo (EMC) method, the authors found the putative ground state when assuming large parts of its known structure as constraints. This amounts of course to non-blind search. Without these constraints, the putative ground state was not hit in [\cite=lw01] either, although the authors claimed their algorithm to be more efficient than all previous ones. We easily found states with E =  - 52, but we also found many conformations with E =  - 53. At exp (1 / T) = 90 it took ca. 10 min CPU time between successive hits on the Sun ULTRA 1.

(e) Four 3D HP sequences with N = 58, 103, 124, and 136 were proposed in [\cite=dfc93] [\cite=lfd94] as models for actual proteins or protein fragments. Low energy states for these sequences were searched in [\cite=tt96] using a newly developed and supposedly very efficient algorithm. The energies reached in [\cite=tt96] were E =  - 42, - 49, - 58 and - 65, respectively. We now found lower energy states after only few minutes CPU time, for all four chains. For the longer ones, the true ground state energies are indeed much lower than those found in [\cite=tt96], see Table [\ref=table2].

Note the very low temperatures needed to fold the very longest chains in an optimal time. If we would be interested in excited states, higher temperatures would be better. For instance, to find E =  - 66 for the 136-mer (which is one unit below the lowest energy reached in [\cite=tt96]), it took just 2.7 seconds/hit on the DEC 21264 when using exp (1 / T) = 40.

(f) The only case where we could not find a known ground state is a 3-d HP sequence of length 88 given in [\cite=bd96]. As shown there, it folds into an irregular β  /  α-barrel with E min =  - 72. The difficulties of PERM with this sequence are easily understood by looking at the configuration shown in [\cite=bd96]. The nucleus of the hydrophobic core is formed by amino acids #36-53. Before its formation, a growth algorithm starting at either end has to form very unstable and seemingly unnatural structures which are stabilized only by this nucleus, a situation similar to the 64-mer of Ref. [\cite=um93]. In order to fold also this chain, we would have either to start from the middle of the chain (as done in [\cite=bast98] for some sequences) or use some other heuristics which help the formation of the hydrophobic core. Since we wanted our algorithm to be as general and "blind" as possible, we did not incorporate such tricks [\cite=footnote].

A more detailed discussion of our algorithm, the results, and comparison with other methods is given elsewhere [\cite=hmng]. A list containing all sequences for which we found new lowest energy configurations is given in Table [\ref=table2].

In the present paper we presented a new version of PERM which is a depth-first implementation of the 'go-with-the-winners' strategy (or sequential importance sampling with re-sampling). The main improvement over old PERM is that we now do not make identical clones of high weight (partial) configurations, but we branch such that each continuation is forced to be different. We do not expect this to have much influence for systems at high temperatures, but as we showed, it leads to substantial improvement at very low temperatures.

Comparing our results to previous work, we see that we found the known lowest energy states in all cases but one. Moreover, whenever we could compare with previous CPU times, the comparison was favourable for our new algorithms, except for the CG method of Beutler and Dill [\cite=bd96]. But we should stress that the latter is very specific to HP chains, uses strong heuristics regarding the formation of a hydrophobic core, and does not give correct Boltzmann weights for excited states. All that is not true for our method.

Although our method could be used for a much wider range of applications (see [\cite=chemnitz] for applications of PERM), we presented here only results for heteropolymers with two types of monomers and the simplest non-trivial interactions on the square and simple cubic lattices. But we applied it also successfully to the HP model on the FCC lattice, to off-lattice heteropolymers, and to lattice models with more than 2 types of monomers (to be published). We hope that our results will also foster applications to more realistic protein models. We showed only results for lowest energy configurations, but we should stress that PERM is not only an optimization algorithm. It also gives information on the full thermodynamic behaviour. We skipped this here since finding ground states is the most difficult problem in general, and sampling excited states is easy compared to it.