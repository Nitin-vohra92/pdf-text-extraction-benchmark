Lemma Proposition Conjecture

A matrix weighted T1 theorem for matrix kernelled Calderón-Zygmund operators - I

Introduction

Weighted norm inequalities for Calderón-Zygmund operators (or CZOs for short) acting on ordinary [formula] is a classical topic that goes back to the 1970's with the seminal works [\cite=CF] [\cite=HMW]. On the other hand, it is well known that proving matrix weighted norm inequalities for CZOs is a very difficult task, and because of this, matrix weighted norm inequalities for certain CZOs have only recently been investigated (see [\cite=TV] [\cite=V] for specific details of these difficulties). In particular, if n and d are natural numbers and if [formula] is positive definite a. e. (where as usual [formula] is the algebra of n  ×  n matrices with complex scalar entries), then define Lp(W) for 1  <  p  <    ∞   to be the space of measurable functions [formula] with norm

It was proved by F. Nazarov and S. Treil, M. Goldberg, and A. Volberg, respectively in [\cite=G] [\cite=NT] [\cite=V] that certain CZOs are bounded on Lp(W) when 1  <  p  <    ∞   if W is a matrix A[formula] weight, which means that

[formula]

where p' is the conjugate exponent of p (note that an operator T acting on scalar functions can be canonically extended to [formula] valued functions via the action of T on its coordinate functions.)

Now note that CZOs with matrix valued kernels acting on [formula] valued functions appear very naturally in various branches of mathematics (and as a particular example see [\cite=IM] for extensive applications of matrix kernelled CZOs to geometric function theory.) Despite this and the fact that the theory of matrix weights has numerous applications to Toeplitz operators, multivariate prediction theory, and even to the study of finitely generated shift invariant subspaces of unweighted [formula] (see [\cite=NT] [\cite=Mo] [\cite=V]), virtually nothing is known regarding matrix weighted norm inequalities for matrix kernelled CZOs or related operators.

The purpose of this series of two papers is therefore to investigate the boundedness of matrix kernelled CZOs on Lp(W) when W is a matrix A[formula] weight. We will need to introduce some more notation before we state our main result. It is well known (see [\cite=G] for example) that for a matrix weight W, a cube I, and any 1  <  p  <    ∞  , there exists positive definite matrices VI and VI' such that [formula] and [formula] for any [formula], where [formula] is the canonical [formula] norm and the notation A  ≈  B as usual means that two quantities A and B are bounded above and below by a constant multiple of each other. Note that it is easy to see that [formula] for any cube I. We will say that W is a matrix A[formula] weight if the product VIVI' has uniformly bounded matrix norm with respect to all cubes [formula] (note that this condition is easily seen to be equivalent to ([\ref=MatrixApDef]).) Also note that when p  =  2 we have [formula] and [formula] where mIW is the average of W on I, so that the matrix A[formula] condition takes on a particularly simple form that is very similar to the scalar A[formula] condition.

Now let [formula] be a densely defined operator where the dense domain contains at least the indicator function of all cubes. If 1  <  p  <    ∞   and W is a matrix A[formula] weight, then we will call T a "W-weighted CZO" with associated matrix kernel [formula] (where as usual [formula] is the diagonal) if the following three conditions are true: first,

[formula]

for all [formula] in the dense domain of T with compact support. Second, for each cube [formula], assume that the matrix function VIK(x,y)V- 1I satisfies the "standard kernel estimates" for all [formula] with |x - y| > 2|x - x'| where δ,C  >  0 are independent of I. Third, assume that T satisfies the "weak boundedness property" where 1I is the indicator function of the cube I and [formula] is any matrix norm on [formula]. Moreover, if 1  <  p  <    ∞   and W is a matrix A[formula] weight, then let [formula] be the space of locally integrable functions [formula] where

Our main goal in these two papers will be to prove the following theorem

Let 1  <  p  <    ∞  . If W is a matrix A[formula] weight and T is a W -weighted CZO, then T is bounded on Lp(W) if and only if [formula] and [formula].

In this paper, however, we will focus our attention towards proving matrix weighted norm inequalities for dyadic paraproducts, which will be used to prove Theorem [formula] in part II. In particular, let [formula] be a dyadic system of cubes in [formula] and let [formula] be a system of Haar functions adapted to [formula]. Given a locally integrable function [formula], define the dyadic paraproduct πB with respect to a dyadic grid [formula] by

[formula]

where BI is the matrix of Haar coefficients of the entries of B with respect to I. In this paper will prove the following theorem

Let 1  <  p  <    ∞  . If W is a matrix A[formula] weight then πB is bounded on Lp(W) if and only if [formula] (where here the supremum defining [formula] is taken over all [formula] instead of all cubes I.)

Let us comment that restricting oneself to W-weighted CZOs is in fact quite natural. In particular, note that Theorem [\ref=T1Thm] is false for general matrix A[formula] weights and matrix kernelled CZOs, and in the last section we will construct a very simple example, for each 1  <  p  <    ∞  , of a matrix A[formula] weight W and a matrix kernelled CZO T with T1  =  T*1  =  0 but where T is not bounded on Lp(W).

Moreover, let [formula] be a sequence of matrices. We will then prove (see Section [formula]) that given a matrix A[formula] weight W, the Haar multiplier is bounded on Lp(W) if and only if [formula]. On the other hand, in the last section we will exhibit a very simple example of a sequence A and a matrix A[formula] weight W, for each 1  <  p  <    ∞  , where [formula]. Similarly in the last section we will construct a matrix function [formula] (the ordinary John-Nirenberg BMO space) and a matrix A[formula] weight W for each 1  <  p  <    ∞   where [formula].

The proof of Theorem [\ref=ParaThm] will require the following matrix weighted Carleson embedding theorem, which is obviously of independent interest itself.

Let 1  <  p  <    ∞  . If W is a matrix A[formula] weight and [formula] is a sequence of matrices, then the following are equivalent:

The operator ΠA defined by is bounded on [formula]

There exists C  >  0 independent of [formula] such that if 2  ≤  p  <    ∞  , and if 1  <  p  ≤  2.

Furthermore, the operator norm in (a) and the supremums in (b) and (c) are equivalent in the sense that they are independent of the sequence A. Finally, a matrix function [formula] if and only if the sequence of Haar coefficients of B satisfies any of the above equivalent conditions.

Despite the perhaps strange appearance of Theorem [\ref=CarEmbedThm], first note that if w is a scalar A[formula] weight, then clearly a locally integrable scalar function b is in [formula] if and only if b is in [formula] (i. e. the classical John-Nirenberg BMO space), which in this case is also equivalent to

[formula]

where [formula]. In fact, it is well known (and easy to prove) that if w is a scalar A[formula] weight, then b satisfies () if and only if [formula] (see [\cite=MW] for details.)

Furthermore, note that when p  =  2, the implication (c) ⇒   (a) in Theorem [\ref=CarEmbedThm] gives us that (after replacing [formula] with [formula] and replacing AI with [formula] ) whenever W is a matrix A[formula] weight and [formula] is a "W-Carleson sequence" of matrices in the sense that holds for all [formula].

Interestingly, note that this "weighted Carleson embedding Theorem" in the scalar p  =  2 setting appears as Lemma 5.7 in [\cite=P] for scalar A[formula] weights and was implicitly used in sharp form by O. Beznosova [\cite=Bez] (see (2.4) and (2.5) in [\cite=Bez]) to prove sharp weighted norm inequalities for scalar paraproducts. We will further discuss the connection between Theorem [\ref=CarEmbedThm] and sharp matrix weighted norm inequalities for scalar kernelled CZOs in the final section.

The main tool for proving Theorem [\ref=CarEmbedThm] will be an adaption of the stopping time arguments from [\cite=KP] [\cite=Pott] to the matrix weighted p  ≠  2 setting. Moreover, the proof will require the identification from [\cite=NT] [\cite=V] of Lp(W) as a weighted Triebel-Lizorkin space for 1  <  p  <    ∞   when W is a matrix A[formula] weight, which more precisely says that

[formula]

where [formula] is the Haar coefficient of [formula]. Note that we will use our stopping time to give a new and more classical stopping time proof of ([\ref=LpEmbedding]), which could be thought of as the third contribution of the current paper (and which provides a simpler approach when compared to the ones in [\cite=NT] [\cite=V].) It is hoped that our proofs of Theorem [\ref=CarEmbedThm] and () will convince the reader of the overall usefulness of our stopping approach to matrix weighted norm inequalities and will generate interest in extending other stopping time arguments to the matrix weighted setting (such as the ones pioneered by M. Lacey, S. Petermichl, and M. C. Reguera in [\cite=LPR], which will be discussed further in the last section.)

It is also hoped that the results in this series of two papers will convince the reader of the following philosophy: what is true in the scalar A[formula]/scalar CZO setting should largely be true in the matrix setting after one takes noncommutativity into account.

We will end this introduction by outlining the contents of each section. In the next section we will extend the stopping time arguments in [\cite=KP] [\cite=Pott] to the p  ≠  2 matrix weighted setting and show that this stopping time is a decaying stopping time in the sense of [\cite=KP], which will then be used to prove ([\ref=LpEmbedding]). In the third section, we will prove Theorems [\ref=ParaThm] and [\ref=CarEmbedThm] by utilizing ([\ref=LpEmbedding]) in conjunction with our stopping time arguments. Finally in Section four, we will construct the examples discussed earlier in this introduction. Moreover, we will present some interesting open problems, including other related matrix weighted BMO spaces and their possible equivalences to [formula].

Weighted Haar multipliers and stopping times

We will now describe the Haar multipliers and the stopping time that will be needed throughout this paper. Define the constant Haar multiplier MW,p by

[formula]

Note that trivially πB is bounded on Lp(W) if and only if [formula] is bounded on [formula], and note that

[formula]

The main goal of this section will be to extend the stopping time arguments in [\cite=KP] [\cite=Pott] to the matrix weighted setting and then use these arguments to prove that [formula] is bounded and invertible on [formula] if W is a matrix A[formula] weight, so that one only needs to deal with [formula] in order to prove Theorem [\ref=ParaThm]. Furthermore, note that dyadic Littlewood-Paley theory immediately says that the boundedness and invertibility of [formula] is equivalent to ().

Now assume that W is a matrix A[formula] weight. For any cube [formula], let [formula] be the collection of maximal [formula] such that

[formula]

for some λ1,λ2  >  1 to be specified later. Also, let [formula] be the collection of dyadic subcubes of I not contained in any cube [formula], so that clearly [formula] for any [formula].

Let [formula] and inductively define [formula] and [formula] for j  ≥  1 by [formula] and [formula]. Clearly the cubes in [formula] for j  >  0 are pairwise disjoint. Furthermore, since [formula] for any [formula], we have that [formula]. We will slightly abuse notation and write [formula] for the set [formula] and write [formula] for [formula]. We will now show that [formula] is a decaying stopping time in the sense of [\cite=KP].

Let 1  <  p  <    ∞   and let W be a matrix A[formula] weight. For λ1,λ2  >  1 large enough, we have that [formula] for every [formula].

By iteration, it is enough to prove the lemma for j  =  1. For [formula], let [formula] denote the collection of maximal [formula] such that the first inequality (but not necessarily the second inequality) in () holds. Then by maximality and elementary linear algebra, we have that for some C1  >  0 only depending on n and d.

On the other hand, let For [formula], let [formula] denote the collection of maximal [formula] such that the second inequality (but not necessarily the first inequality) in () holds. Then by the matrix A[formula] condition we have for some C2' only depending on n and d. The proof is now completed by setting λ1  =  4C1 and [formula].

While we will not have a need to discuss matrix A[formula] weights in detail in this paper, note that in fact Lemma 3.1 in [\cite=V] immediately gives us that Lemma [\ref=DSTLem] holds for matrix A[formula] weights (with possibly larger λ2 of course.)

The next main result will be an "Lp Cotlar-Stein lemma" (Lemma [formula]) that is a vector version of Lemma 8 in [\cite=KP]. We will need a few preliminary definitions before we state this result. Fix [formula] with side-length 1 and with 0∈J0 and let [formula] and [formula] Now for each [formula] let Δj be defined by

[formula]

and write [formula].

Let the [formula]'s be as above and write Tj: = TΔj for any linear operator T acting on [formula] valued functions defined on [formula]. If [formula], and if there exists C  >  0 and 0  <  c  <  1 such that

[formula]

for every [formula] then T is bounded on [formula].

It follows directly from Lemma 7 in [\cite=KP] and elementary linear algebra that

[formula]

whenever [formula] The proof of Lemma [formula] is now identical to the proof of Lemma 8 in [\cite=KP].

Let 1  <  p  <    ∞  . If W is a matrix A[formula] weight, then [formula] is bounded on [formula].

Obviously it is enough to prove that the operator T defined by

[formula]

is bounded on [formula]. Note that we also clearly have [formula].

For each [formula], let

[formula]

so that

[formula]

Since VIMI is a constant Haar multiplier and since [formula] if [formula], we immediately have that

[formula]

Now we will show that each Tj is bounded. To that end, we have that

[formula]

Since [formula] on [formula], we can estimate (A) first as follows:

[formula]

As for (B), note that [formula] is constant on [formula], and so we will refer to this constant by [formula]. We then estimate (B) as follows:

[formula]

To finish the proof, we claim that there exists 0  <  c  <  1 such that

[formula]

whenever k  >  j. If we define [formula] as

[formula]

then [formula] is constant on [formula]. Thus, we have that

[formula]

However,

[formula]

On the other hand, it is not hard to show that [formula] is a scalar A[formula] weight for any [formula] (see [\cite=G]), which by the classical reverse Hölder inequality means that we can pick some q  >  p and use Hölder's inequality in conjunction with Lemma [formula] to get

[formula]

Combining () with (), we get that

[formula]

Finally, note that this estimate combined with the Cauchy-Schwarz inequality and Lemma [formula] completes the proof since [formula] is supported on [formula].

Note that the proof of Theorem [formula] only requires Lemma [\ref=DSTLem] and the fact that [formula] satisfies a reverse Hölder inequality for each [formula]. In particular, our proof (as do proofs in [\cite=NT] [\cite=V]) holds for matrix A[formula] weights.

Furthermore, note that Theorem [formula] easily gives us that [formula] is also invertible on [formula] with bounded inverse when W is a matrix A[formula] weight. In particular, it is easy to see that W is a matrix A[formula] weight if and only if W1  -  p' is a matrix A[formula] weight. Thus, we have that [formula] is bounded on [formula] if W is a matrix A[formula] weight, so by duality we have that [formula] is bounded on [formula]. However, one can check very easily that which by the matrix A[formula] condition means that MW,pMW1 - p',p' is a bounded Haar multiplier. We can then finally conclude that is bounded on [formula].

Proof of Theorem [formula]

In this section we will prove Theorem [formula]. First we will need the following preliminary lemmas, the first of which is from [\cite=NT].

Suppose that A is an n  ×  n matrix where [formula] for any [formula]. If | det A|  ≤  δ for some δ  ≥  0, then [formula] where [formula] is the canonical matrix norm on [formula].

The proof follows from elementary linear algebra.

If W is a matrix A[formula] weight then for any [formula].

First we show that for some C independent of [formula], which will prove half of the lemma. Furthermore, note that the proof of this inequality will in fact also complete the other half of the proof. Since W1  -  p' is a matrix A[formula] weight, Proposition 2.2 in [\cite=V] says that W satisfies the "reverse matrix Jensen inequality" for any [formula] where C is independent of I. Combining this with the matrix Jensen inequality (Lemma 7.2 in [\cite=NT]) we have that so that [formula].

Moreover, note that for any [formula] we have

[formula]

which means that for any [formula]. The proof now follows immediately from Lemma 3.1.

Now note that by definition Thus, since πB is bounded on Lp(W) if and only if [formula] is bounded on [formula], Theorem [formula] immediately follows from Theorem [\ref=CarEmbedThm], which we now prove.

Proof of Theorem [\ref=CarEmbedThm]: First note that if AI is the sequence of Haar coefficients of some matrix valued function B, then (c) is equivalent to the original definition of [formula] by an easy application of () and elementary linear algebra.

(b) ⇒   (a): By dyadic Littlewood-Paley theory, we need so show that for any [formula]. To that end, if ε  >  0 is small enough, then the reverse Hölder inequality gives us that

[formula]

Thus, by Lemma [formula], we are reduced to estimating

[formula]

However, condition (b) precisely says that [formula] is a Carleson sequence, so an application of Carleson's Lemma (Lemma 5.3 in [\cite=P]) gives us that

[formula]

where Md is the ordinary dyadic maximal function, which completes the proof that (b) ⇒   (a).

(a) ⇒   (b): Fixing [formula], plugging in the test functions [formula] into ΠA for any orthonormal basis [formula] of [formula], and using (a) combined with dyadic Littlewood-Paley theory and elementary linear algebra gives us that

[formula]

which says that Condition (b) now follows immediately from Lemma [\ref=RedOp-AveLem] and Theorem 3.1 in [\cite=NTV].

We now prove that (c) ⇒   (b) and (a) ⇒   (c) for the case 2  ≤  p  <    ∞  .

(c) ⇒   (b) when 2  ≤  p  <    ∞  : Note that condition (c) is equivalent to for any [formula]. Fix [formula] and for each [formula] let [formula] and [formula] be defined as they were in Section [\ref=HaarMult] where λ1,λ2  >  1 are large enough so that Lemma [\ref=DSTLem] is true. Then inequality ([\ref=STDef]) tells us that

[formula]

(a) ⇒   (c) when 2  ≤  p  <    ∞  : Fix [formula] and [formula]. If [formula], then condition (a), the definition of VJ, and Hölder's inequality give us that

[formula]

which proves (c), and in fact shows that (a) ⇔   (b) ⇔   (c) when 2  ≤  p  <    ∞  . We will now complete the proof when 1  <  p  ≤  2.

(b) ⇒   (c) when 1  <  p  ≤  2: To avoid confusion in the subsequent arguments, we will write VI  =  VI(W,p) to indicate which W and p the VI at hand is referring to. As mentioned before, it is easy to see that W is a matrix A[formula] weight if and only if W1  -  p' is a matrix A[formula] weight. Furthermore, one can easily check that VI(W1  -  p',p')  =  VI'(W,p) and VI'(W1  -  p',p')  =  VI(W,p). Now if (b) is true, then the two equalities above give us that

[formula]

However, repeating word for word the proofs of (b) ⇒   (a) ⇒   (c) for the case 2  ≤  p  <    ∞   (where W1  -  p' replaces W and [formula] replaces the sequence A) gives us that there exists C  >  0 where which proves (c) when 1  <  p  ≤  2.

(c) ⇒   (b) when 1  <  p  ≤  2: This follows immediately by again replacing W with W1  -  p', replacing A with [formula], and using the proof of (c) ⇒   (b) when 2  ≤  p  <    ∞  .

Since (a) ⇔   (b) was shown for all 1  <  p  <    ∞  , we therefore have that (a) ⇔   (b) ⇔   (c) for all 1  <  p  <    ∞  . Finally, a careful checking of the above arguments reveals that the [formula] norm of ΠA is equivalent to the canonical supremums defined by conditions (b) and (c).

[formula]

Counterexamples and open problems

We begin this section with a proof of the following result that was mentioned in the introduction.

Let 1  <  p  <    ∞   and let W be a matrix A[formula] weight. If [formula] is any dyadic system of cubes and [formula] is a sequence of matrices, then the Haar multiplier is bounded on Lp(W) if and only if [formula].

If [formula], then two applications of () give us that

[formula]

For the other direction, fix some [formula] and let [formula] with [formula]. Again by () we have that

[formula]

Plugging [formula] for any [formula] into ([\ref=NecHaarMultEq]) and noticing that gives us that [formula] However, Lemma [\ref=RedOp-AveLem] then tells us that [formula]. Using the definition of VJ0' and summing over all of the 2n first generation children J0' of J0 finally (after taking the supremum over [formula]) gives us that [formula], which implies that [formula] as desired.

We will now construct the examples mentioned in the introduction. First let for [formula], where - 1  <    ±  α,  ±  β  <  p  -  1 and α  ≠  β so that W is trivially a matrix A[formula] weight. (In fact, one can easily check that [formula] and [formula] since W is diagonal). Now let T be the matrix kernelled CZO with kernel K(x,y)  =  (x  -  y)- 1A. Then obviously T1  =  T*1  =  0, but one can very easily check that T is not bounded on Lp(W). On the other hand, let [formula] for any dyadic grid [formula] be the constant sequence AI  =  A. Then one can easily check that

We will now show that [formula] and W being a matrix A[formula] weight is not sufficient for πB to be bounded on Lp(W) for any 1  <  p  <    ∞  , which will turn out to be more involved than the above examples. First we will need the following result, which is potentially of independent interest and whose proof is similar to the proof of Lemma 2.1 in [\cite=B].

Let ΠA be the operator defined in Theorem [\ref=CarEmbedThm] for some fixed sequence of matrices [formula] and some fixed matrix A[formula] weight W. If ΠA is bounded on [formula], then ΠA is bounded on [formula] for all p  ≤  q  <    ∞  .

Since we have that [formula] is supported on J for each [formula]. One can then use the Calderón-Zygmund decomposition to check that Π*A is weak type (1,1), which by interpolation gives us that Π*A is bounded on [formula] for all 1  <  q  <  p'. Duality now completes the proof.

Now let [formula] be any dyadic system of intervals in [formula]. For any α  =  α(p)  >  0 with - 1  <    ±  α  <  p  -  1, let W be the 2  ×  2 matrix A[formula] weight defined on [formula] by Now let b(x): =  log |x| and let [formula]. Pick any [formula] such that JN  ⊆  [null] is the Hölder exponent of the standard estimates for the kernel of T. Furthermore, the ω's in the notation for the haar shifts and dyadic paraproducts in ([\ref=HytonenFormula]) indicates that these dyadic operators are taken with respect to the dyadic system [formula].

Now suppose that T is a matrix kernelled CZO and W is a matrix A[formula] weight on [formula]. Then after performing elementary matrix multiplications and applying ([\ref=HytonenFormula]), we immediately get that

[formula]

for any [formula] with compact support, where T*1 is the matrix function defined by and T1 is similarly defined. Furthermore, Sijω is a Haar shift with matrix coefficients aIJK that satisfies (the obvious matrix analogue of) ([\ref=HaarShiftCoefAssump]).

This immediately raises the following question: If W is a matrix A[formula] weight and Sij is a Haar shift of order (i,j) with respect to [formula], then is

[formula]

where Note that if ([\ref=HaarShiftAssumption]) was true, then by duality and Theorem [\ref=MainThm] we would have that T is bounded on Lp(W) if [formula] when T is a matrix kernelled CZO.

Unfortunately, as the next result (which is potentially of independent interest) shows, ([\ref=HaarShiftAssumption]) is in general not true.

If [formula] is any dyadic system of cubes, W a matrix A[formula] weight, and [formula] is any sequence of matrices then the Haar multiplier is bounded on Lp(W) if and only if [formula].

First assume that [formula]. By duality, it is enough to show that [formula] is bounded on [formula]. Furthermore, writing

[formula]

the comments immediately following the proof of Theorem [\ref=WtdHaarMultThm] tell us that it is enough to show that is bounded on [formula].

However, the proof of this is very similar to the proof of Theorem [\ref=WtdHaarMultThm]. In particular, if we can show that is uniformly bounded (with respect to [formula]) on [formula], then the proof that [formula] is bounded on [formula] will in fact follow almost word for word from the proof of Theorem [\ref=WtdHaarMultThm].

To that end, by ([\ref=STDef]) and the definition of [formula] we have that for any [formula]. Replacing [formula] with [formula] we get that

[formula]

where the last inequality comes from ([\ref=ArbWeightProp]). By our assumption, this means that [formula] is uniformly bounded for [formula] and [formula] which means that VIMI is uniformly bounded on [formula].

For the other direction, fix some [formula] and let [formula] with [formula]. Again by the comments immediately following the proof of Theorem [\ref=WtdHaarMultThm], we can assume that [formula] is bounded on [formula]. By dyadic Littlewood-Paley theory we then have that

[formula]

Plugging [formula] for any [formula] into ([\ref=NecHaarMultEq]) and noticing that gives us that [formula] However, the first half of the proof of Lemma [\ref=RedOp-AveLem] then tells us that [formula]. Using the definition of VJ0' and summing over all of the 2n first generation children J0' of J0 finally (after taking the supremum over [formula]) gives us that [formula] as desired.

In light of Proposition [\ref=HaarMultThm] we will make the following reasonable conjecture:

Let W be a matrix A[formula] weight and let Sij be a Haar shift with respect to [formula] with matrix coefficients aIJK that satisfy Then where

Note that a slight modification of the proof of Proposition [\ref=HaarMultThm] actually proves Conjecture [\ref=HaarShiftConj] without the necessary summation condition on the Lp(W) operator norm of Sij. It would therefore be interesting to know if the ideas from [\cite=HPTV] [\cite=LPR] can be combined with the proof of Proposition [\ref=HaarMultThm] to prove Conjecture [\ref=HaarShiftConj].

Unfortunately, even if Conjecture [\ref=HaarShiftConj] were true, it is unclear what kind of matrix weighted norm inequalities this would give for matrix kernelled CZOs. In particular, one can most certainly carefully examine the proof of ([\ref=HytonenFormula]) and explicitly write down the matrix coefficients aIJK of each Haar shift Sijω in ([\ref=MatrixHytonenFormula]) (which are related to the Haar coefficient matrix [formula] of the matrix kernelled CZO T for certain [formula], and in most cases are in fact precisely 〈ThI,hJ〉L2 for certain [formula].) However, it is far from clear whether doing this in conjunction with Conjecture [\ref=HaarShiftConj] will in fact lead to any concrete matrix weighted norm inequalities for T. With this in mind, it would most certainly be interesting to know if the classical arguments in [\cite=G] can be modified to give any concrete matrix weighted norm inequalities for matrix kernelled CZOs (and if so, what these matrix weighted norm inequalities would even look like.)

We will end this paper with an interesting remark regarding ([\ref=HytonenFormula]). Note that in fact ([\ref=HytonenFormula]) was proved in [\cite=H] when the usual L2 boundedness of the CZO T is replaced by the David-Journé "T1 assumptions" that [formula] and the weak boundedness property where the supremum is over all cubes [formula]. Furthermore, recall from Proposition [\ref=BMOWtoBMOProp] that [formula] for any matrix weight W implies that [formula].

It would therefore be interesting to know if W is a matrix A[formula] weight and [formula] implies that [formula]. Obviously if this is true, then we would be able to replace the [formula] boundedness of the matrix kernelled CZO T in ([\ref=MatrixHytonenFormula]) with the matrix weak boundedness property where [formula] is the matrix defined in the obvious way by

Finally, it would be interesting to know if one can come up with a matrix kernelled CZO T and matrix weight W where T is not necessarily bounded on Lp(W). Since one can do this for matrix symbolled dyadic paraproducts, it is reasonable to expect that one can do this for matrix kernelled CZOs too.

Acknowledgements

The first author would like to thank Kelly Bickel and Brett Wick for their interesting discussions regarding sharp matrix weighted norm inequalities.