Information Entropy Dynamics and Maximum Entropy Production Principle

Introduction

Matters of evolution in the nature and society raise a great number of various discussions. One of the efficient ways to describe and interpret the evolution is to use entropy.

Entropy is an information theory tool, designed to quantify the information content and possibly information loss for various systems. The term of information can be used as an inverse of uncertainty. In this case the growth of uncertainty is identiﬁed with an increase of the entropy which in turn is interpreted as the information loss.

Entropy and related information measures provide useful descriptions of the long term behavior of random processes. The notion of entropy often becomes the center of discussions both in statistical physics and in thermodynamics.

To describe the evolution of non-stationary processes that follow the principle of maximum entropy the maximum entropy production principle (MEPP) is often used [\cite=c777]. The MEPP is that a system evolves in "natural" environment maximizing its entropy production when some restrictions are imposed. The "natural" environment means that there is no direct external action. Thus if the principle of maximum entropy (MaxEnt) says that a system tends to its state of maximum entropy then the MEPP says that the system tends to it at the highest possible rate. In some cases of system evolution analysis, these principles allow one to obtain missing information required in order to determine the direction of further evolution.

For now, attempts to justify MEPP widely use an approach based on the information entropy proposed by E.T. Jaynes (1957) [\cite=c2] [\cite=c63] [\cite=c63_2]. This approach is a simple and convenient way to construct (both classical and quantum) statistical thermodynamics; it does not require some complexities such as the ergodic hypothesis. An important advantage of Jaynes' formalism is its ability of being generalized to analyze non-equilibrium systems.

An approach to derive the MEPP using Jaynes' formalism is proposed by Dewar [\cite=c77] [\cite=c78]. This approach seeks the most probable path of evolution which describes non-equilibrium stationary systems. Dewar analyzes a non-equilibrium stationary open system (with volume V and boundary Ω) and uses a concept of "microscopic path" that implies microstate changes over time. However, according to the discussion in [\cite=c777], it is still an open problem to trace connection between the maximum information entropy of trajectories and the MEPP, and therefore to determine the entropy evolution of the system. We propose a new justification of MEPP based on control theory.

It is known that methods of the optimal control (such as Bellman dynamic programming, Pontryagin's maximum principle, etc.) can be effectively used to develop models of mechanical [\cite=c4], thermodynamic [\cite=c5] and other complex systems. Using such methods also seems promising in the context of the MEPP. Equations of the dynamics of physical systems can be obtained from extremal principles if the goal is to reach the extremum of an objective functional. We can consider the entropy maximization of a system as such a goal and use the speed-gradient (SG) principle [\cite=Fradkov_4] [\cite=Fradkov_5] [\cite=Fradkov_UFN] [\cite=Fradkov_7] [\cite=c10] originated in control theory. In this case, having determined the equations of the system dynamics that ensure the maximum entropy increment, the SG principle can justify the MEPP.

The SG principle is successfully applied in [\cite=Fradkov_3] [\cite=Fradkov_4] to obtain equations of the statistical dynamics of finite systems of particles that follow the principle of maximum entropy. Applicability of the SG principle is experimentally tested in [\cite=Fradkov_7]; it is done on the system of particles simulated with the molecular dynamics method on the basis of equations of classical mechanics. However, it is still an open question to apply these results to systems with continuous distributions.

An approach proposed in this paper provides the evolution law of the system in the following form:

[formula]

where I is identity operator, Ψ is a linear integral operator that is invariant for p, Γ > 0 is a constant gain.

By means of this approach the distribution corresponding to the maximum value of entropy can be found. A way how to find the distribution achieving the extreme value (maximum or minimum) of entropy within a given variational distance from any given distribution is proposed in [\cite=Ho_1]. Approximation of probability distribution is built there based on a new bounds on entropy distance. Also these bounds are applied to entropy estimation. The application of these bounds to typical sequences is discussed in [\cite=Ho_2].

Convergence of differential entropies which corresponds to pdfs from eq. ([\ref=common_eq]) can be proven on the basis of sufficient conditions provided by Godavarti and Hero [\cite=Godavarti]. According to Godavarti and Hero [\cite=Godavarti], the convergence of differential entropies can be traced to the problem of asymptotic analysis of various communication systems where the maximum asymptotic rate of communication is investigated [\cite=G_4] [\cite=G_9] [\cite=G_16] [\cite=G_18] [\cite=G_20]. Also the differential entropy convergence can be used in communication systems where the asymptotically optimal source compression [\cite=G_7] [\cite=G_8] or the asymptotic storage capacity [\cite=G_14] is analyzed. Entropy estimation and the convergence of differential entropies are also investigated in [\cite=G_3] [\cite=G_1] [\cite=G_17]

Jaynes's MaxEnt principle was successfully used for inductive inference in [\cite=Shore]. It is shown that given information in the form of constraints on expected values, there is only one appropriate distribution which can be obtained by maximizing entropy. Appropriateness of this unique distribution is that it satisfies the constraints that can be chosen by a procedure that satisfies the consistency axioms. Continuous probability densities are also considered there. Inductive inference can be used in systems with non-stationary processes which satisfy the MaxEnt [\cite=PhysScripta]. In [\cite=PhysScripta] the notion of Entropy Dynamics (ED) is used. ED is a theoretical framework which combines inductive inference [\cite=Shore] and Information Geometry [\cite=Amari]. ED investigates the possibility of deriving dynamics from purely entropic arguments.

The main result of this paper is the extension of the [\cite=Fradkov_3] [\cite=Fradkov_4] results to systems with continuous probability distribution. The SG principle is used to derive equations of the dynamics of transient states of the systems that in a steady state follow the principle of maximum entropy.

The next section formulates the SG principle. Jaynes' formalism is introduced in 3rd section. The 4th section gives an example of a dynamic system with continuous distribution of parameters that follows the principle of maximum entropy. Cases with one and two constraints are reviewed. Equations of the transient state are derived; and their properties are analyzed. The asymptotic stability of pdfs and differential entropy convergence is proved.

Speed-Gradient Principle

Let us consider a category of open physical systems which dynamics is described by the system of differential equations

[formula]

where [formula] is the system state vector, u is the vector of input (free) variables t  ≥  0. The task of system simulation (model development) can be defined as deriving the law of variation (of evolution) u(t) that satisfies some criterion of "naturalness" of its performance to give the model features characterizing a real physical system.

Developing such a criterion based on extreme and variational principles usually implies specifying some integral functional (for example, an action functional of the principle of least action [\cite=Lancosh_8]) that characterizes the system performance. Functional minimization defines probable trajectories of the system {x(t),u(t)} as points in the corresponding functional space. The advanced apparatus of the calculus of variations is used to define the law of the system dynamics.

Besides integral principles, differential (local by time) ones are used, for example, Gauss's principle of least constraint, the principle of least dissipation of energy, etc. According to M. Planck [\cite=Plank_9], local principles have some advantage over integral ones because the current state and motion of the system do not depend on its later states and motions there. Using [\cite=Fradkov_5] [\cite=Fradkov_3], let us formulate one more local variational principle based on the speed-gradient method proposed earlier to synthesize the laws of the nonlinear and adaptive control.

The speed-gradient principle: of all the probable motions, the system implements the ones for which input variables vary directly as the speed-gradient of some "goal" functional Qt. If restrictions are imposed on a motion of the system then the direction is a speed-gradient vector projection on the acceptable directions (the ones that satisfy the restrictions) set.

The SG principle can be represented in the finite form

[formula]

where [formula] is a rate of change of the goal functional along the trajectory of the system ([\ref=PrincSkorGrad]). Let us describe application of the SG principle in the simplest (but at the same time in the most important) case where a category of models of the dynamics ([\ref=PrincSkorGrad]) is specified as the relation:

[formula]

The relation ([\ref=eq_4]) just means that we are deriving the law of variation of variables speeds of the system state. In accordance with the SG principle, the goal functional (function) Q(x) needs to be specified first. Q(x) should be based on physics of a real system and reflect its tendency to decrease the current Q(x(t)) value. After that, the law of dynamics can be expressed as ([\ref=SkGrad2]).

The SG principle is also applicable to develop models of the dynamics of distributed systems that are described on infinite-dimensional state spaces. There in particular can be a vector x in a Hilbert space X and a nonlinear operator f(x,u,t) defined on a dense set DF  ⊂  X; in this case, the solutions of equation ([\ref=PrincSkorGrad]) are generalized.

Jaynes's Maximum Entropy Principle

The approach proposed by Jaynes [\cite=c2] [\cite=c63] [\cite=c63_2] became the foundation for statistical physics nowadays. Its main ideas are described below.

Let p(x) be a probability density function (pdf) of a multidimensional random variable x. This is an unknown function that needs to be defined on the basis of certain system information. Let us suppose that there is the information about some average values [formula] which are known a priori:

[formula]

The next equality is also true for the density function

[formula]

Conditions ([\ref=sred_ogr]) and ([\ref=plotn_raspred]) in general can be insufficient to derive p(x). In this case, according to Jaynes, applying maximization of information entropy SI is the most objective method to define the density function.

[formula]

Maximum search with additional conditions ([\ref=sred_ogr]) and ([\ref=plotn_raspred]) is performed by using Lagrange multipliers; it leads to

[formula]

[formula]

where λm can be derived from conditions ([\ref=sred_ogr]).

These formulas allow definition of the distribution function for microcanonical, canonical and other ensembles. We substitute the conditions characterizing each equilibrium ensemble for condition ([\ref=sred_ogr]) [\cite=c63]. In case of equilibrium (when appropriate random variables x are selected), the formulas also show that the maximum information entropy coincides with the Gibbs entropy and can be identified with the thermodynamic entropy.

Jaynes showed a close connection and succession between his approach and both the classical papers dealing with probability theory and statistics (Bernoulli, Laplace) and the papers doing with physics and information theory (in particular J. Gibbs and C. Shannon) [\cite=c65].

Although information theory was initially based on some concepts of statistical physics, now, thanks to C. Shannon, the information approach can be taken as a basis to develop statistical physics. According to [\cite=c777], formalism of statistical mechanics is some sequence of operations. Having limited information about microworld but following this sequence, we can get the most objective estimation (this is a method of error prevention).

Maximization of entropy with Speed-Gradient method

The maximum entropy principle of Gibbs and Jaynes [\cite=c63] [\cite=c63_2] defines the asymptotic behavior of the system, but does not say anything about how there is a movement to an asymptotic behavior. To answer this we use the SG principle.

System with a continuous distribution of states

Consider a system with a continuous distribution of the set of possible states. Probability distribution over states is characterized by pdf p(t,r) which is continuous everywhere except for a set with zero measure:

[formula]

where Ω is a compact carrier.

State of the system evolves over time. We are interested in the behavior of both steady and transient mode. Steady state is determined by the MaxEnt principle. If nothing else about the system is known then its supreme behavior will maximize its measure of uncertainty (entropy). As a measure of uncertainty we choose differential entropy which is defined as

[formula]

Let's define a law of system dynamics as

[formula]

We have to define a function u(t,r).

According to speed-gradient principle a rate of entropy change ([\ref=diff_entropy]) which is based on a system ([\ref=system]) has to be calculated first. Then a gradient of rate for function u has to be found. And finally, control parameters has to be defined. These parameters are proportional to projection of gradient on a surface of bounds ([\ref=plotnost_ver]).

Let's calculate [formula]

[formula]

From ([\ref=plotnost_ver]) it follows that

[formula]

So, [formula] Gradient of [formula] by u is equal to [formula]. According to ([\ref=grad_skal_pr]) we have that [formula]

Speed-gradient principle of motion forms u =  - Γ log p(t,r)  +  λ, where Γ can be taken as a scalar value and LaGrange multiplier λ is selected to satisfy a restriction ([\ref=ogr_u]).

[formula]

where

[formula]

Final system dynamics equation has the following form

[formula]

Eq. ([\ref=odno_ogr1]) can be represented in more general form

[formula]

where [formula] is a linear operator which is invariant for p and I ia an identity operator.

Physical meaning of equation ([\ref=odno_ogr1]) can be described as a movement to the direction of maximum rate of entropy production. It corresponds to MEPP.

Equilibrium stability

Let's investigate a stability of obtained equilibrium equation ([\ref=odno_ogr1]).

Theorem 1 There exists a unique limit pdf p*(t,r) defined by equation ([\ref=odno_ogr1]):

S(p*(t,r))  =  Smax. And [formula]

Proof

Consider an entropy function of Lyapunov.

[formula]

Let's find a derivative of function ([\ref=w1])

[formula]

After substitution of expression for u from ([\ref=odno_ogr1]) to ([\ref=w1]) we obtain

[formula]

After several conversions it is true that

[formula]

We will use the Cauchy-Bunyakovsky inequality

[formula]

for functions f =  log p and g = 1. Taking into account that a scalar value Γ is positive we get that [formula]. Let's denote a set of functions where [formula] has null values as [formula] It is known that equality in the Cauchy-Bunyakovsky inequality is achieved when multiplicity occurs, i.e. f(x) = αg(x). In our case [formula] is true when log p(t,r)  =  α. It is possible only when p(t,r)  =  const. Using restriction ([\ref=plotnost_ver]) we get that [formula]. And set D consists of only one solution D = {p*}. [formula]

Asymptotic convergence

We will show an asymptotic convergence of all solutions to p*. To do it we use Barbalat's lemma.

Barbalat's lemma If differentiable function f(t) has a finite limit for t  →    ∞   and its derivative [formula] is uniformly continuous then [formula] for [formula]

Theorem 2 For all pdfs defined by equation ([\ref=odno_ogr1]) it is true that p(t,r)  →  p* for t  →    ∞  .

Proof

For the sake of simplicity we define a designation for V in ([\ref=Lyap_11]) as [formula] We will use a Barbalat's lemma to show that [formula] We use v(t) as a function f(t). Because of [formula] and [formula] the function v(t) has a finite limit for t  →    ∞  .

Let's show conditions when function [formula] is bounded. That will lead us to the fact that [formula] is uniformly continuous.

[formula]

Expression [formula] comes true when

[formula]

where [formula] is defined as ([\ref=mes]).

A similar conclusion may by performed for function [formula] In this way a function [formula] is uniformly continuous if condition ([\ref=mes_0]) is satisfied. Then according to Barbalat's lemma [formula] for [formula].

Let ft  =   log pt. Taking into account that [formula] the expression for [formula] may be written as

[formula]

where α(t) =  cos (〈1,ft〉).

If [formula] then [formula]. It means that [formula] It is equivalent to [formula] Due to the bound for the density for all [formula] it is true that [formula] Thus [formula] is wrong if only [formula] The case when [formula] we consider as a degenerate. Given ([\ref=dot_v]) we obtain [formula] It means that   →  , where [formula] and [formula] are normalized values for ft and 1 respectively.

It follows that pt tends to the stationary distribution. As explained earlier this distribution is unique.

Thus, ptt  →    ∞  →  p*. [formula]

Convergence of differential entropies

Let's prove the convergence of differential entropies

Theorem 3 For differential entropy defined as

[formula]

it is true that

[formula]

where pdf p(t,r) is defined by equation ([\ref=odno_ogr1]) and p* is limiting pdf: p(t,r)t  →    ∞  →  p*(r).

Proof

In [\cite=Godavarti] Godavarti and Hero provide sufficient conditions for convergence of differential entropies H(pn)  →  H(p*). The only assumptions are that pn  →  p* and that exists a constant L and some k > 1 such that for all N

[formula]

and

[formula]

For all t our pdf p(t,r) from ([\ref=odno_ogr1]) the first assumption pn  →  p* is satisfied due to Theorem 2. Conditions ([\ref=g1]) and ([\ref=g2]) are also satisfied on the compact carrier Ω. According to [\cite=Godavarti] it means that ([\ref=entr_conv]) is true. [formula]

So with eq. ([\ref=common_form]) we are able to predict the evolution of system's entropy.

Total energy constraint

Restriction ([\ref=plotnost_ver]) can be interpreted as the law of conservation of mass on a space Ω. Let's consider a system with additional constraint for the law of total energy conservation. We will consider a conservative case when energy does not depend on a time. The new constraint may be described as

[formula]

where E is a common energy of a system and h(r) is a density of energy.

Let's consider a system

[formula]

The problem is to find an operator u which satisfies to both constraints ([\ref=plotnost_ver]) and ([\ref=ogr_energ]) at any time t. And the following goal condition is true.

[formula]

To solve this problem we use the speed-gradient method. As a goal function we take

[formula]

where S is a differential entropy, λ'1 and λ'2 are LaGrange multipliers. Due to the speed-gradient principle an operator u has to be described as

[formula]

Let's calculate the derivative of a goal functional

[formula]

Taking the gradient by u we get

[formula]

Now then

[formula]

where λ1 =  - Γλ'1, λ2 =  - Γ(λ'2 + 1).

Now we find LaGrange multipliers λ1 and λ2 based on boundary conditions. For the sake of simplicity we omit the arguments of functions. So, for example we use log p instead of log p(t,r). It is follows from the condition ([\ref=ogr_u]) that

[formula]

Condition ([\ref=ogr_energ]) is equivalent to [formula] From this condition it should be

[formula]

Solving the system of equations ([\ref=1usl]) and ([\ref=2usl]) we obtain

[formula]

[formula]

Equations ([\ref=koeff1]) and ([\ref=koeff2]) are defined when denominator in both fractions is not equal to zero. If we take in the Cauchy-Bunyakovsky inequality f = h аnd g = 1 then the following inequality comes true

[formula]

This inequality becomes equality when h = const. It means that all energy levels coincide. This case is supposed to be degenerate and not considered here. Thus the expression

[formula]

is always true.

Given ([\ref=koeff1]), ([\ref=koeff2]) and substituting ([\ref=dva_ogr]) in equation ([\ref=system_eq]) we obtain the common equation of system dynamics:

[formula]

Law of evolution ([\ref=dva_ogr_full]) can be represented in abbreviated form:

[formula]

where I is an identity operator, Ψ is a linear integral operator that is independent of p

[formula]

[formula].

Stability of equilibrium

Further we examine the equilibrium of obtained equation ([\ref=dva_ogr_full]).

Theorem 4 There exists a unique limit pdf p* defined by equation ([\ref=dva_ogr_full]):  S(p*)  =  Smax.

p*  =  Ce-  μh, where [formula] [formula] and λ1, λ2 are defined in ([\ref=dva_ogr]).

Proof

Let's calculate the derivative of functional ([\ref=Lyap_11]) for the system ([\ref=dva_ogr_full]):

It can be proved that

[formula]

For the proof of inequality ([\ref=neravenstvo]) we define a functional:

[formula] [formula]

[formula]

New functional has several useful properties

1. Linearity in the first argument

[formula]

2. Symmetry

[formula]

3. Positiveness and the condition of zero value

[formula]

Let's prove inequality ([\ref=neravenstvo]) base on properties 1-3.

Obvious that for any f,g∈L2(Ω) and [formula] it is true that f - λg∈L2(Ω). This function has property 3: 〈f - λg,f - λg〉  ≥  0. Using properties 1 and 2 we get the quadratic inequality with respect to λ:

[formula]

This inequality holds for any real λ. Hence the discriminant can not be positive.

[formula]

Thus

[formula]

If the equality takes place in ([\ref=ner_inner]) then there exists a unique solution [formula] of an equation 〈f - λg,〈f - λg〉  =  0. But then by property 3 we have [formula].

Substituting f =  log p,g = h to the inequality ([\ref=ner_inner]) we get

[formula]

Which implies the inequality ([\ref=neravenstvo]).

Note that the equality ([\ref=neravenstvo]) holds if and only if

[formula]

In the case of equilibrium the expression ([\ref=dva_ogr]) can be written as

[formula]

which coincides with ([\ref=ravenstvo_skal_pr]). Thus there is a unique pdf corresponding to the equilibrium state:

[formula]

where [formula] [formula]. This state corresponds to the Gibbs distribution, which is consistent with the results of classical thermodynamics. [formula]

Asymptotic convergence

We prove asymptotic convergence with Theorem 5.

Theorem 5 For all pdfs defined by equation ([\ref=dva_ogr_full]) it is true that p(t,r)  →  p* for t  →    ∞  .

Proof

The proof of asymptotic convergence for eq. ([\ref=dva_ogr_full]) will be performed similar to the case with one constraint (Theorem 2). To use Barbalat's lemma we have to check conditions under which the function [formula] is limited.

[formula]

We obtain

[formula]

Considering ([\ref=dva_ogr_full]) we get that [formula] is limited under the same conditions which were used in the case of one restriction.

Namely, [formula]

According to Barbalat's lemma it is true that

[formula]

We introduce a scalar product as [formula]. Having [formula] the expression ([\ref=v_dot]) can be written as

[formula]

Consider the case when [formula]. By Cauchy-Bunyakovsky inequality the equality in inequality

[formula]

takes place when log p  =  α.

We have previously demonstrated that the equality [formula] holds in the only one case when log p  =  λh  +  μ, where λ and μ are constants. Then h must be a constant since the equality λh  +  μ  =  α. Such a case we assume degenerate because then the denominator in the expressions for the coefficients λ1 and λ2 (([\ref=koeff1]) и ([\ref=koeff2])) is equal to zero.

Given ([\ref=v_dot_null]), ([\ref=dva_ogr_skal_pr]) and [formula] we obtain [formula]. Which implies that p  →  , where p and [formula] are normalized values for log p and h respectively. Thus p tends to the only one stationary distribution p* since h does not depend on time. [formula]

Convergence of differential entropies

Similar to differential entropies convergence described in paragraph 4.1.3 (see Theorem 3) the convergence of differential entropies for the case of two constraints can be proved.

Theorem 6 For pdf which is defined by equation ([\ref=dva_ogr_full]) it is true that

[formula]

where H(t) = H(p(t,r)) is differential entropy and p* is limiting pdf: p(t,r)t  →    ∞  →  p*(r).

Conclusion

The MEPP is widely used in different studies of complex systems of physical, chemical or biological origin [\cite=c777]. Using MEPP, P. Zupanovic [\cite=c156] derived Kirchhoff law of electrical circuits.

The task to justify MEPP was unresolved for a long time. We propose such a justification based on results originated in the control theory.

It is an important problem to derive the principle that determines the dynamics of non-stationary (transient) states, and describes a way and trajectory of the system that tends to the state with maximum entropy. If a goal function is the entropy of a system then the extreme SG principle supplements Gibbs and Jaynes maximum entropy principle to determine the direction of evolution of the system when it tends to the state of maximum entropy. This direction corresponds to maximum entropy production rate (growth rate).

SG principle generates equations for the transient (non-stationary) states of the system operation, i.e. it gives an answer to the question of How the system will evolve? This fact distinguishes the SG principle from the principle of maximum entropy, the principle of maximum Fisher information and others characterizing the steady-state processes and providing an answer to the questions of To where? and How far?

The equations derived on the basis of the SG principle allow forecasting the dynamics of non-equilibrium systems with continuous distribution of parameters. These equations can prove to be useful to study both evolutions and relaxations of non-equilibrium systems of macroscopic and microscopic world.

Preliminary Information

Scalar Product. In space of real functions L2(Ω) a scalar product can be specified as

[formula]

where Ω is a compact carrier. This scalar product generates a norm:

[formula]

Allowing completeness of space Lp(Ω) we can consider space L2(Ω) as a Hilbert space.

Variational Derivative and Gradient of Scalar Product. Let us assume that functional Φ is specified as [formula] A variational derivative of Φ can be specified as the analog of a finite-dimensional gradient.

[formula]

where [formula] is a variational derivative of Φ with respect to f, and df is a variation. If variation dΦ  =  Φ(f  +  df)  -  Φ(f) can be expressed as [formula] then A is a variational derivative of Φ with respect to f.

Thus for each scalar product [formula] in space of real functions L2(Ω) a function a can be regarded as a variational derivative with respect to g, i.e.

[formula]

Differential and information entropy. If discrete random variable X is x1,x2,...,xn  with with probabilities p1,p2,...,pn,  respectively then its measure of uncertainty is

[formula]

Let us consider p(x)dx as a probability of random variable hitting into indefinitely small interval  (x,x + dx) then the entropy in [\eqref=1] can be formalized for a continuous case as:

[formula]

where p(x) is a pdf.

In expression [\eqref=3] only the first term depends on the probability density of a random variable but the second one is always  ∞  . The measures of uncertainty for different distributions can be compared by comparing only the first terms of expression [\eqref=3]. To do it, a concept of differential measure of uncertainty (differential entropy) is introduced.

[formula]

Differential entropy as an entropy of continuous distribution can be interpreted as the average information of continuous source, i.e. information entropy.

Properties of functional 〈f,g〉 from the proof of Theorem 2 (sect. 4.2.2)

1. Linearity in the first argument

[formula]

Proof Using the linearity of the integral we obtain

[formula]

2. Symmetry

[formula]

Proof

[formula]

3. Positiveness and the condition of zero value

[formula]

Proof Let's consider a scalar multiplication ([\ref=skal_pr]). Cauchy-Bunyakovsky comes true for it: [formula] и [formula] Substituting [formula] we get

[formula]

Thereby it is true that

[formula]

Moreover [formula] т.е. f = μ   [formula]