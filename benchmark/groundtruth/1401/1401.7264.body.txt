Convergence bound in total variation for an image restoration model

Introduction

A.L. Gibbs [\cite=key-1] introduced a stochastic image restoration model for an N pixel image [formula]. More specifically, in this model each pixel xi corresponds to a real value in [formula], where a black pixel is represented by 0 and a white pixel is represented by the value 1. It is assumed that in the real-world space of such images, each pixel tends to be like its nearest (in the absence of any evidence otherwise). This assumption is expressed in the prior probability density of the image , which is given by

[formula]

on the state space [formula], and is equal to 0 elsewhere. The sum in ([\ref=eq:prior]) is over all pairs of pixels that are considered to be , and the parameter γ represents the strength of the assumption that pixels are similar. Here images are assumed to have an underlying graph structure. The familiar 2-dimensional digital image is a special case, where one might assume that the of a pixel xi in the interior of the image (i.e. xi not on the boundary of the image) are the 4 or 8 pixels surrounding xi, depending on whether or not we decide to consider the 4 pixels diagonal to xi.

The actual observed image [formula] is assumed to be the result of the original image subject to distortion by random noise, with every pixel modified independently through the addition of a [formula] random variable (hence [formula]). The resulting posterior probability density for the original image is given by

[formula]

supported on [formula].

Samples from ([\ref=eq:posterior]) can be approximately obtained by means of a Gibbs sampler. In this instance, the algorithm works as follows: at every iteration the sampler a site i uniformly at random, and replaces the value xi at this location according to the full conditional density at that site. This density is given by

[formula]

on [formula] and 0 elsewhere. Here ni is the number of the ith pixel has, and j  ~  i indicates that the jth pixel is one of them. It follows that ([\ref=eq:pifc]) is a restriction of a [formula] distribution to the set [formula].

The bound on the rate of convergence to equilibrium given in [\cite=key-1] is stated in terms of the Wasserstein metric dW. This is defined as follows: if μ1 and μ2 are two probability measures on the same state space which is endowed with some metric d, then

[formula]

where the infimum is taken over all joint distributions [formula] such that ξ1  ~  μ1 and ξ2  ~  μ2.

Another commonly used metric for measuring the distance of a Markov chain from its equilibrium distribution is the total variation metric, defined for two probability measures μ1 and μ2 on the state space Ω by

[formula]

where the supremum is taken over all measurable A  ⊆  Ω.

The underlying metric on the state space used throughout [\cite=key-1] (and hence used implicitly in the statement of Theorem [\ref=thm:0]) is defined by [formula]. This is a non-standard choice for a metric on [formula], however it is comparable to the more usual l1 taxicab metric [formula] since

[formula]

where [formula] and [formula]. Hence, for two probability measures μ1 and μ2 on [formula], it follows immediately that

[formula]

where dŴ and dW are the Wasserstein metrics associated with [formula] and d respectively.

If Θ1 and Θ2 are two random variables on the same state space with probability measures m1 and m2 respectively, then we shall write

[formula]

Gibbs [\cite=key-1] shows that

[\cite=key-1] Let Xt be a copy of the Markov chain evolving according to the Gibbs sampler, and let Zt be a chain in equilibrium, distributed according to πposterior. Then if [formula] is given the metric [formula], it follows that [formula] whenever

[formula]

By the comments preceding the statement of this theorem, ([\ref=eq:Wmixtime]) remains true with the standard l1 metric on the state space, if we replace ε by nmin  ·  ε in the right-hand side of this inequality. It is not difficult to see that dTV is a special case of dW when the underlying metric is given by [formula] if x  ≠  z. In general however, convergence in dW does not imply convergence in dTV, and vice versa (see [\cite=key-2] for examples where convergence fails, as well as some conditions under which convergence in one of dW, dTV implies convergence in the other). The purpose of this paper is to obtain a bound in dTV by making use of ([\ref=eq:Wmixtime]) and simple properties of the Markov chain, without specifically engaging in a new study of the mixing time.

Let Xt be a copy of the Markov chain, and let μt be its probability distribution. Furthermore, define [formula], [formula] and [formula]. If π is the posterior distribution with density function πposterior, we show that

Let Xt be a copy of the Markov chain evolving according to the Gibbs sampler, and let Zt be a chain in equilibrium. Then [formula] whenever

[formula]

where [formula] and [formula] .

Akin to the bound for the metric dW, this bound is also [formula]. A notable difference, however, is that in our bound there is a (quadratic) dependence on ζ (and hence a quadratic dependence on [formula]).

Since this state space is bounded, it also easily follows (using previously defined notation) that [formula] and [formula]. Therefore, Theorem [\ref=thm:1] also implies a bound in dW as well as dŴ.

Section [\ref=sec:2] will present the proof of Theorem [\ref=thm:1], and will conclude with a discussion of the proof strategy.

From dW to dTV

Let t be some fixed time, and let Xs and [formula] ([formula]) be two instances of the Markov chain, evolving as defined in the lines preceding ([\ref=eq:pifc]). The coupling method [\cite=key-3] allows us to bound total variation via the inequality

[formula]

Having uniformly selected i from [formula], we couple the pixel Xt + 1i with Zt + 1i as follows: let fi and gi be the conditional density functions of Xt + 1i given Xt and of Zt + 1igiven Zt, respectively. Choose a point [formula] uniformly from the area defined by [formula] - i.e. the area under the graph of fi, and set Xt + 1i = a1. If the point [formula] is also in the set [formula], then set Zt + 1i = Xt + 1i = a1. Otherwise [formula], and in this case choose a point [formula] uniformly from [formula] and set Zt + 1i = b1. Observe that Xs and Zs ([formula]) are indeed two faithful copies of the Markov chain.

In order to proceed, we will establish the following results.

Let [formula] and [formula], and let W1 and W2 have the distributions of U1 and U2 conditioned to be in some measurable set [formula]. Let fU1, fU2, fW1 and fW2 be their respective density functions. Then

[formula]

We start by noting that

[formula]

The first equality is one of a few different equivalent definitions of total variation. A proof is given in Proposition 3 of [\cite=key-4].

Now if [formula], then the above is bounded by

[formula]

The second inequality follows from the observation that

[formula]

Similarly, if [formula], then we repeat the same argument with

[formula]

in place of ([\ref=eq:lem1ineq1]), arriving at the same result.

A simple but useful result is the following lemma:

[formula]

This is trivial, since [formula] for any [formula].

Now let [formula] and [formula]. Applying Lemma [\ref=lem:2] to [formula] with [formula], we see that conditional on [formula] (sigma algebra generated by Xt and Zt)

[formula]

For the second inequality we have used Lemma [\ref=lem:3]. By Lemma 15 of [\cite=key-2] it follows that

[formula]

Hence by ([\ref=eq:dtvxz])

[formula]

We can now proceed with the proof of Theorem [\ref=thm:1].

Let ε > 0 be given, and define [formula] (recall that [formula]) and [formula] with [formula]. By Theorem [\ref=thm:0], [formula] whenever [formula]. Since the infimum in the definition of dW is achieved (see for example Section 5.1 of [\cite=key-6]), we can find a joint distribution [formula] of two random variables uτ  ~  Xτ and vτ  ~  Zτ, such that [formula] (we use the superscript τ in uτ and vτ to preserve notational consistency with Xτ and Zτ). And by Markov's inequality we get

[formula]

For [formula] , define the Markov chains uτ + s  ~  Xτ + s and vτ + s  ~  Zτ + s by uniformly choosing (for every s) a site i and assigning values to [formula] as described at the beginning of Section [\ref=sec:2]. Note that [formula], hence it suffices to show that [formula] whenever [formula]. By splitting up the above probability and applying ([\ref=eq:dtvxz2]) and ([\ref=eq:xkzkomega]), we conclude that at the chosen site i

[formula]

Let im be the pixel chosen at time τ + m for [formula] . For [formula], define the events [formula] and [formula], and observe that in the event [formula], we have [formula]. Therefore by equations ([\ref=eq:dtvxz2]) and ([\ref=eq:xkzkomega])

[formula]

By induction on m we get that

[formula]

Note that the case m = 1 follows directly from ([\ref=eq:epstilde]). We will now refer to the 'coupon collector' problem, discussed in section 2.2 of [\cite=key-5]: if θ is the first time when a coupon collector has obtained all N out of N coupons, then

[formula]

Let φ: = τ + M and let [formula] - i.e. τ  +  θ is the first time when every pixel site has been chosen at least once after τ. Recall also that [formula]. Then

[formula]

This proves the statement of the theorem.

This research was supported in part by the NSERC Discovery Grant of Neal Madras at York University.