Relaxation of a Simple Quantum Random Matrix Model

INTRODUCTION

We will derive from the Schrödinger equation an effective equation which will turn out to be a rate equation. The Hamiltonian is taken to have a deterministic part plus a weak random part. The statistics of these types of models have been investigated in [\cite=BHZ95], [\cite=BZ95] and the dynamics have been numerically investigated in [\cite=SGM06], [\cite=MMGM05] and [\cite=BSG08] in the context of the emergence of Fourier's law and statistical relaxation in closed quantum systems. Random matrices are used in many situation either to model a complex system or mimic quantum chaos. On the other hand rate equations are widely used in order to model some complicated non-equilibrium situation by a simple set of differential equations. The essence of the results here is thus the emergency of these simple equations from complex quantum or quantum chaotic systems. The random matrix here represents somehow the "complexity". We take a simple random matrix model to illustrate how to treat fully the random interaction but this type of analysis can be forwarded to more complicated models with structures of various kinds. We will comment on this latter on. The model here is that of a quantum particle that can only move between two sites which we denote site 1 and site 2. Each site has N energy levels and for simplicity we take them to be equidistant. These energies are taken to be bounded between 0 and 1 and as N increase they grow nearer to each other. The particle can then hop from one energy level of one site to the next with a random amplitude. Pictorially it can be represented as in figure [\ref=fig1]. If P1t is the probability to be on site 1 and P2t that of being on site 2 we will prove that they satisfy on average

[formula]

in certain limits. Similar models were introduced and studied in [\cite=Weg78], [\cite=SGM06] and [\cite=Leb] where the emergency of diffusion and relaxation behavior was discusses. The methods we use are those used in [\cite=Spo77], [\cite=EY00], [\cite=ES]. We will expand the formal solution of the Schrödinger equation in powers of the random interaction and then average over the product of random matrices (sections [\ref=sec:duhamel], [\ref=sect:AveragingAndGraphs]). This average will be equal to a sum graph dependent functions and, in the limits considered, we will show that some graphs yield a vanishing contribution (sections [\ref=sec:crossing], [\ref=sec:nested] and [\ref=sec:simple]). The remaining graphs can then be summed over again and a solution to a rate equation is found (section [\ref=sec:effective]). Section [\ref=sec:error1] is devoted to showing that the error in the limits considers tends to zero.

THE MODEL

The model we analyze here is a two site tight binding model. At every site the particle has N possible states to be in, each one with different energy, E. Our Hilbert space is then spanned by the vectors |x,E〉 where x refers to the site and can take on the values 1 or 2. For simplicity we take the spectrum to be equidistant and we also take it to be bounded between 0 and 1. Thus the spectrum consists of the points [formula] Our unperturbed Hamiltonian is the following:

[formula]

with [formula]. Our density of states is thus constant. The perturbation is given by a type of GUE matrix. Each matrix entry is a complex gaussian distributed random variable. We restrict the interaction to be between energy states of different sites.

[formula]

V has thus two off diagonal blocks while the rest is zero. The distribution over this type of random matrix is then

[formula]

We have then the following for the average on a matrix element:

[formula]

Our total Hamiltonian is:

[formula]

We will be interested in calculating the time evolution of the probability of the particle to be on site 1 or 2. These are

[formula]

The theorem is then as follows:

Say |ψNt〉 is a solution to the Schrödinger equation with the Hamiltonian of Eq. ([\ref=eq:Hamiltonian]) with initial data |ψN0〉. The initial data is taken such that the population around the edges of the spectrum of H0 is zero in a small neighborhood of distance ε of the edges. That is 〈x0,E|ψN0〉 = 0 if E  ≤  ε or 1 - ε  ≤  E. Then in the limit N  →    ∞   and t  →    ∞   (taken in this order), and with the following scaling

[formula]

the average over the random matrix of the time evolution of the probabilities ([\ref=p1]) and ([\ref=p2]) will follow the next differential equations:

[formula]

The initial data is given by

[formula]

Eq. ([\ref=sca1]) is called the Van Hove limit.

EXPANSION AND IDENTITIES

According to the Duhamel formula, [\cite=EY00], we have the next identity for the evolution operator.

[formula]

By applying successively this identity we can expand the evolution operator in orders of λ. Thus we can write it as follows:

[formula]

with

[formula]

|φM + 1t〉 is the error term of the time evolved wave function. We adopt the following notation for multiple time integrals:

[formula]

We are interested in calculating the time evolution of the observables P̂1 and P̂2 given by Eqs. ([\ref=p1]) and ([\ref=p2]). Using the expansion of Eq. ([\ref=eq:gammaprop]) until the [formula] order, the time evolution of the observables Px0,Nt is

[formula]

with

[formula]

Rx0,M,Nt encodes the remainder of the evolution. It is our error term in the evolution of the probability Px0,Nt and has the following form:

[formula]

We will compute Px0,M,Nt in the limit N  →    ∞   and the Van Hove limit, [formula]. In section [\ref=sec:error1] we will show that remainder goes to 0.

[formula]

This implies that we can use Px0,M,Nt to obtain the evolution of Px0t. That is,

[formula]

When inserting Eq. ([\ref=eq:gamma]) in 〈x0,E0|Γn(t)|xn,En〉 and identities after each interaction term we obtain the following:

[formula]

with

[formula]

We denote by {xi,Ei} the set of all energy variables, [formula], and position variables, [formula]. We have then for Px0,M,Nt:

[formula]

where we have taken up the following notation :

[formula]

The subscript 0 in Eq. ([\ref=sum2]) denotes the fact that we are not summing over x0. From Eq. ([\ref=eq:wignerlfullexpansion]) we see we have E0' = E0 and x0 = x'0. The Ln({xi,Ei}) function is the statistical weight given to this history or process by the random interaction. It carries no time dependency. Since we want to calculate the average and the randomness is all encoded in the Lnm factor we will calculate [formula]. The purpose of the next section is to characterize this average.

AVERAGING AND GRAPHS

The main purpose in this section is to introduce graphs as representations of contributions to the average we want to calculate such that averaging will turn out to be a sum over different graphs. We will introduce three classes of graphs just as in [\cite=EY00]. First we differentiate between crossing and non-crossing graphs. Non-crossing graphs are also called planar graphs, [\cite=TH2] [\cite=BIP+78]. They carry individually more weight then crossing graphs and thus crossing graphs will vanish in the limit N  →    ∞  . We recall here Wick's theorem.

Say we have 2k random Gaussian variables denotes by Xi, 1  ≤  i  ≤  2k, and say we have [formula]. Denote by π(2k) a list of pairs of all the elements of the set s, [formula]. We have then

[formula]

where (i,j) refers to a pair of the list π(2k). π(2k) thus defines a graph on the set [formula].

We set XEi,Ej(xi,xj) = 〈xi,Ei|V|xj,Ej〉 which allows us to write the product of random variables m({x'j,E'j})Ln({xi,Ei}) as

[formula]

We now apply theorem [\ref=thm:wicks] to [formula].

[formula]

with

[formula]

and

[formula]

π(n,m) is then a list of pairs of the set s̄, or a graph, and (l,p) is a pair of the list. We say the order of a graph on s̄ is the length of the set s̄. The order of π(n,m) is then n + m. We call Cπ(n,m)({Ei,E'j},{xi,x'j}) the graph function. Notice that by Eqs. ([\ref=eq:OnePair]) and ([\ref=eq:OnePairp]) the graph function can be split into a graph function depending on {Ei,E'j} times a graph function depending on {xi,x'j}.

[formula]

where C1π(n,m)({Ei,E'j}) is a product of the δ functions in Ei and E'j divided by [formula] and C2π(n,m)({xi,x'j}) is a product of the δ functions in xi and x'j. We make the following definitions to classify the possible graphs:

Say we have a graph, π(n,m), on s̄ where

[formula]

The average of a pair XiXj is called a inner contraction if i,j  ≤  m or when i,j > m. It will be called an outer contraction if i  ≤  m and j > m or when i > m and j  ≤  m.

The average of a pair XiXj is called a next neighboring contraction (nn-contraction) if j = i + 1.

If we have a contraction, between Xi and Xj, and a contraction between Xk and Xl and i < k < j < l then we call this a crossing.

If we have a contraction, between Xi and Xj, and a contraction between Xk and Xl and, i < k < l < j  ≤  m or m < i < k < l < j then we call this a nest.

From definition [\ref=def:contractions] we see that in Eq. ([\ref=eq:GraphFunction]) we have an inner contraction whenever both random variables are dependent on primed variables or when both depend on non primed variables. With these definitions we make three classes of graphs as in [\cite=EY00].

Say we have a graph π(n,m) on s̄.

We say the graph is a crossing graph (c-graph) if it possesses at least one crossing and we call a graph a non-crossing graph (nc-graph) if it possesses no crossings. The set of all c-graphs of order (n,m) is denoted by G2(n,m) and the set of all c- graphs is denoted by G2. An example of a crossing graph is the previous Fig. [\ref=figure2].

We say the graph is a nested graph (n-graph) if it is a nc-graph and possesses at least one nest and call a graph a non-nested graph (nn-graph) if it possesses none. The set of all n-graphs of order (n,m) is denoted by G1(n,m) and the set of all n-graphs is denoted by G1. An example of a nested graph is shown in [\ref=figure3]

We say the graph is a simple graph (s-graph) if it is a nc and nn-graph. The set of all s-graphs of order (n,m) is denoted by G0(n,m) and the set of all s-graphs is denoted by G0. An example of a simple graph is shown in Fig. ([\ref=figure4]).

Notice that simple graphs are build from next neighboring contractions and outer contractions since no crossing nor nests are allowed. The total number of graphs of order n + m is [formula] while the number of non crossing graphs is equal to the [formula] catalan number. This one is bounded by Cn + m, where C is a constant. From the definitions of simple, nested and crossing graphs we note that these classes are mutually exclusive and cover the set of all possible graphs. We have then the following identity:

[formula]

Thus from Eq. ([\ref=eq:two])

[formula]

From Eq. ([\ref=eq:GraphFunction]), ([\ref=eq:OnePair]) and ([\ref=eq:OnePairp]) we see that a graph function of order n + m is a product of Kronecker delta functions divided by [formula]. Thus not all the energy variables and position variables are independent. When summing up over these variables the more of these that are independent the larger the sum will become. This motivates the following definitions:

For a graph function [formula] we define: [formula] [formula] κπ(n,m)  =  {Number of independent variables we have of the set {Ei,E'j} given by the graph function Cπ(n,m)}

With these definitions we have then

[formula]

From the definitions [\ref=def:ABK] and Eq. ([\ref=eq:2Cs]) we have

[formula]

With these definitions we can estimate certain sums of graphs functions. We first prove the following property of the graph function:

For any graph function Cπ(n,m)({Ei,E'i},{xi,x'i}) we have

[formula]

First we relabel the n + m + 1 energy variables {Ei,E'j} to {Ei} and the position variables {xi,x'j} to {xi}. Thus in the set {Ei} and {xi} the index i runs from 0 to n + m. Then Eqs. ([\ref=eq:OnePair]) become

[formula]

where i and j can take on the values [formula]. Thus the from the graph function we have that for each i there is a unique j such that

[formula]

Note that j,i  ≠  n + m. Since for each i there is a unique j when summing over i form 0 to n + m - 1 and summing also the corresponding and unique j we obtain

[formula]

and so

[formula]

Following the same reasoning for the xi variables we have

[formula]

This implies then that for the set {Ei,E'j} we have En = E'm and for the set {xi,x'j} we have xn = x'm.

From this we have

[formula]

We now turn to proving the following essential theorem.

If π(n,m) is a non crossing graph then [formula]. If π(n,m) is a crossing graph then [formula].

From Eq. (2.12) we have that

[formula]

Therefore after averaging we get

[formula]

From Eq. ([\ref=eq:proptodelta]) we have

[formula]

Thus

[formula]

By the definitions of dependent and independent variables we have

[formula]

where we have applied Eq. ([\ref=eq:sumdependentvar]) in going from the first to the second line. Thus

[formula]

We know by [\cite=TH2] that the leading contribution in N of the average of the trace of a product of random matrices comes from non crossing graphs (planar diagrams), G0 and G1. That is:

[formula]

Comparing ([\ref=eq:OldResult]) and ([\ref=eq:NewResult]) we see we must have [formula] for non crossing graphs. In order for the contribution of crossing graphs to be of the order of N- 1 or less we must have for crossing graphs [formula].

ANALYSIS OF PROPAGATORS

In this section we mainly will write the average of the time evolution of our observable, [formula], in a more convenient form for the analysis. Starting from Eq. ([\ref=eq:explicitP]) and inserting the expression for [formula] of Eq. ([\ref=eq:twoprime]) we obtain

[formula]

By theorem [\ref=thm:endsmeet] we have in Eq ([\ref=eq:begin]) that the graph function will impose that E'm = En and x'm = xn. Thus we can implement this relationship in the product ψ*0(x'm,E'm)ψ0(xn,En)

[formula]

We can split the contributions to [formula] in Eq. ([\ref=eq:begin]) according to the three different type of graphs. This is the index a in Eq. ([\ref=eq:begin]).

[formula]

with

[formula]

and a can take up the values 0, 1 or 2. We introduce a different representation of Px0,M,Na,t that will turn out useful later on. We call this the α-representation. Starting from Eq. ([\ref=firstK]) we use the following identities

[formula]

with η > 0 and obtain

[formula]

The same can be done for qm(t,{E'j}) and so we can rewrite Kn(t,{Ej}) and qm(t,{E'j}) as

[formula]

The product of qm and Kn, for example in Eq. ([\ref=eq:Paxt]), has then n + m + 2 propagators. Remember that E0' = E0. We set η = t- 1 so that the exponential term eηt is bounded by a constant. Inserting Eqs. ([\ref=eq:Kbar]) and ([\ref=eq:K]) in Eq. ([\ref=eq:Paxt]) we obtain the following expression for Px0,M,Na,t:

[formula]

From the definitions of dependent and independent variables of section [\ref=sect:AveragingAndGraphs] we have

[formula]

The sum over {xi,x'j}0 is a sum over all elements excluding x0. Because of the form of the interaction, Eq. ([\ref=eq:interactionM]), we have that if xj = 1(2) then xj + 1 = 2(1). That is

[formula]

Thus we have [formula] and [formula]. The same holds for x'i, [formula] and x'i, [formula]. Therefore if n is even then xn = x0 and if n is odd then xn  ≠  x0. We thus define

[formula]

where x̄0 = 1 if x0 = 2 and vice versa. We have then with the definition in Eq. ([\ref=eq:Px0]) we get

[formula]

As discussed in section [\ref=sect:AveragingAndGraphs] the graph function, Cπ(n,m)({Ei,E'j},{xi,x'j}), is a product of Kronecker delta functions divided by [formula]. Thus only a part of the variables {Ei,E'j} are independent. This means that when having a sum of the type

[formula]

which we have in Eq. ([\ref=eq:Pat2]), each independent variable El of the set {Ei,E'j} will appear a certain amount of times in f and g, which we denote by kl and pl. That is if we relabel the independent energy variables by ωj, Eq. ([\ref=eq:exampleC]) has the following form:

[formula]

where kj and pj depends on the graph and κπ(n,m) is equal to the number of independent variables. We labelled the independent variable related to En (the one referring to the initial data ) by ωκπ. In Eq. ([\ref=eq:Pat2]) the functions f and g are the propagators [formula] and [formula]. We call kj and pj the left and right multiplicity of the independent variable ωj, and kj + pj the multiplicity of ωj. We obtain then from Eq. ([\ref=eq:Pat2])

[formula]

This is then called the α-representation. The information about pj and kj lies in the graph π(n,m) but since the amount of propagators from a term of order n + m of the expansion is n + m + 2, as can be seen in Eq. ([\ref=eq:Pat2]), we must have

[formula]

We define QNπ(n,m)(t,λ,x0) such that

[formula]

QNπ(n,m) is the contribution of the graph π(n,m) to the probability to be at x0. Notice that if we sum over x0 and over a in Eq. ([\ref=eq:Pat2]) we obtain the squared norm of [formula]. Thus [formula] is the contribution of the graph π(n,m) to the norm of the wave vector.

CROSSING GRAPHS

We now prove the following lemma for crossing graphs

The contribution of crossing graphs to the time evolution of the observable P̂x0 tends to zero in the limit N  →    ∞  . That is

[formula]

By inspecting Eq. ([\ref=eq:PNaxt]) we see that we have a factor of [formula] and a sum over κπ energy variables, where one sum is weighted by P0(x0,ωκ). If [formula] then each sum is weighted by a N- 1 factor except one that is weighted by P0(x0,ωκ), the initial probability distribution. All the sums would be finite. But if [formula] then a factor of N- 1 could be extracted and so this term would vanish. This is the case for crossing graphs. From Eq. ([\ref=eq:Paxt]) we have

[formula]

From Eq. ([\ref=firstK]) we have that

[formula]

Thus

[formula]

NESTED GRAPHS

Nested graphs are non crossing graphs. If there are no crossing it means that when there is a contraction between two elements, for example XEg,Eg + 1(xg,xg + 1) and XEh,Eh + 1(xh,xh + 1), then the elements in between these two, in the total product mLn, can only contract among themselves and thus the energy variables in between Eg + 1 and Eh are independent of all the others. This mean that in the sum

[formula]

there are independent variables, ωj, for which kj or pj is 0. The simplest example is that of an nn contraction. If XEg,Eg + 1(xg,xg + 1) contracts with XEg + 1,Eg + 2(xg + 1,xg + 2) this imposes according to Eq. ([\ref=eq:OnePairp]) the relationship

[formula]

The second equation is of course superflues but since there are no more random elements in the product that depend on Eg + 1 there are no more contraction which could relate Eg + 1 to another energy variable. Thus Eg + 1 is independent of the rest. Then in the product of Eq. ([\ref=eq:exam]) if ωl = Eg + 1 we would have pl = 0 and kl = 1 and thus a term f(ωl). The particularity of nested graphs is that there is at least one independent variable ωj such that pj = 0 and kj > 1 or kj = 0 and pj > 1. This is easy to see as follows. Say we have a nested graph, that is suppose we have no crossings and that XEg,Eg + 1(xg,xg + 1) and XEh,Eh + 1(xh,xh + 1) contract with g + 1 < h. We have then Eg + 1 = Eh. Since no elements XEj,Ej + 1(xj,xj + 1) with g < j < h can contract with a primed random variable Eh cannot be equal to a primed E'j variable. Thus for the independent variable ωl = Eg + 1 we will have pl = 0 and have kl  ≥  2. Simple graphs do not have such independent variables. According to theorem [\ref=thm:kappa] we have for non crossing graphs in Eq. ([\ref=eq:PNaxt]) [formula]. Thus for non crossing graphs we have

[formula]

From Eq. ([\ref=eq:PNaxt2]) we have in the limit N  →    ∞

[formula]

We will now prove the following theorem:

In the Van Hove limit (λ2t = T <   ∞  ) the contribution from nested graphs (G1) to the average of the time evolution of the observable, [formula], vanishes. That is

[formula]

We define the following:

[formula]

This is just the limit of QNπ(n,m)(t,λ,x0) as N  →    ∞   of Eq. ([\ref=eq:qN]). Notice that this is the form of QNπ(n,m) for all non crossing graphs. For a = 0,1 we have then from Eq. ([\ref=eq:contPaxt])

[formula]

Since we are considering a nested graph there exists an ωl such that either kl = 0 and pl > 1 or vice versa. We can thus perform the integration over this variable. From Eq. ([\ref=eq:Qfunction]) we have

[formula]

We can perform the integration over ωl first. After taking the absolute value we use inequality ([\ref=ine:two]) to bound almost all integrations over ωj. We can only apply inequality ([\ref=ine:two]) to those integrations where kj + pj  ≥  2 and we do so except for two variables which we denote ω1 and ω2. For these variables we bound the set of propagators by

[formula]

When kj = 0 and pj = 1 we can bound the integral by a [formula] term. We denote by n' the number of cases in which kj = 0 and pj = 1 or kj = 1 and pj = 0. This corresponds then to the number of propagators with multiplicity equal to 1. We denote by n̄ + 1 the number of propagators of multiplicity higher then 1. Thus we have n̄ + n' + 1 = κπ(n,m). For non crossing graphs we have then [formula]. Therefore we have [formula]. We have then :

[formula]

The sum over j in the exponent of η should be over those j for which kj + pj  ≥  2 but since we are summing kj + pj - 1 we can extend to all j since if kj + pj = 1 then we are summing zero. By using inequality ([\ref=eq:4kintegrals]) and remembering that η = t- 1 we get

[formula]

Since for non crossing graphs [formula], we have from Eq. ([\ref=eq:propagatorcount])

[formula]

Inserting the last equation in Eq. ([\ref=eq:QN]) and maximizing n' by [formula] gives

[formula]

with λ2t = T. This vanishes in the Van Hove limit.

[formula]

Thus from Eqs. ([\ref=eq:PxatOfQ]) and ([\ref=eq:qtozero]), and from the fact the number of nested graphs of length n + m is less then cn + m, with c a constant , we have for the contribution of the nested graphs the following bound

[formula]

Thus the contribution of a nested graph vanishes.

SIMPLE GRAPHS

As mentioned, simple graphs are graphs which are build from nn contractions and outer contractions. This means that in Eq. ([\ref=eq:Qfunction]) we can either have kj = 1 and pj = 0 (nn contractions) or we can have kj  ≥  1 and pj  ≥  1. We can see this as follows. Say we have two outer contractions between XEq,Eq + 1 and XE'p + 1,E'p and between XEg,Eg + 1 and XE'h + 1,E'h. and suppose there are no outer contractions in between these two outer contractions. That is there is no outer contraction between XEa,Ea + 1 and XE'b + 1,E'b with g + 1 < a < q and h + 1 < b < p. we take the outer contraction between XEq,Eq + 1 and XE'p + 1,E'p to be the [formula] outer contraction and the contraction between XEg,Eg + 1 and XE'h + 1,E'h to be the [formula]. We are thus counting from the inside to the outside. If the graph is a simple graph then all elements XEa,Ea + 1 with g + 1 < a < q contract amongst each other and form only nn contractions. The same is valid for all elements XE'b + 1,E'b with h + 1 < b < p. By Eq. ([\ref=]) we have then

[formula]

All of the other variables, [formula], are independent and of multiplicity 1. If we set ωj = Eq as the independent variable with respectively kj and pj as left and right multiplicities then there are kj - 1 variables in between the two outer contractions of multiplicity 1 on the left and pj - 1 on the right. Thus in Eq. ([\ref=eq:exam]) there will be in the product a term

[formula]

In view of this we will change our notation. We denote by n̄ the number of outer contractions for a graph and so there are n̄ + 1 independent variables of multiplicity higher then 1. We set n' to be the number of variables of multiplicity equal to 1. Instead of kj denoting the multiplicity of any independent variable we will denote by kj + 1 the multiplicity of independent variables with multiplicity higher then 1. Eq. ([\ref=eq:form]) then becomes

[formula]

Notice that the set of numbers n̄,{kj,pj} determine uniquely the simple graph and so for each set there is unique graph. We will introduce this notation in Eq. ([\ref=eq:Qfunction]). In between each two outer contractions we will have a product of the form of Eq. ([\ref=eq:form2]) and so we have from Eq. ([\ref=eq:Qfunction])

[formula]

with

[formula]

kj and pj here are not those from section [\ref=sec:nested]. Since a graph of order n + m has n + m + 2 propagators and that there are [formula] independent variables we have in this new notation

[formula]

and

[formula]

We now will prove that in Eqs. ([\ref=eq:simpleQ]) and ([\ref=eq:PatM]) the function Θ(α,η) can be replaced by Θ(ωn̄), with Θ(ωn̄) =  lim η  →    ∞Θ(ωn̄,η), such that the error goes to zero in the van Hove limit. We define then

[formula]

Thus we will analyze the difference [formula]. For briefness we denote ΔQπ(n,m)(t,λ,x) by ΔQπ in this section.

[formula]

and show that it tends to zero in the van Hove limit such that [formula] tends to zero in the limit. We will prove the following theorem:

In the Van Hove limit we have

[formula]

To prove this theorem we will first bound ΔQπ. First we bound the term in the second line of Eq. ([\ref=DeltaQ]). We split this term as follows:

[formula]

We bound the two parts as follows:

[formula]

Thus

[formula]

where we have by Eq. ([\ref=eq:kpnm]) [formula]. Inserting this in Eq. ([\ref=DeltaQ]) we obtain

[formula]

We will bound the part including [formula] as the part with [formula] can be done analoguesly. We have then by using inequality ([\ref=eq:thetabound])

[formula]

We first bound the term including [formula] by using inequality ([\ref=ine:two]) for the integrations over all ωj except ωn̄ and ω0.

[formula]

By bounding succesivly the integrations over ωn̄, β, ω0 and α by [formula] we obtain

[formula]

Setting η = t- 1 and using Eq. ([\ref=eq:kpnm]) we obtain in the van Hove limit (λ2t = T <   ∞  )

[formula]

We analyze the term including [formula], which is the second type of term, by applying the same strategy as for P1

[formula]

Once again we bound the integrations over α, ω0 and β by [formula] .Since P0(x,ωn̄) is taken to be zero around the edges 0 and 1 in some ε interval we have

[formula]

The remaining terms can be analyzed in a similar manner. Therefore we have

[formula]

From Eqs. ([\ref=eq:PatM]), ([\ref=eq:PMattilde2]) and ([\ref=eq:DeltaQ]) we have then

[formula]

EFFECTIVE EQUATION

We will now derive the effective equations by calculating the Van Hove limit of P̃x,M0,t. We recapitulate here our previous results. In section [\ref=sec:crossing] and [\ref=sec:nested] we showed that

[formula]

and in section [\ref=sec:simple] we showed that in the Van Hove limit

[formula]

with π(n,m)(t,λ,x) defined through Eq. ([\ref=eq:PMattilde2]). Thus we have

[formula]

Since a simple graph is completely characterized by the numbers n̄, kj and pj the sum over all simple graphs π(n,m) is a sum over n̄, kj and pj such that

[formula]

The sum [formula] in Eq. ([\ref=eq:QsimpleP]) is then a sum over n̄, kj and pj such that the inequalities are satisfied. We denote this as follows

[formula]

where the superscript c refers to the fact that the conditions of Eqs. ([\ref=cond1]), ([\ref=cond2]) and ([\ref=cond3]) have to be satisfied. In the limit M  →    ∞   these conditions are always satisfied and so we get

[formula]

were (t,λ,x,n̄,{kj,pj}) is given by Eq. ([\ref=eq:PMattilde2]) when expressing n and m as a function of n̄, kj and pj.

[formula]

If the the rest, Eq.([\ref=eq:Rest]), vanishes in these limits then we have derived our solution in the limits considered.

[formula]

By the identity

[formula]

we get

[formula]

We can sum up over each kj and pj by grouping the λ2, sj and Θ. We obtain

[formula]

Integrating over α and β we get

[formula]

By the following change of variables

[formula]

we get

[formula]

and by the following change of variable and identity

[formula]

we obtain

[formula]

Where

[formula]

We have then in the limit t  →    ∞

[formula]

Inserting Eq. ([\ref=eq:deltaomega]) in Eq. ([\ref=eq:almost]) we get

[formula]

We note the following about P0(x,ωn̄). From Eq. ([\ref=cond2]) we see that if n is even then n̄ is even and if n is odd so must be n̄. According to Eq. ([\ref=eq:Px0]) P0(x,ωn̄) = Px0(ωn̄) if n is even and so also if n̄ is even. P0(x,ωn̄) = Px̄0(ωn̄) if n is odd or if equivalently if n̄ is odd. Depending on whether n̄ is odd or even we have

[formula]

And so

[formula]

These solutions satisfy the following rate equations

[formula]

ANALYSIS OF THE ERROR

In this section we analyze the error term, Eq. ([\ref=eq:Rest]). By the form of Eq. ([\ref=eq:Rest]) we see that if the norm of |φM + 1t〉 vanishes in the limits considered

[formula]

then the error term will also vanish and this is what we will show. Up to now we have expanded our solution up to the Mth term and derived the equation it would follow when taking M  →    ∞  . Thus we shall prove that when taking M  →    ∞   for the error term this one vanishes. In order to do this we will expand the error term until the M(t)th order, where M(t) now depends on t which is scaled with the coupling constant.

[formula]

To prove Eq. ([\ref=eq:errorlimit]) we shall prove that the norm of the two terms in Eq. ([\ref=eq:twophi]) vanish.

[formula]

We focus now on proving Eq. ([\ref=eq:MMt]). Since |φ̃M,M(t)t〉 is a sum of |ψnt〉 vectors we can write it down as a function of Qπ(n,m) function. We already have some usefull bounds on the different type of graphs. We will use the bounds of Eq. ([\ref=eq:Qnestedbound]) on nested graphs and also Eq. ([\ref=eq:DeltaQ]) for a part of the simple graphs. We will thus look to bound the remaining part of simple graphs. Thus we turn to bound π(n,m) from Eq. ([\ref=eq:PMattilde2]).

For simple graphs we have the following bound for π(n,m)(t,λ,x) defined in Eq. ([\ref=eq:PMattilde2]):

[formula]

with [formula].

From Eq. ([\ref=eq:PMattilde2]) we have

[formula]

With the following relations fulfilled:

[formula]

Therefore we have [formula]. The Θ functions are bounded by a constant and so have no importance. Since we have

[formula]

we can easily see that the following bound holds

[formula]

We use this to bound the second line of Eq. ([\ref=eq:Qerror]). We bound the remaining in Eq. ([\ref=eq:Qerror]) by bounding the integrals over ωj as follows.

[formula]

We bound [formula] by [formula] and for j  ≥  2 we use Eq. ([\ref=eq:oneminusa]) to bound the integration over ωj of the remaining propagators. That is in applying Eq. ([\ref=eq:oneminusa])in this case we have using [formula] in Eq. ([\ref=eq:oneminusa]).

[formula]

For ω0 and ω1 we use first Eq. ([\ref=eq:ABdelta]) and then Eq. ([\ref=eq:oneminusa])

[formula]

Combining this estimate with Eq. ([\ref=eq:powera]) in Eq. ([\ref=eq:Qerror]) we get

[formula]

We will now bound [formula] with

[formula]

We have

[formula]

Similar to the proof in ([\ref=lem:CrossContribution]) we have that the contributions from crossing graphs will vanish. Thus we obtain

[formula]

Using the bounds of Eqs. ([\ref=eq:Qnestedbound]), ([\ref=eq:DeltaQ]) and ([\ref=eq:Qboundeda]) we get

[formula]

We choose [formula] with γ < 1 and take [formula]. We also set log t = x. We have then

[formula]

For large enough M we have then

[formula]

and so

[formula]

What we have left to bound is the average of |φM(t)t〉. We shall drop the t dependency of M for now. According to Eq. ([\ref=eq:gammatilde]) we have

[formula]

We will follow [\cite=EY00] in bounding this term. That is we will divide the time integration in κ parts, where κ will eventually depend on t, and expand each piece of the time integrations once again using the Duhamel formula, Eq. ([\ref=eq:duhamel]). We will thus extract again a term which is a succession of free evolutions and one which will depend on the whole evolution. We have then

[formula]

Where

[formula]

We have the following expansion for each e- i(θj - s)H from Eq. ([\ref=eq:gammaprop]):

[formula]

and so

[formula]

|ψ2M,M0,κ(t)〉 has M + M0 + 2 products of random matrices. We define

[formula]

|ψM,n,κ,θj(s̃)〉 has M + n + 1 random matrices and n + M + 2 propagators. With the definition of Eq. ([\ref=psiaux]) we can rewrite Eqs. ([\ref=eq:psi1]) and ([\ref=eq:psi2]) as

[formula]

We first bound |ψ2M,M0,κ(t)〉 through the following theorem:

We have the following bound for the norm of |ψ2M,M0,κ(t)〉 in the limit N  →    ∞  :

[formula]

From Eq. ([\ref=psi2]) we have

[formula]

We can once again rewrite the average, [formula], as a sum over graph evaluated functions starting from Eq. ([\ref=psiaux]). In addition to the 2(M + M0 + 1) random matrices that come from the expansion we have 2 random matrices. When inserting Eq. ([\ref=psiaux]) in Eq. ([\ref=vsquared]) the resulting expression has 2(M0 + M + 2) random matrices but 2(M0 + M + 2) propagators. In our previous sections and definitions of Qπ(n,m) we had, for the expansion of the order n + m, n + m random matrices and n + m + 2 propagators. Since now we have 2 extra random matrices the number of random matrices equals the number of propagators. Analoguesly to how it was done in section [\ref=sec:nested] and [\ref=sec:simple] we can introduce a Qπ(M0 + M + 2,M0 + M + 2)(θj,s̃,λ) function that encodes the contribution of the graph π(M0 + M + 2,M0 + M + 2) to the average. The fact that we have 2 extra random matrices will modify a bit the relationships we had. We can use the α-representation two times in Eq. ([\ref=psiaux]), one for the explicit δ function and one for the delta function in |ψMs〉. For the explicit one we have

[formula]

We have then

[formula]

and a similar expression for 〈ψM,M0,κ,θj(s̃)|Ẽ'0,'0〉, where β will stand for α and [formula] for α̃. Thus

[formula]

Where the sum is over all Ej,Ẽj,E'j and Ẽ'j variables. In the limit N  →    ∞   crossing graphs will once again not contribute because each one of them has a weight less then or equal to N- 2. We have then

[formula]

For shortness of notation we refer to Qπ(M + M0 + 1,M + M0 + 1)(θj,s̃,λ) as Qπ. Propagators depending on α come from the right |ψMs〉 and those depending on α̃ come from the right Γ̃M0 + 1. Propagators depending on β come from the left |ψMs〉 and those depending on [formula] come from the left Γ̃M0 + 1. There are thus M + 1 propagators depending on α, M0 + 1 depending on α̃, M + 1 depending on β and M0 + 1 depending on [formula]. When averaging in Eq. ([\ref=eq:long]) and taking only non crossing graphs we will once again have that the number of independent variables is half of the length of the graph plus 1 (theorem [\ref=thm:kappa]). That is M0 + M + 3. The number of independent energy variables will then be equal to M0 + M + 3. Nevertheless we notice that not all independent energy variables must have a set of propagators associated. Previously we had in between each random matrix a propagator which meant that each energy variables (dependent or independent) was associated with a propagator. We see from Eq. ([\ref=eq:long]) that there is no propagator in between the V2 and so if the graphs is such that the variables in between this product is independent it will have no propagator associated. Therefore the sum or integration over this variable will be 1 and so we could omit it. Therefore, depending on the graph, the number of independent energy variables can be either M0 + M + 3 or M0 + M + 2. We have then as in section [\ref=sec:simple] and [\ref=sec:nested]

[formula]

where the graph π(M + M0 + 2,M + M0 + 2) determines the multiplicities aj, bj, cj and dj. The propagators of multiplicity one are dependent on ω'j and there are n' of them. γj can take on the values α, α̃, β or [formula]. This dependents on where the propagator is located and thus depends on the graph. ηj can take on the values η, [formula], -  η or -   depending on which value γj take on. The following relations have to be satisfied:

[formula]

Eq.([\ref=consprop]) expresses that fact that there are 2(M0 + M + 2) propagators. Eq.([\ref=consacprop]) expresses that fact that there are 2M0 + 2 propagators depending on α̃ and [formula]. Since n' counts all propagators with multiplicity equal to 1 there is an inequality sign. Eq.([\ref=consnn]) expresses that fact that the number of independent variables varies between two possibilities as explained earlier. We set the following:

[formula]

This choice guarantees that the exponentials in Eq. ([\ref=eq:Qabcd]) do not diverge since θj < s < s̃. Also   -  η  ≥  t- 1. We fisrt integrate over s and τ.

[formula]

We bound Qπ by taking the absolute value inside the rest of the integrals. Integrations over propagators of multiplicity one are bounded by [formula]. Using inequality ([\ref=ine:two]) on the integrations over ωj with j  ≠  0, and using inequality ([\ref=eq:ABlog]) on the integration over the remaining variables we obtain:

[formula]

By Eqs. ([\ref=consnn]), ([\ref=eta1]) and ([\ref=eta2]) we have the following bound:

[formula]

From Eqs. ([\ref=consnn]) and ([\ref=consacprop]) we have

[formula]

Thus

[formula]

By inserting Eq. ([\ref=kapaQbound]) in Eq. ([\ref=eq:AVncQ]) and inserting this in Eq. ([\ref=vsquared]) we obtain

[formula]

We set now back the t dependency of M and κ and take M0 as follows

[formula]

We have then

[formula]

with a suitable choice of α and γ the coefficient of the exponential is negative and this quantity vanishes in the limit x  →    ∞  . We will now seek to prove the following theorem for the bound of the norm of |ψ1M,M0,κ(t)〉:

[formula]

Mainly the bounds derived here are analogues to the ones derived and used in the previous sections for nested and simple graphs. We will first bound the contribution of a nested graph, similar to how it was done in section [\ref=sec:nested] . Then we will bound a part of a simple graph (ΔQπ), similar to how it was done in section [\ref=sec:simple]. And finally we will bound what remains of the simple graph (π). The only difference is that the expression for Qπ is a bit more complicated. Using the Cauchy-Schwartz inequality on 〈ψ1M,M0,κ(t)|ψ1M,M0,κ(t)〉 when replacing |ψ1M,M0,κ(t)〉 by the expression in Eq. ([\ref=psi1]) we obtain

[formula]

In the large N limit we have

[formula]

The crossing graphs do not contribute once again because their individual contribution is of the order of N- 2. For briefness of notation we refer now to Qπ(M + n + 1,M + n + 1)(θj,θj + 1,λ,κ) with Qπ and have the following expression for it:

[formula]

Eq. ([\ref=eq:Qtsl]) is derived analoguesly to how Eq. ([\ref=eq:Qabcd]) is derived from Eq. ([\ref=psiaux]). The following relations are satisfied for non crossing graphs:

[formula]

These relations express the fact that there are [formula] propagators in emerging from the [formula] expansion and that there are M + n + 2 independent energy variables whenever one has a non-crossing graph. Once again the graphs π(M + n + 1,M + n + 1) can be either nested or simple graphs and depending on this Qπ will render different contributions. We will show that nested graphs have an extra t- 1 factor.

NESTED

For nested graphs we will now prove the following theorem:

If π(M + n + 1,M + n + 1) is a nested graph then we have the following bound for Qπ in Eq. ([\ref=eq:Qtsl]):

[formula]

Starting from Eq. ([\ref=eq:Qtsl]) we can perform the s and τ integrations.

[formula]

A nest can present itself in two ways. First we can have, for a specific j, one of the indices aj, bj, cj or dj different from 0 with all of the others equal to 0. Secondly we can have, for a specific j, both cj,dj  ≠  0 and aj,bj  =  0 or cj,dj  =  0 and aj,bj  ≠  0. The first case can be analyzed similarly to how the original bound for nested graphs was done in section [\ref=sec:nested]. We analyze the second case. If the nest is such that cl and dl are different then zero and al = bl = 0 then the nested part of the Qπ function can be bound as follows:

[formula]

By introducing [formula] and integrating over s1 and s2 we obtain

[formula]

For the other integrations over the ωj's, with j  ≥  2, in Eq. ([\ref=eq:Qtsl]) we use the usual bounds

[formula]

Inserting these bounds in Eq. ([\ref=eq:Qtsl]) we obtain

[formula]

Because of Eq. ([\ref=eq:thetaj]) and ([\ref=eq:thetajdif]) we have η  <    <    -  η and so if we replace in Eq. ([\ref=eq:Qtsl2]) η  -   by η and [formula] by η the inequality will still hold. To bound the integration we successively use inequality ([\ref=eq:ABlog]) on the integrations over ω0, ω1, α and α̃ to obtain

[formula]

When μ greater then a constant C this is bounded by [formula] and so we can consider only the region where μ is bounded. For cj or dj greater then 2 we have:

[formula]

For cj = dj = 1 we have

[formula]

Inserting this in Eq. ([\ref=eq:Qtsl2]) we obtain

[formula]

where we have used Eqs. ([\ref=ID1]) and ([\ref=ID2]) to find the exponent of t. In case that the nest is such that for a specific l only one out of al, bl, cl and dl is different then 0 we can perform directly the integration over ωl and follow the procedure of section [\ref=sec:nested].

We now turn to simple graphs.

SIMPLE

If π(M + n + 1,M + n + 1) is a simple graph then in Eq. ([\ref=eq:Qtsl]) for each j we have an aj or bj different from 0 and cj or dj different from 0. Similar to how was done in section [\ref=sec:simple] we can prove that the contribution of a simple graph can be decomposed in two parts contributing in two different ways. We define now π as Qπ from Eq. ([\ref=eq:Qtsl]) but with the propagators [formula] replaced by Θ(ωn̄). The difference between π and Qπ, ΔQπ, is then the following:

[formula]

with n1 + n2 + n3 + n4 = n'. We will now prove the following:

[formula]

As done previously we can rewrite the difference of Θ functions as follows:

[formula]

We define A, B, C and D to be the first second third and fourth part of the sum in Eq. ([\ref=eq:thetas]). We also denote by ΔQAπ, ΔQBπ, ΔQCπ and ΔQDπ the contribution to ΔQπ(θ,s̃,λ) from A, B, C and D in Eq. ([\ref=eq:deltaQ]). Each difference can the again be expanded as follows:

[formula]

Since every Θ(α,η) is bounded by [formula] we have for the first factor for example

[formula]

If we now integrate in Eq. ([\ref=eq:deltaQ]) over s and τ and use Eq. ([\ref=eq:telescopic]) and ([\ref=eq:thetabound]) we get

[formula]

We bound the integrations over ωj, with j  ≠  0,n̄, by using Eq. ([\ref=usualb]).

[formula]

Applying now the bound of Eq. ([\ref=eq:ABlog]) multiple times and remembering that the integration over ωn̄ was cut of and goes from 1 - ε and ε because of our choice of the initial condition we have

[formula]

We have used the identities of Eqs. ([\ref=ID1]) and ([\ref=ID2]) to compute the exponent of t. We can bound similarly the contributions from B, C and D. Thus giving

[formula]

We now bound π.

[formula]

with 0  ≤  a < 1.

We have

[formula]

The proof is similar to that of theorem [\ref=thm:Qtildenm]. Starting from Eq. ([\ref=begin]) we get

[formula]

For the second part , that is the one that is to the power of a, we use the t-representation

[formula]

To bound the first part, that which is to the power of 1 - a, we first integrate over s and τ and take the absolute value.

[formula]

where we have omitted the Θ function since they are bounded by constants. Similar to Eq. ([\ref=ine:two]) we have

[formula]

where we have used Eq. ([\ref=eq:oneminusa]) to bound the last integration. Using this in Eq. ([\ref=first(1-a)]) for the integrations over ωj with j  ≠  0 and j  ≠  n̄ we obtain:

[formula]

By using inequality of Eq. ([\ref=eq:ABdelta]) on the integrations over α, β, α̃ and [formula] and the applying inequality of Eq. ([\ref=eq:oneminusa]) on the integration over ω0 we obtain

[formula]

Combining the estimates of Eqs. ([\ref=est1]) and ([\ref=est2]) in Eq. ([\ref=final]) we obtain

[formula]

We can now prove theorem [\ref=thm:psi1] .

By Eq. ([\ref=eq:Avsquared2]) and lemmas [\ref=lemmanestedgraphs] and [\ref=lemmasimplegraphs] we have

[formula]

Inserting this in Eq. ([\ref=eq:Avsquared]) we obtain

[formula]

Through Eqs. ([\ref=uno])-([\ref=quatro]) we have

[formula]

Integrals

In this section we will prove and state some useful bounds. The following integral inequalities will be used:

[formula]

[formula]

[formula]

With δ > 1. We set [formula] and z = x0 - iη.

[formula]

In the same manner we can bound

[formula]

where δ < 1. We can apply this to the following integrals

[formula]

We now analyze

[formula]