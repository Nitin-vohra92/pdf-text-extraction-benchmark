Proposition Lemma Corollary Claim Definition Example

Quadratization of Symmetric Pseudo-Boolean Functions

Endre Boros

Yves Crama

Aritanan Gruber

Quadratizations of pseudo-Boolean functions

A pseudo-Boolean function is a real-valued function [formula] of n binary variables, a mapping from {0,1}n to [formula]. It is well-known that every pseudo-Boolean function can be uniquely represented as a multilinear polynomial in its variables. Nonlinear binary optimization problems, or pseudo-Boolean optimization (PBO) problems, of the form where f(x) is a pseudo-Boolean function, have attracted the attention of numerous researchers, and they are notoriously difficult, as they naturally encompass a broad variety of models such as maximum satisfiability, maximum cut, graph coloring, simple plant location, and so on; see, e.g., [\cite=CH2011]. In recent years, several authors have revisited an approach initially proposed by Rosenberg [\cite=Rosenberg75]. This involves reducing PBO to its quadratic case (QPBO) by relying on the following concept.

For a pseudo-Boolean function f(x) on {0,1}n, we say that g(x,y) is a quadratization of f if g(x,y) is a quadratic polynomial depending on x and on m auxiliary binary variables [formula] such that

Clearly, if g(x,y) is a quadratization of f, then

[formula]

so that the minimization of f is reduced through this transformation to the QPBO problem of minimizing g(x,y). We are also interested (see [\cite=ABCG]) in special types of quadratizations, which we call y-linear quadratizations, which contain no products of auxiliary variables. If g(x,y) is a y-linear quadratization, then g can be written as

[formula]

where q(x) is quadratic in x and each ai(x) is a linear function of x. When minimizing g over y, each product ai(x)yi takes the value min {0,ai(x)}. Thus, y-linear quadratizations can be viewed as piecewise linear functions of the x-variables.

As an easy explicit example, consider the negative monomial

[formula]

This elementary pseudo-Boolean function has the following standard quadratization (Freedman and Drineas [\cite=FreedDrineas2005]):

[formula]

The reason is as follows: unless all the xi are 1, then the quantity in parentheses in the expression for sn is non-negative and the minimum value of sn is therefore 0, obtained when y = 0; and, if all xi are 1, the expression equals - y, minimized when y = 1, giving value - 1. In both cases, the minimum value of sn is the same as the value of the negative monomial.

The positive monomial is the function

[formula]

Ishikawa [\cite=Ishikawa2011] showed that it can be quadratized using [formula] auxiliary variables, and this is currently the best available bound for positive monomials; see also [\cite=FGBZ2011] [\cite=Ishikawa2011].

Rosenberg [\cite=Rosenberg75] has proved that every pseudo-Boolean function f(x) has a quadratization, and that a quadratization can be efficiently computed from the polynomial expression of f. This also easily follows from our foregoing observations that every monomial has a quadratization. (It is also the case -- see [\cite=ABCG] -- that any pseudo-Boolean function has a y-linear quadratization.) Of course, quadratic PBO problems remain difficult in general, but this special class of problems has been thoroughly studied for the last few decades, and much progress has been made in solving large instances of QPBO, either exactly or heuristically. Quadratization has emerged in recent years as one of the most successful approach to the solution of very large-scale PBO problems arising in computer vision applications. (See, for instance, Boykov, Veksler and Zabih [\cite=BVZ01], Kolmogorov and Rother [\cite=KR2007], Kolmogorov and Zabik [\cite=KZ2004], Rother, Kolmogorov, Lempitsky and Szummer [\cite=RKLS2007], Boros and Gruber [\cite=BG2011], Fix, Gruber, Boros and Zabih [\cite=FGBZ2011], Freedman and Drineas [\cite=FreedDrineas2005], Ishikawa [\cite=Ishikawa2011], Ramalingam, Russell, Ladický and Torr [\cite=RRLT2011], Rother, Kohli, Feng and Jia [\cite=RKFJ].)

In a related paper, the present authors [\cite=ABCG] initiated a systematic study of quadratizations of pseudo-Boolean functions. We investigated the minimum number of auxiliary y-variables required in a quadratization of an arbitrary pseudo-Boolean function. In this paper, our focus is on symmetric pseudo-Boolean functions. A symmetric pseudo-Boolean function is one in which the value of the function depends only on the weight of the input. More precisely, a pseudo-Boolean function [formula] is symmetric if there is a function [formula] such that f(x) = k(l) = kl where [formula] is the Hamming weight (number of ones) of x. In another way, f is symmetric if it is invariant under any permutation of the coordinates [formula] of its variables. Note, for instance, that the positive and negative monomials are symmetric. Here, we investigate the number of auxiliary variables required in quadratizations of such functions.

Outline

In Section [\ref=sec:rep], we present a representation theorem and corollaries, which provide useful ways of expressing symmetric pseudo-Boolean functions. In Section [\ref=sec:reptoquad] we explain how we can use such representations to construct quadratizations, and we present the implications for upper bounds on the number of auxiliary variables in Section [\ref=sec:numberaux]. Section [\ref=sec:lower] presents two types of lower bounds on the number of auxiliary variables for quadratizations of symmetric functions: an existence result, establishing that there are symmetric functions needing a rather large number of auxiliary variables; and a concrete lower bound on the number of auxiliary variables in any y-linear quadratization of the parity function.

A representation theorem

We introduce a useful piece of notation: for any real number a, [formula] denotes min (a,0), the smaller of a and 0. In this section, we present a result that will be key in our approach to obtaining quadratizations. This is a 'representation theorem' that expresses a symmetric pseudo-Boolean function on variables [formula] as a linear combination of terms of the form [formula], for a suitable range of values a.

Our main result, in its most general form, is as follows.

Let 0 < εi  ≤  1, for [formula]. Then every symmetric pseudo-Boolean function [formula] can be represented uniquely in the form

When all the εi are equal, we can be more explicit about the coefficients in this representation. Recall that kl = k(l) is the value of f(x) in any point x with Hamming weight equal to l. We set k- 1 = 0 by convention.

Let 0 < ε  ≤  1. Then every symmetric pseudo-Boolean function [formula] can be represented uniquely in the form where, for [formula], the value of αj is

[formula]

(The first sum in [\eqref=eq:alpha] is, by usual convention, taken to be 0 if j < 2.)

When [formula], we should have f(x) = kj. So, to find a coefficient vector [formula] which establishes the required representation, we need to find a solution to the following system of n + 1 linear equations:

[formula]

The matrix underlying this system is the lower-triangular matrix

[formula]

Because A is lower-triangular with nonzero diagonal entries -  εq ([formula]), this system does indeed have a unique solution and therefore the representation exists and is unique.

We check that a solution (and hence the solution) of the system [\eqref=eq:alpha2] with εi  =  ε for all [formula], is given by [\eqref=eq:alpha] in the statement of the theorem.

We proceed by induction on j. The case j = 0 is easily verified, since the first equation in [\eqref=eq:alpha2] immediately yields [formula], in agreement with [\eqref=eq:alpha]. Assume now that ([\ref=eq:alpha]) is satisfied by the values of αi up to i = j - 1. Then, from ([\ref=eq:alpha2]) and from the induction hypothesis,

[formula]

Substituting ([\ref=eq:alpha]) in the last term of ([\ref=eq:tech1]) yields

[formula]

where the last equality is obtained by summing the geometric series which appears in the first sum of equation ([\ref=eq:penultimate]).

Combining ([\ref=eq:tech1]) and ([\ref=eq:tech2]), we find

[formula]

which is equivalent to ([\ref=eq:alpha]).

There are two special cases of Theorem [\ref=thm:repepsilon] that we will use in particular. When ε = 1 / 2, Theorem [\ref=thm:repepsilon] yields:

Every symmetric pseudo-Boolean function [formula] can be represented uniquely in the form

[formula]

where

[formula]

for [formula], and k- 1 = 0.

Taking ε = 1 in Theorem [\ref=thm:repepsilon], we obtain the following.

Every symmetric pseudo-Boolean function [formula] can be represented in the form

[formula]

In fact, Corollary [\ref=thm:fix] follows from work of Fix [\cite=Fix], and a simpler direct proof can be given. As Fix observed, if [formula], then

[formula]

where δi(l) = 1 if i = l and δi(l) = 0 otherwise. Then, it can be seen that

[formula]

From this, it follows that

[formula]

On simplification, this gives

[formula]

as required.

From representations to quadratizations

In this section we explain how a representation of the type presented in the previous section can be used to construct quadratizations of pseudo-Boolean functions. One useful observation is that when a coefficient αi is non-negative, the corresponding term [formula] in the representation of Theorem [\ref=thm:repepsilongeneral] of f can be quadratized as [formula]. But this translation simply does not work if αi is negative. The strategy described in this section is to take an expression as given in Theorem [\ref=thm:repepsilongeneral] (or one of its special cases) and add a quantity that is identically-0 and which will result in a final expression that has no terms with negative coefficients. The following Lemma describes three possible such quantities. The first is going to be useful when working with representations of the form given in Corollary [\ref=thm:fix], and the second and third will be useful when working with the representations from Corollary [\ref=thm:rep2].

Let

[formula]

and Then, for all [formula], E(l) = E'(l) = E''(l) = 0.

First we show that E(l) is identically-0. We have

[formula]

We next show that E'(l)  =  0 for all values of l. Fix l and note that [formula] if and only if i  ≤  l. Hence,

[formula]

By considering separately the cases where l is respectively even or odd, one can conclude that E'(l) = 0 for all [formula]. For, if l = 2r, then the expression on the right in equation ([\ref=eqn:E]) is r / 2 - r2 =  - l(l - 1) / 4 and, if l = 2r + 1, it is - r / 2 - r2 =  - l(l - 1) / 4. The identity E''(l) = 0 (for all l) can be proved similarly, or can be deduced from the previous one by observing that, for all [formula],

[formula]

We then can note that

[formula]

so that E'' =  - E' = 0.

We gave a direct, self-contained, proof of Lemma [\ref=lem:zero1], but in fact these three identities follow from Corollary [\ref=thm:rep2] and Corollary [\ref=thm:fix]. For, if we apply Corollary [\ref=thm:fix] to the function [formula], we see that

[formula]

which implies the first identity of Lemma [\ref=lem:zero1]. Applying Corollary [\ref=thm:rep2] to f(x) shows (after some calculation) that

[formula]

giving the second identity (that E' is identically-0). Applying Corollary [\ref=thm:rep2] to the function [formula] yields the third identity.

Upper bounds on number of auxiliary variables

Any symmetric function

We first have the following very general result, which provides an explicit construction of a quadratization of any pseudo-Boolean function, using no more than n - 2 auxiliary variables.

Every symmetric function of n variables can be quadratized using n - 2 auxiliary variables.

Using Corollary [\ref=thm:rep2], we can write any symmetric function f as

[formula]

Let [formula] and αs  =   min {αi:i}. Now add to f the expression

[formula]

which is identically-0. This results in an expression for f of the form

[formula]

where, for each i, if i is even, βi  =  αi  -  αr  ≥  0, and if i is odd, βi  =  αi  -  αs  ≥  0. So all the coefficients βi are non-negative. Furthermore, βr  =  βs = 0, so we have an expression for f involving no more than n - 2 positive coefficients βi. Then,

[formula]

is a quadratization of f involving at most n - 2 auxiliary variables.

(A construction in [\cite=Fix] shows an upper bound of n - 1. This is obtained by adding a multiple of [formula] to each term in the expression from Corollary [\ref=thm:fix], rather than to the expression as a whole, resulting in more complex quadratizations.)

Notice that the quadratization in the proof of Theorem [\ref=thm:symm_quad] is y-linear, so we have in fact shown:

Every symmetric function of n variables has a y-linear quadratization involving at most n - 2 auxiliary variables.

Furthermore, these quadratizations are also symmetric in the x-variables. Not every quadratization of a symmetric function must itself be symmetric in the original variables. For example, consider the negative monomial

[formula]

As we have seen, this has the quadratization [formula], which is symmetric. However, it also has the quadratization

[formula]

where [formula], which is not symmetric in the x-variables.

Monomials

The quadratization of monomials (positive and negative) has been fairly well-studied. The standard quadratization of the negative monomial

[formula]

is

[formula]

(A related paper by the present authors [\cite=ABCG] gives a complete characterization of all the quadratizations of negative monomials involving one auxiliary variable and this is, in a sense, one of the simplest.) If we apply Corollary [\ref=thm:rep2] to the negative monomial, noting that ki = 0 for i < n and kn =  - 1, we obtain the representation

[formula]

which immediately leads to the quadratization

[formula]

only slightly different from the standard one. We could, instead, apply Corollary [\ref=thm:fix], which would show that [formula] from which we immediately obtain the standard quadratization.

As we noted earlier, the best known result (smallest number of auxiliary variables) for positive monomials is that they can be quadratized using [formula] auxiliary variables. This was shown by Ishikawa [\cite=Ishikawa2011]. We can see that this many auxiliary variables suffice by using our representation theorem, Corollary [\ref=thm:rep2], together with the argument given in the proof of Theorem [\ref=thm:symm_quad].

The positive monomial [formula] can be quadratized using [formula] auxiliary variables.

Consider first the case where n is even. By Corollary [\ref=thm:rep2], noting that ki = 0 for i < n and kn = 1, we have [formula] where [formula]. By Lemma [\ref=lem:zero1],

[formula]

This provides the required quadratization using [formula] new variables.

When n is odd, one similarly derives the following from Lemma [\ref=lem:zero1]:

[formula]

This quadratization of P requires the same number of auxiliary variables as Ishikawa's construction. Both quadratizations are, in fact, identical when n is even, but appear to be different when n is odd.

Note that an alternative approach to the case of odd n would be as follows. Write

[formula]

where [formula]. The first term can now be quadratized using [formula] new variables (since it contains an even number of variables), and the second term, viewed as a negative monomial in [formula], has a standard quadratization requiring one further auxiliary variable. Thus, this leads again to a quadratization of P with [formula] new variables. This quadratization is also different from Ishikawa's.

t-out of n and exact-t functions

Consider now the t-out-of-n function defined by:

[formula]

The basic Boolean functions [formula] (a positive monomial) and [formula] are examples of t-out of n functions with t = n and t = 1, respectively. Another popular example is the majority function given by:

[formula]

which breaks ties in favor of ones when n is even. In this case, [formula].

The t-out-of-n function ft,n can be quadratized using [formula] auxiliary variables.

From Corollary [\ref=thm:rep2], ft,n can be represented in the form

[formula]

where αi = 0 when i < t, αt =  - 2, and αi = 4( - 1)i - t - 1 when i > t.

Since the terms of ft,n alternate in sign when i  ≥  t, we can again use Lemma [\ref=lem:zero1] to make all coefficients non-negative by adding either 2E'(l) or 2E''(l) to ([\ref=eq:ftn]), depending on the parity of t. The resulting expression has [formula] positive coefficients, and its remaining coefficients are zero. Thus, it can be quadratized with [formula] auxiliary variables.

A related function is the exact-t (out of n) function, defined as f=t,n(x) = 1 if and only if the Hamming weight of x equals t. Using Corollary [\ref=thm:rep2] again, we have that f=t,n can be represented in the form given in [\eqref=eq:ftn] with αi = 0 when i < t, αt =  - 2, αt + 1 = 6, and αi = 0 when i > t + 1. Depending on the parity of t, we add E'(l) or E''(l) to [\eqref=eq:ftn] to obtain an expression with [formula] positive coefficients, which can then be quadratized with [formula] auxiliary variables. We have just proved the following:

The exact-t function f=t,n can be quadratized using [formula] auxiliary variables.

The positive monomial and the n Boolean function are also special cases of exact-t functions, both with t = n. It is apparent from the argument leading to Corollary [\ref=thm:exact-k] that the reason the positive monomial (and hence, the n function) requires [formula] auxiliary variables instead of [formula] is precisely because t = n.

Parity and its complement

The parity function is the (pseudo-)Boolean function Π(x) such that Π(x) = 1 if the Hamming weight of x is odd, and Π(x) = 0 otherwise. To derive a quadratization of this function, we will use Corollary [\ref=thm:fix] rather than Corollary [\ref=thm:rep2], and will make use of a variant of the argument given to establish Theorem [\ref=thm:symm_quad]. By Corollary [\ref=thm:fix], we can see that Π has the representation

[formula]

Let E(l) be as in Lemma [\ref=lem:zero1]. By adding [formula] to this representation of Π, we obtain a representation with non-negative coefficients, which leads to a quadratization with [formula] auxiliary variables: Π(x) =  min y∈{0,1}mg(x,y) where

[formula]

(The terms with coefficient - 2 in the expansion ([\ref=parity]) disappear on the addition of E.)

The complement, [formula] of Π can be represented as

[formula]

so, by adding [formula], to eliminate negative coefficients, we arrive at the following quadratization involving [formula] auxiliary variables:

[formula]

So we conclude the following:

The parity function of n variables has a y-linear quadratization involving [formula] auxiliary variables, and its complement has a y-linear quadratization involving [formula] auxiliary variables.

Lower bounds on the number of auxiliary variables

Generic lower bounds

The following result is inspired by (but is different and does not follow from) a transformation given in Siu, Roychowdhury and Kailath [\cite=Siu95], in the framework of the representation of Boolean functions by threshold circuits. This result relates quadratizations of arbitrary (possibly non-symmetric) pseudo-Boolean functions to the quadratization of symmetric functions on a larger, related, number of variables. We will then use a lower bound result from [\cite=ABCG] in order to obtain a lower bound result for symmetric functions.

Suppose that n,m are positive integers and suppose that every symmetric pseudo-Boolean function F(z) of N = 2n - 1 variables (that is, every symmetric function [formula]) has an m-quadratization. Then every (arbitrary) pseudo-Boolean function f(x) on {0,1}n also has an m-quadratization.

Let f(x) be an arbitrary pseudo-Boolean function of n variables. We are going to construct a sequence of four functions k, F, G, g, such that g is a quadratization of f. For this purpose, let N = 2n - 1.

Let [formula] be defined as follows: k(w): = f(x) where x is the binary representation of w, that is, [formula].

Let F be the symmetric pseudo-Boolean function of N variables defined by: for all z∈{0,1}N, F(z): = k(|z|), where |z| is the Hamming weight of z. (This defines F completely, given that it is symmetric.)

Let G(z,y) be an arbitrary quadratization of F(z) using m auxiliary variables. (The hypothesis of the theorem is that such quadratizations exist.)

Finally, let g(x,y) be the pseudo-Boolean function on {0,1}n + m that is obtained by identifying each of the variables [formula] with xj in G(z,y), for [formula]; that is,

[formula]

(The unification makes sense since [formula], for all [formula].)

We claim that g(x,y) is a quadratization of f. Indeed, g is clearly quadratic, because G is. Moreover, for every point x∈{0,1}n,

[formula]

(where equality [\eqref=eq:g1] is by definition of g, [\eqref=eq:g2] is by definition of G, [\eqref=eq:g3] is by definition of F, and [\eqref=eq:g4] is by definition of k).

We will now make use of the following result from [\cite=ABCG].

There are pseudo-Boolean functions of n variables for which any quadratization must involve at least Ω(2n / 2) auxiliary variables.

To be more concrete, the analysis in [\cite=ABCG] implies that for any n  ≥  8, there is a pseudo-Boolean function on n variables for which any quadratization will require at least 2n / 2 / 8 auxiliary variables.

This leads to the following lower bound result for symmetric functions.

There exist symmetric functions of n variables for which any quadratization must involve at least [formula] auxiliary variables.

Lemma [\ref=lem:arbtosym] shows that, if every symmetric function F(z) on {0,1}N, with N = 2n - 1, has an m-quadratization, then every (arbitrary) function f(x) on {0,1}n also has an m-quadratization. On the other hand, from Theorem [\ref=thm:lowergeneral], we know that some pseudo-Boolean functions on n variables require Ω(2n / 2) auxiliary variables. It follows that some symmetric functions on N variables must need [formula] auxiliary variables in every quadratization.

We also have a similar lower bound result for y-linear quadratizations. It rests on the following result from [\cite=ABCG]:

There are pseudo-Boolean functions of n variables for which any y-linear quadratization must involve at least Ω(2n / n) auxiliary variables.

We then have the following.

There exist symmetric functions of n variables for which any y-linear quadratization must involve at least Ω(n /  log n) auxiliary variables.

The proof is similar to the previous one: it suffices to observe that when G(z,y) is y-linear, then so is g(x,y), and to rely on the generic lower bound Ω(2n / n) of Theorem [\ref=thm:lowerbound2] for the number of auxiliary variables required in every y-linear quadratization of certain pseudo-Boolean functions.

Note that the lower bound in Theorem [\ref=thm:lb_sym2] for the number of auxiliary variables in y-linear quadratizations comes within a factor O( log n) of the upper bound of n - 2 from Theorem [\ref=thm:upperlinear].

A lower bound for the parity function

The results just obtained prove the existence of symmetric pseudo-Boolean functions which require a significant number of auxiliary variables to quadratize. Specifically, there exist functions needing [formula] auxiliary variables in any quadratization, and functions needing Ω(n /  log n) auxiliary variables in any y-linear quadratization. Those results do not, however, explicitly exhibit particular such functions. We next give a concrete example of a function which needs a significant number of auxiliary variables in any y-linear quadratization.

Every y-linear quadratization of the parity function on n variables must involve at least [formula] auxiliary variables.

Let g(x,y) be an arbitrary y-linear quadratization of the parity function. Then it can be written as

[formula]

where q(x) is quadratic, and [formula] are linear functions of x only.

For each [formula], consider the regions

[formula]

which are closed half-spaces defined by the linear functions [formula]. For each S  ⊆  [m], let RS denote the region [formula]. This is one of the 'cells' into which the m hyperplanes defining the linear functions [formula] partition [formula].

On every cell RS, the function f(x) =  min {g(x,y):y∈{0,1}m} is quadratic. Indeed, on R(S), we have

[formula]

We now use a result from Saks [\cite=Saks93] and Impagliazzo, Paturi and Saks [\cite=IPS] (which was used to obtain lower bounds on the size of threshold circuits representing the parity function). Let us say that a set of hyperplanes slices all r-dimensional subcubes of the Boolean hypercube {0,1}n if for each subcube (or face) of {0,1}n of dimension r, there are two vertices of the subcube that lie on opposite sides of one of these hyperplanes. Then (Proposition 3.82 of [\cite=Saks93]), if a set of m hyperplanes slices all r-dimensional subcubes, we have [formula]. In particular, therefore, any set of hyperplanes that slices every 3-dimensional subcube of {0,1}n must contain more than [formula] planes. Suppose the hyperplanes defined by the linear functions [formula] do not slice all 3-dimensional subcubes. Then there would be some cell RS containing a subcube of dimension 3. The parity function restricted to that subcube would then be equal to the quadratic expression [formula]. However, it is well-known (see, for instance [\cite=Saks93] [\cite=MinskyPapert] [\cite=WangWilliams]) that the parity function on a subcube of dimension r cannot be represented as a pseudo-Boolean function of degree less than r (and it cannot even be represented as the sign of a pseudo-Boolean function of degree less than r). So, we would then have a quadratic, degree-2, representation of parity on a cube of dimension 3, which is not possible. It follows, therefore, that the set of hyperplanes in question must slice all 3-dimensional subcubes and therefore has size [formula].

Conclusions

In this paper, we have studied the number of auxiliary variables required in quadratizations (and y-linear quadratizations) of symmetric pseudo-Boolean function. We have presented explicit general constructions of quadratizations, via special types of representations of the functions. This shows that every such function can be quadratized (with a y-linear quadratization, symmetric in the original variables) using at most n - 2 auxiliary variables. We investigated in more detail the quadratizations of special functions (monomials, t-out-of-n, exact-t, and parity functions), where it was possible to obtain quadratizations using significantly fewer than n - 2 auxiliary variables. By drawing on a general result from our related paper [\cite=ABCG] and establishing a connection between quadratizations of general functions and of symmetric functions on a related number of variables, we showed that there exist symmetric functions requiring [formula] auxiliary variables in any quadratization, and that y-linear quadratization can require Ω(n /  log n) variables. It would clearly be of interest to close the gaps between these lower bounds and the linear upper bound. We established, further, that any y-linear representation of the parity function needs [formula] auxiliary variables. An open question is to determine whether a similar (or better) lower bound can be obtained for any (not necessarily y-linear) quadratization of this, or another specific, symmetric function. For instance, any example of a symmetric function where a non y-linear quadratization needs fewer variables than the y-linear ones would be of interest, as would be any non constant lower bound on the number of auxiliary variables for positive monomials. Furthermore, the number of positive quadratic terms in any known quadratization of the positive monomial is at least n - 1, but no lower bound on such quantity has been found so far. Settling this question is also of great interest, as it is related to the quality of relaxations based on quadratizations for PBO problems.

Acknowledgements. We thank György Turán for several discussions and references on Boolean circuits for symmetric functions. The second author thanks the National Science Foundation (Grant IIS-1161476) for partial support. The third author was partially funded by the Interuniversity Attraction Poles Programme initiated by the Belgian Science Policy Office (grant P7/36) and by a sabbatical grant from FNRS. The fourth author thanks the joint CAPES (Brazil)/Fulbright (USA) fellowship process BEX-2387050/15061676 for partial suport.