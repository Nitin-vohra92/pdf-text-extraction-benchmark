0.6truein 0.0truein

= .5 - =.9

Introduction

The problem posed in this note has its root in discussion carried out more than 10 years ago between the authors. Since then, we have discussed it with numerous people, and it has been posted as an open problem on the web site of one of us. We decided to post it on the ArXiv in order to have a permanent and stable version for it.

The conjecture

Let [formula] denote an N-dimensional Gaussian vector with independent zero mean components of variance σi = E(Y2i). We assume for concreteness that σi  ≥  σi + 1.

Let T(θ) denote an arbitrary orthogonal matrix on I RN (θ is a N(N - 1) / 2 dimensional parameter, and we take T(0) = I), and define the random variable [formula]. For any M < N, define

[formula]

E(N,M,θ) is the mean square error when reconstructing [formula] according to its M largest (in absolute value) components. When the matrix T(θ) is a permutation matrix, this is the reconstruction error when keeping the M largest (in absolute value) components of [formula], where [formula] is already expressed in its Karhunen-Loeve basis, whereas other choices of θ correspond to an expansion in other, non K-L bases.

Let T(θ)∈P if T(θ) is composed only of zeroes and ones, i.e. T(θ) is a permutation and reflection matrix. We have the following

[formula]

Conjecture [\ref=conj-1], if true, implies that the Karhunen-Loeve basis is the best basis not only for linear reconstruction but also for nonlinear reconstruction based on the M largest projections.

The case of M = 1

We do not know how to prove in general Conjecture [\ref=conj-1]. However, it does hold true for M = 1, i.e reconstruction based on the largest projection. Indeed, we have

Conjecture [\ref=conj-1] holds true if M = 1.

Proof:  We can re-parametrize T such that ηi = E(X2i) satisfies ηi  ≥  ηi + 1. Note that [formula]. Clearly, it is enough then to prove that E( max X2i)  ≤  E( max Y2i).

Let [formula] denote a vector of independent Gaussian random variables with Ei = 0 and E(i)2  =  ηi. By Sidak's inequality [\cite=6aut], for any t > 0,

[formula]

implying that

[formula]

Next, we can check that

[formula]

and clearly, because [formula], also

[formula]

Indeed, when m = 1, ([\ref=shur]) holds because [formula]. For m = 2, we have that

[formula]

The general case of ([\ref=shur]) follows by induction.

By an inequality of Marshall and Proschan, see [\cite=SS], one concludes that for any convex, permutation symmetric function φ,

[formula]

Applying this to the function φ(  ·  ) =  max x2i, one concludes that E( max Y2i)  ≥  E( max (i)2), which together with ([\ref=cor-ineq]) yields E( max Y2i)  ≥  E( max X2i), as claimed.

Remark: the Schur convexity part of the argument holds also for the function

[formula]

What is missing in order to prove the conjecture for general M is the analog of ([\ref=cor-ineq]): is it true that

[formula]

Added September 15, 2011: R. van Handel communicated to us the following counter example to ([\ref=eq-11]): take N = 3, M = 2 and Z1,Z2,Z3 three independent standard Gaussians. Define [formula], [formula], and [formula]. The corresponding i are independent standard Gaussians. One checks numerically that 0.17  ~  E min (X2i) < E min (2i)  ~  0.19 (note that Conjecture [\ref=conj-1] does hold in this case). Of course, it is possible that using ([\ref=eq-11]) for only a subset of all Ts can help.

This example also disproves the conjecture in [\cite=lifshitz]

Remark Some inequalities related to the problem discussed in this note can be found in [\cite=GL]. However, the results contained there are not enough to resolve Conjecture [\ref=conj-1], even within a multiplicative factor.