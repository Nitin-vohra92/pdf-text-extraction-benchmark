Random Linear Network Coding: A free cipher?

Introduction

Under the classical networking paradigm, in which intermediate nodes are only allowed to store and forward packets, information security is usually viewed as an independent feature with little or no relation to other communication tasks. In fact, since intermediate nodes receive exact copies of the sent packets, data confidentiality is commonly ensured by cryptographic means at higher layers of the protocol stack. Breaking with the ruling paradigm, network coding allows intermediate nodes to mix information from different data flows  [\cite=ahlswede2000nif] [\cite=koetter2003aan] and thus provides an intrinsic level of data security -- arguably one of the least well understood benefits of network coding.

Previous work on this issue has been mostly concerned with constructing codes capable of spliting the data among different links, such that reconstruction by a wiretapper is either very difficult or impossible. In [\cite=cai2002snc], the authors present a secure linear network code that achieves perfect secrecy against an attacker with access to a limited number of links. A similar problem is considered in [\cite=feldman2004csn], featuring a random coding approach in which only the input vector is modified. [\cite=bhattad2005wsn] introduces a different information-theoretic security model, in which a system is deemed to be secure if an eavesdropper is unable to get any decoded or decodable (also called meaningful) source data. Still focusing on wiretapping attacks, [\cite=jain2004sbn] provides a simple security protocol exploiting the network topology: an attacker is shown to be unable to get any meaningful information unless it can access those links that are necessary for the communication between the legitimate sender and the receiver, who are assumed to be using network coding. As a distributed capacity-achieving approach for the multicast case, randomized network coding [\cite=ho2003bco] [\cite=ho2003rnc] has been shown to extend naturally to packet networks with losses [\cite=lun2005crc] and Byzantine modifications (both detection and correction [\cite=ho2004bmd] [\cite=jaggi2005cae] [\cite=jaggi2006rnc] [\cite=jaggiThesis]).  [\cite=tan2006snc] adds a cost criterion to the secure network coding problem, providing heuristic solutions for a coding scheme that minimizes both the network cost and the probability that the wiretapper is able to retrieve all the messages of interest.

In this work, we approach network coding security from a different angle: our focus is not on the threat posed by external wiretappers but on the more general threat posed by intermediate nodes. We assume that the network consists entirely of "nice but curious" nodes, i.e. they comply with the communication protocols (in that sense, they are well-behaved) but may try to acquire as much information as possible from the data that passes through them (in which case, they are potentially malicious). This notion is highlighted in the following example.

Consider the canonical network coding example with 7 nodes, shown in  Figure [\ref=fig:BU]. Node 1 sends a flow to sinks 6 and 7 through intermediate nodes 2, 3, 4 and 5. From the point of security, we can distinguish between three types of intermediate nodes in this setting: (1) those that only get a non-meaningful part of the information, such as node 5; (2) those that obtain all of the information, such as node 4; and (3) those that get partial yet meaningful information, such as nodes 2 and 3. Although this network code could be considered secure against single-edge external wiretapping -- i.e. , the wiretapper is not able to retrieve the whole data simply by eavesdropping on a single edge -- it is clearly insecure against internal eavesdropping by an intermediate node.

Motivated by this example, we set out to investigate the security potential of network coding. Our main contributions are as follows:

Problem Formulation: We formulate a secure network coding problem, in which all intermediate nodes are viewed as potential eavesdroppers and the goal is to characterize the intrinsic level of security provided by random linear network coding.

Algebraic Security Criterion: Based on the notion that the number of decodable bits available to each intermediate node is limited by the degrees of freedom it receives, we are able to provide a natural secrecy constraint for network coding and to prove some of its most fundamental properties.

Security Analysis for Complete Directed Acyclic Graphs: As a preliminary step towards understanding the interplay between network topology and security against eavesdropping nodes, we present a rigorous characterization of the achievable level of algebraic security for this class of complete graphs.

The remainder of this paper is organized as follows. First, a formal problem statement is in Section [\ref=sect:ProblemFormulation], followed by a detailed analysis of the algebraic security of Randomized Linear Network Coding in Section [\ref=sect:secRLNC]. In Section [\ref=sect:DAG], this analysis is carried out specifically for complete directed acyclic graphs. The paper concludes with Section [\ref=sect:ConcludingRemarks].

Problem Setup

We adopt the network model of  [\cite=koetter2003aan]: we represent the network as an acyclic directed graph G  =  (V,E), where V is the set of nodes and E is the set of edges. Edges are denoted by round brackets e = (v,v')∈E, in which v = (e) and v' = (e). The set of edges that end at a vertex v∈V is denoted by ΓI(v)  =  {e∈E:(e)  =  v}, and the in-degree of the vertex is δI(v)  =  |ΓI(v)|; similarly, the set of edges originating at a vertex v∈V is denoted by ΓO(v)  =  {e∈E:(e)  =  v}, the out-degree being represented by δO(v)  =  |ΓO(v)|.

Discrete random processes X1,...XK are observable at one or more source nodes. To simplify the analysis, we shall consider that each network link is free of delays and that there are no losses. Moreover, the capacity of each link is one bit per unit time, and the random processes Xi have a constant entropy rate of one bit per unit time. Edges with larger capacities are modelled as parallel edges and sources of larger entropy rate are modelled as multiple sources at the same node. We shall consider multicast connections as it is the most general type of single connection; there are [formula] receiver nodes. The objective is to transmit all the source processes to each of the receiver nodes.

In linear network coding, edge e = (v,u) carries the process Y(e), which is defined below:

[formula]

The transfer matrix M describes the relationship between an input vector [formula] and an output vector [formula],   =  M; M = A(I - F)- 1BT, where A and B represent, respectively, the linear mixings of the input vector and of the output vector, and have sizes K  ×  |E| and ν  ×  |E|. F is the adjacency matrix of the directed labelled line graph corresponding to the graph G. In this paper we shall not consider matrix B, which only refers to the decoding at the receivers. Thus, we shall mainly analyse parts of the matrix AG, such that G = (I - F)- 1; i and i denote column i of A and AG, respectively. We define the partial transfer matrix M'ΓI(v) (also called auxiliary encoding vector [\cite=lun2005crc]) as the observable matrix at a given node v, i.e.  the observed matrix formed by the symbols received at a node v. This is equivalent to the fraction of the data that an intermediate node has access to in a multicast transmission.

Regarding the coding scheme, we consider the random linear network coding scheme introduced in  [\cite=ho2003bco]: and thus each coefficient of the matrices described above is chosen independently and uniformly over all elements of a finite field [formula], q = 2m.

Our goal is to evaluate the intrinsic security of random linear network coding, in multicast scenarios where all the intermediate nodes in the network are potentially malicious eavesdroppers. Specifically our threat model assumes that intermediate nodes perform the coding operations as outlined above, and will try to decode as much data as possible.

Algebraic Security of Random Linear Network Coding

Algebraic security

The Shannon criterion for information-theoretic security [\cite=shannon1949cta] corresponds in general terms to a zero mutual information between the cypher-text (C) and the original message (M), i.e.  I(M;C) = 0. This condition implies that an attacker must guess ≤  H(M) symbols to be able to compromise the data. With network coding, on the other hand, if the attacker is capable of guessing M symbols, K - M additional observed symbols are required for decoding -- by noting that each received symbol is a linear combination of the K message symbols from the source, we can see that a receiver must receive K coded symbols in order to recover one message symbol. Thus, as will be shown later, restricted rank sets of individual symbols do not translate into immediately decodable data with high probability. This notion is illustrated in Figure [\ref=fig:SC1]. In the scheme shown on top, each intermediate node can recover half of the transmitted symbols, whereas in the bottom scheme none of the nodes can recover any portion of the sent data.

Notice that the previous definition is equivalent to computing the difference between the global rank of the code and the local rank in each intermediate node v. Moreover, as more and more symbols become compromised of security criteria, the level of security tends to 0, since as we shall show in this section, with high probability the number of individually decodable symbols ld goes to zero as the size of the field goes to infinity.

Security Characterization

We are now ready to solve the problem of characterizing the algebraic security of random linear network coding. The key to our proofs is to analyze the properties of the partial transfer matrix at each intermediate node. Recall that there are two cases in which the intermediate node can gain access to relevant information: (1) when the partial transfer matrix has full rank and (2) when the partial transfer matrix has diagonalizable parts. Thus, we shall carry out independent analyzes in terms of rank and in terms of partially diagonalizable matrices.

The following lemmas will be useful.

See the Appendix.

It follows from this lemma that it is only necessary to consider the case in which K  ≤  δI(v).

The probability that a linear combination of independent and uniformly distributed values in [formula] yields the zero result is bounded by

[formula]

where h(q) is a function such that O(h(q)) < O(q2). Moreover, P(Xlin = 0) tends to 0 when q  →    ∞  .

See the Appendix.

See the Appendix.

Let M' be the transpose of the partial transfer matrix at some vertex v, M' = MTΓI(v). We consider the process of Gaussian elimination of M'. It is unnecessary to consider rank K, since in that case the matrix, w.h.p, is invertible and hence diagonalizable [\cite=ho2003rnc]. Thus, M' is a δI(v)  ×  K matrix, δI(v)  <  K.

We prove the theorem constructively by analysing the probability of having K - 1 zeros in one or more lines of M'. Let p be the probability of having K - 1 zeros in a line of M', and let X be a random variable representing the recoverable number of symbols when an intermediate node has δI(v) degrees of freedom. It follows from Lemma [\ref=prop:lineTransferMatrix] that

[formula]

In the base case with δI(v) = 1, at most X = 1 symbols can be recovered, since there are not enough degrees of freedom to perform Gaussian elimination and the only chance for recovering a symbol is that the line of the matrix M already has K - 1 zeros. The probability for this is p.

In the case that 1 < δI(v) < K, we can obtain directly a number L = l of lines with K - 1 zeros, and a number δI(v) - l of lines in the opposite situation. Since we have δI(v) degrees of freedom to perform Gaussian elimination, we can obtain at most δI(v) symbols by successive elimination. At each step the probability of obtaining a line with K - 1 zeros is bounded by p.

By analysing the different possibilities of combinations for the lines that already have K - 1 zeros and the ones that can be obtained by Gaussian elimination, we get

[formula]

[formula]

where Pl(X = x) represents P(X = x|L = l).

Approximating the binomial distribution by a normal distribution yields

[formula]

where

[formula]

Since p  →  p *  < 1, we can state that, when q  →    ∞   and p  →  0 is ≈   exp (x2). When K goes to ∞  , so does x, and hence

[formula]

and

[formula]

Since

[formula]

and Pl(X = K - 1) decreases exponentially, and l only increases linearly,

[formula]

The probability of obtaining X  <  K - 1 symbols is bounded by P(X = K - 1); it follows that the probability of decoding X symbols with any δI(v) < K goes to zero as q and K tend to infinity.

Algebraic Security of the Complete Graph

Notice that, in consequence of the property outlined in Lemma  [\ref=prop:rank], the algebraic security of a graph is topology dependent. A node with δI(v)  ≥  K will not necessarily receive a full-rank partial transfer matrix. The rank depends on the available paths between sources and each intermediate node. More specifically, depending on the topology of the graph, some nodes may receive only combinations of symbols derived from matrices with restricted rank, i.e. less than K. This includes, for example, trees, where a node connected directly to the source by a link of capacity C can only have children that receive at most rank C.

As a first step towards general network models, we consider the case of complete acyclic directed graphs G = (V,E), n = |V|, which can be generated as follows.

Generate random labels for the n vertices. These have some ordering {e1,e2,...,en} associated to them;

Make an outgoing (directed) edge from the vertex with the minimum label to every vertex with a higher label;

Continue until we reach a vertex where there are no more possibilities for connections.

This algorithm generates a complete acyclic directed graph with one source, one sink and |E| = n(n - 1) / 2 edges, since the total degree of each vertex is n - 1 = δI(v) + δO(v). The source and the sink are naturally determined as those nodes that have only outgoing edges or only incoming edges, respectively. The ordering ensures that this algorithm always generates an acyclic directed graph, conferring the graphs generated in this way specific properties such as the distribution of the in and out-degrees. These properties can be determined directly from the order of the vertex using δO(v) = n - order(v) and δI(v) = n - δO(v) - 1 = order(v) - 1.

Before proving our next theorem, we introduce the following lemmas.

See the Appendix.

See the Appendix.

Suppose, by contradiction, that K = n - 1 is the max-flow min-cut capacity of the complete directed acyclic graph. The maximum order of an intermediate node v is n - 2, thus by Lemma [\ref=prop:deltaDAG1] we have ΔS(v)  =  1 / (n - 1). It follows that the secure max-flow of the complete acyclic directed graph equals the capacity of the graph.

By contradiction, let the minimum number of required symbols for secured transmission be ms  ≤  n - 2. There exists an intermediate node v such that (v) = n - 1, and consequently, ΔS(v)  =  0. Then the minimum number of required symbols for secure transmission is ms = n - 1.

It follows that the way to secure this class of complete graphs is to transmit at the max-flow min-cut capacity, if necessary by adding "dummy" symbols.

Conclusions

Intrigued by the security potential inherent to random linear network coding, we developed a specific algebraic security criterion, for which we proved a set of key properties. Perhaps one of the most striking conclusions of our analysis is that algebraic security with network coding is very dependent on the topology of the network. As an example, we focused on complete acyclic directed graphs, and determined the secure max-flow, as well as the minimum number of symbols required for algebraic security. As part of our ongoing work, we are extending this analysis to other more general network models. Ultimately, we would like to develop secure communication protocols capable of exploiting random linear network coding as an almost free cypher.

Acknowledgements

The authors gratefully acknowledge insightful discussions with Rui A. Costa (Univ. of Porto).

Proof of Lemma [\ref=prop:rank]

We will prove this constructively in terms of the ranks of parts of the transfer matrix. The auxiliary encoding vector in each intermediate node v is given by

[formula]

where M'ΓI(v) denotes the columns of the matrix corresponding to the incoming edges of v. The dimension of M'ΓI(v) is K  ×  δI(v), with δI(v) < |E|.

To determine the rank of the partial transfer matrix, we note that the transfer matrix M = A(I - F)- 1BT for the network must be invertible, and hence, (M) = K. On the other hand, to determine the rank of A(I - F)- 1 we use the fact that (I - F)- 1 is invertible and thus ((I - F)- 1)  =  |E|. We also have

[formula]

because the dimension of A(I - F)- 1) is K  ×  |E|. But, since

[formula]

holds and K < |E| (true because K must be less than the minimum cut in the network) we conclude that

[formula]

We now consider ΔS(v) at some vertex v. For that, we can consider two distinct cases: the first one is if K  <  δI(v). In this case, we cannot assume anything about ΔS(v), since the rank of the matrix M'ΓI(v) will be dependent on the topology of the network. As for the second case, (M'ΓI(v)) < K  ⇒  ΔS(v) < 0. [formula]

Proof of Lemma [\ref=prop:linCombFq]

Contrary to the sum, the product of independent and uniformly distributed values in [formula] is not independent and uniformly distributed. In fact, there are two ways to obtain a zero in a multiplication in [formula]: (1) by multiplication between an element [formula] and 0, and (2) by multiplication over two elements [formula] and [formula], such that a  ≠  0 and b  ≠  0, but ab = 0. Now, the total number of entries of the multiplicative table between q elements of [formula] is q2, and there are at most 2q instances of the first case: q instances of ab = 0, a = 0 and [formula], and q instances of ab = 0, a = 0 and [formula]. As for the second case, it is possible to prove by contradiction that the number of zeros obtained this way is strictly less than q2: if this was not the case, all products of elements of [formula] would be zero, and that is absurd. Since this is true for any q, the number of zeros grows O(h(q)) < O(q2). Thus, we have

[formula]

Since for large enough q we have (2 + h(q)) / q  <  1, it follows that

[formula]

[formula]

Proof of Lemma [\ref=prop:lineTransferMatrix]

Each position of a line of the transfer matrix M is a linear combination of independently and uniformly chosen values in [formula], and thus, the probability of obtaining a zero in a position is given by Lemma [\ref=prop:linCombFq]. The result follows by considering all the combinations of the possible positions in which the Y zeros may occur. [formula]

Proof of Lemma [\ref=prop:deltaDAG2]

Suppose that a given intermediate node receives R = K + θ symbols, [formula]. It is clear that the maximum possible rank is K and thus there is a way to remove θ columns s.t. the rank of the resulting set will still be at maximum K. Now consider the case in which vertex v receives at most K symbols. If the columns are linearly dependent, the condition

[formula]

such that [formula] and h1,h2,...,hn represent the columns ∈ΓI(v), will be satisfied. Since the linear combination of lines of the transfer matrix is again a linear combination of independent and uniformly distributed values in [formula], it follows from Lemma [\ref=prop:lineTransferMatrix] that the probability of obtaining (0...0)T tends to 0 when q  →    ∞   and K  →    ∞  , and thus, the columns h1,h2,...,hn∈ΓI(v) are linearly independent w.h.p. [formula]

Proof of Lemma [\ref=prop:deltaDAG1]

It follows from Lemma [\ref=prop:deltaDAG2] that w.h.p., the number of symbols received by a vertex is the rank of the partial transfer matrix received (and at most K) and thus

[formula]

[formula]