Corollary

Keep Ballots Secret: On the Futility of Social Learning in Decision Making by Voting

Introduction

Consider a set of agents making a decision collectively by voting, with each agent having equal influence. It would seem that the best collective decisions would come from each agent having as much information as possible. For example, if the voting is sequential rather than simultaneous, it would seem that the collective decision would be improved by later-acting agents having knowledge of the votes of the earlier-acting agents. Using the methods of signal processing to analyze a simple model, we show that this is not the case. In a social or political context, this provides a mathematical justification for the use of secret ballots, independent of any other merits, such as avoiding bribery, intimidation, or insincere voting. To be clear, though, our interest is in binary decision making under uncertainty, not voting to express individual preferences.

In contemporary popular culture, the advantage of (properly) aggregating opinions of many (reasonably diverse and independent) agents is known as "the wisdom of crowds" [\cite=Surowiecki2004]. In statistical signal processing, this is nothing more than a reduction in effective noise level from averaging or aggregating. Suppose private signals observed by decision-making agents are not perfectly informative due to noise. If N agents share their private signals, assumed conditionally independent and identically distributed (iid) given the unknown variable of interest, then the sharing effectively increases the signal-to-noise ratio (SNR) by a factor of N. Even if a communication capacity limit restricts the amount of shared information, sharing still helps the detection system work much better than a single-agent system. For example, in systems where agents with Gaussian noise-corrupted observations share 1-bit signals that are fused with the majority fusion rule, the effective SNR is asymptotically increased by a factor of 2N  /  π [\cite=VarshneyRVG2011].

In this paper, we consider a team of agents that together make a binary decision (between 0 and 1) by voting. Binary decisions often made by teams include whether to make a large purchase, whether to hire a job applicant, and whether to convict a defendant; the final example highlights that aggregation by voting, with equal weight to each vote, does not imply the use of majority rule. The agents have their own private signals and make local decisions in some preordained order. Because of this ordering, we refer to the agents as a sequence. The agents form a distributed detection and data fusion system because their local decisions are fused to reach a global decision, and only the global decision determines their performance.

Now assume that the agents can watch other agents' choices as public signals so that they can use the predecessors' decisions in decision making. The framework of sequential decision making was independently introduced in [\cite=Banerjee1992] and [\cite=BikhchandaniHW1992]. A key concept in these works is herding. A herd of agents takes place when all agents beyond some index have the same local decision. Both works found that a herd of agents making the incorrect decision might arise with positive probability when private signals are bounded; this is a disappointing occurrence since the optimal aggregation of private signals would result in vanishing error probability. Subsequently, [\cite=SmithS2000] showed that agents will asymptotically settle on the correct decision if private signals are unbounded. Recently, [\cite=AcemogluDLO2011] extends the result to general network topologies where each agent can observe decisions made by its neighbors instead of all previous agents.

This work contrasts from previous works in two key ways: we consider an arbitrary but finite number of agents N; and we consider any symmetric fusion of the local decisions (i.e., voting by an L-out-of-N rule). Because the number of agents is finite, presence or absence of herding is not central to our study; a herd of agents might arise and yet form a small fraction of the N total agents. Also, the fusion by voting makes an early-acting agent important not only for its influence on later-acting agents but also because its vote counts.

As the first to study this scenario, we ask whether it is beneficial for the agents not only to send their local decisions to the fusion center but also to share among themselves.

The public signals raise two changes to the model: the belief update that is standard in social learning and a fusion rule update that has not appeared previously in the context of social learning.

Each agent will update its belief about the true state based on the public signals (in a Bayesian setting) and design a better decision rule. The previous decisions reflecting the private signals of the precedent agents contain information that the following agents do not have. If an agent observes that most predecessors have chosen 1, then the agent will have a stronger belief on 1 and a weaker belief on 0. Hence, the update of belief is a positive feedback that encourages an agent to follow the precedents.

Each agent will adjust the fusion rule based on the public signals. For example, if the first agent has chosen 0, then the L-out-of-N fusion rule changes to the L-out-of-(N  -  1) rule for the remaining agents. And if the second agent has subsequently chosen 1, then the fusion rule becomes the (L  -  1)-out-of-(N  -  2) rule, etc. Thus, the previous decisions put a following agent in a different position; if most previous agents have chosen 1, then a few more votes for 1 will determine the global decision as 1. This fact makes the agent become more careful to choose 1. The evolution of the fusion rule is a negative feedback that discourages an agent to follow the precedents.

Our mathematical analysis shows that those positive and negative effects are exactly canceled out and that the optimal decision rules with public signals are equal to those without public signals. It implies that observing public signals is practically useless.

Section [\ref=sec:Model] describes our decision-making model formally. Section [\ref=sec:2-agent] provides results for two agents and Section [\ref=sec:N-agent] extends the results for an arbitrary number of agents. Section [\ref=sec:Conclusion] concludes the paper.

The Formal Model

A team of N agents--Alexis, Blake, ..., Norah--performs a binary hypothesis test for an object. The agents are aware of the prior probabilities of the object in state H  =  0 and in state H  =  1, which are denoted by [formula] and [formula]. The agents individually receive private signals about the state and perform tests to make their own binary decisions Ĥi. They are a team in the sense that they place the same relative importance on false alarms and missed detections and share a common goal to minimize the cost of global decisions. The cost for a false alarm is c10 and the cost for a missed detection is c01. Thus, for the L-out-of-N fusion rule, the average cost (i.e., Bayes risk) is given as follows:

[formula]

The private signals Yi are conditionally iid given the state H, with the likelihood function fYi|H. In other words, all agents observe private signals of equal quality. Bayesian agents use a likelihood ratio test (LRT) as the optimal decision rule, which chooses Ĥi  =  1 if the ratio fYi|H(yi  |  1)  /  fYi|H(yi  |  0) is greater than a certain threshold [\cite=NeymanPearson1933] [\cite=Varshney97]. We assume that the likelihood ratio is an increasing function of yi so that the LRT is simplified to a decision rule with a decision threshold λi:

[formula]

We will compare the optimal decision thresholds in the following two scenarios:

A common distributed detection system: Agents only observe private signals and make local decisions in parallel without knowing other agents' decisions. Then their decisions are fused by a specific L-out-of-N rule to make a global decision. Alternatively, we call this scenario parallel decision making.

A distributed detection system combined with sequential decision making: Agents observe private signals and sequentially make local decisions. Before each agent makes a decision, the agent observes precedents. Then their decisions are fused by a specific L-out-of-N rule to make a global decision.

Our notations for decision thresholds are distinguished in the two scenarios: λ in the first scenario and ρ in the second scenario.

In Scenario 1, we will say that the optimal decision thresholds are identical, i.e., [formula] for the following reasons: Using identical decision thresholds is asymptotically optimum for the binary hypothesis testing problem [\cite=Tsitsiklis1988]. Furthermore, by numerical experiments, it turns out that constraining to identical decision rules causes little or no loss of performance for finite N and the corresponding optimal fusion rule has the L-out-of-N form [\cite=Tsitsiklis1993]. Our numerical experiments (not reported here) for fixed fusion rules and conditionally iid private signals show that the optimal decision thresholds are in fact identical at least for any N  ≤  7 in multiple cases with such as Gaussian and exponential likelihood functions.

We use PIe and PIIe as notations for probabilities of Type I (false alarm) and Type II (missed detection) errors. We use a subscript index to indicate a specific agent. For example, error probabilities of Alexis are written as

[formula]

Since all agents have equally good private signals, their error probabilities are the same as [\eqref=eq:ErrorProb_NoPublicSignal] in the parallel decision-making scenario.

In Scenario 2, the agents sequentially make hard decisions: Alexis first makes a decision Ĥ1, Blake next makes a decision Ĥ2, and so on. Predecessors' decisions, which we call public signals, may cause different error probabilities by following agents. In this case, we use superscript notation to specify the public signals. For example, [formula] denotes the probability of Type I error of Blake (the second agent) upon observing Ĥ1  =  0 and [formula] denotes the probability of Type II error of Chuck (the third agent) upon observing Ĥ1  =  0 and Ĥ2  =  1. We sometimes use a notation like [formula] that specifies Alexis's decision as Ĥ1  =  0 but does not specify Blake's decision Ĥ2.

Once the error probabilities of all agents are computed, the conditional probabilities of the global decision being in error are given from the L-out-of-N fusion rule:

[formula]

where

[formula]

Two Agents

Let us consider the simplest case for distributed detection, which is N  =  2. We will compare two cases, which are depicted in Fig. [\ref=fig:TwoAgents]. We start from an assumption that Alexis does not change her strategy whether the agents observe public signals or not. The assumption comes from an intuition that she is the first agent to make a decision and does not observe any previous decisions in both scenarios.

Suppose that sharing previous decisions does not change Alexis's decision rule. Then, for N  =  2 and any L-out-of-N fusion rule, the existence of public signals does not affect the decision strategies of agents.

N Agents

In Section [\ref=sec:2-agent], we have shown that knowing Alexis's decision practically does not change Blake's optimal strategies for N  =  2 and any L-out-of-N fusion rule. Now let us expand the problem to a general N-agent problem by mathematical induction.

Suppose that sharing previous decisions does not change Alexis's decision rule (i.e., [formula]). If the existence of the public signals does not affect optimal decision thresholds of a team of N agents for a specific N and any K-out-of-N fusion rule, then the existence of the public signals also does not affect optimal decision thresholds of a team of N  +  1 agents and any L-out-of-(N  +  1) fusion rule.

We want to clarify the term belief in Fig. [\ref=fig:EvolutionN], which is distinguished from prior probability. The prior probability is fixed as p0 and known to all agents. The belief is how probable the agents think H  =  0 is. The belief can change as agents observe previous decisions even though the prior probability cannot. The above proof does not mean that the prior probability is changed after the agents observe Alexis's decision. It is saying that the problem of determining optimal thresholds upon observing Alexis's decision is equivalent to Problem B0 or B1 corresponding to Ĥ1.

The essence of this proof is to show that the effect of new fusion rules, L-out-of-N and (L  -  1)-out-of-N, exactly cancels out the effect of new beliefs q0 and q1. It is observed when we compare [\eqref=eq:DecThres0] [\eqref=Nagents] [\eqref=serial] and [\eqref=eq:DecThres1] [\eqref=Nagents] [\eqref=serial] to [\eqref=eq:DecThres] [\eqref=N+1agents] [\eqref=parallel]. As we mentioned earlier in Section [\ref=sec:Introduction], the public signals seem to have the same amount of a positive feedback and a negative feedback. From an overall standpoint, the public signals neither harm nor help the decision-making task.

Suppose that sharing previous decisions does not change Alexis's decision rule (i.e., [formula]). For any N and L-out-of-N fusion rule, the existence of the public signals does not affect optimal decision thresholds of a team of N agents.

Corollary [\ref=cor:GeneralN] is trivial for N  =  1 and is proven by Theorem [\ref=thm:2Agent] for N  =  2. For N  ≥  3, we can iteratively break down the problem until we have 2N  -  2 two-agent problems like in Fig. [\ref=fig:EvolutionN]. The backward process from the leaves (two-agent problems) to the root (N-agent problem) will demonstrate Corollary [\ref=cor:GeneralN].

Corollary [\ref=cor:GeneralN] only refers to the optimal decision thresholds. However, it implies that team's performance (i.e. Bayes risk) is not affected by the public signals. This is because decision thresholds determine the probabilities of errors and, thus, the Bayes risk.

Conclusion

We have discussed sequential decision making in a distributed detection and fusion system by a team of agents. It would be intuitively desired to have as much information as possible when performing a hypothesis test. However, our study has revealed that it is useless to observe other agents' decisions in this system. The agents just need to individually make the best decisions.

This result is justified by symmetries throughout our model. The first symmetry is the equal quality of private signals due to the identical likelihood functions. The second symmetry is the equal (1-bit) votes that agents have. The third symmetry is the equal weights of the votes implied by the L-out-of-N fusion rule.

One interpretation of the main result is as follows: Each agent sends 1 bit of information about its private signal to the fusion center. If Blake refers to Alexis's decision, then the fusion center effectively receives less than 1 bit of information about Blake's private signal from him. Therefore, in order to prevent such an efficiency loss, Blake should make a reasonable decision only based on his own private signal.

This result is obtained under an assumption that Alexis uses the same decision thresholds in both scenarios, and the assumption is not unreasonable. The assumption is trivially true for N  =  1. It is also true for N  =  2; our proof of Theorem [\ref=thm:2Agent] even does not use this assumption. In addition, we have confirmed that it is true at least for any N  ≤  9 by numerical experiments. This assumption heuristically seems true, and our future work is to verify it for arbitrary N.

Acknowledgment

Discussions with V. Krishnamurthy, J. Z. Sun, and L. R. Varshney are greatly appreciated.