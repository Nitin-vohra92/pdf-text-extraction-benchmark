How to make dull cellular automata complex by adding memory: Rule 126 case study

Introduction

In this paper we are making use of the memory tool to get a complex system from a chaotic function in discrete dynamical environments. Such technique takes the past history of the system for constructing its present and future: the memory [\cite=kn:AMM01] [\cite=kn:AM02] [\cite=kn:Alo03] [\cite=kn:AM03] [\cite=kn:Alo06] [\cite=kn:Alo09]. It was previously reported in [\cite=kn:MAA09] how the chaotic ECA Rule 30 is decomposed into a complex system applying memory on this function. Recent results show that other chaotic functions (Rule 86 and Rule 101) yield complex dynamics selecting a kind of memory, including a controller to obtain self-organization by structure reactions and simple computations implemented by soliton reactions [\cite=kn:MAA09a].

We focus this work on cellular automata (CA) evolving in one dimension, in particular taking the well-known ECA where each function evaluates a central cell and its two nearest neighbors (from left and right) and, every cell takes a value from a binary alphabet. Such ECA were introduced by Wolfram and have been widely studied in several directions [\cite=kn:Wolf94].

Among such ECA, there is a set of functions evolving in chaotic global behaviour where a number of cells remain unordered and their transitions have a large number of ancestors [\cite=kn:Wue94]. In this sense, special attention is given on a chaotic one: the ECA Rule 126 introduced by Wolfram in [\cite=kn:Wolf83]. Particularly in [\cite=kn:Wolf02], it is commented that Rule 126 generates a regular language with average growing faster than any polynomial time. This property can be analysed as well by de Bruijn diagrams with additional features; in particular another partial analysis with de Bruijn and subset diagrams was done by McIntosh [\cite=kn:Mc09] showing that string 010 in Rule 126 is the minimal Garden of Eden configuration (having no ancestors).

Based on the idea developed in previous results for obtaining complex dynamics from chaotic functions selecting memory and working systematically, it was suspected that a complex dynamics may emerge in Rule 126 given its relation to regular languages; making use of gliders coded by regular expressions, as it was studied in Rule 110 [\cite=kn:MMS08] and Rule 54 [\cite=kn:MAM08].

In this way Rule 126 provides a special case of how a chaotic behaviour can be decomposed selecting a kind of memory into a extraordinary activity of gliders, glider guns, still-life structures and a huge number of reactions. Such features can be compared to Brain Brian's rule behaviour or Conway's Life but in one dimension; actually none traditional ECA could have a glider dynamics comparable to the one revealed in this ECA with memory denoted as φR126maj (following notation described in [\cite=kn:MAA09] [\cite=kn:MAA09a]).

One-dimensional cellular automata

One-dimensional CA is represented by an array of cells xi where [formula] (integer set) and each x takes a value from a finite alphabet Σ. Thus, a sequence of cells {xi} of finite length n describes a string or global configuration c on Σ. This way, the set of finite configurations will be expressed as Σn. An evolution is comprised by a sequence of configurations {ci} produced by the mapping Φ:Σn  →  Σn; thus the global relation is symbolized as:

[formula]

where t represents time and every global state of c is defined by a sequence of cell states. The global relation is determined over the cell states in configuration ct updated at the next configuration ct + 1 simultaneously by a local function φ as follows:

[formula]

Wolfram represents one-dimensional CA with two parameters (k,r), where k  =  |Σ| is the number of states, and r is the neighbourhood radius, hence ECA domain is defined by parameters (2,1). There are Σn different neighbourhoods (where n = 2r + 1) and kkn distinct evolution rules. The evolutions in this paper have periodic boundary conditions.

Cellular automata with memory

Conventional CA are ahistoric (memoryless): i.e., the new state of a cell depends on the neighbourhood configuration solely at the preceding time step of φ. CA with memory can be considered as an extension of the standard framework of CA where every cell xi is allowed to remember some period of its previous evolution. Basically memory is based on the state and history of the system, thus we design a memory function φ, as follows:

[formula]

such that τ  <  t determines the backwards degree of memory and each cell si∈Σ is a function of the series of states in cell xi up to time-step t - τ. Finally to execute the evolution we apply the original rule again as follows:

[formula]

In CA with memory, while the mapping φ remains unaltered, a historic memory of past iterations is retained by featuring each cell as a summary of its previous states; therefore cells canalize memory to the map φ. As an example, we can take the memory function φ as a majority memory:

[formula]

where in case of a tie given by Σ1  =  Σ0 in φ, we shall take the last value xi. So φmaj represents the classic majority function for three variables [\cite=kn:Mins67], as follows:

on cells [formula] and defines a temporal ring before calculating the next global configuration c. In case of a tie, it is allows to break it in favor of zero if xτ - 1 = 0, or to one whether xτ - 1 = 1. The representation of a ECA with memory (given previously in [\cite=kn:MAA09] [\cite=kn:MAA09a]) is given as follows:

[formula]

where CAR represents the decimal notation of a particular ECA and m the kind of memory given with a specific value of τ. Thus the majority memory (maj) working in ECA Rule 126 checking tree cells (τ = 3) of history is simply denoted as φR126maj:3. Figure [\ref=memEvol] depicts in detail the memory working on ECA.

Note that memory is as simple as any CA local function but sometimes the global behaviour produced by the local rule is totally unpredictable.

Disclaimer

The memory mechanism considered here differs from other CA with memory previously reported, often referred as higher order (in-time) CA. These ones, in most cases, explicitly alter the function φ and incorporate memory by direcly determining the new configuration in terms of the configurations at previous time-steps. Thus, in second order in time (memory of capacity two) rules, the transition rule operates as: xt + 1  =  Φ(ct,ct - 1). Double memory (in transition rule and in cells) can be implemented as: xt + 1  =  Φ({st},{st - 1}). Particularly interesting is the reversible formulation: [formula]; reversible CA with memory are studied in [\cite=kn:Alo09].

Some authors define rules with memory as those with dependence in φ on the state of the cell to be updated [\cite=kn:Wolf00] [\cite=kn:Kau84]. So one-dimensional rules with no memory adopt the form: xt + 1  =  φ(xti - 1,xti + 1). Memory is not here indentified with delay, i.e., refering cells exclusively to their state values a number of time-steps in the past, [\cite=kn:RJ09]. So, for example, the cell to be updated may be referenced not at t but at t - 1: xt + 1  =  φ(xti - 1,xti,xti + 1) [\cite=kn:Let07]. Again, the mapping function is not extended, for example, to consider the influence of cell i at time t - 1: xt + 1  =  ψ(xt - 1i,xti - 1,xti,xti + 1) as done in [\cite=kn:XQM05].

The use of the locution associative memory usually refers, when used in the CA context, to the study of configuration attractors [\cite=kn:GMD02] [\cite=kn:MC08], which are argued by Wuensche [\cite=kn:Wue94b] to constitute the network's global states contents addressable memory in the sense of Hopfield [\cite=kn:Hop82].

Finally, it is not intended here to emulate human memory, i.e., the associative, pattern matching, highly parallel function of human memory. The aim is just to store the past, or just a part of it, to make it work in dynamics. Thus, working storage might replace here the use of the term memory, avoiding the anthropomorphic, and rather unavoidable, connotations of the word memory [\cite=kn:Alo09].

The basic function: ECA Rule 126

The local-state transition function φ corresponding to Rule 126 is represented as follows:

[formula]

Rule 126 has a chaotic global behaviour typical from Class III in Wolfram's classification [\cite=kn:Wolf94]. In φR126 we can easily recognize an initial high probability of alive cells, i.e. cells in state '1'; with a 75% to appear in the next time and, complement of only 25% to get state 0. It will be always a new alive cell iff φR126 has one or two alive cells such that the equilibrium comes when there is an overpopulation condition. Figure [\ref=randomEvol] shows these cases in typical evolutions of Rule 126, both evolving from a single cell in state '1' (fig. [\ref=randomEvol]a) and from a random initial configuration (fig. [\ref=randomEvol]b) where a high density of 1's is evidently in the evolution.

While looking on chaotic space-time configuration in fig. [\ref=randomEvol] we understand the difficulty for analysing the rule's behaviour and selecting any coherent activity among periodic structures without special tools.

Mean field approximation in ECA Rule 126

This section presents a probabilistic analysis with mean field theory, in order to search basic properties about φR126 evolution space and its related chaotic behaviour. Such analysis will offer a better spectrum where we can start to explore the evolution space from more useful and specific initial conditions where some interesting behaviours may emerge.

Mean field theory is a well-known technique for discovering statistical properties of CA without analysing evolution spaces of individual rules [\cite=kn:Mc09]. The method assumes that states in Σ are independent and do not correlate each other in the local function φR126. Thus we can study probabilities of states in a neighbourhood in terms of the probability of a single state (the state in which the neighbourhood evolves), and probability of the neighbourhood is product of the probabilities of each cell in it.

In this way, [\cite=kn:Mc90] presents an explanation of Wolfram's classes by a mixture of probability theory and de Bruijn diagrams, resulting a classification based on mean field theory curve:

class I: monotonic, entirely on one side of diagonal;

class II: horizontal tangency, never reaches diagonal;

class IV: horizontal plus diagonal tangency, no crossing;

class III: no tangencies, curve crosses diagonal.

For the one-dimensional case, all neighbourhoods are considered as follows:

[formula]

such that j is an index number relating each neighbourhood and X are cells [formula]. Thus n is the number of cells into every neighbourhood, v indicates how often state '1' occurs in X, n - v shows how often state '0' occurs in the neighbourhood X, pt is the probability of cell being in state '1' while qt is the probability of cell being in state '0' i.e., q = 1 - p. The polynomial for Rule 126 is defined as follows:

[formula]

Because φR126 is classified as a chaotic rule, we expect no tangencies and its curve must cross the identity; remembering that φR126 has a 75% of probability to produce a state one.

Mean field curve (fig. [\ref=meanField]) confirms that probability of state '1' in space-time configurations of φR126 is 0.75 for high densities related to big populations of 1's. The curve demonstrates also that φR126 is chaotic because the curve cross the identity with a first fixed point at the origin f = 0 and the non existence of any unstable fixed point inducing non stable regions in the evolution. Nevertheless, the stable fixed point is f = 0.6683, which represents a 'concentration' of '1's diminishing during the automaton evolution.

So the initial inspection indicates no evidence of complex behaviour emerging in φR126. Of course a deeper analysis is necessary for obtaining more features from a chaotic rule, so the next sections explain other techniques to study in particular periodic structures.

Basins of attraction

A basin (of attraction) field of a finite CA is the set of basins of attraction into which all possible states and trajectories will be organized by the local function φ. The topology of a single basin of attraction may be represented by a diagram, the state transition graph. Thus the set of graphs composing the field specifies the global behaviour of the system [\cite=kn:WL92].

Generally a basin can also recognize CA with chaotic or complex behaviour following previous results on attractors [\cite=kn:WL92]. Thus we have that Wolfram's classes can be represented as a basin classification:

class I: very short transients, mainly point attractors (but possibly also periodic attractors) very high in-degree, very high leaf density (very ordered dynamics);

class II: very short transients, mainly short periodic attractors (but also point attractors), high in-degree, very high leaf density;

class IV: moderate transients, moderate-length periodic attractors, moderate in-degree, very moderate leaf density (possibly complex dynamics);

class III: very long transients, very long periodic attractors, low in-degree, low leaf density (chaotic dynamics).

The basins depicted in fig. [\ref=r126_2-18] show the whole set of non-equivalent basins in Rule 126 from l = 2 to l = 18 (l means length of array) attractors, all they display not high densities from an attractor of mass one and attractors of mass 14. This way Rule 126 displays some non symmetric basins and some of them have long transients that induce a relation with chaotic rules.

Particularly we can see specific cycles in fig. [\ref=cyclesR126] where it is possible to find:

static configurations as still life patterns (l = 8);

traveling configurations as gliders (l = 15);

meshes (l = 12);

or empty universes (l = 14).

The cycle diagrams expose only displacements to the left, and this empty universe evolving to the stable state 0 is constructed all times on the first basin for each cycle, see fig. [\ref=r126_2-18].

This way some cycles could induce some non trivial activity in Rule 126, but the associated initial conditions are not generally predominant. However some information is useful indeed looking periodic patterns that have a high frequency inside this evolution space and hence for recognizing a kind of filter useful to get a better view of a possible complex activity in Rule 126.

De Bruijn diagrams

De Bruijn diagrams [\cite=kn:Mc09] [\cite=kn:Voor96] are very adequate for describing evolution rules in one-dimensional CA, although originally they were used in shift-register theory (the treatment of sequences where their elements overlap each other). Paths in a de Bruijn diagram may represent chains, configurations or classes of configurations in the evolution space.

For an one-dimensional CA of order (k,r), the de Bruijn diagram is defined as a directed graph with k2r vertices and k2r + 1 edges. The vertices are labeled with the elements of the alphabet of length 2r. An edge is directed from vertex i to vertex j, if and only if, the 2r - 1 final symbols of i are the same that the 2r - 1 initial ones in j forming a neighbourhood of 2r + 1 states represented by [formula]. In this case, the edge connecting i to j is labeled with [formula] (the value of the neighbourhood defined by the local function) [\cite=kn:Voor06].

The de Bruijn diagram associated to Rule 126 is depicted in fig. [\ref=dB126].

Figure [\ref=dB126] exposes that there are two neighbourhoods evolving into 0 and six neighbourhoods into 1; so the higher frequency is for state 1; indicating the possibility of having an injective automaton; that is, the existence of Garden of Eden configurations [\cite=kn:Mc09] [\cite=kn:Voor96]. Classical analysis in graph theory has been applied over de Bruijn diagrams for studying topics such as reversibility [\cite=kn:Seck05]; in other sense, cycles in the diagram indicate periodic constructions in the evolution of the automaton if the label of the cycle agrees with the sequence defined by its nodes, taking periodic boundary conditions. Let us take the equivalent construction of a de Bruijn diagram in order to describe the evolution in two steps of Rule 126 (having now nodes composed by sequences of four symbols); the cycles of this new diagram are presented in fig. [\ref=dB126-1].

The extended de Bruijn diagrams [\cite=kn:Mc09] are useful for calculating all periodic sequences by the cycles defined in the diagram. These ones also show the shift of a sequence for a certain number of generations. Thus we can get de Bruijn diagrams describing periodic sequences for Rule 126.

Cycles inside de Bruijn diagrams can be used for obtaining regular expressions representing a periodic pattern. Figure [\ref=dB126-1] displays three patterns calculated as: (a) shift - 3 in 2 generations representing a pattern with displacement to the left, (b) shift 0 in 2 generations describing a static pattern traveling without displacement, and (c) shift + 3 in 2 generations is exactly the symmetric pattern given in the first evolution.

So we can also see in fig. [\ref=dB126-1] that it is possible to find patterns traveling in both directions, as gliders or mobile structures. But generally these constructions (strings) cannot live in combination with others structures and therefore it is really hard to have this kind of objects with such characteristics. Although, moreover Rule 126 has at least one glider! This will be explained in the next sections.

Filters for recognizing dynamics in Rule 126

Filters are a useful tool for discovering hidden order in chaotic or complex rules. Filters were introduced in CA studies by Wuensche who employed them to automatically classify cell-state transition functions, see [\cite=kn:Wue99]. Also filters related to tiles were successfuly applied and deduced in analysing space-time behaviour of ECA governed by Rules 110 and 54 [\cite=kn:MMS06] [\cite=kn:MAM06] [\cite=kn:MAM08].

This way, we have found that Rule 126 has two types of two-dimensional tiles (which together work as filters over φR126):

the tile [formula], and

the tile [formula].

Filter t1 works more significantly on configurations generated by φR126, the second one is not frequently found although it is exploited when Rule 126 is altered with memory (as we can see in following sections).

The application of the first filter is effective to discover gaps with little patterns traveling on triangles of '1' states in the evolution space. Although even in this case it may be unclear how a dynamics would be interpreted, a careful inspection on the evolution brings to light very small gliders (as still life), as shown in fig. [\ref=R126filtered].

This glider emerging in Rule 126 and localized by a filter is precisely the periodic pattern calculated with the basin (fig. [\ref=cyclesR126]a) and the de Bruijn diagram (fig. [\ref=dB126-1]b); in particular the last one offers more information because such cycles allow to classify the whole phases when this glider is coded in the initial condition. The next sections demonstrate the effect of filters for recognizing an amazing universe evolving in this CA with memory.

CA φR126m:4 and complex dynamics

This section discusses both relevant aspects of classic Rule 126 (φR126) and Rule 126 with memory (φR126m:τ).

Dynamics emerging with majority memory

As it was explained in [\cite=kn:Alo09b] [\cite=kn:MAA09] a new family of evolution rules derived from classic ECA can be found selecting a kind of memory.

Figure [\ref=majMemory] illustrates dynamics for some values of τ in φR126maj. The space-time configurations are also filtered to show a raw dynamics. We found that large odd values of τ tend to define macrocells-like patterns [\cite=kn:Wolf94] [\cite=kn:Mc09]. Even values of τ are responsible of a mixture of periodic and chaotic dynamics.

On exploring systematically distinct values of τ, we found that φR126maj:4 produces an impressive and non-trivial emergence of patterns traveling and colliding; so yet when the memory is working as a new function, it is possible to recognize some fragments inherited of the original rule φR126.

We start our simulations with a single non-quiescent cell, an example of this space-time configuration is provided in fig. [\ref=oneCell] showing the first 1,156 steps, where in this case the automaton needed other 12,000 steps to reach a stationary configuration. Filter is convenient to eliminate the non relevant information about gliders. In fig. [\ref=oneCell] we can see a number of gliders, glider guns, still-life configurations, and a wide number of combinations of such patterns colliding and traveling with different velocities and densities. Consequently we can classify a number of periodic structures, objects and interesting reactions.

Basic primitive gliders are displayed in fig. [\ref=basicGliders], there are still-life patterns s1 and s2, and gliders g1 and g2 respectively. These structures can be ordered in a set GφR126maj:4  =  {s1,s2,g1,g2}.

Figure [\ref=gliderGuns] shows the three more frequent glider guns (gun1, gun2, and gun3) emerging in φR126maj:4. The next three guns (fig. [\ref=gliderGuns](a), (b) and (c)) are combined in basic guns synchronized by multiple reactions which preserve emission of gliders although some of them can get other frequencies. We can include them increasing the set of periodic structures GφR126maj:4  =  {s1,s2,g1,g2,1,2, 3,4}. The last gun is presented in fig. [\ref=selfOrgGun] as a collision of gliders.

Basic properties of GφR126maj:4 are given in table [\ref=tableGliders], where also glider guns can be classified by frequencies of glider emission as follows:

small 1 fires a gliders g1 and g2 (in turn) every five steps;

medium 2 fires g1 and g2 (in turn) every 26 steps;

large 3 fires five g1 and g2 gliders every 100 steps.

Frequencies are related to the number of emitted gliders (in intervals) by a glider gun. Hence the gun2 generates one g1 and another g2 glider eight steps before to produce the next ones, and a gun3 yields five g1 and five g2 gliders 100 steps before to produce the other ones.

Collisions between gliders

Coding glider positions to get a desired reaction is a well-known solution for some related problems about complex behaviours. One of them is precisely the problem of self-organization (by structures fig. [\ref=selfOrganization]) [\cite=kn:Kau93]. In this way, we present how each basic glider can be produced by collisions between other different gliders.

A little bit more complicated is to obtain glider guns by collisions. Figure [\ref=selfOrgGun](a) and (b) depicts the production of a gun2 from a multiple collision of gliders. Later on we shall present two new combinations of guns (fig. [\ref=selfOrgGun](c) and (e)) and a new gun4 (fig. [\ref=selfOrgGun](d)).

Other collisions

A large variety of objects can be generated by collisions between gliders in φR126maj:4. Some of these objects are useful for designing complex dynamical structures. For instance, fig. [\ref=eaters](a), (b) and (c) shows how to delete (as an eater configuration) a single glider or a stream of gliders g1 and g2. Two kinds of annihilations are depicted as well (see fig. [\ref=eaters](d) and (e)).

Figure [\ref=blackHole] describes a number of black hole patterns emerging in φR126maj:4. Traditionally a black hole is a Life object absorbing any glider that comes close to the main body (in this case, still life patterns). Its relevance consists of knowing how many patterns are able of attracting gliders and consuming all of them forever, in these cases the g1 and g2 gliders.

Figure [\ref=soliton] displays soliton reactions, where colliding gliders preserve their original forms. As known, a soliton has a small change in their phase and displacement; also soliton reactions are obtained with single gliders or by a stream of them.

The last set of examples (fig. [\ref=otherCollisions]) presents other binary reactions and some multiple collisions between g1 and g2 gliders. Some of them are conservative and others produce a new number of these structures. Finally we can take some collisions to exploit their dynamics and controlling glider reactions (see an extended relations of collisions in table [\ref=tableCollisions]). Thus it can be obtained a full number of reactions for generating desired gliders. The set of collisions is useful as 'raw material' in the implementation of computations on φR126maj:4.

Computing in φR126maj:4

Given the large number of reactions in φR126maj:4 (see table [\ref=tableCollisions]) the rule could be useful for implementing collision-based computing schemes [\cite=kn:Ada03] [\cite=kn:MAM06].

Figure [\ref=gatesColliding-1] illustrates the interaction of gliders traveling, colliding one another and implementing a Boolean conjunction as result. Initially from previous collisions we can embed logical constructions of and and not gates from this figure, as follows:

for the gate ([formula]) the implementation with φR126maj:4 is in fig. [\ref=otherCollisions](b); but only with one g2 glider (see tab. [\ref=tableCollisions]).

for the gate ([formula]) the implementation corresponds to fig. [\ref=selfOrganization](a).

for the gate ([formula]) the implementation is presented in fig. [\ref=otherCollisions](a); but only with one g1 glider (see table [\ref=tableCollisions]).

for one fanout gate (a  ↔  b  =  a  +  a  +  b) the implementation is shown in fig. [\ref=otherCollisions](d).

Indeed, here we also adopt ideas developed by Rennard in his design of Life computing architectures [\cite=kn:Ren03]. Glider g1 represents value 0, two g1 gliders together represent a value 1. Two gliders 2g2 traveling in positive direction describe the operator and one the register. Thus the register will read false or true if they are produced successfully.

Figure [\ref=gatesColliding-2] illustrates the basic reactions required to produce a primitive computational scheme in φR126maj:4. The following set of relations is applied (see table [\ref=tableCollisions]):

so we can represent serial reactions as:

and a not gate can be represented as:

false  +  2g2  =   true+ 2g2, or

true  +  2g2  =   false+  2g2.

Constructing formal languages since gliders collisions in φR126maj:4

To be considered as a mathematical machine, φR126maj:4 should compute sets of formal languages [\cite=kn:Arb69]. We consider such implementation as an easy way to illustrate how implement some collision-based processes in φR126maj:4.

Let Σ be a non-empty finite alphabet. Thus a string over Σ is a finite sequence of symbols from Σ. A set of all strings over Σ of length n is denoted by Σn. For example, if Σ  =  {0,1}, then Σ2  =  {00,01,10,11} to Σ3  =  {000,001,010,011,100,101,110,111}, and so on. This way Σ0  =  {ε} for any alphabet Σ. The set of all strings over Σ of any length is the Kleene closure of Σ and is denoted as Σ*. However we can write such expression in terms of Σn, as follows:

[formula]

This way for a binary alphabet [formula]. Finally a set of strings on Σ is called a formal language.

Making use of gliders in φR126maj:4 we can get any set of strings of Σ*. For example, for the formal language 1* we need to code all the initial conditions with reactions true. For the formal language (00 + 11)* the initial condition will be coded as: (g1g1  +  2g12g1)*. To yield an arbitrary length of strings we increase the number of cells in the CA. All distances between gliders must be preserved and the left part become periodic.

Conclusions

We have enriched ECA Rule 126 with majority memory and have demonstrated that by applying certain filtering procedures we can extract rich dynamics of gliders, guns and infer a sophisticated system of reactions between gliders. We have discovered how a complex dynamics emerges from a chaotic system selecting an adequate memory. We have shown that the majority memory increases nominal complexity but decreases statistical complexity of patterns generated by the CA. By applying methods as de Brujin diagrams, cycles and graph theory, we have proved that Rule 126 with memory opens a new spectrum of complex rules, in this case a new CA with memory: φR126maj:4. Finally we have demonstrated some capacities for computing specific logical and memory functions, and a future work will be constructing a universal device.

Acknowledgement

Genaro J. Martínez and Ramon Alonso-Sanz are supported by EPSRC (grants EP/F054343/1 and EP/E049281/1). Juan C. Seck-Tuoh-Mora is supported by CONACYT (project CB-2007/83554).