Knot Signature Functions are Independent

Introduction

Associated to each knot K  ⊂  S3 there is a Seifert matrix VK. The set of such Seifert matrices consists of those square integral matrices V satisfying det (V  -  VT)  =    ±  1, where VT denotes the transpose. For each unit complex number ω the hermitianized Seifert form, Vω, is defined by Vω  =  (1  -  ω)V  +  (1 - )VT; the signature of this matrix is denoted σω(V). It is possible to associate different Seifert matrices to a given knot, however the value of σω(VK) is known to depend only on K and not the choice of Seifert matrix [\cite=le1] [\cite=tr]; σω(VK) is usually denoted σω(K).

Let S denote the set of all unit complex numbers with positive imaginary parts. In this paper we study the linear independence of the set of these signature functions, {σω}ω∈S, viewed as real valued functions on the set of all Seifert matrices, and consequently as functions on the set of all knots. Our first result is the following:

The set of functions, {σω}ω∈S, is linearly independent.

Previously the only sets D for which it was known that {σω}ω∈D is linear independent were certain discrete subsets of S, [\cite=le1] [\cite=tr]. Applications of this result include the demonstration that a number of results that hold in high-dimensional knot theory fail in dimension 3. This is briefly summarized in Section [\ref=appsect].

A Seifert matrix is necessarily of even dimension, say 2g. It is called metabolic if there is a summand of dimension g of [formula] on which the associated bilinear form vanishes. It is called hyperbolic if [formula] is the direct sum of two such summands. Over the rational numbers these are identical concepts, but that is not the case over [formula]. In particular, σω(V) is identically 0 if V is hyperbolic, but can be nonzero for a metabolic form V if ω is a root of the Alexander polynomial of V, ΔV(t)  =   det (V  -  tVt). A detailed analysis of the signature functions of metabolic forms was accomplished in [\cite=le3]. The topological significance of these concepts is that metabolic forms correspond to slice knots and hyperbolic forms correspond to double null-concordant knots [\cite=su]. Renewed interest in double null-concordance, as summarized in Section [\ref=appsect], motivates our study of the signature functions associated to metabolic Seifert forms.

Polynomials that occur as Alexander polynomials are precisely those polynomials that are symmetric, Δ(t- 1)  =    ±  tjΔ(t), for some j, and satisfy Δ( - 1)  =    ±  1. Let D  ⊂  S denote the set of unit roots of Alexander polynomials with positive imaginary parts.

The set of functions, {σω}ω∈D, is linearly independent on the set of all metabolic Seifert matrices.

This has the following topological corollary.

If ν is a unit root of some Alexander polynomial, there is a slice knot K with σω(VK)  ≠  0 if and only if ω  =  ν.

Independence of Signature Functions

For a given Seifert matrix V, σω(V) can be viewed as an integer valued function of ω∈S. Simple arguments show that jumps of this function can occur only at those values of ω that are roots of ΔV(t), and if the root is simple the jump is nontrivial. Also, for each V, σω(V) = 0 for all ω close to 1. (For proofs, see, for instance, [\cite=le1].)

We will next show that for any given ω∈S there is an ω'∈S arbitrarily close to ω and a Seifert matrix V whose signature function has its only nontrivial jump at ω'. From this the theorem follows since one easily constructs, for any finite set {σωi}1  ≤  i  ≤  N and any chosen k,1  ≤  k  ≤  N, a Seifert matrix Vk with σωk(Vk)  ≠  0 and σωi(Vk)  =  0 if 1  ≤  i  ≤  N and i  ≠  k.

To construct the desired matrix V we construct a polynomial Δ having a unique root in S at a point ω' that can be made as close to ω as desired. Since Δ will be constructed to be integral, to satisfy Δ(1)  =    ±  1 and to be symmetric, it is the Alexander polynomial of some Seifert matrix V, [\cite=se].

For a given r, - 1  <  r < 1, consider the polynomial

[formula]

It is easily seen that Fr(t) has a pair of (unit) complex roots with real part r. Let r  =  Re(ω) so that F has roots at ω and [formula]. For a given ε there is a δ such that a perturbation of the coefficients of Fr by less than δ moves the roots less than ε. Choose a rational approximation a / b, b  >  0, to r so that replacing r in the coefficients of Fr by a / b changes the coefficients by less than δ  /  2. Furthermore, choose b large enough so that 1  /  b < δ  /  2. Then the roots of

[formula]

are within ε of those of Fr. Multiplying through by b yields the desired polynomial:

[formula]

Since Δ(1)  =   - 1 and b  >  0, Δ(t) has at least two real roots. The remaining roots ω' and ' are within ε of ω and [formula]. Since Δ(t) is real, symmetric, and it has exactly two nonreal roots, these roots must be lie on the unit circle. The result follows.

A Remark on Concordance

There is an equivalence relation on the set of Seifert forms called algebraic concordance: V1 and V2 are concordant if [formula] is metabolic. The set of equivalence classes forms a group, G, the algebraic concordance group. (See [\cite=le1].) The signature functions are not well-defined on G, but this difficulty can be overcome by considering the averaged signature function, σ*ω, obtained as the two-sided average of σω. Our theorem is easily seen to apply to the set {σ*ω}ω∈S, where this is now a set of homomorphisms, not simply functions, on G.

The same result holds for the corresponding topological construction, the concordance group of knots, C. Further details will be summarized in the final section.

Signature Functions of Metabolic Forms

A simple algebraic calculation shows that the matrix Vω is singular precisely when the unit ω is a root of ΔV(t). If V is metabolic it follows readily that σω(V)  =  0, except perhaps when ω is a root of ΔV(t). In [\cite=le3], Levine constructed metabolic matrices with nontrivial signature at ω  =  eπi  /  3, the root of t2  -  t + 1.

Our goal is to show that Levine's construction can be expanded to cover any root of any Alexander polynomial. One slightly subtle point in the proof of Theorem [\ref=thmmet] is in dealing with Alexander polynomials that have several unit roots; in such cases we must be able to specify at exactly which roots the signature function is nonzero.

Let [formula] be an Alexander polynomial. Since multiplication by ±  tj does not change the unit roots of Δ(t), we can assume that d0  ≠  0, d2g - i  =  di and that Δ(1)  =  1.

Consider the matrix V below, with 02g a 2g  ×  2g matrix of zeroes and Ig the g  ×  g identity. The g  ×  g and 2g  ×  2g integer matrices Ag and B2g will be specified in the course of the proof. We will choose B2g to be symmetric, so assume so throughout the discussion.

[formula]

Since det (V  -  VT)  =  1, V is the Seifert matrix. The half-dimensional block of zeroes implies that V is metabolic.

Simple work with the matrices and algebraic manipulations yield that ΔV(t) is the square of det ((1 - t)2Ag + t), or, more usefully,

[formula]

where λ(x)  =   det (Ag  +  xIg). Writing [formula], it follows that ΔV(t) = (P(t))2, where

[formula]

From this description of P if follows that: 1) P(t) is symmetric, 2) for k  ≤  g, the coefficient of tk in P(t) is a linear function of [formula], and 3) in that linear function of [formula], ak appears with coefficient 1.

It follows from these observations that we can choose the aj so that P(t)  =  Δ(t). (Solve first to find a0  =  d0 and then solve recursively for the remaining aj in order.) We now have ΔV(t)  =  Δ(t)2. Since Δ(1)  =  1, it follows that: 4) ag  =  1. Also, since d0  ≠  0 we have: 5) a0  ≠  0. We must now find a matrix Ag having the desired λ; the matrix we use is of the following form, presented here in the case g  =  4.

[formula]

We now consider the matrix (1  -  ω)V  +  (1 - )VT. Performing appropriate row operations on the top 2g rows, and simultaneous conjugate column operations of the first 2g columns, quickly yields the following matrix, where Ω  =  (1 - ω)(1  -  )  =  (1 - ω) + (1  -  ). (Notice that Ω is nonzero; it equals 0 only if ω  =  1, which is outside our domain.)

[formula]

Choose B2g so that all the entries that are not in the lower right g  ×  g block, denoted Bg, are zero. The [formula] block can be cleared using column operations, and simultaneous row operations will clear the [formula] block. It then follows that the signature of Vω is the signature of the following matrix.

[formula]

Next, simultaneous column operations on the last g columns and row operations on the last g rows can be used to put the ΩA  -  Ig block into lower triangular form and the ΩAT  -  Ig block into upper triangular form. If this is done, all entries on the diagonal of the upper right hand g  ×  g block are nonzero (actually - 1) except the last diagonal element, which becomes [formula]. If Bg is chosen so that all entries are 0 except its top right and bottom left entries, let's call them b1, and the bottom right entry, say b2, then after these row and column operations, the bottom right entry of the entire matrix has become Ω2b2  +  2Ω2a0b1. Hence, the signature of the original matrix Vω is equal to the signature of the 2  ×  2 matrix,

[formula]

From the identity [formula] we see that [formula]. Hence the matrix is nonsingular with 0 signature unless ω is root of the Δ. On the other hand, if ω is a root of Δ, then the signature is given by the sign of Ωb2  +  2Ω2a0b1, which is the same as the sign of b2  +  2Ωa0b1 since Ω  =  (1  -  ω)(1  -  ) is a nonzero norm.

It remains to select b1 and b2 appropriately. Suppose that Δ has unit roots with positive imaginary parts [formula], placed in order of increasing real part, and let p satisfy 1  ≤  p  ≤  k. Since Ω  =  2  -  2ω is a decreasing function of the real part of ω, it is clear that b1 and b2 can be selected so that b2  +  2Ωa0b1 is positive for ωj when j  ≤  p and it is negative for ωj when j  >  p. The corresponding matrix, say V1, has signature σωj(V1)  =  1 if k  ≤  p and σωj(V1)  =   - 1 if k  >  p. Similarly, construct V2 so that σωj(V2)  =   - 1 if k  <  p and σωj(V2)  =  1 if k  ≥  p. The direct sum of these two matrices has the desired property: its only nontrivial signature is t [formula].

Comment. For the matrix constructed we have σωp  =  2 and all other signatures are 0. Can a similar matrix be constructed, only with σωp  =  1? If the irreducible polynomial for ωp has a unique root ω∈S the construction gives such an example. If, however, there are multiple roots in S, it can be shown that the parity of the signatures at each of these roots must be the same, as follows. The parity of the signature of Vω is determined by its rank and nullity of Vω. Both of these are invariant under the action of the Galois group permuting the roots of Δ(t).

Higher Dimensional Knots

The algebraic theory of 1 dimensional knots in S3 extends to a general theory of codimension 2 knots in S2n + 1. According to Levine [\cite=le1], the case of knots in dimension S4n  +  3 is identical to the classical case. Hence, all the results presented so far apply for knots in these dimensions. In this section we will describe how to modify our previous work to apply to knots in S4n + 1. The reference for this is [\cite=le1].

In the case of knots in S4n + 1, a Seifert matrix is a 2g  ×  2g integral matrix satisfying det (V  +  VT)  =  1. The signature function of such a Seifert matrix is given by

[formula]

The Alexander polynomial is given by Δ(t) =  det (tV + VT). An integral polynomial is the Alexander polynomial of some such Seifert matrix if and only if Δ(t) = t2gΔ(t- 1), Δ(1) = ( - 1)g, and Δ( - 1) is a square.

Extending Theorem [\ref=thmind]. To extend the proof of Theorem [\ref=thmind] to the case of knots in S4n + 1, we need to modify the polynomial Δ(t) constructed in the proof to assure that it satisfies the stricter conditions on Alexander polynomials in these dimensions. To do this, we replace Δ(t) with the polynomial D(t) = (ct2 + (1 - 2c)t + c)Δ(t) where c = 2(a + b) > 0. Then it is straightforward to check that D(t) is an Alexander polynomial of a Seifert matrix V of a knot in S4n + 1, using the fact that Δ(1) =  - 1 and Δ( - 1) = 8a + 8b - 1. Even though D(t) has an additional zero ω'' in S, where [formula], we can control it by choosing a and b carefully, as follows. Since a / b is to be chosen close to r  >   - 1, we can assume that a / b  >   - 1  +  ε for some fixed positive ε. Hence, c = 2(a + b) > 2bε and we can choose b large enough so that 1 - 1 / 2c is sufficiently close 1. Since both σ1 and σ( - 1) are zero for any knot in S4k + 1, it follows that the signature function σω(V) assumes a constant nonzero value (indeed ±  2) for [formula], and zero for [formula] or [formula]. Thus it can be used to complete the proof in this setting.

Extending Theorem [\ref=thmmet]. The extension of the proof of Theorem [\ref=thmmet] for knots in S4n + 1 is more straightforward. We proceed in the same way but start with

[formula]

which is a Seifert matrix of a slice knot in S4n + 1 for any n by a result of [\cite=le1], and assume that the given Δ(t) satisfies Δ(1) = ( - 1)g. Then it can be shown that σω(V) is zero if Δ(ω)  ≠  0, and σω(V) = b2 - 2Ωa0b1 if Δ(ω) = 0. Now the arguments of the last paragraph of the proof of Theorem [\ref=thmmet] can be applied to construct a desired matrix.

Applications to Knot Concordance

Our detailed examination of signature functions was motivated by problems in studying the concordance group of knots. In this section we give some indication as to the usefulness of the algebraic results of this paper.

The Seifert form VK associated to a knot K in S3 is not unique. However, as mentioned in Section [\ref=concord], by placing an equivalence relation on the set of knots one arrives at the concordance group of knots, C. The association K  →  VK induces a surjective homomorphism: φ:C  →  G. These notions were defined and studied by Levine [\cite=le1] [\cite=le2].

Levine's work contained two main results. One was topological--in higher dimensions the analog of φ is an isomorphism. The second was algebraic--the group G is isomorphic to an infinite direct sum, [formula]. This algebraic result depended in part on the existence of an infinite collection of ω for which the associated signature functions σω are linearly independent.

Several years after Levine's work, Casson and Gordon [\cite=cg1] [\cite=cg2] proved that φ is not an isomorphism (for knots in S3) by developing obstructions to a knot with metabolic Seifert form from being trivial in C. The kernel of φ is called the group of algbebraically slice knots, denoted A. Later, Gilmer [\cite=g1] [\cite=g2] demonstrated that these Casson-Gordon obstructions could be interpreted in terms of knot signatures: not those of the original knot, which are necessarily 0 if the knot is algebraically slice, but rather a knot that reflects the knotting in a surface bounded by the original knot.

The most basic applications of Gilmer's approach to Casson-Gordon invariants called on rather simple facts about the signature function. For instance, constructing algebraically slice knots that are nontrivial in the concordance group was reduced to finding knots with nontrivial signature at a single root of unity.

As the subtleties of A have been explored, deeper facts about signatures have been called on. As one example, Stoltzfus [\cite=st] proved that in higher dimensions if the Alexander polynomial of a knot K factors into irreducible factors with resultant 1, then the associated knot is concordant to a corresponding connected sum of knots. The second author of this paper, in unpublished work, has shown that this result does not apply in dimension three. The simplest example involves the polynomials 2t2  -  3t + 2 and 3t2  -  5t + 3. The construction of the counterexample depended, via Gilmer's work, on finding a knot whose signatures at 67-roots of unity satisfy a complicated linear inequality. Finding such a knot could be carried out by ad hoc methods, but Theorem [\ref=thmind] makes the existence of such a knot automatic.

If one takes on more general problems, the ad hoc methods that can be applied to a single example are no longer useful. For instance, it now appears to be the case that for almost any pair of Alexander polynomials with resultant 1 there is a knot with Alexander polynomial the product of those polynomials, and yet the knot is not concordant to a corresponding connected sum. The proof depends on contructing knots whose signature function at the collection of some (unknown) roots of unity satisfy some (unknown) inequality. Because of the general nature of the problem, little about which roots of unity or what the inequality is can be identified. Yet, with Theorem [\ref=thmind] it is possible to assert that such a knot will exist.

Similar issues arise in a number of related settings. In finding properties of G that do not apply to C, individual examples can sometimes be constructed using (perhaps very messy) ad hoc constructions, but general results demand complete control over the signature function, something that is offered by Theorem [\ref=thmind].

Applications of Theorem [\ref=thmmet] take place in a different realm. Levine's work in [\cite=le3] offered one proof that the quotient G  /  Gh is nontrivial, where Gh is the algebraic concordance group built using the equivalence relation based on hyperbolic rather than metabolic forms. In fact, it follows from [\cite=le3] that the quotient is infinitely generated. This result implied a similar result for the topological setting of double null concordance versus concordance. Levine's work focused on the signature function at a particular root of unity. Recent work of Cochran, Orr, and Teichner [\cite=cot] has renewed interest in the study of double null concordance; in particular, Taehee Kim, in unpublished work, has made significant progress in studying the case in which all invariants of the knot based on G and Gh vanish. This ongoing work points to a need for a further study of the algebra of Gh. The work here demonstrates the a complete analysis of G  /  Gh will depend on considerations of all possible unit roots of Alexander polynomials.