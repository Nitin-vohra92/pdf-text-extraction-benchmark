Lemma Proposition Claim Fact Corollary Conjecture Question Definition Assumption Example

A smooth transition from Wishart to GOE

Jacob Richey

Introduction

The Wishart distribution is a fundamental object appearing in many domains, such as statistics, geometry, quantum physics, and wireless communications, among others. In statistics it arises as the distribution of the sample covariance matrix of a sample from a multivariate normal distribution. In geometry it is known as the Gram matrix of inner products of n points in [formula], and it is also the starting point for canonical models of random geometric graphs [\cite=DGLU11] [\cite=BDER16] [\cite=EM16].

It is well known that an n  ×  n Wishart matrix with d degrees of freedom is close to the appropriately centered and scaled Gaussian Orthogonal Ensemble (GOE) if d is large enough (see, e.g., [\cite=DGLU11]). Recent work [\cite=BDER16] [\cite=jiang2013approximation] shows that the transition happens when [formula] and in this paper we study this critical window. In Theorem [\ref=thm:smooth] below we explicitly compute the total variation distance between the Wishart and GOE matrices when d  /  n3  →  c∈(0,  ∞  ), showing, in particular, that the phase transition from Wishart to GOE is smooth.

Main result

Let X be an n  ×  d matrix where the entries are i.i.d. standard normal random variables, and let [formula] be the corresponding n  ×  n Wishart matrix with d degrees of freedom. Let M(n) be an n  ×  n matrix drawn from the Gaussian Orthogonal Ensemble, i.e., a symmetric n  ×  n random matrix where the diagonal entries are i.i.d. normal random variables with mean zero and variance 2, and the entries above the diagonal are i.i.d. standard normal random variables, with the entries on and above the diagonal all independent. In order to match the first moment and the scale of the Wishart matrix, we center and scale M(n) appropriately: let [formula], where In is the n  ×  n identity matrix.

If d is large enough compared to n, then the Wishart matrix becomes approximately like the GOE. Recent work of Bubeck, Ding, Eldan, and Racz [\cite=BDER16], and independently Jiang and Li [\cite=jiang2013approximation], shows that the transition happens when [formula]. Specifically, they proved the following theorem, where we write [formula] for total variation distance.

Define the random matrix ensembles W(n,d) and M(n,d) as above.

(Bubeck, Ding, Eldan, and Racz [\cite=BDER16]) If d  /  n3  →  0 then

[formula]

(Bubeck, Ding, Eldan, and Racz [\cite=BDER16]; Jiang and Li [\cite=jiang2013approximation]) If d  /  n3  →    ∞   then

[formula]

Our focus is on the critical window and our main result is the explicit computation of the limiting total variation distance between W(n,d) and M(n,d) when [formula].

Define the random matrix ensembles W(n,d) and M(n,d) as above and let d  =  d(n) be such that [formula]. Then

[formula]

where recall that the error function is defined as

[formula]

From this result we can immediately read off that, as c  →  0 and c  →    ∞  , the total variation distance goes to 1 and 0, respectively, recovering the previous results described in Theorem [\ref=thm:transition]. Since [formula] as x  →  0, the limiting total variation distance decays as

[formula]

as c  →    ∞  . The behavior of the limit when c is small is plotted in Figure [\ref=fig:c_small].

From the proof we shall see that the limit in [\eqref=eq:smooth] is the expected value of an explicit function of a two-dimensional Gaussian, which comes from the central limit theorem for the first and third moments of the empirical spectral distribution of a GOE matrix.

Further related work and open problems

Several recent works have explored extensions of Theorem [\ref=thm:transition], and Theorem [\ref=thm:smooth] raises further questions.

Robustness. Bubeck and Ganguly [\cite=BubeckGanguly15] showed that the critical dimension is universal in the following sense: Theorem [\ref=thm:transition] holds (up to logarithmic factors) if the entries of X are i.i.d. from a sufficiently smooth distribution. What can be said about the transition in the critical regime? Are there other distributions for which the limiting total variation distance can be computed explicitly? If not, can one prove similar qualitative behavior?

Anisotropy. Eldan and Mikulincer [\cite=EM16] studied the effect of anisotropy on the power of detecting geometry in random geometric graphs. This is directly related to studying Wishart matrices where each row of X is a multivariate normal with a diagonal covariance matrix. The authors introduce new notions of dimensionality and prove a theorem similar to Theorem [\ref=thm:transition] with appropriate upper and lower bounds on the "effective critical dimension". While the primary open problem is to close the gap between these bounds, one may also ask about the nature of the transition at the effective critical dimension: can anisotropy cause qualitatively different behavior?

Other regimes. Theorems [\ref=thm:transition] and [\ref=thm:smooth] state that as d  /  n3  →    ∞  , all statistics of the Wishart W(n,d) and the GOE M(n,d) have asymptotically the same distribution, but this is not the case if d  /  n3 remains bounded. In the random matrix literature there has been lots of work showing that particular statistics of these ensembles have asymptotically the same distribution even when d  ≪  n3. For instance, when [formula], then the limiting empirical spectral distribution of the Wishart is the Marchenko-Pastur law, which shows the difference between the Wishart and GOE, but the largest eigenvalue of the Wishart already behaves like that of the GOE [\cite=johnstone2001distribution] [\cite=elkaroui2003largest] [\cite=karoui2007tracy]. This naturally raises the question of whether there are other regimes of d and n where there are interesting phase transitions.

Proof of Theorem [\ref=thm:smooth]

The main reason that allows for an explicit computation of the limiting total variation distance in Theorem [\ref=thm:smooth] is that both [formula] and [formula] have explicit densities. The proof of Theorem [\ref=thm:smooth] is similar to the case of d  /  n3  →    ∞   presented in [\cite=BDER16] and proceeds by a Taylor expansion of the ratio of the densities of the two random matrix ensembles. The difference compared to the case of d  /  n3  →    ∞   is that here the Taylor expansion has to be done to one degree higher. As we shall see, taking the limit of the total variation distance as [formula] then requires using the central limit theorem for the moments of the empirical spectral distribution of a GOE matrix.

Step 1: Writing out the total variation distance. Let [formula] denote the cone of positive semidefinite matrices. It is well known (see, e.g., [\cite=wishart1928generalised]) that when d  ≥  n, W(n,d) has the following density with respect to the Lebesgue measure on P:

[formula]

where [formula] denotes the trace of the matrix A. The density of a GOE random matrix with respect to the Lebesgue measure on [formula] is [formula] and so the density of [formula] with respect to the Lebesgue measure on [formula] is

[formula]

Denote the measure given by this density by μn,d, let λ denote the Lebesgue measure on [formula] and write [formula] if A is positive semidefinite. We can then write

[formula]

where [formula]. Let Q denote the set of symmetric matrices for which all of the eigenvalues are in the interval [formula]. Since d  /  n3  →  c  >  0, we have that Q  ⊂  P for all n large enough. It is known (see, e.g., [\cite=anderson2010introduction]) that, with probability [formula], all the eigenvalues of M(n) are in the interval [formula], which implies that [formula]. Since the integrand in [\eqref=eq:TV_1_minus_ratio] is bounded, we can then write

[formula]

and so we may restrict our attention to Q.

Define [formula]. Denote the eigenvalues of an n  ×  n matrix A by [formula]; when the matrix is obvious from the context, we omit the dependence on A. Recall that [formula] and [formula]. We then have that

[formula]

By Stirling's formula we know that [formula] as z  →    ∞  , so

[formula]

Now writing [formula] we get that

[formula]

Defining [formula], we have that

[formula]

Step 2: Taylor expansion and taking the limit. The derivatives of h at d are [formula], [formula], [formula], [formula], [formula], and also [formula]. Approximating h with its fourth order Taylor polynomial around d we get that

[formula]

where ξ is some real number between x and d. From [\ref=eq:alpha_sum_f] we see that to compute [formula], we need to compute the sum over the eigenvalues [formula] of each term in the expansion.

First, we argue that the contribution from the remainder term is negligible. Recall that A∈Q, and hence [formula] for every [formula]. If [formula], then

[formula]

where we used that [formula]. Summing n such terms gives a term of order O(1 / n), which is negligible in the limit. Turning to the four terms that matter, defining and also letting [formula], we thus have that

[formula]

For [formula] define [formula]. If [formula] are the eigenvalues of [formula], then [formula] are the eigenvalues of [formula]. Recall that the empirical spectral distribution [formula] converges weakly to the semicircle distribution with density [formula] (see, e.g., [\cite=anderson2010introduction]). With this notation we can rewrite the four quantities above as follows:

Let U be a random variable distributed according to the semicircle law. We know that for any fixed [formula], the [formula] moment of the empirical spectral distribution converges in probability to the [formula] moment of the semicircle law (see [\cite=anderson2010introduction]), i.e.,

[formula]

Since [formula] and [formula], we have that, as [formula], [formula] and [formula], so put together we have that [formula].

The central limit theorem for the moments of the empirical spectral distribution of a GOE matrix (see [\cite=anderson2010introduction] and [\cite=anderson2006clt]) shows that

[formula]

where [formula] are jointly normal with mean zero and covariance matrix [formula]. The entries of the covariance matrix C are special cases of the more general formulas found in [\cite=anderson2010introduction] [\cite=anderson2006clt], so we do not describe the computations here, but one can verify these numbers by using the identity

[formula]

and computing appropriate moments of normal random variables.

Putting everything together we see that, as [formula], we have that

[formula]

Therefore, since the function [formula] is continuous and bounded, we have by [\eqref=eq:TV], [\eqref=eq:alpha_S], and [\eqref=eq:weak_convergence_moments] that

[formula]

Step 3: Evaluating the limit. What remains is to evaluate the expectation on the right hand side of [\eqref=eq:limit_expectation]. Let Y and Z be independent normal random variables with mean zero and variances 2 and 6, respectively. Then [formula] and [formula] have the same distribution, since both are Gaussian with the same mean vector and covariance matrix. Notice that

[formula]

and hence the right hand side of [\eqref=eq:limit_expectation] is equal to

[formula]

Since [formula] if and only if [formula], we have that

[formula]

which concludes the proof.