=1 hyperref

Robust Variable and Interaction Selection for High-Dimensional Classification via Logistic Regression

Introduction

Nowadays the amount of data generated everyday has been dramatically increasing. Machine learning algorithms are routinely used to extract information and make predictions from the data. Classification, also known as supervised learning, is a foundational building block of statistical machine learning, of which the goal is to train a model from data to predict future observations to one of the known classes. Applications of statistical classification methods include but are not limited to cancer diagnosis [\cite=tibshirani2002diagnosis], text categorization [\cite=joachims1998text], computer vision [\cite=phillips1998support] and bioinformatics problems such as protein-protein interaction prediction [\cite=chowdhary2009bayesian]. Many classification methods have been developed, including logistic regression, naive Bayes, K-nearest-neighbors, support vector machines [\cite=boser1992training], and random forests [\cite=breiman2001random].

As important players in classification methods, linear and quadratic discriminant analysis (LDA and QDA) [\cite=anderson1958introduction] are widely used. One advantage of QDA is its ability to exploit interaction effects of predictors. In recent years, there has been a significant surge of interest in selecting interaction effects for regression or classification problems (e.g. [\cite=simon2012permutation] [\cite=bien2013lasso] [\cite=jiang2014variable] [\cite=fan2015innovated]), which both improves the classification accuracy and is of scientific interest.

With rapid technical advances in data collection, it has been more common that the number of predictors is in a higher order of the number of observations, which is also known as the "large p small n" problem. For example, in gene expression microarray analysis, usually n is in hundreds of samples, and p is in thousands of genes [\cite=efron2010large], and in a typical genome-wide association study, n is in the order of a few thousands of subjects, and p is from some thousands to several millions SNP markers [\cite=waldmann2013evaluation]. Large p small n is a serious problem to quadratic discriminant analysis, as the number of interaction terms is of order [formula]. Vanilla LDA or QDA are infeasible when p > n since the sample covariance matrices are consequently singular. Even in low-dimensional scenario, including unrelated predictors could significantly impair the classification accuracy, as they bring in extra noise and increase the number of parameters to be estimated.

A number of variable selection methods have been developed for high-dimensional classification problems. Many previous work focused on imposing regularization on the LDA model for both sparsity of model and stability of parameter estimation. For example, [\cite=shao2011sparse] proposed a sparse LDA method that takes sparse estimates of the covariance matrix of mean vectors. [\cite=witten2011penalized] proposed to use fused Lasso to penalize discriminant vectors in Fisher's discriminant problem. [\cite=cai2011direct] proposed to estimate the product of precision matrix and the difference between two mean vectors directly through a constrained L1 minimization. [\cite=han2013coda] relaxed the normal assumption of LDA to the larger Gaussian Copula models. For more examples of recent development of high-dimensional LDA, see [\cite=guo2007regularized] [\cite=fan2008high], [\cite=clemmensen2011sparse], [\cite=mai2012direct] and [\cite=fan2013optimal].

Aforementioned methods all work for LDA models with only linear effects. In many real data sets, however, interaction effects may be significant and scientifically interesting. Ignoring interaction effects in these problems may lead to inferior prediction accuracy. To illustrate, consider a two-class Gaussian classification problem with both linear and interaction effects. For simplicity, throughout this article we use "interactions" to denote all second-order effects, including both two-way interactions XiXj with i  ≠  j and quadratic terms such as X2i. Let [formula] denote the set of predictors, and the true Bayes rule is to classify an observation to class 1 if [formula], and to class 0 otherwise, where

[formula]

We simulated 100 independent datasets with 100 samples in each class. Figure [\ref=fig:sim_toy] shows the scatterplot of [formula] for one simulated dataset. For each simulated dataset, we applied LDA, logistic regression and QDA to train classifiers, and the classification accuracy is calculated by 1000 extra samples from the true model. The results are shown in Table [\ref=tab:lda_vs_qda]. As expected, both linear methods, LDA and logistic regression, have poor prediction power, but QDA with ability to exploit interaction effects improved the classification accuracy dramatically.

We further test the classification accuracy of QDA with not only true predictors but also k noise (unrelated) predictors (with k ranging from 1 to 50) drawn independently from [formula]. Figure [\ref=fig:sim_toy] shows the classification error rate of QDA increases dramatically as the number of noise predictors increases.

As shown above, methods with ability to conduct simultaneous main effects and interaction effects selection are of great interest. However, a direct application of Lasso on logistic regression with all second-order terms is not feasible for moderately large p (e.g. [formula]). To cope with this difficulty, [\cite=fan2015innovated] proposed innovated interaction screening (IIS) based on transforming the original p-dimensional predictor vector by multiplying the estimated precision matrix for each class. IIS first reduces the number of predictors to a smaller order of p, and then identifies both important main effects and interactions using elastic net penalty [\cite=zou2005regularization]. The performance of the method, IIS-SQDA, heavily depends on the estimation of the p  ×  p dimensional precision matrix, which is usually a hard problem under high-dimensional setting.

Recently, [\cite=murphy2010variable], [\cite=zhang2011bic] and [\cite=maugis2011variable] proposed stepwise procedures for QDA variable selection that are similar to each other. Their methods assume that related and unrelated predictors jointly follow a multivariate normal distribution. These methods were shown to be consistent under the normality assumption, however in practice the performance can be much compromised when this assumption is violated. Many false positive predictors can be selected when predictors follow heavier-tailed distributions or they are correlated in non-linear manners (see Section [\ref=sub:sim_QDA]).

In this article, we consider the logistic regression instead of QDA model to avoid the joint normality assumption on predictors. In particular, we study the logistic regression model with second-order terms, which covers quadratic discriminant analysis as a special case. Since predictors are conditioned on, our method is robust to misspecified generative distributions on predictors. To deal with high-dimensional predictors, we penalize the model likelihood with the extended Bayesian information criterion (EBIC) introduced in [\cite=chen2008extended]. We propose the method SODA (Stepwise cOnditional likelihood variable selection for Discriminant Analysis), which starts with a forward stepwise screening procedure to add in predictors with main or interaction effects so as to reduce the number of candidate predictors to a smaller order of n, and finishes with a backward stepwise elimination procedure for further narrowing down individual main and interaction effects. Under some regularity conditions, we establish the screening consistency of the forward procedure and establish the individual term selection consistency of the backward procedure under high-dimensional setting.

This article is organized as follows. In Section 2, we briefly review QDA and propose our procedure SODA for variable and interaction selection. Theoretical properties of SODA are studied in Section 3. In Section 4, we evaluate the performance of SODA and other methods by simulation studies. We further apply SODA to a couple of real datasets to evaluate its empirical performance in Section 5. A discussion section ends the paper in Section 6. Proofs of theorems are provided in the Appendix.

SODA for variable and interaction selection

QDA and existing variable selection methods

We consider the K-class classification problem with quadratic discriminant analysis. Let [formula] denote the class index and [formula] be a vector of p predictors. Let [formula] denote n independent observations on [formula]. We want to build a model for predicting a new observation's class membership [formula] based on its predictor values [formula]. QDA assumes true predictors in each class follow multivariate normal distribution,

[formula]

where [formula] and [formula] denote the mean vectors and covariance matrices for the K classes and [formula] denotes the multivariate normal distribution. Incorporating the prior probability of Y being in each class, denoted as [formula], we can calculate the posterior distribution of Y,

[formula]

where φ denotes the multivariate normal density function. For a new observation [formula], the Bayes rule based on 0-1 loss is to predict the corresponding Y as the class with the highest posterior probability,

[formula]

In general, the classification boundaries are quadratic functions of [formula]. When covariance matrices are assumed to be equal, i.e. [formula], classification boundaries are linear in [formula], and QDA reduces to LDA. In real applications, parameters [formula], [formula] and [formula]s are estimated from training samples by the maximum likelihood estimation (MLE).

When p is large, usually only a small proportion of predictors have predictive power on Y. Recently [\cite=murphy2010variable], [\cite=zhang2011bic] and [\cite=maugis2011variable] proposed three similar variable selection procedure based on the BIC for QDA model. Let S index a subset of predictors, [formula] and, let [formula] denote predictors in S. Let P denote the set of truly relevant predictors. All of the three methods make following two assumptions:

(A1) Given predictors in P, unrelated predictors in Pc do not contribute to the prediction of Y. In other words,

[formula]

(A2) All of the related and unrelated predictors follow a jointly multivariate normal distribution in each class.

Combining assumptions (A1) and (A2) leads to the following generative model,

[formula]

for some vector [formula] and matrix [formula]. Let [formula] denote the maximum log-likelihood for the model ([\ref=eq:XAc|XA] [\ref=Y=00003Dk-MVN]). The BIC proposed in [\cite=zhang2011bic] [\cite=murphy2010variable] [\cite=maugis2011variable], denoted as G, is defined as

[formula]

where [formula] denotes the number of parameters for the model with selected predictors in S. It has been shown that the set selected to minimize the BIC is a consistent estimator of P.

Assumption (A2) appears rather strong and may lead to false positive selections if certain noise variables distributions deviate from the posited Gaussian structure. Indeed, examples in Sections [\ref=sec:simstudy] and [\ref=sec:realdata] show that if unrelated predictors do not nicely follow model ([\ref=eq:XAc|XA] [\ref=Y=00003Dk-MVN]), there will easily be many false positive variable selections and the accuracy of the trained classifier will be compromised. Moreover, these methods do not scale well to high- dimensional cases when p is much larger than n.

Conditional likelihood model and its extended BIC

We consider a variable selection method without an explicit distributional assumption on [formula]. We make the model assumption that the conditional distribution of Y given [formula] is in the following parametric form,

[formula]

where [formula] is the discriminant function for class k and [formula] denotes the vector of parameters. Choose class K as the baseline class, then [formula] and

[formula]

Since [formula] is conditioned on, we do not need to model the distribution of [formula] or [formula], which much improves the robustness of the variable selection procedure. Special cases of this model include but are not limited to:

(Multinomial) logistic regression (with [formula] for all k)

Linear/quadratic discriminant analysis, where [formula] is multivariate normal distribution

Discriminant analyses where [formula] is in the multivariate exponential family,

[formula]

To see the connection between QDA and model ([\ref=eq:main_model]), it is noted that for QDA models,

[formula]

Let M and I denote subsets of main effect and interaction pairs, respectively, and let M0 and I0 denote corresponding true sets, defined as

[formula]

with k indicating the class label. Let [formula] and [formula] denote the true set. The true set of related predictors, P, can be derived from A as

[formula]

Inference of P is implied by the inference of A. The main objective is to infer individual terms in A, and we are especially interested in interaction terms in I0.

Let [formula] denote a parameter vector where coefficients are 0 for terms not in S, and [formula] denote the corresponding coefficients for class k. For a dataset [formula], the log-likelihood for [formula] is denoted as [formula]. Let [formula] be the augmented version of [formula], containing intercept 1, main effect and interaction terms of [formula], and let [formula] be the i-th observation of [formula]. Then [formula] takes the form of a logistic regression model in [formula]:

[formula]

Let S denote the MLE of [formula]. By Lemma 2 in the appendix, with high probability [formula] is convex and S can be obtained by Newton-Raphson algorithm. Let [formula] denote the true parameter vector. Theorem 1 illustrates the consistency of S for S with S  ⊃  A.

Under conditions C1 ~ C4 in section [\ref=sec:theory], as n  →    ∞  ,

[formula]

where 0 < ξ < 1 / 2 and [formula] are any positive constants independent of n.

In high-dimensional setting, classical BIC is too liberal and tends to select many false positives [\cite=broman2002model]. [\cite=chen2008extended] proposed extended BIC (EBIC) and showed it to be consistent for linear regression models under high-dimensional setting. The EBIC for set S is specified as

[formula]

where [formula] is the size of set S, and γ is a tunning parameter. Selection of γ depends on the relative order of n and p, and heuristics of determining γ is discussed in section [\ref=sub:impl]. Let [formula] be the selected set of predictors minimizing the EBIC, let Q be any positive constant greater than constant p0 in condition (C1) in section [\ref=sec:theory], then

[formula]

where [formula] denotes the size of set S. The asymptotic property of [formula] is shown by the following theorem.

(EBIC criterion consistency) Under conditions C1 ~ C4 in section [\ref=sec:theory], [formula] is a consistent estimator of A,

[formula]

for any [formula].

By treating our model as a logistic regression on [formula], Theorem [\ref=theorem:EBIC] follows directly from the asymptotic consistency of EBIC for generalized linear models (GLM), which was proved in [\cite=chen2012extended] and [\cite=foygel2011bayesian] in both fixed and random design contexts. We thus omit its proof. Different from [\cite=chen2012extended] and [\cite=foygel2011bayesian], here we require [formula] instead of [formula] to penalize additional model flexibility caused by the inclusion of interaction terms.

SODA: a stepwise variable and interaction selection procedure

In practice it is infeasible to enumerate all possible S to find the one that minimizes the EBIC. For a closely related generalized linear model variable selection problem, [\cite=chen2012extended] and [\cite=foygel2011bayesian] used Lasso [\cite=tibshirani1996regression] to obtain a solution path of predictor sets, and chose the optimal set with the lowest EBIC. However, this method also fails under the high-dimensional setting for QDA, in which there are [formula] candidate interaction terms. Furthermore, Lassos consistency for logistic regression requires the incoherence condition [\cite=ravikumar2010high] that can be easily violated due to the correlation between interaction terms and their corresponding main effect terms. Thus, it is highly likely that the true set A is not even on the solution path of Lasso. The IIS procedure proposed in [\cite=fan2015innovated] requires the estimation of p  ×  p precision matrix, which is by itself a computationally intensive challenging problem. If the related and unrelated predictors are moderately correlated, IISs marginal screening strategy has difficulties in filtering out noise predictors.

To overcome limitations of existing methods, we propose here the stepwise procedure SODA, consisting of three stages: (1) forward main effect screening; (2) forward interaction screening and (3) backward elimination.

Forward main effect screening: Let Mt denote the selected set of main effects at step t. SODA starts with [formula] and iterate the operations below until termination.

For each predictor j∉Mt, create a new candidate set [formula].

Find the predictor j with lowest [formula]. If [formula], continue with Mt + 1  =  Mt,j, otherwise terminate with F and go to 2.

Forward interaction screening: Let Ct denote the selected set of predictors at step t, and [formula] denote the set of terms induced by Ct. SODA starts with [formula] and iterate the operations below until termination.

For each j∉Ct, create a candidate set [formula] and let [formula].

Find the predictor j with lowest [formula]. If [formula], continue with Ct + 1  =  Ct,j, otherwise terminate with F and go to 3.

Backward elimination: Let St denote the selected set of individual terms at step t of backward stage. SODA starts with [formula] and iterate the operations below until termination.

For each main or interaction term j∈St (e.g. j = 1 or [formula]), create a candidate set [formula].

Find term j with lowest [formula]. If [formula], remove term j, otherwise terminate and retain set   =  St.

SODA first runs the forward main effect screening and forward interaction effect screening until no new predictor can be added to reduce the EBIC score, then the backward elimination stage follows until no term should be eliminated. Stepwise forward procedure is widely used on variable screening for linear regressions (e.g. [\cite=wang2009forward] and [\cite=wasserman2009high]). The goal for forward screening stage is to add all related terms into the model at the expense of adding a small number of unrelated ones. The backward stage then removes those false positives. The forward screening does not assume the joint normality among predictors and thus is more robust than IIS. It also does not need to estimate the p  ×  p precision matrix thus can be much faster than IIS.

An important feature of SODA's forward screening is that in each step we only need to evaluate the EBIC for adding each of the p predictors, therefore its time complexity is [formula], which is much less than the number of interaction terms [formula]. Forward screening stage usually reduces the number of predictors to a much smaller number than p. One feature of SODA's backward stage is the exclusion of individual terms instead of all terms relate to one predictor. For example in Eq ([\ref=eq:toy]), true terms include X1X2 and X2X3 therefore X2 is a true predictor, but X22 is not a related term in A. Including X22 in the model increases the variance of estimation thus is sub-optimal. In other words, SODA selects individual main and interaction effect terms. Therefore SODA is adaptive in the sense that it automatically chooses between linear model with only main effect terms or more complicated quadratic classification model.

We note that only the forward interaction screening stage is required for achieving the screening consistency. However, the number of parameters and the EBIC penalization in the forward interaction screening stage increases quadratically with the cardinality of Ct, therefore it can be hard to add predictors with only weak main effects. To optimize the empirical performance, we add to SODA the forward main effect screening stage to identify the predictors with only weak main effects. Asymptotic properties of SODA will be studied in Section [\ref=sec:theory] and effectiveness of SODA will be shown empirically in Sections [\ref=sec:simstudy] and [\ref=sec:realdata].

Implementation issues: tuning parameter and screening depth

In the empirical analysis, we need to choose the tuning parameter γ of EBIC. Sections [\ref=sec:theory] characterizes asymptotic properties of the EBIC and SODA, and provides some guidelines for choosing γ. However, these theoretical results are not directly usable because the consistency result is only valid in an asymptotic sense. In practice, we propose to use a 10-fold cross-validation (CV) procedure for selecting γ from [formula]. For simulation study and real data analysis in Section [\ref=sec:simstudy] and [\ref=sec:realdata], to make SODA more easily comparable with Lasso with EBIC studied in [\cite=chen2012extended], we fix γ = 0.5 which is also used in [\cite=chen2012extended].

The forward screening stage terminates if the EBIC of all candidate models are larger than the EBIC of the current model. Therefore, the screening depth of the forward stage is determined by the EBIC. In Theorem [\ref=theorem:forward], we show that this procedure is asymptotically screening consistent, namely the true related terms will be all included by the end of the forward stage. Nevertheless, SODA is not sensitive to adding more terms in the forward stage, since those unrelated terms will be eventually eliminated in the backward stage. Moreover, missing one related term is usually more harmful than including one unrelated term. Therefore, to optimize the empirical performance, we let SODA continue the forward interaction screening stage for pf steps after the step that fails to decrease EBIC (default pf = 3).

Theoretical properties of SODA

To study theoretical properties of SODA procedure, we assume following regularity conditions:

(C1) The divergence speed of p is bounded above by p  ≤  nκ for some κ > 0, and the size of the true predictor set P is bounded as [formula] for a fixed integer p0.

(C2) Magnitudes of true coefficients in [formula] are bounded above and below by constants, namely there exist positive constants θmax  >  θmin > 0 such that

[formula]

(C3) Let [formula] be the augmented version of [formula], containing intercept 1, as well as all first-order and second-order terms of [formula]. Each [formula] is sub-exponential, i.e. there are positive constants C1 and C2 such that,

[formula]

(C4) Let [formula] denote the covariance matrix of [formula]. There exist constants 0 < τ1  <  τ2  <    ∞   such that

[formula]

where [formula] and [formula] denote the smallest and largest eigenvalues of a matrix.

We first establish the screening consistency of the forward screening stage. We can show that the forward interaction screening step is already screening consistent. To proceed, we need to define the following concept to study the stepwise detectability of true predictors in P.

Let [formula] denote the population version of the risk minimizer,

[formula]

where the expectation is over the joint distribution of [formula]. Let vector [formula] be parameters in [formula] associated with predictor Xj. The stepwise detectable condition is necessary for forward screening consistent.

(Stepwise detectable condition) A set of predictors C1 is stepwise detectable given C2 if [formula], and for any set C satisfying C  ⊃  C2 and [formula], there exist constants θmax  >  θmin > 0, such that

[formula]

where [formula] with [formula] and Ij  =  Mj  ×  Mj, and [formula] denotes the L∞ norm. Let [formula] and [formula]. The set of true predictors P is said to be stepwise detectable if [formula] for all j∈P.

In other words, if the current selection C contains C2, then there always exist detectable predictors conditioning on currently selected variables until we include all the predictors indexed by C1. A true predictor j∈P is not stepwise detectable either because it perfectly correlates with some other terms, or its effects can only be detected conditioning on some other stepwise undetectable terms.

We give an example to illustrate the scenarios when stepwise detectable condition may or may not hold. Suppose there are two true jointly normal relevant predictors X1 and X2 with means μ1 and μ2, and there is only one interaction term X1X2 in model ([\ref=eq:main_model]), i.e. [formula]. P is not stepwise detectable if both μ1 = 0 and μ2 = 0, since [formula] and [formula]. Starting from empty set [formula], the forward procedure will not add any of the two into the model, because there is no main effect for X1 and X2 and the interaction term X1X2 does not correlate with marginal terms X1 and X2. However, if either [formula] or [formula], [formula] is stepwise detectable.

Let [formula] denote the selected set of terms at the end of forward screening stage. It is unrealistic to require F  =  A. However, it should be demanded that F  ⊇  A, i.e. S̃F contains all related terms. We define the forward stage to be screening consistent if [formula]. We also don't want the size of F to be too large, otherwise forward screening loses its purpose. The screening consistency of forward stage is established by the following theorem.

(Forward stage screening consistency) If conditions C1 ~ C4 hold, and all predictors in P are stepwise detectable, then the forward interaction screening stage finishes in finite number of steps and is screening consistent. In particular, as n  →    ∞  ,

[formula]

where [formula], λ1 is a positive constant defined in Lemma 2 in appendix, K is the number of classes, and θmin is a positive constant defined in condition C2.

In other words, asymptotically F contains all predictors in P, which implies F  ⊇  A, and the forward stage stops in finite number of steps.

We show in the following theorem two uniform bounds guaranteeing that all unrelated terms will be eliminated and all related terms will be kept in the backward stage. Once again, symbol j in the theorem indexes a main effect or interaction term.

(Uniform bound of EBIC in backward stage) Fix any positive constant Q > 0. Under conditions C1 ~ C4, as n  →    ∞  ,

[formula]

and

[formula]

for any constant [formula].

Eq ([\ref=eq:backward_1]) implies that if [formula] and [formula], there will be at least one unrelated term [formula] such that removing j from S leads to lower EBIC. Eq ([\ref=eq:backward_2]) implies that if S  ⊃  A and [formula], there is no related term j∈A such that removing j from S leads to lower EBIC. As a summary, as n  →    ∞  , with probability tending to 1, no related term will be eliminated, and all unrelated terms will be eliminated in the backward stage until   =  A. Theorem [\ref=theorem:backward] requires candidate sets have finite size ([formula]), which is proved by Theorem [\ref=theorem:forward] to hold asymptotically for the starting set of the backward stage F. Hence, combining Theorem [\ref=theorem:forward] and [\ref=theorem:backward] establishes the model selection consistency of SODA.

Simulation studies

Logistic regression with only main effects

We first study the performance of SODA under scenarios when there are only main effects but no interactions. In this section, we compare SODA and Lasso (denoted as Lasso-Logistic) on logistic regression variable selection.

We consider two simulation settings in Examples 1.1 and 1.2 respectively. In both examples, we simulated predictors [formula] from the multivariate normal distribution with covariance matrix [formula]. In Example 1.1 we set [formula] to have power decay correlations between variables, and in Example 1.2 we obtained [formula] from a real dataset. Let [formula] denote the Fisher information matrix of the form,

[formula]

Let sub-matrices [formula] and [formula]. The consistency of Lasso-Logistic requires the incoherence condition [\cite=ravikumar2010high] that there exists an [formula] such that

[formula]

Let [formula], then [formula] has the length as the number of unrelated predictors, and the incoherence condition requires each element of [formula] to be smaller than 1.

For each setting, we randomly generated 100 datasets from logistic regression model with [formula] observations, and applied SODA and Lasso-Logistic to each data set. We used [formula] as criterion for both SODA and Lasso-Logistic. Lasso-Logistic fitted a solution path of selected predictors, and chose the optimal set of predictors with the lowest [formula]. In simulation studies, we set γ = 0.5 for SODA and Lasso-Logistic. We calculated the average number of false negatives (FN) and false positives (FP), and the percentage of correct fits (PCF), which is the percentage of times that the selected set is the true set A. For SODA, any selected interaction term would also be considered as a false positive.

Example 1.1. Let p = 1000, and we randomly selected 5 true predictors with coefficients [formula], j∈A. The covariance matrix is set to have power decay correlation such that [formula]. Following a similar argument as Corollary 3 of [\cite=zhao2006model], it is easy to show that [formula] satisfies the incoherence condition. The histogram of elements of [formula] in log-scale for one simulation run is plotted in Figure [\ref=fig:sim_c_hist], and it is shown that no [formula] in [formula]. As shown in Figure [\ref=fig:sim_1], SODA and Lasso-Logistic had very similar performances under this setting.

Example 1.2. In this example, we also randomly selected 5 true predictors with coefficients [formula], j∈A. The covariance matrix [formula] was set to be the sample covariance matrix of the Michigan lung cancer dataset [\cite=beer2002gene] analyzed in Section [\ref=sub:mich_lung] for p = 5,217 genes. So Example 1.2 had a much higher dimension than Example 1.1. The histogram of elements of [formula] in log-scale for one simulation run is plotted in Figure [\ref=fig:sim_c_hist].

As illustrated by Figure [\ref=fig:sim_c_hist], in real dataset predictors are usually highly correlated with each other, and the incoherence condition is strongly violated. As shown in Figure [\ref=fig:sim_1], in this case Lasso-Logistic had a very poor performance whereas SODA performed robustly. As n increases, the Lasso-Logistic's total number of FPs and FNs increased, and PCF stayed at zero. In contrast, SODA had increasing probability of selecting the correct model A as n increases. In both two examples, SODA did not select no any interaction term for all simulations.

Quadratic discriminant analysis with interactions

In this section, we compare performances of several methods on variable and interaction selection for quadratic relationship models. Besides SODA, we also consider the backward procedure proposed in [\cite=zhang2011bic], denoted as ZW, and the forward-backward procedure proposed in [\cite=murphy2010variable], denoted MDR. Both methods assume joint normality between [formula] and [formula] as specified in Eq ([\ref=eq:XAc|XA] [\ref=Y=00003Dk-MVN]). We also consider the IIS-SQDA in [\cite=fan2015innovated]. The screening stage of IISQ-SQDA assumes the joint normality between [formula] and [formula], while the variable and interaction selection stage does not depend on the assumption. SODA does not assume the joint normality throughout the procedure.

We consider five simulation settings respectively in Examples 2.1 - 2.5. The first setting follows the multivariate normal model as assumed in Eq ([\ref=eq:XAc|XA] [\ref=Y=00003Dk-MVN]) while the other settings do not. There are two classes (K = 2) and p predictors, where the first 3 predictors, X1, X2 and X3, are related predictors and other p - 3 predictors are unrelated but correlated with the 3 related predictors. Example 2.1 - 2.4 are low-dimensional with p = 50, and Example 2.5 studies the high-dimensional scenario with p = 1000. Mean vectors and covariance matrices for the two classes are [formula], [formula], [formula], and [formula], where [formula] and [formula]. The true classification rule is classifying an observation to class 1 if [formula], where

[formula]

There are one linear effect term on X1 and four interaction effect terms on X1, X2 and X3, and [formula]. X1, X2 and X3 are related predictors, but not all of their associated terms are in A.

For each simulation setting, we generated 100 datasets with 10 different sample sizes for each class, ranging linearly in log-scale from 100 to 1000: [formula]. For SODA and IIS-SQDA, the set of selected predictor variables is defined as the union of all predictors appear in selected linear and interaction terms. We calculated the average number of false negatives and false positives for variable selection (VFN and VFP), main effect term selection (MFN and MFP), and interaction term selection (IFN and IFP).

To benchmark the classification accuracy, we also include the full model of LDA and QDA with all predictors, and the Oracle model that contains exactly the five true terms. The average classification test error rate (TE) of models is estimated by testing the trained model on 10,000 extra observations simulated from true models. Results for these five examples are shown in Figure [\ref=fig:sim_2.1-2.4] and [\ref=fig:sim_2.5]. For SODA and IIS-SQDA, we also counted the number of FNs and FPs for main effect and interaction terms that are shown in Table [\ref=tab:sim_2.1-2.5_MI].

Example 2.1. (Multivariate normal predictors) Unrelated predictors were simulated as linear combinations of Xk and Xl, with Gaussian noise. For [formula],

[formula]

where Xk and Xl are randomly selected from X1, X2 and X3, coefficients bj,0, bj,1 and bj,2 are drawn from uniform distribution [formula], and Gaussian noise term [formula].

Since the linear-Gaussian assumption in Eq ([\ref=eq:XAc|XA] [\ref=Y=00003Dk-MVN]) hold for this example, three methods ZW, MDR and SODA were able to detect all relevant predictors in [formula] as n increases, and both VFN and VFP were low. However, it seems that IIS-SQDA selected too false positives, and the number VFP+VFN increased with n. Estimated classification errors for different methods are also shown in Figure [\ref=fig:sim_2.1-2.4]. As expected, LDA and QDA without variable selection performed the worst, and methods consistent in this scenario (ZW, MDR and SODA) achieved almost Oracle classification accuracy. IIS-SQDA performed sub-optimal due to its selection of too many irrelevant terms.

The individual term selection performance of IIS-SQDA and SODA are shown in Table ([\ref=tab:sim_2.1-2.5_MI]). It shows that SODA selected individual terms correctly. The phenomenon that IIS-SQDA tends to select too many false positive terms was also observed in [\cite=fan2015innovated], and the reason is that the variable selection consistency of elastic net procedure in IIS-SQDA requires the so-called Elastic Irrepresentable Condition [\cite=jia2010model] that might not hold in this case.

Example 2.2. (Cauchy unrelated predictors) We consider the scenario when the distribution of unrelated predictors have heavy tails and contain outliers. In particular, each unrelated predictor Xj, [formula], was simulated as

[formula]

As shown in Figure [\ref=fig:sim_2.1-2.4], ZW and MDR on average selected about 20 and about 45 false positive and negative predictors, and classification accuracies were close to 50%, which demonstrates the sensitivity of two methods to the joint normality assumption in ([\ref=eq:XAc|XA] [\ref=Y=00003Dk-MVN]). In contrast, SODA is robust to the heavy tail and outliers in unrelated predictors. IIS-SQDA worked almost as well as SODA.

Example 2.3. (Quadratic unrelated predictors) We simulate scenarios where unrelated predictors are non-linearly dependent on related predictors. In particular, each unrelated predictor was simulated as a quadratic function of X1 and X2 with Gaussian noise. For [formula],

[formula]

where Xk and Xl were randomly selected from X1, X2 and X3, coefficients bj,0, ..., bj,4 are drawn from [formula], and [formula]. As shown in Figure [\ref=fig:sim_2.1-2.4], ZW and MDR methods selected on average 4 to 10 false positive and negative predictors. IIS-SQDA selected a large number of false positive main and interaction terms, as shown in Table [\ref=tab:sim_2.1-2.5_MI], due to the correlation between related and unrelated predictors as well as correlation between main and interaction terms.

Example 2.4. (Heteroskedastic model) We simulated the unrelated predictors from the following model. For [formula],

[formula]

where Xk and Xl were randomly selected from X1, X2 and X3, coefficients bj,1 and bj,3 are simulated from [formula], and [formula]. It violates the constant variance assumption of ZW and MDR as specified in Eq ([\ref=eq:XAc|XA] [\ref=Y=00003Dk-MVN]). Same as previous two examples, ZW, MDR and IIS-SQDA had sub-optimal performance. SODA selected almost no VFP and VFN, and achieved almost Oracle prediction accuracy when [formula].

Example 2.5. (High dimensional scenario with p = 1000) Unrelated predictors were simulated as follows. For [formula], we first drew all predictors from [formula], [formula], and then randomly picked 40% of them and re-simulated their non-linear correlation between Xj and [formula] similarly as ([\ref=eq:sim_3]), ([\ref=eq:sim_4]) or ([\ref=eq:sim_5]), where k and l were randomly drawn from [formula]. For [formula], we first drew all predictors from [formula], and then randomly picked 40% of them and re-simulated their non-linear correlation between Xj and [formula] similarly as ([\ref=eq:sim_3]), ([\ref=eq:sim_4]) or ([\ref=eq:sim_5]), where k and l are indexes uniformly drawn from [formula]. We changed ZW to a forward procedure since the backward procedure is not feasible when p > n. Results are shown in Figure [\ref=fig:sim_2.5] and Table [\ref=tab:sim_2.1-2.5_MI]. MDR results are not shown because it is unstable for highly correlated [formula] matrix and usually keeps on adding new predictors until the estimation of covariance matrices become singular. Overall, SODA achieved much better performance compared to ZW and IIS-SQDA, and the classification accuracy of SODA was almost the same as the Oracle model for n > 100.

To compare the computational efficiency of IIS-SQDA, ZW and SODA, we show their running times in log-scale versus n in Figure [\ref=fig:sim_2.5_time]. IIS procedure requires the estimation of p  ×  p precision matrix, which can be slow in high-dimensional setting. On average, IIS-SQDA took 800 minutes, ZW took 22 minutes and SODA took 4 minutes to analyze one simulated dataset with p = 1000 and n = 1000. SODA was more than 200 times faster than IIS-SQDA in this setting.

Real data analysis

We applied SODA, Lasso-Logistic, MDR and IIS-SQDA on real datasets to compare their performances. We did not include ZW method due to its similarity with MDR. The classification accuracy of selected models were evaluated by 10-fold cross-validation after the variable selection. For Lasso-Logistic and SODA, we used [formula] as model selection criterion. We consider two cancer biomedical datasets analyzed in [\cite=efron2009empirical]: prostate cancer dataset and Michigan lung cancer dataset. Both of two datasets are in high dimension (p > 5000). We also consider a dataset with a smaller dimension (p = 33), Ionosphere, which is publicly available in the UCI Machine Learning Repository.

Prostate cancer dataset

The microarray technology is widely used for measuring expression abundance of genes. There have been tremendous efforts on building classification methods to diagnose cancer patients from microarray data. In [\cite=singh2002gene], researchers measured the gene expressions of 52 prostate cancer patients and 50 controls on p = 6,033 genes. The goal is to predict whether a person has prostate cancer from the expression of those genes. [\cite=efron2009empirical] proposed an empirical Bayes approach for large-scale classification, and compared the performance of it with the shrunken centroids method proposed in [\cite=tibshirani2002diagnosis]. With different thresholds, the shrunken centroids method and the empirical Bayes report selected set of predictors truncated at different sizes. The common way of applying two methods is to obtain selected predictors with different thresholds, and pick the best set by cross-validation. We compare the performance of methods by calculating the cross-validation prediction error on selected gene sets with different sizes. The number of selected genes and the 10-fold cross-validation error (CVE) of two methods on different thresholds are shown in Table [\ref=tab:prostate].

The shrunken centroids method selected 377 genes at the threshold λ = 2.16 that achieved the lowest CV error, and empirical Bayes method selected the best set with 51 genes. In the solution path of Lasso-Logistic, the lowest [formula] was achieved at 133.3 with 3 genes, and the corresponding cross-validation error rate was 17%. SODA selected 6 main effects and 0 interaction with [formula] score at 93.4 and cross-validation error rate 6%.

MDR method failed to converge on this dataset. In particular, MDR selects as many genes as possible until the number of selected genes was the same as the number of samples in the smaller class (50). Subsequently the estimated covariance matrix for the smaller class became singular and the procedures could not proceed. [formula], defined as the difference of [formula] in Eq ([\ref=eq:BIC_G]) between two adjacent steps, is shown for each step in Table [\ref=tab:prostate]. MDR proceeds if [formula] and eventually selects 49 genes with cross-validation error rate 52%.

We applied IIS-SQDA method by running R code provided by its authors, but for this dataset the analysis did not finish in 48 hours. The reason is as noted in [\cite=fan2015innovated] that IIS needs to estimate the precision matrices, which can be very slow when the number of predictors p is large.

Michigan lung cancer dataset

We next consider the Michigan lung cancer dataset that was also analyzed in [\cite=efron2009empirical]. This dataset was published in [\cite=beer2002gene], in which researchers measured the expression for p = 5,217 genes for 86 lung cancer patients. Among the 86 patients, 62 are labeled as in "good status", and 26 in "bad status". The goal is to classify new patients into one of two statuses.

Results on this dataset are summarized in Table [\ref=tab:mich_lung]. IIS-SQDA procedure also did not finish in 48 hours for this dataset. In the solution path of Lasso-Logistic, the lowest [formula] was achieved at 112.2 with 1 gene, and the corresponding cross-validation error rate was 29%. SODA selected 2 main effect and 2 interaction effect terms with [formula] score at 69.8 and cross-validation error rate 11%. Same as observed from prostate cancer dataset, SODA worked much better than Lasso-Logistic for finding the minimum of [formula] (69.8 vs 112.2). Comparing results of Lasso-Logistic and SODA selected models, it is obvious that interaction effects selected by SODA contribute substantially to the classification accuracy.

MDR also failed to converge on this dataset. MDR selected as many genes as possible until the number of selected genes was same as the number of samples in the smaller class (26) and achieves cross-validation error rate 28%. The observation that MDR failed to converge for both of these two large p datasets illustrates the fact that the QDA variable selection methods with joint normality assumption work poorly for high-dimensional real datasets.

Ionosphere dataset

This dataset is a two-class classification problem with 351 samples and 32 predictors. Targets are "Good" and "Bad" radar returns from the ionosphere. "Good" radar returns are those showing evidence of some type of structure in the ionosphere, while "Bad" returns do not.

We applied Lasso-Logistic, MDR, IIS-SQDA and SODA on this dataset. Since this dataset only contains 32 predictors, it is feasible to run Lasso with all interaction terms. Therefore we also run Lasso-Logistic with all main effect terms and [formula] interaction terms, which is referred as Lasso-Logistic-2. Results are summarized in Table [\ref=tab:Ionosphere]. In the solution path of Lasso-Logistic, the lowest [formula] was achieved at 302.9 with 6 predictors, and the corresponding cross-validation error rate was 14%. Lasso-Logistic-2 selected 2 main effect terms and 5 interaction terms with [formula] 248.7 and CV error rate 8%. SODA selected 4 main effect and 4 interaction effect terms with [formula] score at 204.2 and cross-validation error rate 6%. Same as observed above, SODA worked better than Lasso-Logistic for minimizing [formula] (204.2 v.s. 302.9 and 248.7).

MDR method selected all 32 predictors and achieves cross-validation error rate 28%. IIS-SQDA selected 10 main effect and 96 interaction terms and achieved cross-validation error rate 16%. Since MDR selected all 32 predictors, by definition MDR selected model is the full QDA model. Comparing the CVE of this full QDA model and SODA selected model, it is obvious that variable selection substantially reduces the classification error rate and is essential to real dataset analysis.

Concluding remarks

We study the variable and interaction selection for logistic regression with second-order terms, which covers QDA as a special case. We propose a two-stage stepwise procedure SODA that is computationally efficient and enjoys nice theoretical property. Asymptotic properties of SODA are studied under high-dimensional setting. Contrast to [\cite=murphy2010variable] [\cite=zhang2011bic] [\cite=maugis2011variable], the consistency of SODA does not require joint normality assumption of related and unrelated predictors. Compared to IIS in [\cite=fan2015innovated], SODA's forward screening does not need to make normal assumption and does not need to estimate large precision matrices. By empirical studies, we show that SODA not only has better selection accuracy compared to other methods but is also much faster. SODA is applicable for model selection for logistic regression, linear/quadratic discriminant analysis and other discriminant analyses with generative model [formula] in multivariate exponential family.

LDA and QDA complement each other in terms of the bias-variance trade-off. Given finite observations, LDA is simpler and more robust when the response Y is mostly correlated with linear effects of [formula]. QDA has the ability to exploit interaction effects, which may contribute dramatically to classification accuracy, but has much more parameters to estimate and is more vulnerable to selected noise predictors. SODA is designed to be adaptive in the sense that it automatically chooses between LDA or QDA model and take advantages from both sides. Instead of selecting predictors, SODA selects individual main and interaction effect terms, which enables SODA to simultaneously utilize interaction terms and get rid of unrelated terms to avoid large number of parameters to estimate.

The main limitation of SODA is that the stepwise detectable condition might not hold when marginal effects are very weak. However, in empirical studies we found the SODA works well and has better performance compared to other methods, which suggests this problem may not be severe in real data. Indeed, even for QDA it takes some efforts to construct mean vectors and covariance matrices that result in only interaction but no main effect.

The implementation of SODA procedure is available in R package sodavis on CRAN (http://cran.us.r-project.org).