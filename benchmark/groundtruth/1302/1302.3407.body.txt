A consistent clustering-based approach to estimating the number of change-points in highly dependent time-series

Introduction

Change-point estimation is a classical problem in statistics and machine learning, with applications in a broad range of domains, such as market analysis, bioinformatics, audio and video segmentation, fraud detection, only to name a few. The change-point problem may be described as follows. A sequence [formula] is composed of some (unknown) number κ + 1 of non-overlapping segments. Each segment is generated by one of r (unknown) stochastic process distributions. The process distributions that generate every pair of consecutive segments are different. The index where one segment ends and another starts is called a change point. The change-points are unknown, and the objective is to estimate them given [formula].

In this work we consider the change-point problem for highly dependent data, making as little assumptions as possible on how the data are generated. In particular, the distributions that generate the data are unknown and can be arbitrary; the only assumption is that they are stationary ergodic. This means that we make no such assumptions as independence, finite memory or mixing. Moreover, we do not require the finite-dimensional marginals of any fixed size before and after the change points to be different.

However, with no further assumptions or additional information, the estimation of the number of change-points is impossible even in the weakest asymptotic sense. Indeed, as shown by [\cite=Ryabko:10discr], it is impossible to distinguish even between the cases of 0 and 1 change-point in this setting, even for binary sequences. As an alternative to imposing stronger assumptions on the distributions that would allow for the estimation of the number of change points, we assume that the correct number r of the process distributions that generate [formula] is provided as a parameter.

This formulation is motivated by applications. Indeed, the assumption that the time-series data are highly dependent complies well with most real-world scenarios. Moreover, in many applications the number r of distributions is a natural parameter of the problem. For instance, the case of just r = 2 distributions can be interpreted as normal versus abnormal behavior; one can imagine a sequence with many change-points in this scenario. Another application concerns the problem of author attribution in a given text written collaboratively by a known number r of authors. In speech segmentation r may be the total number of speakers. In video surveillance as well as in fraud detection, the change may refer to the point where normal activity becomes abnormal (r=2). The identification of coding versus non-coding regions in genomic data is yet another potential application. In other words, in many real-world applications the number r of process distributions comes with a natural interpretation.

Main Results. We propose a nonparametric algorithm to estimate the number of change points and to locate the changes in time-series data. We demonstrate both theoretically and experimentally that our algorithm is asymptotically consistent in the general framework described. A key observation we make is that given the total number r of process distributions, estimating the number of change-points is possible via a consistent time-series clustering method. We use a so-called list-estimator to generate an exhaustive list of change-point candidates. This induces a partitioning of the sequence into consecutive segments. We then apply a simple clustering algorithm to group these segments into r clusters. The clustering procedure uses farthest-point initialization to designate r cluster centers, and then assigns each remaining point to the nearest center. To measure the distance between the segments, empirical estimates of the so-called distributional distance [\cite=Gray:88] are used [\citep=Ryabko:10clust]. In each cluster, we identify the change-point candidate that joins a pair of consecutive segments as redundant. Finally, we remove the redundant estimates from the list and provide the remaining estimates as output. The consistency of the proposed method can be established using any list-estimator that is consistent under the considered framework, in combination with the time-series clustering algorithm mentioned above. An example of a consistent list-estimator is provided by [\cite=khaleghi:12mce]. Thus, the proposed method establishes a new link between two classical unsupervised learning problems: clustering and change-point analysis, potentially bringing a new insight to both communities.

Related Work. In a typical formulation of the change-point problem the samples within each segment are assumed to be generated i.i.d, the distributions have known forms and the change is in the mean. In more general nonparametric settings, the form of the change and/or the nature of dependence are usually restricted. For example. the process distributions are assumed to be strongly mixing [\citep=brodsky:93] [\citep=basseville:93] [\citep=Giraitis:95] [\citep=HarizWylieZhang2007] [\citep=Carlstein:93], and the finite-dimensional marginals are almost exclusively assumed to be different. The problem of estimating the number of change-points is nontrivial, even under these more restrictive assumptions. In such settings, this problem is usually addressed with penalized criteria; see, for example, [\citep=Lebarbier2005717] [\citep=Lavielle20051501]. Such criteria necessarily rely on additional parameters, and the resulting number of change-points depends on these parameters. Note that the algorithm proposed in this work also requires an input parameter: the number r of distributions. However, this parameter has a natural interpretation in many real-world applications as discussed above.

For the general framework considered in this work, the particular case of a known number κ of change points has been considered in [\citep=Ryabko:103s] (κ=1) and [\citep=arxiv12] (κ > 1). However, if the number κ of change-points provided to the algorithm is incorrect, the behavior of these algorithms can be arbitrarily bad. An intermediate solution for the case of unknown κ in this general setting is given by [\cite=khaleghi:12mce] where a list estimator is proposed: a (sorted) list of possibly more than κ candidate estimates is produced whose first κ elements are consistent estimates of the change-points. The algorithms in these works, as well as in the present paper, are based on empirical estimates of distributional distance, which turns out to be a rather versatile tool for studying stationary ergodic time series.

Organization. In Section [\ref=sec:pre] we introduce some preliminary notation and definitions. In Section [\ref=sec:protocol] we formalize the problem. In Section [\ref=sec:theoretical] we present our algorithm and give an informal description and in Section [\ref=sec:proof] we prove the main consistency result. In Section [\ref=sec:exp] we present some experimental results and finally in Section [\ref=sec:conc] we provide our conclusions.

Preliminaries

Let X be a measurable space (the domain); in this work we let [formula] but extensions to more general spaces are straightforward. For a sequence [formula] we use the abbreviation X1..n. Consider the Borel σ-algebra B on X∞ generated by the cylinders [formula], where the sets [formula] are obtained via the partitioning of Xm into cubes of dimension m and volume 2- ml (starting at the origin). Let also [formula]. Process distributions are probability measures on the space (X∞,B). For [formula] and B∈Bm let [formula] denote the frequency with which [formula] falls in B, i.e.

[formula]

A process ρ is stationary if for any i,j∈1..n and [formula], we have ρ(X1..j∈B) = ρ(Xi..i + j - 1∈B). A stationary process ρ is called ergodic if for all B∈B with probability 1 we have lim n  →    ∞ν(X1..n,B)  =  ρ(B).

The distributional distance between a pair of process distributions ρ1,ρ2 is defined as follows [\citep=Gray:88].

[formula]

where we set wj: = 1 / k(k + 1), but any summable sequence of positive weights may be used.

In words, this involves partitioning the sets Xm, [formula] into cubes of decreasing volume (indexed by l) and then taking a sum over the differences in probabilities of all the cubes in these partitions. The differences in probabilities are weighted: smaller weights are given to larger m and finer partitions. We use empirical estimates of this distance defined as follows.

The empirical estimate of the distributional distance between a sequence [formula] and a process distribution ρ is given by

[formula]

and that between a pair of sequences [formula]. is defined as

[formula]

While the calculation of (  ·  ,  ·  ) involves infinite summations it is fully tractable. Remark 1 (Calculating (  ·  ,  ·  )) Consider a pair of sequences [formula] with [formula]. Let smin correspond to the partition where each cell B∈B contains at most one point i.e.

[formula]

Indeed in [\eqref=eq:emd1] all summands corresponding to m >  max i = 1,2ni equal 0; moreover, all summands corresponding to l > smin are equal. Thus as shown by [\cite=Ryabko:10clust] even the most naive implementation of [formula] has computational complexity O(n2 log n log smin) which may be further optimized to [formula], see [\citep=khaleghi:12mce] [\citep=Ryabko:10clust] [\citep=khaleghi:12].

Problem Formulation

We formalize the problem as follows. The sequence [formula] is formed as the concatenation of some unknown number κ + 1 of sequences

[formula]

where θk∈(0,1), ~ k = 1..κ. Each of the sequences [formula] is generated by one out of r  ≤  κ + 1 unknown stationary ergodic process distributions [formula]. Thus, there exists a ground-truth partitioning

[formula]

of the set {1..κ + 1} into r disjoint subsets where for every k = 1..κ + 1 and r' = 1..r we have k∈Gr' if and only if [formula] is generated by ρr'. The parameters θk, ~ k = 1..κ are called change-points since the indices nθk, ~ k = 1..κ separate consecutive segments [formula] generated by different process distributions. The change-points are unknown, and our goal is to estimate them given the sequence [formula]. The process distributions [formula] are completely unknown and may even be dependent. Moreover, the means, variances, or more generally, the finite-dimensional marginal distributions of any fixed size before and after the change-points are not required to be different. We consider the most general scenario where the process distributions are different. Let the minimum separation of the change-points be defined as

[formula]

Since the consistency properties we are after are asymptotic in n, we require that λmin > 0. This is because if the length of one of the sequences is constant or sub-linear in n then asymptotic consistency is impossible in this setting. Note, however, that we do not make any assumptions on the distance between the process distributions (e.g., the distributional distance): they may be arbitrarily close.

Since it is provably impossible [\citep=Ryabko:10discr] to distinguish between the case of one and zero change-points in this general framework, the number κ of change-points cannot be estimated with no further information. Instead of making additional assumptions on the nature of the distributions generating the data, we assume that the total number r of distributions is provided (while the number κ of change-points remains unknown).

Thus, the problem formulation we consider is as follows: given a sequence [formula], a lower-bound on the minimum separation of the change points λ, and the total number of distributions r, it is required to find the number of changes κ and estimate the change points [formula]. A change-point estimator is a function that takes a sequence [formula] to produce a number [formula] (estimated number of change points) and a set [formula] of estimated change points. It is asymptotically consistent if with probability 1 we have   =  κ from some n on and The algorithm we propose relies on a so-called list-estimator, which is a procedure that, given [formula] and λ, outputs a (long, exhaustive) list of change point estimates, without attempting to estimate the number of changes. More precisely, we have the following definition.

A list-estimator Υ is a function that, given a sequence [formula] and a number λ∈(0,1), produces a set [formula] of some [formula] estimates [formula], that are at least λ apart: where 0(n): = 0, ~ m + 1(n): = 1.

Let [formula] have change-points at least λmin apart for some λmin∈(0,1). A list-estimator Υ is said to be consistent if for every λ∈(0,λmin) there is a subset [formula] of [formula] for some μi∈1..m, ~ i = 1..κ such that with probability one we have

An example of a consistent list-estimator is provided in [\citep=khaleghi:12mce]. In particular we use the following statement.

There exists a consistent list-estimator Υ.

Main Result

In this section we introduce an asymptotically consistent algorithm for estimating the number of change points and locating the changes.

Let [formula] be a sequence with change-points at least λmin apart, for some λmin∈(0,1). Let r denote the total number of process distributions generating [formula]. Then CluBChaPo[formula] is asymptotically consistent for all λ∈(0,λmin].

The proof of Theorem [\ref=thm1] is deferred to Section [\ref=sec:proof]; here we provide an intuitive explanation of how the algorithm works and why it is consistent. The algorithm works as follows. First, a (consistent) list-estimator is used to obtain an initial set of change-point candidates. The candidates are sorted in increasing order to produce a set S of consecutive non-overlapping segments of [formula]. The set S is then partitioned into r clusters. In each cluster, the change-point candidate that joins a pair of consecutive segments of [formula] is identified as redundant and is removed from the list. Once all of the redundant candidates are removed, the algorithm outputs the remaining change-point candidates. Next we give an intuitive explanation as to why the algorithm works.

Since the list estimator Υ is consistent, from some n on an initial set of possibly more than κ change-points are generated that is guaranteed to have a subset of size κ whose elements are arbitrarily close to the true change-points. Therefore, from some n on the largest portion of each segment in S is generated by a single process distribution. Since the initial change-point candidates are at least nλ apart, the segments in S have lengths linear in n. Thus, we can show that from some n on the distance between a pair of segments in S converges to 0 if and only if the same process distribution generates most of the two segments. Given the total number of process distributions, from some n on the clustering algorithm groups together those and only those segments in S that are generated by the same process distribution. This lets the algorithm identify and remove the redundant candidates. By the consistency of Υ the remaining estimates converge to the true change-points.

As an example of a consistent list-estimator the method proposed by [\cite=khaleghi:12mce] may be used. This algorithm outputs a list of estimates whose first κ elements converge to the true change-points, provided that the parameter λ satisfies λ∈(0,λmin]. Since κ is unknown, all we can use here is that the correct change-point estimates are somewhere in the list. In general the algorithm may use any list-estimator that is consistent (in the sense of Definition [\ref=defn:gen]) for stationary ergodic time series. In the proposed algorithm the following consistent clustering procedure is used. First, a total of r cluster centers are obtained as follows. The first segment [formula] is the first cluster center. Through an iteration on j = 2..r a segment is chosen as a cluster center if it has the highest minimum distance from the previously chosen cluster centers. Once the cluster centers are specified, the remaining segments are assigned to the closest cluster. Remark 2 (Computational Complexity) In this implementation, an initial set of λ- 1 change-point candidates is obtained by the algorithm of [\cite=khaleghi:12mce] which as shown by the authors has complexity [formula]. It is easy to see that the clustering procedure requires rλ- 1 pairwise distance calculations to partition the λ- 1 + 1 segments into r groups. By Remark 1, (  ·  ,  ·  ) has computational complexity of [formula]. The remaining calculations are of order O(r(λ- 1 + 1)). This brings the resource complexity of the proposed algorithm to [formula].

Proof of Theorem [\ref=thm1]

In this section we prove the consistency of the proposed algorithm. The proof relies on a Lemma [\ref=prop0]. We introduce the following additional notation. Consider the set S of segments specified by [\eqref=alg:main:eq:segs] in Algorithm [\ref=alg:main]. For every segment [formula] where i = 1..m + 1 define [formula] as the process distribution that generates the largest portion of [formula]; that is, first define and then let [formula] where j is such that K∈Gj, and Gj, ~ j = 1..r are the ground-truth partitions defined by [\eqref=eq:gt].

Let [formula] be a sequence with κ change-points at least λmin apart for some λmin∈(0,1). Assume that the distributions that generate [formula] are stationary and ergodic. Let S be the set of segments specified by [\eqref=alg:main:eq:segs] in Algorithm [\ref=alg:main]. For all λ∈(0,λmin) with probability one we have

Fix an ε∈(0,λ / 2). There exists some T such that

[formula]

Moreover, for every n  ≥  T / λ and m∈1..T we have

[formula]

For simplicity of notation define πk: = nθk, ~ k = 1..κ. Since the initial set of change-point candidates are produced by a consistent list-generator Υ (see Definition [\ref=defn:gen]), there exists an index-set [formula] and some N0 such that for all n  ≥  N0 we have

[formula]

Moreover, the initial candidates are at least nλ apart so that

[formula]

where ψ0: = 0 and ψm + 1: = n. Let [formula]. By [\eqref=prop0:eq:constmuk] and [\eqref=prop0:eq:linlen] for all n  ≥  N0 the candidates indexed by I' have linear distances from the true change-points.

[formula]

Denote by [formula] the subset of the segments in S whose elements are formed by joining pairs of consecutive elements of I' and let [formula] be its complement. Let the true change-points that appear immediately to the left and to the right of an index j∈1..n - 1 be given by

[formula]

respectively, with π0: = 0, ~ πκ + 1: = n where equality occurs when j is itself a change-point. 1. Consider [formula]. Observe that by definition [formula] cannot contain a true change-point for n  ≥  N0 since otherwise either i - 1 or i would belong to I contradicting the assumption that [formula]. Therefore for all n  ≥  N0 we have [formula] where [formula] is the process distribution that generates XL(ψi - 1)..R(ψi - 1). To show that [formula] we proceed as follows. For each [formula] we can find a finite subset βm,l of Bm,l such that ρ(βm,l)  ≥  1 - ε. Observe that the segments XL(ψi - 1)..b have lengths at least λn for all b∈L(ψi - 1) + nλ..R(ψi - 1). Therefore, for every [formula] there exists some N(B) such that for all n  ≥  N(B) with probability 1 we have

[formula]

Using the definition of ν(  ·  ,  ·  ) given by [\eqref=eq:nu] we obtain the following algebraic manipulation of the frequency function. For every [formula] we have where the last summation is upper bounded (in absolute value) by [formula]. Let [formula]. For all n  ≥  Ni' we have

[formula]

where [\eqref=p2] follows from [\eqref=prop:eq:ml], the definition of βm,l and the fact that |ν(  ·  ,  ·  ) - ρ(  ·  )|  ≤  1; [\eqref=p3] follows from [\eqref=eq:numan], and [\eqref=p4] follows from [\eqref=prop:eq:mbound], [\eqref=prop0:eq:linlen], and [\eqref=prop0:eq:freq]. Let N': =  max i∈|S1|Ni'. For all n  ≥  N' we have

[formula]

2. Take [formula]. Observe that by definition [formula] so that either i - 1 or i belong to I. We prove the statement for the case where i - 1∈I. The case where i∈I is analogous. We start by showing that   ⊆  [π   -   ε,π'  +  ε] for all n  ≥  N0 where, Since i - 1∈I, by [\eqref=prop0:eq:constmuk] for all n  ≥  N0 we have [formula]. We have two cases. Either i∈I so that by [\eqref=prop0:eq:constmuk] for all n  ≥  N0 we have [formula], or i∈I' in which case ψi  <  π'. To see the latter statement assume by way of contradiction that ψi  >  π' where π'  ≠  n; (the statement trivially holds for π' = n). By the consistency of Υ there exists some j  >  i  -  1∈I such that [formula] for all n  ≥  N0. Thus from [\eqref=prop0:eq:constmuk] and [\eqref=prop:eq:mingap] we obtain that ψi  -  ψj  ≥  λ - 2ε > 0. Since the initial estimates are sorted in increasing order, this implies j  ≤  i leading to a contradiction. Thus we have   ⊆  [π   -   ε,π'  +  ε] so that [formula] where ρ is the process distribution [formula] that generates Xπ..π'. To show that [formula] we proceed as follows. Let π'': =  min {ψi,π'}. It is easy to see that by [\eqref=defn:thetamin], [\eqref=prop:eq:mingap], and the assumptions that λmin > 0 and λ∈(0,λmin) the segment Xπ..π'' has length at least nλ. Therefore, for each [formula] we can find a finite subset βm,l of Bm,l such that ρ(βm,l)  ≥  1 - ε. For every [formula] there exists some N'(B) such that for all n  ≥  N'(B) we have

[formula]

For every B∈Bm,l, ~ m,l∈1..T we have the following algebraic manipulation of [formula]. For all B∈βm,l, ~ m,l∈1..T and all n  ≥   max {N0, max B∈βm,l, ~ m,l∈1..TN'(B)} we have, where the first inequality follows from [\eqref=prop:newdec] and the second inequality follows from [\eqref=prop0:eq:constmuk], [\eqref=prop0:eq:linlen] and [\eqref=prop:eq:freq]. Let [formula]. For all n  ≥  Ni'' we have,

[formula]

where the first inequality follows from [\eqref=prop:eq:ml], the definition of βm,l and observing that |ν(  ·  ,  ·  ) - ρ(  ·  )|  ≤  1 and the second inequality follows from[\eqref=prop:eq:mbound], [\eqref=prop0:eq:linlen] and [\eqref=prop:numanbound]. Let [formula]. For n  ≥  N'' we have

[formula]

Finally, by [\eqref=prop:firsthalf] and [\eqref=prop:secondhalf] for all n  ≥   max {N',N''} we have [formula] Since ε can be chosen arbitrary small, this proves the statement.

(of Theorem [\ref=thm1]) Let δ: =  min r'  ≠  r''∈1..rd(ρr',ρr'') denote the minimum distance between the distinct distributions that generate [formula]. Fix an ε∈(0,δ / 4). By Lemma [\ref=prop0] and applying the triangle inequality there exists some N1 such that for all n  ≥  N1 we have

[formula]

Let πk: = nθk, ~ k = 1.κ. By the consistency of Υ (see Definition [\ref=defn:gen] and Proposition [\ref=thm0]) there exists some N2 such that for all n  ≥  N2 there exists a set [formula] such that

[formula]

Let N: =  max Ni, ~ i = 1,2. By [\eqref=thm:same] for all n  ≥  N we have

[formula]

where cj, ~ j = 1..r is given by [\eqref=alg:cj]. Hence, the cluster centers [formula] are each generated by a different process distribution. On the other hand, the rest of the segments are each assigned to the closest cluster, so that from ([\ref=thm:same]) for all n  ≥  N we have

[formula]

By construction the index-set C generated by Algorithm [\ref=alg:main] corresponds to those and only those change-point candidates that separate consecutive segments assigned to different clusters, by [\eqref=thm:const_tag] for all n  ≥  N and all i∈C we have [formula]. Thus   =  κ and [formula]. Notice that by [\eqref=thm_eq_const] ψμk, ~ k = 1..κ are consistent estimates of πk.

Experimental Results

In this section we present empirical evaluations of our algorithms on synthetically generated data. To generate the data we use stationary ergodic process distributions that do not belong to any "simpler" general class of time-series, and cannot be approximated by finite state models. In particular they cannot be modeled by hidden Markov process distributions with finite state-spaces. Moreover, the single-dimensional marginals of all distributions are the same throughout the generated sequence. Similar distribution families are commonly used as examples in this framework [\citep=Sheilds:96]. The distributions and the procedure to generate a sequence [formula] are as follows. Fix a parameter α∈(0,1) and two uniform distributions U1 and U2. Let r0 be drawn randomly from

[formula]

Discussion

We have presented an asymptotically consistent method to estimate the number of change-points and do locate the changes in highly dependent time-series data. The considered framework is very general and as such is suitable for real-world applications.

Note that in this setting rates of convergence (even of frequencies to respective probabilities) are provably impossible to obtain. Therefore, unlike in the traditional settings for change-point analysis, the algorithms developed for this framework are forced not to rely on any rates of convergence. We see this as an advantage of the framework as it means that the algorithms are applicable to a much wider range of situations. At the same time, it may be interesting to derive the rates of convergence of the proposed algorithm under stronger assumptions (e.g., i.i.d.  data, or some mixing conditions). We conjecture that the algorithm is indeed optimal (up to some constant factors) in such settings as well (although it clearly cannot be optimal under parametric assumptions); however, we leave this as future work.

In the proposed algorithm a specific consistent clustering method is used to estimate the number of change-points. An interesting extension would be to establish the consistency of this method using any list-estimator in combination with any time-series clustering algorithm, that possess suitable asymptotic consistency guarantees.

Finally, the consistency of the algorithm is established when the distributional distance is used as the distance between the segments. The proof relies on some properties specific to this distance. Other distances can also be used in problems concerning stationary ergodic time series [\citep=Ryabko:12red]; thus, it is interesting to investigate which distances can be used with the algorithm proposed in the current paper.