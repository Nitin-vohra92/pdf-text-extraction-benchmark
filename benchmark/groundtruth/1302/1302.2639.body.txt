Corollary Definition Remark

Matrix Completion and Tensor Rank

introduction

Suppose we are given a rectangular array which has only been partially filled out with entries in [formula] (or some other field). The low rank matrix completion problem asks to fill out the remaining entries such that the resulting matrix has minimal rank. For example, the array

[formula]

can be completed to a rank 1 matrix

[formula]

but clearly cannot be completed to a rank 0 matrix. For a survey on matrix completion problems, see [\cite=Johnson] [\cite=Laurent]. The low rank matrix completion problem has various applications, such as statistics, computer vision, signal processing and control. The low rank matrix completion problem is known to be NP-hard (see [\cite=Peeters]). For the field [formula] or [formula] one sometimes can solve the matrix completion problem using convex relaxation: under certain assumptions minimizing the nuclear norm of the matrix (the sum of the singular values) one also obtains the minimal rank completion. See for example [\cite=RFP] [\cite=CR] [\cite=CT] [\cite=KMO]. The rank of a tensor was defined in [\cite=Hitchcock]. Using this notion, matrix completion problems can be generalized to higher order tensors (see [\cite=GRY]).

Suppose that [formula] is a field, and [formula] for [formula]. The tensor product space

[formula]

can be viewed as a d-dimensional array of size [formula]. A pure tensor is an element of V of the form

[formula]

where v(i)∈V(i) for all i. The rank of a tensor T∈V is the smallest nonnegative integer r such that T can be written as a sum of r pure tensors:

[formula]

where v(i)j∈V(i) for all i and j. We denote the tensor rank of T by [formula]. If A = (ai,j) is an n  ×  m matrix, then we can identify A with the tensor

[formula]

in [formula], where ei denotes the i-th basis vector. The tensor rank in this case is exactly the same as the rank of the matrix. For d  ≥  3 it is often difficult to find the rank of a given tensor. Finding the rank of a tensor is NP-complete if the field [formula] is finite ([\cite=Hastad] [\cite=Hastad2]) and NP-hard if the field is [formula] ([\cite=Hastad] [\cite=Hastad2]), or if it contains [formula] ([\cite=HL]). Approximation of a tensor by another tensors of low rank is known as the PARAFAC ([\cite=Harshman]) or CANDECOMP ([\cite=CC]) model. There are various algorithms for finding low-rank approximations. See [\cite=KB] [\cite=TB] for a discussion. The problems of finding the tensor rank of a tensor, and to approximate tensors with tensors of low rank has many applications, such as the complexity of matrix multiplication, fluorescence spectroscopy, statistics, psychometrics, geophysics and magnetic resonance imaging. In general, the rank of higher tensors more ill-behaved than the rank of a matrix (see [\cite=DSL]).

In the next section we will show that the low rank matrix completion problem can be reduced to finding the rank of a certain tensor. Lek-Heng Lim pointed out to the author, that because low rank matrix completion is NP-hard, this gives another proof that determining the rank of a tensor is NP-hard.

The main result

Suppose that [formula] is a field, and A = (ai,j) is an n  ×  m array for which some of the entries are given, and the entries in positions [formula] are undetermined. Define ei,j as the matrix that has a 1 in position (i,j) and 0 everywhere else. We can reformulate the low rank matrix completion problem as follows. Define aik,jk = 0 for [formula] and find a matrix B of the form

[formula]

which has minimal rank.

We can view matrices as second order tensors. So we identify ei,j with [formula] and we have

[formula]

Define uk = eik and vk = ejk. The matrix completion problem asks to find [formula] such that the tensor

[formula]

has minimal rank.

Let [formula] be the vector space spanned by [formula].

We define

[formula]

So the matrix completion asks for the value of [formula] and to find a matrix B∈A + U for which [formula].

We define a third order tensor [formula] by

[formula]

Our main result is:

We have

[formula]

The theorem is effective: given an explicit decomposition of Â as a sum of [formula] pure tensors, the proof shows that one easily can construct a matrix B in A + U such that [formula].

Let [formula] and [formula]. By definition, there exists a matrix B∈A + U with rank r. We can write

[formula]

Since B has rank r, we also can write

[formula]

for some [formula] and [formula]. We have

[formula]

We have written Â as a sum of r + s pure tensors. So [formula].

Conversely, we can write

[formula]

For every i, choose a linear function [formula] such that [formula] and [formula] if j  ≠  i. Applying [formula] to the tensor Â gives

[formula]

This shows that ei lies in the span of [formula] for all i. So [formula] span the vector space [formula]. After rearranging [formula], we may assume that [formula] is a basis of [formula]. There exists a linear function [formula] such that [formula] and f(es + 1) = 1. We apply [formula] to Â:

[formula]

The tensor above is a matrix in A + U which has rank at most l - s, and by definition of [formula] it has rank at least r. It follows that r  ≤  l - s. We have already proven that r + s  ≥  l, so we conclude that r + s = l.

In the proof we have not used that uk and vk are basis vectors. So Theorem [\ref=theo:main] is true whenever U is the span of linearly independent pure tensors

[formula]

and Â is given by ([\ref=eq:Ahat]).

Define

[formula]

by

[formula]

where e2 appears in the i-th position if i  ≤  s, and

[formula]

We define a tensor [formula] by

[formula]

A proof, similar to that of Theorem [\ref=theo:main] shows that [formula]. The ambient vector space of [formula] is much larger than that of Â. But one can imagine that using the tensor [formula] can be advantageous for proving lower bounds for [formula] because it is, in a way, more rigid.

Theorem [\ref=theo:main] also easily generalizes to the higher order analog of matrix completion: tensor completion. Suppose that [formula] are finite dimensional [formula]-vector spaces and [formula]. Assume that U  ⊆  V is a subspace spanned by s linearly independent pure tensors

[formula]

and

[formula]

is a tensor. As before, we define

[formula]

Define a (d + 1)-th order tensor by

[formula]

Then we have

[formula]

Acknowledgment

The author thanks Lek-Heng Lim for some useful suggestions, and Reghu Meka for providing me with an important reference.

Harm Derksen Department of Mathematics University of Michigan 530 Church Street Ann Arbor, MI 48109-1043, USA hderksen@umich.edu