Objective Probabilistic Forecasts of Future Climate Based on Jeffreys' Prior: the Case of Correlated Observables

Introduction

Predicting the future climate is very difficult: this can be seen in the wide spread of predictions and projections that come from different climate prediction models [\citep=ipcc4]. This wide spread is indicative of forecast uncertainty, and for those who might use climate predictions, it is important that this uncertainty is quantified as well as possible. Only then can decisions be made as to whether certain climate predictions should be used or ignored, and, if they are to be used, how they should be used and how much weight they should be given.

One major driver of climate prediction uncertainty is parameter uncertainty: that is, that different parameter settings in climate models lead to different predictions, and that no single set of parameters is correct. In statistical climate predictions, parameter uncertainty can be estimated and incorporated rather easily using standard statistical techniques. For instance, [\citet=j115] discusses a Bayesian method for putting parameter uncertainty into predictions from flat-line and linear trend climate prediction models. In numerical model climate predictions, however, parameter uncertainty is rather more difficult to estimate and incorporate into predictions since the models are more complex and the number of parameters is much larger. Some attempts to deal with numerical model parameter uncertainty using classical statistics are described in [\citet=allen09], and some that use subjective Bayesian statistics are described in [\citet=tomassini07]. We, however, are particularly interested in the idea of using a third statistical paradigm known as objective Bayesian statistics to capture the parameter uncertainty in numerical climate models. Objective Bayesian statistics is Bayesian statistics in which those priors which cannot be determined from previous independent studies are determined using a rule, rather than subjectively using intuition. We have described how this approach can be applied to climate models in [\citet=jp1]. We proposed using the Jeffreys' prior [\citep=jeffreys] which is the most standard of the various rules available, and we then showed that the implementation of such an approach can be simplified by using a parametric form for the predictive distribution from the climate model. This simplifies the calculation of the prior, because the two steps of differentiating the probabilities from the climate model and taking the expectation over all possible realisations are replaced by a single step of differentiating the parameters of the fitted distribution.

One of the shortcomings of the method described in [\citet=jp1] is that we assumed that the observables (or predicted variables) were independent. This simplifies matters because it means that the predictive distribution factorises into a product of predictive distributions for each variable. Since we assumed a multivariate normal predictive distribution, that factorised into a product of independent normal distributions, and the evaluation of the prior became a matter of differentiating the means and the variances of those normal distributions.

In this paper, we stick with the assumption that the observations are multivariate normally distributed. However, we now relax the assumption that the observations are independent, and replace it with the assumption that the covariance matrix between the observations is constant as a function of the climate model parameters. This allows us to derive another set of relatively simple expressions for the prior, that could readily be evaluated using a suitably designed set of integrations of a numerical model.

In section [\ref=s2] we give a brief overview of objective priors and the work in [\citet=jp1]. In section [\ref=s3] we then derive expressions for the new case we consider in this paper, for the constant variance multivariate normal. In section [\ref=s4] we summarise.

The Use of Objective Priors in Climate Modelling

The starting point for Bayesian methods for making probabilistic forecasts that include parameter uncertainty is the following equation from probability theory, sometimes known as the law of total probability:

[formula]

This equation says that the probability of future event y, given the past data x, is given by an average over probabilistic predictions made with all possible parameter values, where the prediction for y from a model based on the parameter value θ is written as p(y|θ). The average is a weighted average, where the weights on each prediction are given by the likelihood p(θ|x).

Thus far, there is nothing Bayesian about this equation, since Bayes' Rule has not yet been used. In Bayesian methods the term p(θ|x) is evaluated by factorising it using Bayes' Theorem:

[formula]

The task of evaluating p(θ|x) now becomes a question of evaluating p(x|θ), which is the probability of the past events x given each parameter value θ, and of evaluating the prior p(θ).

Evaluating p(x|θ) is, at least conceptually, straightforward since it involves comparing probabilistic predictions from a climate model with past observations. The distinction between subjective and objective Bayesian methods appears in how the term p(θ) is evaluated. In subjective methods p(θ) is based on intuition, while in objective methods it is based on a rule. The idea of using a rule is to make the resulting predictions less arbitrary: this is discussed at greater length in [\citet=jp1].

The most widely discussed rule is the Jeffreys' Prior, given by:

[formula]

If this equation is applied to all parameters, then there is a standard case in which the results are questionable. This problem is widely discussed in textbooks on Bayesian statistics (for instance, see page 90 in [\citet=peterlee]). The problem was actually resolved, however, by Jeffreys' himself (see page 1345 of [\citet=kasswasserman] for an explanation), using the separate treatment of location parameters.

In [\citet=jp1] we discussed how Jeffreys' Prior might be evaluated for a climate model. The steps in equation [\ref=eq1] in which the log of the probability are first differentiated and then integrated (to evaluate the expectation) are somewhat daunting, and likely to be computationally intensive. However, they can be simplified if we make the assumption that the output from the model is independent and normally distributed. The steps of differentiation and integration can then be performed analytically, and the expression above becomes:

[formula]

where n is the number of observations used to validate the model, and μi and σ2i are the means and variances of initial condition ensembles. To evaluate this new expression, the means and variances from initial condition ensembles need to be differentiated with respect to the underlying parameters of the climate model θ. One can imagine doing this by running multiple initial condition ensembles (although there may be more efficient methods). This is still not a trivial exercise, but is simpler than differentiating the probabilities from the model and integrating over all possible realisations. Also, with careful experimental design it should be possible to evaluate this expression by re-using the model integrations that are needed to calculate the likelihood term p(x|θ).

In the case that the ensemble variance does not vary as a function of the parameters, expression [\ref=eq2] reduces to:

[formula]

Jeffreys' Prior for Correlated Observations with Constant Variance

We now consider a slightly different approximation in order to allow for correlations between observations. We still assume that the observations come from a multivariate normal distribution, as before. However, instead of assuming that the observations are independent, but that the ensemble variance can vary as a function of the parameters, we now make a complementary set of approximations in which we assume that the observations are correlated, but that the covariance matrix is constant as a function of the parameters.

In general, probability densities from the multivariate normal distribution are given by:

[formula]

where

x is a vector for the observables, or predicted variables, produced by the model

θ is a vector for the parameters in the model

μ=μ(θ) is a vector of the mean response of the model for each observable (i.e. the ensemble mean of x for an infinite-sized initial condition ensemble for fixed parameters θ)

Σ  =  Σ(θ) is the covariance matrix of the response of the model between observables (i.e. the ensemble covariance matrix of x for an infinite-sized initial condition ensemble for fixed parameters θ)

S = Σ- 1 = S(θ) is the inverse of the covariance matrix

and D = (Σ) = D(θ) is the determinant of the covariance matrix

This gives:

[formula]

Since S is symmetric, xTSμ  =  μTSx (see appendix 1) which means that the above expression for ln p(x|θ) simplifies a little to:

[formula]

We now consider two cases.

Single parameter, multiple correlated observations

The first case we consider, as a warm-up, is where there is just a single parameter in the climate model.

If we consider θ to be this single (scalar) parameter, then:

[formula]

We now make the further approximation that the covariance matrix Σ is constant, which simplifies the subsequent algebra considerably. If Σ is constant, then both D and S are also constant, and so:

[formula]

Again, since S is symmetric, [formula], which simplifies the above expression to

[formula]

Taking another derivative wrt θ gives:

[formula]

Taking expectations over x (and noting that E(x) = μ) gives:

[formula]

That the second derivatives cancel and disappear from this expression is no surprise: we know from a standard result that the Jeffreys' Prior can only contain first derivatives (see lemma 2, page 87, [\citet=peterlee]).

The Jeffrey's Prior is then given by:

[formula]

If there are n observations then:

μ is an n x 1 vector

[formula] is an n x 1 vector

μT is a 1 x n vector

[formula] is a 1 x n vector

S is an n x n matrix

[formula] is a scalar

and p(θ) is a scalar

In the case in which the observations are independent, Σ reduces to a diagonal matrix with the variances of each of the n observations σ21,σ22,...,σ2n on the diagonal, and S is a diagonal matrix with the inverse variances on the diagonal. The matrix multiplication in the above expression then reduces to a simple sum over the observations:

[formula]

which agrees with the uncorrelated observations case given by equation 20 in [\citet=jp1].

Multiple parameter, multiple observations

We now consider the more general case with multiple parameters. As a first step we consider two parameters. Taking the derivative of [formula], from equation [\ref=eq4] above, wrt a second parameter φ gives:

[formula]

Taking expectations gives:

[formula]

Generalising from two to multiple parameters, and writing the vector of parameters as θ, the Jeffreys' Prior is then:

[formula]

If there are n observations and m parameters then:

μ is an n x 1 vector

[formula] is an n x m matrix

μT is a 1 x n vector

[formula] is an m x n matrix

S is an n x n matrix

[formula] is an m x m matrix

det[formula] is a scalar

and p(θ) is a scalar

In the independent observations case this reduces to:

[formula]

which agrees with the uncorrelated observations case given by equation 37 in [\citet=jp1], and is also given above as equation [\ref=eq6].

Summary and Discussion

Bayesian statistics offers the only effective framework for including parameter uncertainty into probabilistic forecasting. Part of the Bayesian approach involves specifying a prior distribution for the parameters, and there are two options for how to do this: take a subjective approach, where the prior is based on intuition, and take an objective approach, where the prior is based on a rule.

Of the various rules that might be used in the objective approach, one in particular is the most widely discussed, and is the closest to being an accepted standard: the Jeffreys' Prior. When we consider how to apply Jeffreys' Prior in climate modelling, we find that the probabilities from initial condition ensemble runs of a climate model need to be differentiated with respect to the parameters of the model, and integrated over all possible model states. This could be done, but is cumbersome. However, by making parametric assumptions for the shape of the predictive distributions there is the potential for this to be simplified. The most obvious parametric assumption is that all output from the model is distributed according to the multivariate normal. We have now considered two special cases of this. In [\citet=jp1] we considered the case where the observations were considered to be independent, but where both the means and the variances of initial condition ensembles could vary as a function of the parameters. In this paper we have considered the case where the observations are not independent, but where the covariance matrix between observations is constant. Neither of these two cases is a special case of the other, clearly.

We have derived expressions for the Jeffreys' Prior for the constant covariance case. These expressions show that evaluating the Jeffreys' Prior reduces to evaluating first derivatives of the ensemble mean with respect to the various parameters in the model, and performing simple a calculation using those first derivatives. This calculation involves the correlation matrix between different observations, which can be estimated from the grand ensemble of all models runs with all parameter values, since we are assuming that the correlation matrix is constant.

Overall we have presented a method for making objective probabilistic forecasts which is sufficiently simple that it could be applied to real climate models, even when the observations are considered correlated. Our next challenge is to attempt to tackle the general multivariate normal case for correlated observations with non-constant covariance matrix, and to consider predictive distributions other than normal.