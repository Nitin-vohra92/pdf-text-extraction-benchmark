=1

Lemma Corollary

Definition Example Problem

Remark

Approximating max-min linear programs with local algorithms

Introduction

We study the limits of what can and what cannot be achieved by local algorithms [\cite=naor95what]. We focus on the approximability of a certain class of linear optimisation problems, which generalises beyond widely studied packing LPs; the emphasis is on deterministic algorithms and worst-case analysis.

Local algorithms

A local algorithm is a distributed algorithm where each node must operate solely based on the information that was available at system startup within a constant-size neighbourhood of the node. We focus on problems where the size of the input per node is bounded by a constant; in such problems, local algorithms provide an extreme form of scalability: the communication, space and time complexity of a local algorithm is constant per node, and a local algorithm scales to an arbitrarily large or even infinite network.

The study of local algorithms has several uses beyond providing highly scalable distributed algorithms. The existence of a local algorithm shows that the function can be computed by bounded-fan-in, constant-depth Boolean circuits; we can say that the function is in the class NC0. A local algorithm is also an efficient centralised algorithm: the time complexity of the centralised algorithm is linear in the number of nodes; furthermore, due to spatial locality in memory accesses, we may be able to achieve a low I/O complexity in the external memory [\cite=vitter01external] model of computation. In certain problems, a local approximation algorithm can be used to construct a sublinear time algorithm which approximates the size of the optimal solution, assuming that we tolerate an additive error and some probability of failure [\cite=parnas07approximating]. A local algorithm can be turned into an efficient self-stabilising algorithm [\cite=dolev00self-stabilization]; the time to stabilise is constant [\cite=awerbuch91distributed]. Finally, the existence and nonexistence of local algorithms gives us insight into the algorithmic value of information in distributed decision-making [\cite=papadimitriou91value].

Max-min packing problem

In this section, we define the optimisation problem that we study in this work. Let V, I and K be index sets with [formula]; we say that each v∈V is an agent, each k∈K is a beneficiary party, and each i∈I is a resource (constraint). We assume that one unit of activity by v benefits the party k by ckv  ≥  0 units and consumes aiv  ≥  0 units of the resource i; the objective is to set the activities to provide a fair share of benefit for each party. In notation, assuming that the activity of agent v is xv units, the objective is to

[formula]

Throughout this work we assume that the support sets defined for all i∈I, k∈K, and v∈V by Vi  =  {v∈V:aiv > 0}, Vk  =  {v∈V:ckv > 0}, Iv  =  {i∈I:aiv > 0}, and Kv  =  {k∈K:ckv > 0} have bounded size. That is, we consider only instances of [\eqref=eq:max-min] such that [formula], [formula], [formula] and [formula] for some constants [formula], [formula], [formula] and [formula]. To avoid uninteresting degenerate cases, we furthermore assume that Iv, Vi and Vk are nonempty.

LP formulation

If the sets V, I and K are finite, the problem can be represented using matrix notation. Let A be the nonnegative [formula] matrix where the entry at row i, column v is aiv; define C analogously. We write ai for the row i of A and ck for the row k of C. Let x be a column vector of length [formula]. The goal is to maximise ω  =   min k∈Kckx subject to [formula] and [formula].

In the special case [formula], this is the widely studied fractional packing problem: maximise cx subject to [formula] and [formula]. This simple linear program (LP) has nonnegative coefficients in c and A. We refer to a problem of this form as a packing LP; the dual is a covering LP. Naturally the case of any finite K can also be written as a linear program, but the constraint matrix is no longer nonnegative: maximise ω subject to [formula], [formula] and [formula].

Distributed setting

We construct the hypergraph H  =  (V,E) where the hyperedges are [formula]. This is the communication graph in our distributed optimisation problem. The variable xv is controlled by the agent v∈V, and two agents u,v∈V can communicate directly with each other if they are adjacent in H. We write [formula] for the shortest-path distance between u and v in H. The agents are cooperating, not selfish; the difficulty arises from the fact that the agents have to make decisions based on incomplete information.

Initially, each agent v∈V knows only the following local information: the identity of its neighbours in the graph H; the sets Iv and Kv; the values aiv for each i∈Iv; and the values ckv for each k∈Kv. That is, v knows with whom it is competing on which resources, and with whom it is working together to benefit which parties.

When we compare the present work with previous work, we often mention the special case [formula], as this corresponds to the widely studied packing LP. However, in this case the size of Vk is not bounded by a constant [formula]: we have Vk  =  V for the sole k∈K. Therefore we introduce a restricted variant of the distributed setting, which we call collaboration-oblivious. In this variant, the hyperedges are E  =  {Vi:i∈I}. Whenever we study related work on the packing LP, we focus on the collaboration-oblivious setting.

Local setting

We are interested in solving the problem [\eqref=eq:max-min] by using a local algorithm. Let [formula] be the local horizon of the algorithm; this is a constant which does not depend on the particular problem instance at hand. Let [formula] be the set of nodes which have distance at most r to the node v in H. The agent v must choose the value xv based on the information that is initially available in the agents [formula].

We focus on the case where the size of the input is constant per node. The elements aiv and ckv are represented at some finite precision. Furthermore, we assume that the nodes have constant-size locally unique identifiers; i.e., any node can be identified uniquely within the local horizon.

Approximation

A local algorithm has the approximation ratio α for some α  >  1 if the decisions xv are a feasible solution and the value ω is within a factor α of the global optimum. A family of local algorithms is a local approximation scheme if we can achieve any α  >  1 by choosing a large enough local horizon r.

Contributions

In Section [\ref=sec:inapprox] we show that while a simple algorithm achieves the approximation ratio [formula] for [\eqref=eq:max-min], no local algorithm can achieve an approximation ratio less than [formula] in the general case. In Section [\ref=sec:approx] we present a local approximation algorithm which can achieve an improved approximation ratio if we can bound the relative growth of the vertex neighbourhoods in H.

Applications

Consider a two-tier sensor network: battery-powered sensor devices generate some data; the data is transmitted to a battery-powered relay node, which forwards the data to a sink node. The sensor network is used to monitor the physical areas K. Let S be the set of sensors, and let T be the set of relays; choose [formula].

For each sensors device s∈S, there may be multiple relays t∈T which are within the reach of the radio of s; we say that there is a wireless link (s,t) from s to t. The set V consists of all such wireless links, and the variable x(s,t) indicates how much data is transmitted from s via t to the sink. Transmitting one unit of data on the link v  =  (s,t)∈V and forwarding it to the sink consumes the fraction asv of the energy resources of the sensor s and also the fraction atv of the energy resources of the relay t.

Let ckv  =  1 for each link v  =  (s,t) if the sensor s is able to monitor the physical area k∈K. Now [\eqref=eq:max-min] captures the following optimisation problem: choose the data flows in the sensor network so that we maximise the minimum amount of data that is received from any physical area. Equivalently, we can interpret the objective as follows: choose data flows such that the lifetime of the network (time until the first sensor or relay runs out of the battery) is maximised, assuming that we receive data at the same average rate from each physical area.

Similar constructions have applications beyond the field of sensor networks: consider, for example, the case where each k∈K is a major customer of an Internet service provider (ISP), each s∈S is a bounded-capacity last-mile link between the customer and the ISP, and each t∈T is a bounded-capacity access router in the ISP's network.

Related work

Papadimitriou and Yannakakis [\cite=papadimitriou93linear] present the safe algorithm for the packing LP. The agent v chooses

[formula]

This is a local [formula]-approximation algorithm with horizon r  =  1.

Kuhn et al. [\cite=kuhn06price] present a distributed approximation scheme for the packing LP and covering LP. The algorithm provides a local approximation scheme for some families of packing and covering LPs. For example, let aiv∈{0,1} for all i,v. Then for each [formula], [formula] and α  >  1, there is a local algorithm with some constant horizon r which achieves an α-approximation. Our work shows that such local approximation schemes do not exist for [\eqref=eq:max-min].

Another distributed approximation scheme by Kuhn et al. [\cite=kuhn06price] forms several decompositions of H into subgraphs, solves the optimisation problem optimally for each subgraph, and combines the solutions. However, the algorithm is not a local approximation algorithm in the strict sense that we use here: to obtain any constant approximation ratio, the local horizon must extend (logarithmically) as the number of variables increases. Also Bartal et al. [\cite=bartal97global] present a distributed but not local approximation scheme for the packing LP.

Kuhn and Wattenhofer [\cite=kuhn05constant-time] present a family of local, constant-factor approximation algorithms of the covering LP that is obtained as an LP relaxation of the minimum dominating set problem. Kuhn et al. [\cite=kuhn05locality] present a local, constant-factor approximation of the packing and covering LPs in unit-disk graphs.

There are few examples of local algorithms which approximate linear problems beyond packing and covering LPs. Kuhn et al. [\cite=kuhn06fault-tolerant] study an LP relaxation of the k-fold dominating set problem and obtain a local constant-factor approximation for bounded-degree graphs.

For combinatorial problems, there are both negative [\cite=kuhn04what] [\cite=linial92locality] and positive [\cite=floreen07local] [\cite=kuhn06fault-tolerant] [\cite=kuhn05constant-time] [\cite=naor95what] [\cite=urrutia07local] results on the applicability of local algorithms.

Inapproximability

Even though the safe algorithm [\cite=papadimitriou93linear] was presented for the special case of [formula], [formula], and finite I and V, we note that the safe solution x defined by [\eqref=eq:safe] and the optimal solution x* also satisfy

[formula]

Therefore we obtain a local approximation algorithm with the approximation ratio [formula] for [\eqref=eq:max-min].

One could hope that widening the local horizon beyond r  =  1 would significantly improve the quality of approximation. In general, this is not the case: no matter what constant local horizon r we use, we cannot improve the approximation ratio beyond [formula]. In this section, we prove the following theorem.

Let [formula] and [formula] be given. There is no local approximation algorithm for [\eqref=eq:max-min] with the approximation ratio less than [formula]. This holds even if we make the following restrictions: aiv∈{0,1}, [formula] and [formula].

We emphasise that the local algorithm could even choose any local horizon r depending on the bounds [formula], [formula], [formula] and [formula]. Nevertheless, an arbitrarily low approximation ratio cannot be achieved if [formula] or [formula]. In the case [formula] the existence of a local approximation scheme remains an open question.

Analogous proof techniques, using constructions based on regular bipartite high-girth graphs, have been applied in previous work to prove the local inapproximability of packing and covering LPs [\cite=kuhn06price] and combinatorial problems [\cite=kuhn04what].

Proof outline

Choose any local approximation algorithm A for the problem [\eqref=eq:max-min]. Let r  ≥  1 be the local horizon of A and let α be the approximation ratio of A. We derive a lower bound for α by constructing two instances of [\eqref=eq:max-min], S and S', such that certain sets of nodes in the two instances have identical radius-r neighbourhoods in both instances. Consequently, the deterministic local algorithm A must make the same choices for these nodes in both instances. The nodes with identical views are selected based on the solution of S computed by A, which enables us to obtain a lower bound on α by showing that this solution is necessarily suboptimal as a solution of S'.

Construction of S

We now proceed with the detailed construction of the instance S. The constructions used in the proof are illustrated in Figure [\ref=fig:inapprox].

Let [formula] and [formula]; without loss of generality we can assume that at least one of the inequalities is strict because setting [formula] in the theorem statement yields the trivial bound α  ≥  1. Let [formula] and [formula]. Observe that dD > 1. Let R > r; the precise value of R is chosen later and will depend on d, D and α only.

Let Q be a dRDR - 1-regular bipartite graph with no cycles consisting of less than 4r + 2 edges. (A random regular bipartite graph with sufficiently many nodes has this property with positive probability [\cite=mckay04short].) The graph Q provides the template for constructing the hypergraph underlying the instance S.

Before describing the construction, we first introduce some terminology. A complete (d,D)-ary hypertree of height h is defined inductively as follows. For h = 0, the hypertree consists of exactly one node and no edges; the level of the node is 0. For h > 0, start with a complete (d,D)-ary hypertree of height h - 1. For each node v at level h - 1, introduce a new hyperedge and new nodes as follows. If h - 1 is even, the new hyperedge consists of the node v and d new nodes. If h - 1 is odd, the new hyperedge consists of the node v and D new nodes. For future reference, call these hyperedges of types I and II, respectively. The new nodes have level h in the constructed hypertree. The constructed hypertree is a complete (d,D)-ary hypertree of height h. The root of the hypertree is the node at level 0, the leaves are the nodes at level h. Each level [formula] has either [formula] or [formula] nodes depending on whether [formula] is even or odd, respectively. See Figure [\ref=fig:inapprox] for an illustration.

We now construct the hypergraph underlying S. Denote by Q the vertex set of Q. Form a hypergraph H by taking [formula] node-disjoint copies of a complete (d,D)-ary hypertree of height 2R - 1. For q∈Q, denote the copy corresponding to q by Tq. Denote the node set of Tq by Tq. For [formula], denote the set of nodes at level [formula] in Tq by [formula]. Denote the set of leaf nodes in Tq by Lq = Tq(2R - 1).

Observe that the number of leaf nodes in each Tq is equal to the degree of every vertex in Q. For each vertex q∈Q and each leaf node v∈Lq, associate with v a unique edge of Q incident with the vertex q. Each edge of Q is now associated with exactly two leaf nodes; by construction, these leaf nodes always occur in different hypertrees Tq. For a leaf [formula], let f(v) be the other leaf associated with the same edge of Q. Observe that f(f(v)) = v holds for all [formula]; in particular, f is a permutation of [formula]. To complete the construction of H, add the hyperedge {v,f(v)} to H for each [formula]. Call these hyperedges type III hyperedges.

Let us now define the instance S of [\eqref=eq:max-min] based on the hypergraph H. Let the set of agents V be the node set of H. For each hyperedge e of type I, there is a resource i∈I; let aiv = 1 if v∈e, otherwise aiv = 0. For each hyperedge e of type II, there is a beneficiary party k∈K; let ckv = 1 / D if v∈e, otherwise ckv = 0. For each hyperedge e of type III, there is a beneficiary party k∈K; let ckv = 1 if v∈e, otherwise ckv = 0. The locally unique identifiers of the agents can be chosen in an arbitrary manner. (This proof applies also if the identifiers are globally unique; for example, we can equally well consider the standard definition where the identifiers are a permutation of [formula].) This completes the construction of S. Observe that S has H as its underlying hypergraph.

Construction of S'

Next we construct another instance of [\eqref=eq:max-min], called S', by restricting to a part of S. To select the part, we apply the algorithm A to the instance S. We do not care what is the optimal solution of S; all that matters at this point is the fact that each agent v∈V must choose some value xv  ≥  0. In particular, we pay attention to the values xv at the leaf nodes [formula].

For all q∈Q, let

[formula]

For all P  ⊆  Q, let [formula]. Because f is a permutation of [formula] with f(f(v)) = v for all [formula], we have δ(Q)  =  0. Thus, there exists a p∈Q with δ(p)  ≥  0.

The instance S' is now constructed based on p. The set of agents in S' is

[formula]

the set of resources is I'  =  {i∈I:Vi  ⊆  V'}, and the set of beneficiary parties is K'  =  {k∈K:Vk  ⊆  V'}. The coefficients aiv and ckv for i∈I', k∈K', and v∈V' are the same as in the instance S. The locally unique identifiers of the agents v∈V' are the same as in the instance S. (If we prefer globally unique identifiers which are a permutation of [formula], we can add redundant variables to V'.)

The structure of S'

Next we show that the structure of S' is tree-like, that is, there are no cycles in the hypergraph H' defined by the instance S'; by construction, H' is a subgraph of H.

For each q∈Q, the subgraph induced by Tq in H is a hypertree. Furthermore, the subsets Tq form a partition of V. Therefore any cycle in H and, therefore, any cycle in H' must involve hyperedges which cross between the subsets Tq and, finally, return back to the same subset.

The only hyperedges which connect nodes in Tq and Tw for distinct q,w∈Q are the hyperedges of type III. There is at most one such hyperedge for any fixed q  ≠  w; this hyperedge corresponds to the edge {q,w} in the graph Q. Therefore a cycle in H' implies a cycle in [formula]; this implies a cycle of length at most 4r + 1 in Q; by construction, no such cycle exists.

A feasible solution of S'

Next we show that there is a feasible solution x̂ of S' with ω  =  1. Let u be the root node in Tp. By construction, u∈Tp  ⊆  V'. For each v∈V', let x̂v  =  1 if [formula] is even; otherwise, let x̂v  =  0. See Figure [\ref=fig:inapprox] for an illustration.

Because S' is tree-like, there is a unique path connecting u to v in H' for each v∈V'. In particular, this path is a shortest path and has length [formula]. It follows that each hyperedge in H' has a unique node (that is, the node having the minimum distance to u) of its distance parity to u. Observe that hyperedges of resources and beneficiary parties alternate in paths from u. By the structure of S and S', it follows that the hyperedges of resources (type I) have a unique node with even distance to u. Therefore, [formula] for each i∈I'; the solution is feasible. Analogously, the hyperedges of beneficiary parties (types II and III) have a unique node with odd distance to u. Therefore, [formula] for each k∈K', implying ω  =  1.

The solution achieved by A in S'

Now we apply A to S'. The local radius-r view of the nodes v∈Tp is identical in both S and S'. In particular, the deterministic local algorithm A must make the same choices xv for v∈Tp in both instances.

As there is a feasible solution with ω  =  1, the approximation algorithm A must choose a solution x with [formula] for all k∈K'.

We proceed in levels [formula] of Tp. We study the total value assigned to the variables at level [formula], defined by

[formula]

Recall that [formula] for [formula] even, and [formula] for [formula] odd.

Let us start with level [formula], that is, the leaf nodes in Tp. For each v∈Lp, there is a k∈K' such that V'k  =  {v,f(v)} and ckv  =  ckf(v)  =  1. Therefore, by [\eqref=eq:delta-q] and the fact that δ(p)  ≥  0,

[formula]

Next, we study the remaining odd levels [formula] for [formula]. Consider the set [formula]. Observe that the hyperedges of type II occurring in Fp(2j - 1) form a partition of Fp(2j - 1). Each of the djDj - 1 hyperedges in the partition has exactly one node in Tp(2j - 1) and exactly D nodes in Tp(2j). The coefficients ckv of each beneficiary party k∈K' associated with these hyperedges are 1 / D for all v∈V'k. Thus, by the approximation ratio, we obtain the bound

[formula]

Let us finally study the even levels [formula] for [formula]. Observe that the hyperedges of type I occurring in [formula] partition Fp(2j). Each of the djDj hyperedges in the partition has exactly one node in Tp(2j) and exactly d nodes in Tp(2j + 1). The coefficients aiv of the resources i∈I' associated with these hyperedges are 1 for all v∈V'i. Thus, by the feasibility of x, we obtain the bound

[formula]

Put together, we have, for [formula],

[formula]

which, together with the assumption dD  >  1, implies

[formula]

Therefore [formula]. Should we have α  <  d / 2  +  1  -  1 / (2D), we would obtain a contradiction by choosing a large enough R. This concludes the proof of Theorem [\ref=thm:inapprox].

The same proof with D = 1 gives the following corollary which shows inapproximability even if both aiv∈{0,1} and ckv∈{0,1}.

Let [formula] be given. There is no local approximation algorithm for [\eqref=eq:max-min] with the approximation ratio less than [formula]. This holds even if we make the following restrictions: aiv∈{0,1}, ckv∈{0,1}, [formula], [formula] and [formula].

Approximability

We have seen that the approximation ratio provided by the safe algorithm is within factor 2 of the best possible in general graphs; there is no local approximation scheme if [formula] or [formula].

However, the graph in our construction is very particular: it is tree-like, and the number of nodes in a radius-r neighbourhood grows exponentially as the radius r increases. Such properties are hardly realistic in practical applications such as sensor networks; if nodes are embedded in a low-dimensional physical space, the length of each communication link is bounded by the limited range of the radio, and the distribution of the nodes and the network topology are not particularly pathological, we expect that the number of nodes grows only polynomially as the radius r increases. We shall see that better approximation ratios may be achieved in such cases.

Formally, we define the relative growth of neighbourhoods by

[formula]

We prove the following theorem.

For any R, there is a local approximation algorithm for [\eqref=eq:max-min] with the approximation ratio γ(R - 1)  γ(R) and local horizon Θ(R).

To illustrate this result, consider the case where H is a d-dimensional grid. In such a graph, we have [formula] and [formula]. Therefore γ(r)  =  1  +  Θ(1 / r) and our algorithm is a local approximation scheme in this family of graphs.

We emphasise that the algorithm does not need to know any bound for γ(r). We can use the same algorithm in any graph. The algorithm achieves a good approximation ratio if such bounds happen to exist, and it still produces a feasible solution if such bounds do not exist. Furthermore, due to the local nature of the algorithm, if the graph fails to meet such bounds in a particular area, this only affects the optimality of the beneficiary parties that are close to this area.

Algorithm

The algorithm is based on the idea of averaging local solutions of local LPs; similar ideas have been used in earlier work to derive distributed and local approximation algorithms for LPs [\cite=kuhn07distributed] [\cite=kuhn05locality] [\cite=kuhn06price].

Fix a radius [formula]; the local horizon of the algorithm will be Θ(R). For each agent u∈V, define

[formula]

For each k∈K and i∈I, define

[formula]

See Figure [\ref=fig:approx] for an illustration. For each u∈V, let xu be an optimal solution of the following problem:

[formula]

The solution xu can be computed by the agent u; or it can be computed separately by each agent j∈Vu which needs xu, by using the same deterministic algorithm.

The agent j∈V makes the following choice, which depends only on its radius 2R + 1 neighbourhood:

[formula]

Constraints

Consider a resource i∈I. We note that

[formula]

and

[formula]

By definition, βj  ≤  ni  /  Ni for all i∈Ij, that is, for all j∈Vi. Combining these observations, we obtain

[formula]

Therefore [formula] is a feasible solution of [\eqref=eq:max-min].

Benefit

Let x* be an optimal solution of [\eqref=eq:max-min], with ω  =  ω*. Then x* is a feasible solution of [\eqref=eq:max-min-local], with ωu  ≥  ω*. Therefore the optimal solution xu of [\eqref=eq:max-min-local] satisfies

[formula]

for all k∈Ku. Let β  =   min j∈Vβj  =   min i∈Ini  /  Ni.

Consider a beneficiary party k∈K. We note that

[formula]

and

[formula]

Combining these observations, we obtain

[formula]

In summary, the solution [formula] approximates [\eqref=eq:max-min] within the approximation ratio max k∈KMk / mk  ·   max i∈INi / ni. To complete the proof of Theorem [\ref=thm:approx], observe that max k∈KMk  /  mk  ≤  γ(R - 1) and max i∈INi  /  ni  ≤  γ(R).