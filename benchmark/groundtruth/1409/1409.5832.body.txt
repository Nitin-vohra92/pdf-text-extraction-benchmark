Lemma Theorem Corollary Fact Observation Definition

[formula]

Efficient First-Order Methods for Linear Programming and Semidefinite Programming

Introduction

The study of first-order methods has largely dominated research in continuous optimization for the last decade, yet still the range of problems for which "optimal" first-order methods have been developed is surprisingly limited, even though much has been achieved in some areas with high profile, such as compressed sensing. Even if one restricts attention to, say, linear programming, the problems proven to be solvable by first-order methods in O(1 / ε) iterations all possess noticeably strong structure.

We present a simple transformation of any linear program or semidefinite program into an equivalent convex optimization problem whose only constraints are linear equations. The objective function is defined on the whole space, making virtually all subgradient methods be immediately applicable. We observe, moreover, that the objective function is naturally "smoothed," thereby allowing most first-order methods to be applied.

We develop complexity bounds in the unsmoothed case for a particular subgradient method, and in the smoothed case for Nesterov's original "optimal" first-order method for smooth functions. We achieve the desired bounds on the number of iterations, O(1 / ε2) and O(1 / ε), respectively. However, contrary to most of the literature on first-order methods, we measure error relatively, not absolutely. On the other hand, also unlike most of the literature, we require only the level sets to be bounded, not the entire feasible region to be bounded.

Perhaps most surprising is that the transformation from a linear program or a semidefinite program is simple and so is the basic theory, and yet the approach has been overlooked until now, a blind spot. Once the transformation is realized, the remaining effort in establishing complexity bounds is mainly straightforward, by making use of various works of Nesterov.

The following section presents the transformation and basic theory. At the end of the section we observe that the transformation and theory extend far beyond semidefinite programming with proofs virtually identical to the ones given. Thereafter we turn to algorithms, first for the unsmoothed case. This is where we actually rely on structure possessed by linear programs and semidefinite programs but not by conic optimization problems in general.

A forthcoming paper [\cite=renegar2014hyperbolic] generalizes the results to all of hyperbolic programming. That paper depends on this one.

Basic Theory

As a linear programming problem

[formula]

is a special case - duality aside - of a semidefinite program in which all off-diagonal entries are constrained to equal 0, in developing the theory we focus on semidefinite programming, as there is no point in doing proofs twice, once for linear programming and again for semidefinite programming. After proving the first theorem, we digress to make certain the reader is clear on how to determine the implications of the paper for the special case of linear programming. (We sometimes digress to consider the special case of linear programming in later sections as well.)

For [formula] (n  ×  n symmetric matrices), and [formula], consider the semidefinite program

[formula]

where 〈  ,  〉 is the trace inner product, where [formula], and where [formula] is shorthand for [formula] (cone of positive semidefinite matrices). Let [formula] be the optimal value of SDP.

Assume C is not orthogonal to the nullspace of A, as otherwise all feasible points are optimal.

Assume a strictly feasible matrix E is known. Until section [\ref=sect.scaling], assume E  =  I, the identity matrix. Assuming the identity is feasible makes the ideas and analysis particularly transparent. In section [\ref=sect.scaling], it is shown that the results for E  =  I are readily converted to results when the known feasible matrix E is a positive-definite matrix other than the identity. Until section [\ref=sect.scaling], however, the assumption E  =  I stands, but is not made explicit in the formal statement of results.

For symmetric matrices X, let [formula] denote the minimum eigenvalue of X. It is well known that X  ↦  λmin(X) is a concave function.

Assume [formula] has bounded optimal value. If [formula] satisfies A(X)  =  b and 〈C,X〉  <  〈C,I〉, then [formula]

Proof: If λmin(X)  ≥  1, then I  +  t(X  -  I) is feasible for all t  ≥  0. As the function t  ↦  〈C,I  +  t(X - I)〉 is strictly decreasing (because 〈C,X〉  <  〈C,I〉), this implies SDP has unbounded optimal value, contrary to assumption. [formula]

For all [formula] for which λmin  <  1, let Z(X) denote the matrix where the line from I in direction X  -  I intersects the boundary of [formula], that is,

[formula]

We refer to Z(X) as "the projection (from I) of X to the boundary of the semidefinite cone."

The following result shows that SDP is equivalent to a particular eigenvalue optimization problem for which the only constraints are linear equations. Although the proof is straightforward, the centrality of the result to the development makes the result be a theorem.

Let [formula] be any value satisfying   [formula] If X* solves

[formula]

then Z(X*) is optimal for [formula]. Conversely, if Z* is optimal for [formula], then [formula] is optimal for ([\ref=eqn.ba]), and Z*  =  Z(X*).

Proof: Fix a value satisfying [formula], and consider the affine space that forms the feasible region for ([\ref=eqn.ba]):

[formula]

Since [formula], it is easily proven from the convexity of [formula] that X  ↦  Z(X) gives a one-to-one map from the set ([\ref=eqn.bb]) onto

[formula]

where [formula] denotes the boundary of [formula].

For X in the set ([\ref=eqn.bb]), the objective value of Z(X) is

[formula]

a strictly-decreasing function of λmin(X). Since the map X  ↦  Z(X) is a bijection between the sets ([\ref=eqn.bb]) and ([\ref=eqn.bc]), solving SDP is thus equivalent to solving ([\ref=eqn.ba]). [formula]

SDP has been transformed into an equivalent linearly-constrained maximization problem with concave - albeit nonsmooth - objective function. Virtually any subgradient method can be applied to this problem, the main cost per iteration being in computing a subgradient and projecting it onto the subspace {V:A(V)  =  0〈C,V〉  =  0}. In section [\ref=sect.nesterov], it is observed that the objective function has a natural smoothing, allowing almost all first-order methods to be applied, not just subgradient methods.

We digress to interpret the implications of the development thus far for the linear programming problem

[formula]

LP can easily be expressed as a semidefinite program in variable [formula] constrained to have all off-diagonal entries equal to zero, where the diagonal entries correspond to the original variables [formula].

In particular, the standing assumption that I is feasible for SDP becomes, in the special case of LP, a standing assumption that [formula] (the vector of all ones) is feasible. The eigenvalues of X become the coordinates [formula]. The map X  ↦  λmin(X) becomes x  ↦   min jxj. Lemma [\ref=lem.ba] becomes the statement that if x satisfies Ax  =  b and [formula], then  min jxj  <  1.

Finally, Theorem [\ref=thm.bb] becomes the result that for any value satisfying [formula], LP is equivalent to

[formula]

in that, for example, x* is optimal for ([\ref=eqn.bda]) if and only if the projection [formula] is optimal for LP.

In this straightforward manner, the reader can realize the implications for LP of all results in the paper.

Before leaving the simple setting of linear programming, we make observations pertinent to applying subgradient methods to solving ([\ref=eqn.bda]), the problem equivalent to LP.

The subgradients of x  ↦   min jxj at x are the convex combinations of the standard basis vectors e(k) for which xk  =   min jxj. Consequently, the projected subgradients at x are the convex combinations of the vectors k for which xk  =   min jxj, where k is the kth column of the matrix projecting [formula] onto the nullspace of [formula], that is

[formula]

In particular, if for a subgradient method the current iterate is x, then the chosen projected subgradient can simply be any of the columns k for which xk  =   min jxj. Choosing the projected subgradient in this way gives the subgradient method a combinatorial feel. If, additionally, the subgradient method does exact line searches, then the algorithm possesses distinct combinatorial structure. (In this regard it should be noted that the work required for an exact line search is only O(n log n), dominated by the cost of sorting.)

If m  ≪  n, then [formula] is not computed in its entirety, but instead the matrix   =  (ĀĀT)- 1 if formed as a preprocessing step, at cost O(m2n). Then, for any iterate x and an index k satisfying xk  =   min jxj, the projected subgradient k is computed according to

[formula]

for a cost of [formula] per iteration, where O(n log n) is the cost of finding a smallest coordinate of x.

Now we return to the theory, expressed for SDP, but interpretable for LP in the straightforward manner explained above.

Assume, henceforth, that SDP has at least one optimal solution. Thus, the equivalent problem ([\ref=eqn.ba]) has at least one optimal solution. Let [formula] denote any of the optimal solutions for the equivalent problem.

[formula]

Proof: By Theorem [\ref=thm.bb], [formula] is optimal for SDP - in particular, [formula]. Thus, according to ([\ref=eqn.bd]),

[formula]

Rearrangement completes the proof. [formula]

We focus on the goal of computing a matrix Z that is feasible for SDP and has objective value which is significantly better than the objective value for I, in the sense that

[formula]

where ε  >  0 is user-chosen. Thus, for the problem of main interest, SDP (or the special case, LP), the focus is on relative improvement in the objective value.

The following proposition provides a useful characterization of the accuracy needed in approximately solving the SDP equivalent problem ([\ref=eqn.ba]) so as to ensure that for the computed matrix X, the projection Z  =  Z(X) satisfies ([\ref=eqn.be]).

Let 0  ≤  ε  <  1, and let [formula] be a value satisfying [formula]

If X is feasible for the [formula] equivalent problem ([\ref=eqn.ba]), then

Proof: Assume X is feasible for the equivalent problem ([\ref=eqn.ba]). For [formula] we have the equality ([\ref=eqn.bd]), that is,

[formula]

Thus,

[formula]

Hence, Using Lemma [\ref=lem.bc] to substitute for the rightmost occurrence of [formula] completes the proof. [formula]

It might seem that to make use in complexity analysis of the equivalence of ([\ref=eqn.bg]) with ([\ref=eqn.bf]), it would be necessary to assume as input to algorithms a lower bound on [formula]. Such is not the case, as is shown in the following sections.

In concluding the section, we observe that the basic theory holds far more generally. In particular, let K be a closed, pointed, convex cone in [formula], and assume e lies in the interior of K. For [formula], define

[formula]

It is easy to show x  ↦  λmin ,e(x) is a closed, concave function with finite value for all [formula].

Assume additionally that e is feasible for the conic optimization problem

[formula]

(where 〈  ,  〉 is any fixed inner product). The same proof as for Theorem [\ref=thm.bb] then shows that for any value satisfying [formula], ([\ref=eqn.bh]) is equivalent to the linearly-constrained optimization problem

[formula]

in the sense that if x is optimal for ([\ref=eqn.bi]), then [formula] is optimal for ([\ref=eqn.bh]), and conversely, if z* is optimal for ([\ref=eqn.bh]), then [formula] is optimal for ([\ref=eqn.bi]); moreover, z*  =  z(x*).

Likewise, Proposition [\ref=prop.bd] carries over with the same proof.

Furthermore, analogous results are readily developed for a variety of different forms of conic optimization problems. Consider, for example, a problem

[formula]

Now assume known a feasible point e' in the interior of the feasible region. Then, for any value satisfying [formula], the conic optimization problem ([\ref=eqn.bj]) is equivalent to a problem for which there is only one linear constraint:

[formula]

where e: = Ae'  -  b, and where λmin ,e is as defined in ([\ref=eqn.bga]). The problems are equivalent in that if x* is optimal for ([\ref=eqn.bk]), then the projection z(x*) of x* from e' to the boundary of the feasible region is optimal for ([\ref=eqn.bj]) - that is,

[formula]

is optimal for ([\ref=eqn.bj]) - and, conversely, if z* is optimal for ([\ref=eqn.bj]), then [formula] is optimal for ([\ref=eqn.bk]); moreover, z*  =  z(x*).

We focus on the concrete setting of semidefinite programming (and linear programming) because the algebraic structure thereby provided is sufficient for designing provably-efficient first-order methods, in both smoothed and unsmoothed settings. We now begin validating the claim.

Corollaries for a Subgradient Method

Continue to assume SDP has an optimal solution and I is feasible.

Given ε  >  0 and a value satisfying [formula], we wish to approximately solve the SDP equivalent problem

[formula]

where by "approximately solve" we mean that feasible X is computed for which

[formula]

with ε' satisfying

[formula]

Indeed, according to Proposition [\ref=prop.bd], the projection Z  =  Z(X) will then satisfy

[formula]

We begin by recalling a well-known complexity result for a subgradient method, interpreted for when the method is applied to solving the SDP equivalent problem ([\ref=eqn.ca]). From this is deduced a bound on the number of iterations sufficient to obtain X whose projection Z  =  Z(X) satisfies ([\ref=eqn.cb]). We observe, however, that in a certain respect, the result is disappointing. In the next section, the framework is embellished by applying the subgradient method not to ([\ref=eqn.ca]) for only one value [formula], but to ([\ref=eqn.ca]) for a small and carefully chosen sequence of values, [formula]. The embellishment results in a computational scheme which possesses the desired improvement.

For specifying a subgradient method and stating a bound on its complexity, we follow Nesterov's book [\cite=nesterov2004introductory]:

Subgradient Method

Inputs:

Number of iterations: N

Initial iterate: X0 satisfying A(X0)  =  b and 〈C,X0〉  <  〈C,I〉. [formula]       Let [formula].

Distance upper bound: R, a value for which there exists [formula] [formula]             satisfying [formula]

Initial "best" iterate: X  =  X0

Initial counter value: k  =   - 1

Update counter: k + 1  →  k

Iteration: Compute a subgradient [formula] and orthogonally project it onto the subspace

[formula]

Denoting the projection by Gk, compute

[formula]

If λmin(Xk + 1)  >  λmin(X), then make the replacement Xk + 1  →  X  .

Check for termination: If k  =  N  -  1, then output X and terminate. [formula]           Else, go to Step 1.

For [formula], the output X satisfies

[formula]

where [formula] and X0 is the input matrix.

Proof: The function X  ↦  λmin(X) is Lipschitz continuous with constant 1:

[formula]

The result is thus a simple corollary of Theorem 3.2.2 in Nesterov's book, by choosing the parameter values there to be [formula] for [formula]. [formula]

We briefly digress to the special case of linear programming.

Recall for LP - the linear program ([\ref=eqn.bz]) - the projected subgradients at x are the convex combinations of the columns k for which xk  =   min jxj, where [formula] is the matrix projecting [formula] orthogonally onto the nullspace of [formula], that is,

[formula]

In particular, if x is the current iterate for Subgradient Method, a projected subgradient can be selected simply by computing any column k for which xk  =   min jxj. Subgradient Method then moves from x to [formula]. The geometry is interesting in that each step is being chosen from among only the vectors [formula] for [formula].

The geometry is made even more interesting by Theorem [\ref=thm.ca] asserting that even for the choice of steps coming from this limited set of vectors, still it holds that the final output x satisfies

[formula]

where [formula] denotes the jth coordinate of the optimal solution x* for the LP equivalent problem

[formula]

Now we return to the more general setting of semidefinite programming.

Below, the input matrix X0 to Subgradient Method is required to be feasible for SDP, mainly so that the input R can be chosen as a value with clear relevance to SDP, a value we now describe.

The "level sets" for SDP are the sets

[formula]

where [formula] is any fixed value. Of course [formula] if [formula].

If some nonempty level set is bounded, then all level sets are bounded. On the other hand, if a level set is unbounded, then either SDP has unbounded optimal value or can be made to have unbounded value with an arbitrarily small perturbation of C. Thus, in developing numerical methods for approximating optimal solutions, it is natural to focus on the case that level sets for SDP are bounded (equivalently, the dual problem is strictly feasible). Hence, we assume the level sets are bounded.

Let [formula] be a known value satisfying

[formula]

that is, an upper bound on the diameters of all level sets for better objective values than the value for the level set containing I.

Although the assumption of knowing the upper bound [formula] is strong, it is consistent with assumptions found throughout the literature on first-order methods, such as the requirement for Subgradient Method that the input R be an upper bound on [formula], where X0 is the input matrix.

Moreover, even though the assumption of knowing [formula] is strong, still there are many interesting situations in which the assumption is valid, particularly when a problem is specifically modeled in such a way as to make the diameter of the level sets (for [formula]) be of reasonable magnitude. For example, when I is on (or near) the central path, the choice of upper bound [formula] is valid, albeit for various carefully modeled semidefinite programs in which I is explicitly made to be near the central path, stronger upper bounds hold (e.g., [formula] in numerous interesting cases, some of which are displayed in the forthcoming paper [\cite=renegar2014hyperbolic]).

In most of the literature on optimal first-order methods, the feasible region is required to be bounded, not just the level sets. By focusing on relative error ([\ref=eqn.cb]) rather than absolute error, we are able to require only that the level sets be bounded, not the feasible region.

In the following corollary regarding Subgradient Method, the choice of input N depends on the optimal value for SDP. Naturally the reader will infer that in addition to knowing the upper bound [formula], our algorithmic scheme will require knowing a lower bound on [formula], but this is not the case for the scheme. The corollary is used for motivating the next step in specifying the scheme.

Assume X0 is feasible for [formula] and satisfies 〈C,X0〉  <  〈C,I〉. Define [formula]. Let 0  <  ε  <  1.

If X0 and [formula] are inputs to [formula], along with an integer N satisfying

[formula]

then for the output X, the projection Z(X) satisfies

[formula]

Proof: Since X0 is feasible, so is [formula] (because [formula]). Thus, [formula], making [formula] a valid input to Subgradient Method.

For inputs as specified, Theorem [\ref=thm.ca] immediately implies the output X for Subgradient Method satisfies

[formula]

Invoking Proposition [\ref=prop.bd] completes the proof. [formula]

The dependence of the iteration lower bound ([\ref=eqn.ce]) on ε2 is unfortunate but probably unavoidable without smoothing the objective function X  ↦  λmin(X), as is done in sections [\ref=sect.nesterov] and [\ref=sect.smoothed]. Likewise, a significant dependence on [formula] - or some other meaningful quantity capturing the distance [formula] - probably is unavoidable. However, the dependence on [formula] is disconcerting.

To understand why the dependence is disconcerting, consider that the most natural choice for the input matrix is [formula], where π(C) is the orthogonal projection of C onto the subspace {V:A(V)  =  0}. This is the choice for X0 obtained by moving from I in direction   -  π(C) until the boundary of the semidefinite cone is reached.

However, even when I is on the central path (in which case the direction   -  π(C) is tangent to the central path), it can happen that the value [formula] is of magnitude [formula] for [formula] and [formula]. Thus, even for problems modeled carefully so that I is on the central path and [formula] is of limited size, the iteration lower bound ([\ref=eqn.ce]) can grow significantly with n regardless of the value for ε. This is disconcerting.

Moreover, we want an algorithm for which [formula] does not explicitly figure into choosing the inputs. We already assume the upper bound [formula] is known. We want to avoid also assuming a lower bound on [formula] is known.

These matters are handled in the following section.

The NonSmoothed Scheme

The observations concluding the preceding section raise a question:

Is it possible to efficiently move from an initial feasible matrix U0 satisfying 〈C,U0〉  <  〈C,I〉, to a feasible matrix Y for which [formula] satisfies, say, [formula]?

We begin this section by providing an affirmative answer, but first let us again display the pertinent optimization problem:

[formula]

Recall that [formula] denotes any optimal solution of ([\ref=eqn.da]), an optimization problem which is equivalent to SDP (assuming [formula]).

Consider the following computational procedure:

NonSmoothed SubScheme

Initiation:

Input: A matrix U0 that is feasible for SDP and satisfies 〈C,U0〉  <  〈C,I〉.

Let [formula]

Let [formula].

Outer Iteration Counter Step: [formula]

Inner Iterations:

Apply Subgradient Method with inputs [formula], [formula] and [formula].

Rename the output X as [formula].

Check for Termination:

If [formula], then output [formula] and terminate.

Else, compute the projection

[formula]

and go to Step 1.

[formula] outputs Y that is feasible for SDP and satisfies

[formula]

where [formula]. The total number of outer iterations does not exceed

[formula]

where [formula] and U0 is the input matrix.

Proof: It is easily verified that all of the matrices [formula] and [formula] computed by NonSmooth SubScheme satisfy the SDP equations A(X)  =  b. Moreover, [formula] is clearly feasible for SDP, lying in the boundary of the feasible region.

Fix [formula] to be any value attained by the counter. We now examine the effects of Steps 2 and 3.

Corollary [\ref=cor.cb] with [formula] shows that in Step 2, the output X from Subgradient Method satisfies

[formula]

that is,

[formula]

Observe

[formula]

Hence, if the method terminates in Step 3 - that is, if [formula] - then the output matrix [formula] satisfies

[formula]

where [formula]. We have now verified that if NonSmoothed SubScheme terminates, then the output Y is indeed feasible for SDP and satisfies the desired inequality ([\ref=eqn.dc]).

On the other hand, if the method does not terminate in Step 3, it computes the matrix [formula] and its objective value, [formula]. Here, observe

[formula]

because [formula] and [formula] (due to no termination). Hence,

[formula]

Since all values [formula] computed by the algorithm satisfy [formula] (as [formula] is feasible for SDP), it immediately follows that

[formula]

is an upper bound on the number of outer iterations. [formula]

Specifying our overall computational scheme relying on the subgradient method, and analyzing the scheme's complexity, both are now easily accomplished:

NonSmoothed Scheme

Inputs: A value 0  <  ε  <  1, and a matrix U0 which both is feasible for [formula] and satisfies 〈C,U0〉  <  〈C,I〉.

For example, the matrix [formula].

Apply NonSmoothed SubScheme with input U0. Let Y denote the output.

Apply Subgradient Method with inputs X0  =  Y, [formula] and

[formula]

Let X denote the output.

Compute and output the projection Z  =  Z(X), then terminate.

In stating the following theorem, we make explicit that I is being assumed as feasible. The generalization to assuming known a strictly feasible matrix, but not necessarily the identity, is presented in section [\ref=sect.scaling].

Assume I is feasible for [formula]. [formula] outputs Z which is feasible for [formula] and satisfies

[formula]

The total number of iterations of [formula] is bounded above by

[formula]

where [formula] and U0 is the input matrix.

Proof: Proposition [\ref=prop.da] shows the output matrix Y from Step 1 is feasible for SDP and satisfies

[formula]

where [formula]. Thus, by Corollary [\ref=cor.cb], when X0  =  Y is input into Subgradient Method, along with [formula] and [formula], the projection Z(X) of the output X satisfies

[formula]

establishing correctness of NonSmoothed Scheme.

The bound for total iterations of Subgradient Method is immediate from the outer iteration bound of Proposition [\ref=prop.da], and the choices for the number of iterations in Step 2 of NonSmoothed SubScheme and in Step 2 of NonSmoothed Scheme. [formula]

The following corollary is useful when an optimization problem is modeled so as to make I be on (or near) the central path. The proof follows standard lines in interior-point method theory, but nonetheless we include the proof for completeness.

If I is on the central path and the input matrix is chosen as [formula], then the same conclusions as in Theorem [\ref=thm.db] apply but now with the number of [formula] iterations bounded above by

[formula]

Proof: Assume I is on the central path, that is, assume for some μ  >  0 that I is the optimal solution for

[formula]

Since the gradient of the objective function at [formula] is C  -  X- 1, a first-order optimality condition satisfied by I is that there exists a vector y for which

[formula]

where [formula] is the adjoint of A. This implies that the projection of C and μI onto the nullspace of A are identical. Consequently, Hence, all X which are both feasible for SDP and have better objective value lie within the set [formula], a set which is contained within the ball of radius n centered at I. Thus, all feasible X for SDP satisfy

[formula]

that is,

[formula]

On the other hand, the feasible matrix [formula] lies distance at least 1 from I, because the unit ball centered at I is contained in [formula] and because U0 lies in the boundary of [formula]. Hence,

[formula]

Consequently,

[formula]

Combining ([\ref=eqn.dd]) and ([\ref=eqn.de]) gives

[formula]

Substitution into Theorem [\ref=thm.db] completes the proof. [formula]

It is interesting to observe that for any fixed value of ε, if one is able to model a family of optimization problems as semidefinite programs [formula] parameterized by n (the number of variables) in such a way that for every n, both In is on (or near) the central path and for some p  <  1 / 4, [formula], then the iteration bound provided by the corollary is better than the best iteration bound established for interior-point methods, i.e., [formula] iterations when ε is fixed. As each iteration of Subgradient Method is cheap relative to the cost of an interior-point method iteration, in this case NonSmoothed Scheme wins hands down.

On the other hand, of course, if n is held fixed and ε goes to zero, the bound O( log (1 / ε)) on the number of iterations for interior-point methods is massively better than the bound O(1 / ε2) for NonSmoothed Scheme.

Starting Points [formula]

In this section it is observed that the theory and algorithms from previous sections are readily converted to the case that the starting point is a strictly-feasible matrix E  ≠  I.

As in the remarks closing section [\ref=sect.thy], the relevant concave function is

[formula]

(the smallest eigenvalue of the matrix E- 1 / 2XE- 1 / 2, where E1 / 2 is the positive definite matrix satisfying E  =  E1 / 2E1 / 2). As those remarks noted, the theory of that section is easily generalized, which for the present situation means replacing all occurrences of λ min appearing in section [\ref=sect.thy] by λmin ,E, while simultaneously replacing I by E, assuming E is strictly feasible.

The algorithms and theory from sections [\ref=sect.subgrad] and [\ref=sect.nonsmoothed], however, are not so obviously extended. At issue is that unlike X  ↦  λmin(X), the function X  ↦  λmin ,E(X) need not be Lipschitz continuous with constant 1, a fact that was critical in the proof of Theorem [\ref=thm.ca]. Thankfully, the issue is easily handled by changing from the trace inner product to the inner product on [formula] used in interior-point method theory:

[formula]

Thus, for example, when SubGradient Method computes a subgradient for iterate Xk, the subgradient should be with respect to 〈  ,  〉E rather than with respect to 〈  ,  〉.

Likewise, when SubGradient Method projects a subgradient onto the subspace ([\ref=eqn.cc]), the projection should be orthogonal with respect to 〈  ,  〉E.

Finally, the value [formula] should be replaced by a value [formula] satisfying

[formula]

With these changes, all of the results of previous sections are valid with E in place of I.

For linear programming, the resulting changes to Subgradient Method are quickly described. Letting e denote the known strictly-feasible point (not necessarily the vector of all ones), and letting [formula] be any value satisfying [formula], the problem equivalent to LP is

[formula]

In applying Subgradient Method, the relevant inner product is

[formula]

With respect to this inner product, the subgradients at [formula] are the convex combinations of the vectors e'(k) for which xk  /  ek  =   min jxj / ej, where e'(k) has all coordinates equal to zero except for the kth coordinate, which is equal to ek.

The 〈  ,  〉e-orthogonal projections of the vectors e'(j) ([formula]) onto the nullspace of

[formula]

are the columns of the matrix e that 〈  ,  〉e-orthogonally projects [formula] onto the nullspace, that is,

[formula]

where Δ(e) is the diagonal matrix with jth diagonal entry equal to ej. Thus, the projected subgradients relied upon by Subgradient Method are now the convex combination of the columns of e.

Perhaps the easiest way to understand why all of the results of previous sections remain valid when I is replaced by E - and 〈  ,  〉 is replaced by 〈  ,  〉E - is to use the standard trick in the interior-point method literature of "scaling" SDP to an equivalent semidefinite program for which I is feasible. The equivalent semidefinite program (in variable Y) is

[formula]

The equivalence is seen by noting X is feasible for SDP if and only if Y  =  E- 1 / 2XE- 1 / 2 is feasible for [formula], and the objective value of X for [formula] is the same as the objective value of Y for [formula].

Moreover, the inner product 〈  ,  〉E is transformed into the trace inner product, in that 〈X1,X2〉E  =  〈Y1,Y2〉 for Yj  =  E- 1 / 2XjE- 1 / 2 (j  =  1,2). Thus, for example, the 〈  ,  〉E-diameter of level set [formula] is the same as the 〈  ,  〉-diameter of level set [formula].

Lastly, as is straightforward but tedious to verify, each of the algorithms transforms as well. For example, consider Subgradient Method, and fix two of the inputs, R and N. Assume the algorithm is applied with 〈  ,  〉E to solving the linearly-constrained problem equivalent to SDP:

[formula]

Then [formula] is a possible resulting sequence if and only if [formula] - where Yj: = E- 1 / 2XjE- 1 / 2 - is a possible resulting sequence when Subgradient Method is applied using the trace inner product to the problem equivalent to [formula]:

[formula]

Applying any of the algorithms with strictly-feasible E - and with inner product 〈  ,  〉E - is, in other words, equivalent to scaling SDP, applying the algorithm with I and the trace inner product, and then unscaling the answer.

We choose to assume I is feasible only to reduce notational clutter and make evident the simplicity of the main ideas.

(Unfortunately, the trick of scaling does not generalize to hyperbolic programming, making the proofs in the forthcoming paper [\cite=renegar2014hyperbolic] necessarily more abstract than the ones here.)

In closing the section, we remark that the results throughout the paper can be developed just as readily for semidefinite programs of, say, the form

[formula]

One assumes known a strictly feasible point e', and relies upon the concave function X  ↦  λmin ,E(X) specified in ([\ref=eqn.ea]), letting [formula]. The equivalent problem solvable by a subgradient method is

[formula]

for any value satisfying [formula]. The relevant inner product at e' is

[formula]

For the special case of a linear program

[formula]

letting αTi denote the ith row of A and letting e: = Ae'  -  b, the equivalent problem for [formula] is

[formula]

The relevant inner product is

[formula]

where Δ(e) is the diagonal matrix with ith diagonal entry equal to ei.

Corollaries for Nesterov's "First First-Order Method"

Assume SDP has an optimal solution and I is feasible. (In exactly the same manner as previous results generalize to an arbitrary strictly-feasible initial matrix E, so do all of the remaining results.)

Recall that given ε  >  0 and a value [formula] satisfying [formula], we wish to approximately solve the SDP equivalent problem

[formula]

where by "approximately solve" we mean that feasible X is computed for which

[formula]

with ε' satisfying

[formula]

Indeed, according to Proposition [\ref=prop.bd], the projection Z  =  Z(X) will then satisfy

[formula]

With [\cite=nesterov2005smooth], Nesterov initiated a huge wave of research, by displaying that some significant non-smooth optimization problems can be efficiently solved by "smoothing" the problem and then applying optimal first-order methods for smooth functions. In [\cite=nesterov2007smoothing], he extended the approach to include some problems within the domain of semidefinite programming. Here he gave emphasis to the nonsmooth convex objective function X  ↦  λ max (X), but the results trivially adapt to the concave function of interest to us, X  ↦  λmin(X).

For the nonsmooth concave function X  ↦  λ min(X), the useful smoothing is

[formula]

where μ  >  0 is user-chosen, and where [formula] are the eigenvalues of X. For motivation, observe that for all [formula],

[formula]

Not obvious, but which Nesterov proved,

[formula]

where [formula] is the Frobenius norm. That is, the gradient of fμ is Lipschitz continuous, with constant 1 / μ.

The smoothed version of ([\ref=eqn.fa]) is

[formula]

Let [formula] denote an optimal solution (which the reader should be careful to distinguish from [formula] an optimal solution for ([\ref=eqn.fa])).

In passing, we note that the gradient of fμ at X is the the matrix

[formula]

where [formula] is an eigendecomposition of X.

For the special case of linear programming, the function fμ becomes

[formula]

for which the gradient at x is the vector with jth coordinate equal to

[formula]

It is readily seen from ([\ref=eqn.fe]) that for any value ε'  >  0 and for all [formula], if [formula], then

[formula]

Consequently, in order to compute X which is feasible for ([\ref=eqn.fa]) and satisfies ([\ref=eqn.fb]), it suffices to fix [formula] and compute X which is feasible for ([\ref=eqn.ff]) and has objective value within ε' / 2 of [formula].

Since the objective function in ([\ref=eqn.ff]) is smooth and the only constraints are linear equations, we can apply many first-order methods. It is only fitting that we rely on the original "optimal" first-order method for smooth functions, due to Nesterov [\cite=nesterov1983method], and which we refer to as "Nesterov's first first-order method," or for brevity, "Nesterov's first method."

Letting X0 denote an initial feasible point, then according to Theorem 2.2.2 in [\cite=nesterov2004introductory], Nesterov's first method produces a sequence of iterates [formula] satisfying

[formula]

(where we have used the fact that the Lipschitz constant for the gradient is 1 / μ). Thus, fμ(Xk) is within ε' / 2 of the optimal value if

[formula]

that is, if

[formula]

(using [formula]). We summarize these results in a theorem.

Let ε' be any positive value, and [formula]. Assume X satisfies A(X)  =  b and [formula]. If Nesterov's first first-order method is applied to solving the smoothed problem ([\ref=eqn.ff]), then the resulting iterates [formula] satisfy

[formula]

Recall that [formula] is assumed to be a known quantity satisfying

[formula]

Assume X is strictly feasible for SDP and [formula].

For any value 0  <  ε'  ≤  2  λmin(X), by letting [formula], if Nesterov's first first-order method is applied to solving the smoothed problem ([\ref=eqn.ff]), then the resulting iterates [formula] satisfy

[formula]

Proof: Assume X, ε' and μ are as in the statement. Then fμ(X)  ≥  0, by ([\ref=eqn.fe]) and μ  ≤  λmin  /   ln (n). Hence, [formula] (because [formula]).

Also by ([\ref=eqn.fe]), [formula] Thus, [formula] is feasible for SDP. Hence, [formula] Substitution into Theorem [\ref=thm.fa] completes the proof. [formula]

Assume X is feasible for SDP and satisfies

[formula]

where [formula]. Let 0  <  ε  <  1.

For [formula], if Nesterov's first first-order method is applied to solving the smoothed problem ([\ref=eqn.ff]), then the resulting iterates [formula] satisfy

[formula]

Proof: Let ε': = ε / 3  ≤  1 / 3. Then, by assumption, ε'  ≤  2λmin(X), and hence Corollary [\ref=cor.fb] can be applied with

[formula]

giving

[formula]

where the last implication is due to the rightmost inequality assumed in ([\ref=eqn.fh]). Invoking Proposition [\ref=prop.bd] completes the proof. [formula]

The Smoothed Scheme

The presentation of the smoothed scheme is done in the same manner as the presentation of NonSmoothed Scheme in section [\ref=sect.nonsmoothed], but now beginning with the following question:

Is it possible to efficiently move from an initial matrix U0 satisfying A(U0)  =  b and 〈C,U0〉  <  〈C,I〉, to a matrix Y satisfying the conditions of Corollary [\ref=cor.fc]?

Before providing an affirmative answer, for ease of reference we again display the pertinent optimization problems:

[formula]

[formula]

Recall that [formula] denotes any optimal solution for ([\ref=eqn.ga]) - a problem equivalent to SDP (assuming [formula]) - whereas [formula] denotes an optimal solution for ([\ref=eqn.gb]) - the smoothed version of ([\ref=eqn.ga]).

Consider the following computational procedure:

Smoothed SubScheme

Initiation:

Input: A matrix U0 that is feasible for SDP and satisfies both 〈C,U0〉  <  〈C,I〉 and λmin(U0)  =  1 / 6.

If a matrix U is available satisfying only A(U)  =  b and 〈C,U〉  <  〈C,I〉, then [formula] is acceptable input.

Let [formula]

Let μ: = 1 / (6   ln n) and [formula].

Let [formula].

Outer Iteration Counter Step:

Let [formula]

Inner Iterations:

Beginning at [formula], apply N iterations of Nesterov's first first-order method to the smoothed problem ([\ref=eqn.gb]), with [formula].

Let [formula] denote the final iterate.

Check for Termination:

If [formula], then output [formula] and terminate.

Else, compute

[formula]

and go to Step 1.

[formula] terminates with a matrix Y which is feasible for [formula] and satisfies

[formula]

where [formula]. Moreover, the number of outer iterations does not exceed

[formula]

where [formula] and U0 is the input matrix.

Proof: The proof - especially the last half - parallels that of Proposition [\ref=prop.da]. Nonetheless, we include the proof in its entirety.

It is easily verified that all of the matrices [formula] and [formula] computed by Smoothed SubScheme satisfy the SDP equations A(X)  =  b. Moreover, [formula] is feasible for SDP, because [formula] (by construction).

Fix [formula] to be a value attained by the counter. We now examine the effects of Steps 2 and 3.

Applying Corollary [\ref=cor.fb] with ε'  =  1 / 3 shows that in Step 2, the final iterate XN computed by Nesterov's first method satisfies

[formula]

that is,

[formula]

Observe that

[formula]

Hence, if the method terminates in Step 3 - that is, if [formula] - then the output matrix [formula] satisfies

[formula]

where [formula]. We have now verified that if the Smoothed SubScheme terminates, then the output Y is indeed feasible for SDP and satisfies the inequalities ([\ref=eqn.gc]).

On the other hand, if the method does not terminate in Step 3, it computes the matrix [formula] and its objective value, [formula]. Here, observe

[formula]

because [formula] and [formula] (due to no termination). Hence,

[formula]

Since all values [formula] computed by the algorithm satisfy [formula] (because [formula] is feasible for SDP), it immediately follows that

[formula]

is an upper bound on the number of outer iterations. [formula]

Specifying our scheme based on Nesterov's first method, and analyzing the scheme's complexity, both are now easily accomplished:

Smoothed Scheme

Input: A value 0  <  ε  <  1, and [formula] satisfying A(U0)  =  b and λmin(U0)  =  1 / 6.

For example, the matrix [formula].

Apply Smoothed SubScheme with input U0. Let Y denote the output.

Beginning at Y, apply [formula] iterations of Nesterov's first first-order method to the smoothed problem ([\ref=eqn.gb]), with [formula] Let X denote the output.

Compute and output the projection Z  =  Z(X), then terminate.

Assume I is feasible. [formula] outputs Z which is feasible for [formula] and satisfies

[formula]

The total number of iterations of Nesterov's first first-order method is bounded above by

[formula]

where [formula] and U0 is the input matrix.

Proof: Proposition [\ref=prop.ga] shows the matrix Y in Step 1 satisfies the conditions of Corollary [\ref=cor.fc], which in turn shows the final output Z  =  Z(X) from Step 3 is feasible for SDP and satisfies ([\ref=eqn.ge]).

The bound on the total number of iterations of Nesterov's first method is a straightforward consequence of the outer iteration bound from Proposition [\ref=prop.ga], the choice for N in Smoothed SubScheme, and the number of iterates in Step 2 of Smoothed Scheme. [formula]

The proof of the following corollary proceeds exactly as does the proof of Corollary [\ref=cor.dc]. The added value 1 is due to λmin(U0)  =  1 / 6 in Smoothed Scheme - unlike λmin(U0)  =  0 in NonSmoothed Scheme - and

[formula]

If I is on the central path and [formula], then the same conclusions as in Theorem [\ref=thm.gb] apply but now with the number of iterations of Nesterov's first first-order method bounded above by

[formula]

Closing Remarks

Similar to the observation immediately following Corollary [\ref=cor.dc], we see from Corollary [\ref=cor.gc] that for fixed ε, if one models a family of problems as semidefinite programs [formula] where In is on (or near) the central path and for which there exists p  <  1 / 2 satisfying [formula], then Smoothed Scheme wins hands down over interior-point methods even on iteration count, let alone on total cost.

Interior-point methods, of course, win hands down if n is fixed and ε goes to zero.

For fixed n, our iteration bound of O(1 / ε) is much worse than the bound [formula] found in literature related to compressed sensing, where problems can be reduced to ones involving only the feasible regions [formula] - or [formula] - for which tractable prox functions are known. However, the approaches used there fail upon including additional constraints, such as requiring X to satisfy a specific sparsity pattern, as is relevant in statistics for fitting a concentration matrix (the inverse of a covariance matrix) to empirical data, and as is relevant in some applications of semidefinite programming to combinatorial problems pertaining to graphs. Among the obstacles is that tractable proximal operators remain unknown except for an extremely small universe of sets.

In this vein, we note that for the algorithms herein, imposing a specific sparsity pattern actually reduces work, assuming the known feasible matrix is E  =  I. Indeed, assuming the sparsity pattern is Xij  =  0 for [formula], and using 〈Ak,X〉  =  bi ([formula] to denote the remaining constraints, projecting a subgradient G is accomplished by overwriting by 0 the entries Gi,j for [formula], and orthogonally projecting the resulting matrix onto the subspace

[formula]

where [formula] (resp., Āk) is the matrix obtained by overwriting by 0 the (i,j)th coordinate of C (resp., Ak), for [formula]. If [formula] - the number of "complicating constraints" - is small and the set [formula] is large, this approach results in significant computational savings per iteration.

Moreover, the resulting iteration cost is very cheap relative to the cost of an iteration of an interior-point method, where sparsity constraints must be handled like any other constraints, due to the inner product 〈  ,  〉Xk being dependent on the iterate, unlike first-order methods where the inner product 〈  ,  〉  =  〈  ,  〉I is held fixed throughout, an inner product for which sparsity constraints are ideally structured.

Additional examples of the relevance of the algorithms and results, and their extensions to hyperbolic programming, are given in the forthcoming paper [\cite=renegar2014hyperbolic].