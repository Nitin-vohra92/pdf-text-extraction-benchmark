Lemma

Bayesian Model Selection Based on Proper Scoring Rules

Introduction

The desire for an "objective Bayesian" approach to model selection has produced a wide variety of suggested methods, none entirely satisfactory from a principled perspective. Here we develop an approach based on the general theory of proper scoring rules, and show that, suitably deployed, it can evade problems associated with arbitrary scaling constants, and deliver consistent model selection.

Bayesian Model Selection

Let M be a finite or countable class of statistical models for the same observable X∈X  ⊆  Rk. Each M∈M is a parametric family, with parameter θM∈TM, a dM-dimensional Euclidean space; when M obtains, with parameter value θM, then X has distribution PθM, with Lebesgue density pM(x  |  θM). Having observed data X  =  x, we wish to make inference about which model M∈M (and possibly which parameter-value θM) actually generated these data.

A subjective Bayesian would begin by assigning a discrete prior distribution over M, with α(M), say, the assessed probability that the true model is M∈M; and, within each model M, a prior distribution ΠM for its parameter θM (to be interpreted as describing conditional uncertainty about θM, given the validity of model M). For simplicity we suppose that ΠM has a density function, πM(θM), with respect to Lebesgue measure dθM over TM.

The predictive density function of X, given only the validity of model M, is

[formula]

This can be thought of as a hybrid between an "objective" component, pM(x  |  θM), and a "subjective" component, π(θM).

Considered as a function of M∈M, for given data x, pM(x) given by [\eqref=eq:preddens]--or any function on M proportional to this--supplies the marginal likelihood function, L(M), over M∈M, based on data x:

[formula]

The posterior probability α(M  |  ) for model M is then given by Bayes's formula:

[formula]

where the omitted multiplicative constant is adjusted to ensure [formula]. In particular, the odds, α(M1) / α(M2), in favour of one model M1 versus another model M2, are multiplied, on observing X  =  x, by the Bayes factor L(M1) / L(M2).

However, although the Bayes factor is "objective" to the extent that it does not involve the initial discrete prior distribution α over the model space M, it does still depend on the prior densities πM1, πM2, within the models being compared. As shown in [\citet=Dawid:2011], if the data are independently generated from a distribution Q, the log-Bayes factor, log L(M1) / L(M2), behaves asymptotically as [formula] when K(Q,M2)  >  K(Q,M1), where K(Q,M) denotes the minimum Kullback-Leibler divergence between Q and a distribution in M; while, if Q lies both in M1 and in M2 (so that K(Q,M2)  =  K(Q,M1)  =  0), with [formula] say, we have log-Bayes factor

[formula]

where [formula] is the "invariantised" prior density with respect to the Jeffreys measure on M; V  =  Op(1), with asymptotic expectation 0; and the dependence of V on the prior specification is [formula].

We thus see that, at any rate for comparing models of different dimension, the dependence of the Bayes factor on the within-model prior specifications is typically negligible compared with the leading term in the asymptotic expansion. Nevertheless, many Bayesians have agonised greatly about that dependence, and have attempted to determine an "objective" version of the Bayes factor. The most obvious approach, of using improper within-model priors, is plagued with difficulties: the term ρ(θ*|M) is perfectly well-defined when we have a fully specified prior density, integrating to 1; but when the prior density is non-integrable this function is specified only up to an arbitrary scale factor--and [\eqref=eq:true] will depend on the chosen value of this factor. A variety of ad hoc methods have been suggested to evade this problem (see, for example, [\citet=OH] [\citet=Ber-Per]). These methods are necessarily somewhat subtle--one might even say contorted--and often do not even respect the leading term asymptotics of [\eqref=eq:true].

In [\citet=Dawid:2011], it was argued that the problem of model selection with improper priors can largely be overcome by focusing directly on the posterior odds, rather than the Bayes factor, between models. An alternative approach, that we develop here, is to replace the Bayes factor by something different (but related), that is insensitive to the scaling of the prior. For preliminary accounts of this idea, see [\citet=Musio-Dawid:2013] [\citet=apd/mm:metron].

Proper Scoring Rules

The log-Bayes factor for comparing models M1 and M2 is

[formula]

One way of interpreting [\eqref=eq:logBF] is as a comparison of the log-scores [\citep=Good:1952] of the two predictive density functions, pM1(  ·  ) and pM2(  ·  ), for X, in the light of the observed data x. That is, defining SL(x,Q)  =    -   log q(x), for any proposed distribution Q with density function q(  ·  ) over X, and x∈X, we can interpret the log-score SL(x,Q) as a measure of how badly Q did at forecasting the outcome x; then the log-Bayes factor measures by how much the log-score for M1 (using the associated predictive density) was better (smaller) than that for M2.

Now the above definition of the log-score, SL(x,Q), is just one of many functions S(x,Q) having the property of being a proper scoring rule (see, e.g. [\citet=Dawid:1986]): this is the case if, defining S(P,Q) as the expected score, [formula], when X has distribution P, S(P,Q) is minimised, for any given P, by the "honest" choice Q  =  P. Associated with any proper scoring rule is a generalised entropy function: and a non-negative discrepancy function: These reduce to the familiar Shannon entropy and Kullback-Leibler discrepancy when S is the log-score.

Standard statistical theory is largely based on the log-score (corresponding to log-likelihood), the Shannon entropy, and the Kullback-Leibler discrepancy. However, a very large part of that theory generalises straightforwardly when these are replaced by some other proper scoring rule, and its associated entropy and discrepancy: see [\citet=apd/mm/lv] for applications of proper scoring rules to general estimation theory. Use of a proper scoring rule other than the log-score typically sacrifices some efficiency for gains in computational efficiency and/or robustness. Because there is a wide variety of proper scoring rules, this offers greatly increased flexibility. The choice of which specific rule to use may be based on external considerations--for example, derived from the loss function of a real decision problem [\citep=pdg/apd:ams04]; or chosen for convenience--for example, for reasons of tractability or robustness [\citep=apd/mm:metron].

In this paper we explore the implications and ramifications, for Bayesian model selection, of replacing the log-score by some other proper scoring rule as a yardstick for measuring and comparing the quality of statistical models. In particular, we shall see that, for a certain class of such proper scoring rules, the problems with improper priors simply do not arise.

Prequential Application

Let [formula], [formula]. Let Q be a distribution for X, with induced joint distribution Qn, having density qn(  ·  ), for Xn. Using a prequential (sequential predictive) approach [\citep=dawi:1984], decompose qn into its sequence of recursive conditionals:

[formula]

where qi(  ·  ) is the density function of the distribution Qi of Xi, given Xi - 1  =  xi - 1; note that this depends on xi - 1, even though the notation omits this. We now apply a proper scoring rule Si (the form of which could in principle even depend on xi - 1) to the ith term in [\eqref=eq:q], and cumulate the scores to obtain the prequential score

[formula]

where Qi is a function of xi - 1. It is readily seen that this yields a proper scoring rule for Xn (strictly proper if every Si is).

Define

[formula]

and

[formula]

where Di is the discrepancy function associated with the component scoring rule Si. Then Dn is in fact a function of xn - 1.

Now [formula] is non-decreasing, and under suitable conditions we will have Dn  →    ∞   [formula]. One useful condition for this is the following:

Suppose that P and Q are mutually singular (as distributions for the infinite sequence X), and for all i and some k > 0, Di(Pi,Qi)  ≥  kH2(Pi,Qi), where H denotes Hellinger distance. Then Dn  →    ∞   [formula].

Singularity implies [formula] [formula] [\citep=Kabanov:1977].

Also,

[formula]

is a 0-mean martingale under P: indeed, it is the difference of the two 0-mean martingales

[formula]

and

[formula]

Under suitable and reasonable conditions on the behaviour of the increments Si(xi,Qi)  -  Si(xi,Pi) of Δn(P,Q), |Un| will remain small in comparison with Dn. For example, if the increments are all of similar size, a martingale law of the iterated logarithm (see, e.g.[\citet=stout:1970]) would restrict sup n|Un| to have order [formula], while Dn would be of order n. It would then follow that, with P-probability 1, Δn  →    ∞  . In such a case, if P is the true distribution generating the data, then eventually we will have, with probability 1, Sn(Xn,P)  <  Sn(Xn,Q). Then choosing the model with the lowest prequential score Sn will yield a consistent criterion for selecting among a finite collection of distributions for X.

Application to Model Selection

The above theory can be applied to the case that P, Q are the predictive distributions associated with different Bayesian models, M and N. In particular, suppose we have statistical models

[formula]

with prior Π over T; and

[formula]

with prior K over F; and corresponding predictive distributions

[formula]

Under conditions that allow application of the above results, we will have P(A) = 1, where A is the event Sn(Xn,Q)  -  Sn(Xn,P)  →    ∞  . Since [formula], we must have Pθ(A)  =  1 for θ∈S, where Π(S)  =  1. In particular, if Π has Lebesgue density π that is everywhere positive, then Pθ(A)  =  1 for almost all θ∈T. So the criterion Sn will choose the correct model with probability 1 under (almost) any distribution in that model. This result generalises the consistency property of log-marginal likelihood [\citep=Dawid:1992] to other proper scoring rules.

Local Scoring Rules

We call a scoring rule S(x,Q) local (of order m) if it can be expressed as a function of x, and of the density function q(  ·  ) of Q and its derivatives up to the mth order, all evaluated at x. Thus the log-score is local of order 0. For the case that the sample space X is an interval on the real line, [\citet=Parry:2012] have characterised all proper local scoring rules. It was shown that these can all be expressed as a linear combination of the log-score and a "key local" scoring rule, which is a proper local scoring rule that is homogeneous in the sense that its value is unchanged if q and (thus) all of its derivatives are multiplied by some constant c > 0.

This property of a key local scoring rule has been found useful in estimation theory. In standard likelihood inference, we need to compute, and differentiate with the respect to the parameter, the log-normalising constant of the statistical model distributions; and this can be computationally prohibitive. But if, instead of log-score, we use a key local scoring rule, the normalising constant simply does not figure in the score, so simplifying computation: for some examples, see [\citet=apd/mm:asta] [\citet=apd/mm:metron]. Applied to model selection, this suggests a way of evading the problematic normalising constant of the compleat Bayesian analysis: if we replace the log-score in [\eqref=eq:logBF] by some key local scoring rule, the dependence on the normalising constant will disappear. Indeed, there is no problem in computing such a score even for an "improper" density q(  ·  ), having infinite integral over X.

For any [formula], the simplest key local scoring rule is the order-2 rule of [\citet=Hyvarinen:2005]:

[formula]

where [formula] denotes gradient, and Δ is the Laplacian operator [formula]. The associated discrepancy function is

[formula]

Variations on [\eqref=eq:genhy] and [\eqref=eq:hyvdisc] can be obtained, on first performing a non-linear transformation of the space X, or equipping X with the structure of a Riemannian space and reinterpreting [formula], Δ accordingly [\citep=Dawid-Lauritzen:2005]. Other key local scoring rules for the multivariate case are considered by [\citet=Parry:2013]. Though such variations can be useful, here we largely confine ourselves to the basic Hyvärinen score SH of [\eqref=eq:genhy]. However, there remains some freedom as to how this is applied: for example, we could apply the multivariate score directly to the data, or to a sufficient statistic, or cumulate the 1-dimensional scores associated with each term in the decomposition [\eqref=eq:q] [\citep=vm/mm/apd:hy]. While such manipulations have no effect on comparisons based on the log-score SL, they do typically affect those based on the Hyvärinen score SH. There is thus greater flexibility to apply this in useful ways, e.g. to ease computation, to improve robustness to model misspecification, or (as in ) to ensure other desirable properties such as consistency.

Multivariate Normal Distribution

Consider in particular the case that the distribution Q of X is multivariate normal:

[formula]

with density

[formula]

where Φ: = Σ- 1 is the precision matrix, and (in contrast to the usual convention for likelihood functions) the "constants" implicit in the proportionality sign are allowed to depend on the parameters, μ and Φ, but not on x.

We have

[formula]

so that, applying [\eqref=eq:genhy],

[formula]

The associated discrepancy between P  =  Nk(μP,Φ- 1P) and Q  =  Nk(μQ,Φ- 1Q) is

[formula]

The score [\eqref=eq:mvnhyv] may be relatively easy to compute if the model is defined in terms of its precision matrix Φ, as for a graphical model. Note also that, whereas the log-score SL in this case would involve computing the determinant of Φ, this is not required for SH.

We can now compare different hypothesised multivariate normal distributions Q for the observed data x by means of their associated SH scores given by [\eqref=eq:mvnhyv].

Univariate Case

For the univariate case Q  =  N(μ,σ2) we get

[formula]

In this case the Kullback-Leibler discrepancy is given by

[formula]

Using log x  ≤  x - 1, we find

[formula]

In the context of , where P and Q are both Gaussian processes for [formula], we can apply Remark [\ref=rem:kostas] to deduce that prequential model comparison between P and Q based on the Hyvärinen score will be consistent whenever P and Q are mutually singular, and (writing σ2Q,i for the variance, under Q, of Xi, given [formula]),

[formula]

and likewise with P and Q interchanged.

Bayesian Model

For the Bayesian the parameter is a random variable, Θ say. Let the statistical model have density at X  =  x, when Θ  =  θ. If the prior density is π(θ), the marginal density of x is Then we find

[formula]

where the expectations and variances are taken under the posterior distribution of Θ given X  =  x, having density π(θ|x)  =  p(x|θ)  π(θ) / q(x). This yields

[formula]

Exponential Family

Suppose further that the model is an exponential family with natural statistic T  =  t(x):

[formula]

Define [formula], [formula] to be the posterior mean-vector and dispersion matrix of Θ, given X  =  x. Then we obtain with [formula], [formula].

For the special case T  =  X, this becomes

Linear Model: Variance Known

Consider the following normal linear model for a data-vector [formula]:

[formula]

where X (n  ×  p) is a known design matrix of rank p, and θ∈Rp is an unknown parameter vector. In this section, we take σ2 as known.

Multivariate Score

Consider giving θ a normal prior distribution:

[formula]

The marginal distribution Q of Y is then

[formula]

with precision matrix

[formula]

on applying the Woodbury matrix inversion lemma ((10) of [\citet=Lindley-Smith:1972]).

An "improper" prior can now be generated by allowing [formula], yielding where with [formula], is the projection matrix onto the space of residuals.

Although this Φ is singular, and thus cannot arise from any genuine dispersion matrix, there is no problem in using it in [\eqref=eq:mvnhyv]. We obtain

[formula]

where R is the usual residual sum-of-squares for model [\eqref=eq:lm], on ν: = n - p degrees of freedom. Note that, unlike marginal log-likelihood, this is well-defined, in spite of the fact that we have not specified a "normalising constant" for the improper prior density. This is, of course, a consequence of the homogeneity of the Hyvärinen score SH.

The above analysis is not, however, applicable if rank(X)  <  p--in particular, whenever n < p. Taking [formula] is equivalent to using an improper prior density [formula], with 0 < c <   ∞  . When X is of rank p, the integral formally defining the marginal density of Y is finite for each y (even though the resulting density is itself improper). However, when rank(X) < p this integral is infinite at each y, so that no marginal joint density--even improper--can be defined.

Using the criterion [\eqref=eq:normhyvimproper] for comparing different normal linear models, all with the same known residual variance σ2, is equivalent to comparing them in terms of their penalised scaled residual sum-of-squares, (R / σ2)  +  2p--which is just Akaike's AIC for this known-variance case. (However, when σ2 varies across models, the criterion [\eqref=eq:normhyvimproper] is no longer equivalent to AIC.)

Now it is well known that AIC is not a consistent model selection criterion. As an example, consider the two models:

[formula]

Then, with [formula] denoting the sample mean [formula], we have [formula], [formula], so that [formula]. When M1 holds, this is distributed, for any n, as χ21 - 2, which has a non-zero probability of being positive, and thus favouring the incorrect model M2.

Hence the above approach does not seem an entirely satisfactory solution to the model-selection problem.

Prequential Score

In an attempt to restore consistent model selection, we turn to the prequential approach.

In [\eqref=eq:lm], let xi be the ith row of X, and Xi the matrix containing the first i rows of X. Assuming X is of full rank, then Xi is of full rank if and only if i  ≥  p.

Define, for i  ≥  p  :

[formula]

and, for i  >  p  :

[formula]

(where the identity in [\eqref=eq:k] follows from the Woodbury lemma).

Then for the improper prior [\eqref=eq:unif] with [formula], the predictive distribution of Yi, given Yi - 1, is

[formula]

That is, in the predictive distribution the [formula] are independent and identically distributedN(0,σ2) variables (which property also holds in the sampling distribution, conditionally on θ); moreover, [formula].

Note that, under the model [\eqref=eq:lm], ηi has expectation [formula] and variance k2i - 1. So the predictive distribution [\eqref=eq:predy] and the true distribution will be asymptotically indistinguishable (the property of "prequentially consistent" estimation--see [\citet=dawi:1984]) if and only if

[formula]

This we henceforth assume, for any model under consideration.

For i > p, the incremental score [\eqref=eq:unihyv] associated with [\eqref=eq:predy] is

[formula]

where

[formula]

Under any distribution in the model, the (Ti) are independent, with

[formula]

As discussed in , minimising the cumulative prequential score

[formula]

should typically yield consistent model choice. We investigate this in more detail in below.

Expression [\eqref=eq:increm] is only defined for an index i exceeding the dimensionality of the model. When comparing models of differing dimensionalities, we should ensure the identical criterion is used for each. We could just cumulate the Si over indices i exceeding the greatest model dimension, pmax say, but this risks losing relevant information. To restore this, we might add to that sum the multivariate score [\eqref=eq:normhyvimproper] computed, for each model, for the first pmax observations.

Multivariate or Prequential?

The multivariate score [\eqref=eq:normhyvimproper] can be expressed as the sum of rescaled incremental scores:

[formula]

and the scaling factor k2i has been assumed to satisfy [\eqref=eq:kk]. It would thus seem that [\eqref=eq:sgen] is asymptotically equivalent to [\eqref=eq:normpreq], and thus that model selection by minimisation of the multivariate score [\eqref=eq:normhyvimproper] should be consistent for model choice. However, we have seen that this is not the case.

Further analysis dispels this paradox. The difference between the prequential and the multivariate score, up to time n, is

[formula]

Under any distribution in the model, this has expectation

[formula]

and variance

[formula]

Suppose the (xi) look like a random sample from a p-variate distribution, with [formula]. Then, for large i, So 1 - 1 / k2i  ≈  p / i; in particular [\eqref=eq:kk] holds. Then [formula]. A similar analysis shows [formula]. Thus, under the model, S*  -  SH  ≈  p( log n) / σ2. So, contrary to first impressions, the difference between the cumulative prequential score S* and the multivariate score SH diverges to infinity (at a logarithmic rate) under any true model.

Prequentially Consistent Model Selection

We now consider the asymptotic behaviour of the cumulative prequential score S*, given by [\eqref=eq:normpreq], when used to select between two models, M1 and M2, both of the general form [\eqref=eq:lm], when M1 is true. Let these models have respective dimensions p1 and p2, and variances σ21 and σ22. Let Zi, k2i, as defined above, refer to M1, and denote the corresponding quantities for M2 by, respectively, Wi, h2i. Let S*1, S*2 denote the cumulative prequential scores for M1, M2, respectively. We assume conditions on the regressors, as discussed above, under which

[formula]

Since the (Yi) are independent normal variables with variance σ21, and the (Zi) and (Wi) are, in each case, constructed from the (Yi) by an orthogonal linear transformation, we will have

[formula]

where the (Zi) have mean 0 since M1 is true, whereas the (νi) may be non-zero.

Let p  =   max {p1,p2}. Apart from a finite contribution from some initial terms, the difference in prequential scores, up to time n, is

[formula]

where [formula] denotes [formula].

On account of [\eqref=eq:zdist] and [\eqref=eq:wdist], this has expectation

[formula]

We now consider various cases for M2.

M2 true

If the true distribution also belongs to M2 (as well as to M1), then we must have σ22  =  σ21  =  σ2 say, and [formula]. Then [\eqref=eq:expdiff] reduces to

[formula]

On account of [\eqref=eq:approxk] and [\eqref=eq:approxh], this behaves asymptotically as (p2 - p1)( log n) / σ2  +  o( log n). Also, an analysis similar to that in shows that [formula] is bounded, so that

[formula]

(Compare this with the behaviour of the log-Bayes factor in this case, which, in line with [\eqref=eq:true], is asymptotic to [formula] when the within-model priors are proper).

In particular, when comparing finitely many true models of different dimensions, minimising the cumulative prequential score will consistently favour the simplest true model, at rate [formula].

We now consider cases where M2 is false. For simplicity we confine attention to the expected score.

Wrong variance

Suppose first that M2 has the wrong variance σ22  ≠  σ21. In this case the first term in [\eqref=eq:expdiff] is non-negative, the second is positive of order n, and the third term is again of order log n. The true model M1 is thus favoured, at rate [formula]--just as for the log-score in the case of proper priors.

Right variance, wrong mean

Suppose now σ22  =  σ21  =  σ2, but the data-generating distribution does not have the mean-structure of M2. We note that the log-Bayes factor [\eqref=eq:true] will tend to infinity (almost surely), so selecting the true model M1, if and only if [formula].

In this case we have

[formula]

where [formula] and [formula].

The first term in [\eqref=eq:expdiff] is non-negative, while the second term behaves asymptotically as (p2 - p1)( log n) / σ2. In particular, if p2  >  p1, then [\eqref=eq:expdiff] increases at rate at least (p2 - p1)( log n) / σ2, so favouring the true model.

However, things are more delicate if p2  <  p1. In this case, if [formula] increases sufficiently slowly -- specifically, at rate less than (p1 - p2)σ2( log n) -- then the increased simplicity of model M2 more than compensates for the slight inaccuracy in its mean-structure, leading to selection of the slightly incorrect model M2.

The case p2 = p1 requires a still more delicate analysis, which we shall not pursue here.

Example

As an example, consider again the comparison of the models M1 and M2 of .

Under M1, with Yi  ~  N(0,1), we have p1  =  0, k2i = 1, Zi  =  Yi. In this special case the cumulative prequential score S*1 is identical to the multivariate score SH,1.

For model M2, with Yi  ~  N(θ,1) ([formula]), we have p2  =  1, h2i  =  i / (i - 1), [formula]. Although [formula], has (under any distribution in M2, and hence also under the simpler model M1) expectation [formula], and bounded variance 2[formula]. Since [formula], and we have seen that SH,2  -  SH,1 is bounded in probability under M1, S*2  -  S*1 diverges to infinity (at rate log n) under M1--so consistently selecting the correct model M1.

On the other hand, under M2 we have while [formula], so that S*2  -  S*1  =   - nθ2  +  op(n), which thus diverges to -    ∞   (this time at rate n)--so now consistently selecting the correct model M2.

In summary, although the multivariate score [\eqref=eq:normhyvimproper] is more straightforward to compute, if consistent model selection is regarded as an important criterion then the prequential score is to be preferred.

Linear Model: Variance Unknown

Now suppose we don't know σ2 in [\eqref=eq:lm]. With φ  =  1 / σ2, we have model density

[formula]

where [formula], with [formula], is the residual sum of squares, on ν  =  n - p degrees of freedom.

The standard improper prior for this model is [formula]. Multiplying [\eqref=eq:moddens] by this and integrating over (θ,φ) yields the (improper) joint predictive density

[formula]

with logarithm (up to a constant)

[formula]

Writing r  =  Πy (the residual vector), we find

[formula]

and so (noting [formula]) the multivariate score [\eqref=eq:genhy] is

[formula]

where 2  =  R / ν is the usual unbiased estimator of σ2. So long as at least one model under consideration has ν  >  4 (a very reasonable requirement), choosing a model by minimisation of the predictive score is thus equivalent to minimising J: = 2 / (ν - 4).

Again, this model selection criterion is typically inconsistent. Thus consider the comparison between models M1 and M2 of , now extended to have unknown variance σ2. We have

[formula]

where [formula] is a consistent estimate of σ2 under either model. Then M2 is preferred if J2  <  J1, which holds when

[formula]

for large n. But, under M1, [formula], so that there is a positive probability of the inequality [\eqref=eq:u1u2] holding, so favouring the more complex model M2.

Prequential Score

From [\eqref=eq:predh], as a function of yi the predictive density of Yi given yi - 1 (for i  >  p) is

[formula]

where Ri is the residual sum-of-squares based on yi, on νi: = i - p degrees of freedom, and zi  =  k- 1i(yi  -  ηi), as given by [\eqref=eq:eta]-[\eqref=eq:z]. Applying the univariate case of [\eqref=eq:genhy] now yields (for i > p) the incremental score:

[formula]

where s2i: = Ri  /  νi is the residual mean square, based on Yi, under the model. The prequential score is now obtained by cumulating Si over i. Once again, under reasonable conditions this can be expected to yield consistent model selection.

We investigate this consistency property further, for the special case of comparing two true models of different dimensions p1  <  p2. We saw in that in this case, when the variance σ2 is known (and under reasonable assumptions on the models) the prequential Hyvärinen score prefers the simpler model over the more complex model, at rate (p2 - p1)( log n) / σ2.

We consider the asymptotic behaviour of [formula] under a distribution in the model. In this case the (Zi:i  >  p) are independent and identically distributed as N(0,σ2).

Writing Ui: = (Z2i  /  σ2) - 1, so that [formula], [formula], we have

[formula]

with [formula] (where νi  =  i - p). Now [formula]. Expanding [\eqref=eq:zform] as a power series in [formula] gives

[formula]

so that

[formula]

Noting

[formula]

we compute

[formula]

whence, on account of [\eqref=eq:kk],

[formula]

where [formula] is the cumulative prequential score [\eqref=eq:normpreq] for the submodel in which the correct variance σ2 is known.

In the remainder of this section, we argue that S*  -  S*0 differs from its expectation [\eqref=eq:plusdiff] by [formula]. Computations have been executed and/or checked using the software Mathematica.

On cumulating the term [formula] in [\eqref=eq:prob1] we obtain variance [formula], which is finite. So this yields a contribution that is Op(1).

Consider now the term [formula] in [\eqref=eq:prob2]. We find [formula], and [formula] and [formula] are uncorrelated for i  ≠  j. Hence on cumulating the term [formula] in [\eqref=eq:prob2] from i = p + 1 to n we get variance [formula]. Thus the random variation in this term contributes [formula] to S*  -  S*0.

There is also a term [formula] in [\eqref=eq:prob2]. Since [formula], its cumulative sum is [formula].

Now consider [\eqref=eq:prob3]. We look first at the term [formula]. We compute [formula], say; and, for i < j,

[formula]

Hence

[formula]

(with ν = n - p), since [formula]. We have [formula], and, for large i, [formula]. So [formula] is of order log n, and cumulating the term [formula] in [\eqref=eq:prob3] again makes a contribution [formula] over and above its expectation.

Now consider the term [formula] in [\eqref=eq:prob3]. We have

[formula]

and, for i < j,

[formula]

By an argument similar to that for [formula], we find that cumulating the term [formula] in [\eqref=eq:prob3] again makes a contribution [formula] (over and above its expectation).

Putting everything together, we have

[formula]

Now we have shown in that, for comparing two true models M1 and M2 with known variance σ2 and respective dimensions p1  <  p2, under conditions on the behaviour of the (xi), the difference in their cumulative prequential scores S*0 behaves asymptotically as (p2 - p1)( log n) / σ2. Since, from [\eqref=eq:finaldiff], the difference between the scores for the unknown and known variance cases is 2( log n) / σ2  +  op( log n) for any model, the identical behaviour applies in the case that the variance is unknown.

Discussion

Replacement of the traditional log-score by a proper scoring rule, applied to the predictive density, supplies a general method for avoiding some of the difficulties associated with the use of improper prior distributions for conducting Bayesian model comparison and selection. In particular, use of a homogeneous scoring rule, such as the Hyvärinen rule, supplies a method for taming the otherwise wild behaviour associated with the arbitrariness of the normalising constant of such a prior distribution. Moreover, when applied prequentially, scoring rule based model selection will typically lead to consistent selection of the true model: we have argued for this property both in general terms and in the context of normal linear models with known or unknown variance, with their usual improper priors.

While the literature on "objective" Bayesian model selection contains some valuable discussion of general principles--see, for example, [\citet=bayarri:2012]--most of it focuses on explorations and recommendations of appropriate priors, or classes of priors, or relationships between priors, for use in specified circumstances or for specified purposes. When those priors are improper, as is commonly the case, further manipulations and distortions of the Bayes factor are required to produce a well-defined procedure. Our approach here makes no specific recommendations, leaving users free to apply their most favoured prior distributions. Instead, we have introduced a very general procedure, based on homogeneous proper scoring rules, that allows the use of improper priors, however selected, without needing to worry about the arbitrariness of their scaling constants.

There remains the issue of the choice of homogeneous proper scoring rule. There are no clear theoretical grounds for preferring one over another. Purely for simplicity, we have confined attention to the most basic homogeneous rule, the Hyvärinen score, but similar results can be expected for other homogeneous scoring rules. Further theoretical and computational exploration and comparison of the properties of the various methods is clearly required. Such exploration might be extended to their performance in other contexts: for example, issues of consistent model selection when the number of parameters increases with the sample size [\citep=moreno:2010] [\citep=johnson:2012].