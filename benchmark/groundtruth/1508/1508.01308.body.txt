Collaborative Total Variation: A General Framework for Vectorial TV Models

This work was supported by the Ministerio de Ciencia e Innovación under grant TIN2011-27539, and by ERC Starting Grant Convex Vision.

Universitat de les Illes Balears, Department of Mathematics and Computer Science, Anselm Turmeda, Ctra. de Valldemossa km. 7.5, 07122 Palma de Mallorca, Spain (joan.duran@uib.es, catalina.sbert@uib.es). During this work, J. Duran had a fellowship of the Conselleria d'Educació, Cultura i Universitats of the Govern de les Illes Balears for the realization of his Ph.D. thesis, which was selected under an operational program co-financed by the European Social Fund. Technische Universität München, Department of Mathematics and Computer Science, Informatik 9, Boltzmannstrasse 3, 85748 Garching, Germany (michael.moeller@in.tum.de, cremers@tum.de).

Introduction

Many problems in image processing require the choice of a good prior that makes assumptions on the structure of the underlying image we seek to estimate. This prior often takes the form of a regularization term for an energy functional which is to be minimized. Observing that quadratic regularization did not allow recovering sharp discontinuities, Rudin, Osher and Fatemi proposed the total variation (TV) penalty [\cite=ROF1992] for solving inverse problems. The total variation pioneered as a discontinuity-preserving regularizer in the sense that it assigns the same energy cost to sharp and smooth transitions. Therefore, it is one of the simplest (convex) variational models that allows discontinuities, yet it disfavours the solution to have oscillations.

Although the TV was originally designed for image denoising, it has become one of the most popular regularizations for many image processing problems and has sparked a tremendous amount of research. While many extensions like anisotropic TV [\cite=Esedoglu2004] [\cite=Grasmair2010] [\cite=Weickert1998], weighted TV [\cite=CollDuran2015] [\cite=GilboaSochen2006] [\cite=Grasmair2009], higher order TV [\cite=Benning2013] [\cite=Bredies2010] [\cite=ChanMarquina2000] [\cite=Papafitsoros2014] [\cite=You1996], nonlocal TV [\cite=DuranMoellerNLTV2015] [\cite=GilboaOsher2007] [\cite=GilboaOsher2008] [\cite=Peyre2008] [\cite=Ranftl2014], or nonconvex TV [\cite=Krishnan2009] [\cite=Mollenhoff2015] have been proposed, the general idea of penalizing image oscillations with one-homogeneous functions depending on the spatial derivatives of the image remain the same. A lot of recent research has focused on extending the classical TV model for grayscale images to vector-valued (color or multichannel) images. We provide below an initial overview on vectorial total variation, which will be detailed and link to our framework in Section [\ref=sec:VTV].

Vector Valued Total Variation

Let [formula] be a bounded domain, then the scalar total variation of a locally integrable function [formula] is

[formula]

where [formula] and

[formula]

is the set of continuously differentiable and bounded functions with compact support in Ω. The definition given in [\eqref=scalarTV] introduces a dual formulation according to which the TV is the convex conjugate of the indicator function of the convex set [formula]. For a differentiable function [formula], one has [formula]. Note that the TV can be defined differently depending on the norm used in [\eqref=scalarTVXi]. For a better understanding, let us restrict ourselves to [formula] and denote its gradient by [formula] at each x∈Ω. Therefore, using [formula] as dual norm leads to the isotropic TV, [formula], whereas the anisotropic TV follows from choosing [formula] in [\eqref=scalarTVXi], [formula].

The idea of the vectorial total variation is to extend the above definitions to vector-valued functions [formula]. A major decision with color images is how to couple channels. A straightforward approach proposed by Blomgren and Chan [\cite=Blomgren1998] consists in using a global channel coupling by penalizing the [formula] norm of the TV contributions across channels. However, local coupling outperforms global coupling in many theoretical and practical aspects [\cite=Holt2014]. In this setting, most of the methods in color image reconstruction used an [formula] or [formula] norm to penalize the TV of the channels at each pixel [\cite=Attouch2006] [\cite=BressonChan2008] [\cite=DuvalAujol2009]. Additionally, some interesting approaches incorporated a change of color space [\cite=ChanKang2001] [\cite=Condat2012]. Further versions of vectorial TV in literature are based on the singular values of the submatrices one obtains by fixing a pixel location and looking at the remaining matrix in the channel and derivative dimensions. Important cases are the Schatten-    ∞   norm [\cite=Goldluecke2012], which penalizes the largest singular value, and the nuclear norm or Schatten- 1 norm [\cite=Lefkimmiatis2013], which is a convex relaxation of minimizing the rank of the image Jacobian at each pixel [\cite=Recht2010].

Problem Formulation

For the sake of simplicity, we will consider discrete versions of the TV for the remainder of this paper. Let us define the Euclidean spaces [formula] and [formula], where N is the number of pixels of the image, M is the number of directional derivatives, and C is the number of color channels. We thus consider a color image as a two-dimensional matrix of size N  ×  C denoted by [formula], with [formula] for each channel [formula]. On the other hand, we define the linear operator K:X  →  Y such that [formula] is a three-dimensional matrix or tensor. In the rest of the paper, we use the colon to denote all elements along one dimension. For example, the [formula] norm of A∈Y with respect to its third dimension reads [formula].

The general problem we are concerned with is

[formula]

where [formula] is a proper, convex, l.s.c. functional and [formula] is a collaborative sparsity enforcing norm penalizing the gradient of the color image to be detailed later.

In this paper, we propose a general and intuitive framework that allows us not only to handle pre-existing vectorial total variation models, but also to introduce some new interesting regularizations for color image processing. Our idea is that, in a discrete setting, the gradient of a vector-valued image is nothing but a three dimensional matrix or tensor with the dimensions corresponding to the spatial extend, the directional derivatives considered as linear operators containing the differences to other pixels, and the color channels. The energy or smoothness of this tensor can be measured by taking different norms along the different dimensions. Depending on the types of norms one obtains very different properties of the regularization.

Two relevant examples immediately arise from the proposed framework. For the sake of clarity, let us write [formula]. If we first take the [formula] norm to the color dimension, then the [formula] norm along the derivative dimension of the remaining 2D matrix and, finally, the [formula] norm to the final pixel vector, one obtains the [formula] norm:

[formula]

In [\eqref=eq:lpqr], any of the indices p, q or r being equal to infinity means taking the maximum of the absolute values along the corresponding dimension. A second important example consists of penalizing with the [formula] norm the singular values of the 2D matrices arising from each pixel (that is, the Schatten- p norm), and then applying the [formula] norm along the remaining vector:

[formula]

As an illustrative example, Figure [\ref=fig:SyntheticEdge] shows the results of a numerical experiment regarding the ability of different channel couplings to suppress color artifacts. We use a synthetic image where we leave open if the colored wave pattern is signal content or noise. We see that the channel-by-channel regularization due to the [formula] norm eliminates all noise from constant regions but the color structure of the underlying image is not touched. On the contrary, the [formula] norm leads to the strongest channel coupling and is able to remove the color oscillations completely. In between both, the [formula] channel coupling significantly reduces the colors around the white square but does not eliminate them. Therefore, we expect a color coupling with an [formula] norm to be stronger the larger p is.

Contributions and Preliminary Works

We streamline below the novelty of our approach. The major contributions of this work are:

The introduction of a large family of (discrete) convex energy functionals that generalize the TV to vector-valued images. Motivated by recent advances in compressed sensing, we interpret the total variation as looking for an image for which the gradient is sparse. We use collaborative sparsity [\cite=YuanLin2006] to model different types of TV which are then used in a variational formulation to provide regularized solutions of ill-posed inverse problems in color imaging. We call this family of regularizers Collaborative Total Variation (CTV).

The definition of general collaborative sparsity enforcing norms that characterize all CTV regularizations. We further compute their dual norms and their subdifferentials, which play a direct role in computing optimality conditions of several regularized problems.

The proof, with the help of the generalized concept of singular vectors [\cite=BenningBurger2013], that an [formula] channel coupling leads to the strongest correlation, makes the most prior assumptions and has the greatest potential to reduce color artifacts.

The proposal of sophisticated collaborative norms such as [formula], [formula], [formula], and [formula], which lead to novel methods for color images. All variants can be solved very efficiently by using the same splitting scheme, for instance, the primal-dual hybrid gradient (PDHG) method [\cite=ChambollePock2011] [\cite=EsserZhang2010] [\cite=Zhu2008]. Since the key to obtaining a fast PDHG algorithm is an efficient evaluation of the proximity operators, they are provided in detail.

An extensive experimental evaluation of some of the proposed CTV methods on several image processing problems, such as denoising, deblurring or inpainting. A detailed performance comparison on different databases for color image denoising using the ROF model together with the proposed collaborative TV regularizations is provided in the companion paper [\cite=DuranMoellerIPOL2015]. We further include some experiments for cartoon and texture decomposition. Code and an online demo to reproduce all examples will be made available soon.

In the original conference paper [\cite=DuranMoellerNLTV2015], which contains preliminary parts of this work, we proposed to penalize the [formula] norm of the three-dimensional structure underlying the nonlocal gradient for color image reconstruction. In particular, the newly proposed [formula]NLTV model yielded superior results. In the current paper, we extend the original framework in order to include more general collaborative norms: we propose novel [formula] norms and further incorporate Schatten [formula] norms. We also provide a mathematical justification of the superiority of the [formula] coupling for restoring high inter-channel correlated images, as well we develop general properties for collaborative norms useful in optimization. Finally, we give a detailed performance comparison of more vectorial TV methods derived from the proposed framework in additional image processing problems.

During the wording of this work, the conference paper by Miyata and Sakai [\cite=Miyata2012], which pioneered the [formula] channel coupling, came to our hands. To the best of our knowledge, [\cite=Miyata2012] is the only paper that uses the supremum norm for vectorial TV. However, the authors proposed to first perform a color transform that reduces the inter-channel correlation. From our point of view, this change of color space is counter-intuitive when combined with the strong inter-channel coupling of [formula]. One of our main contributions is to introduce the [formula] norm in a straightforward way and efficiently exploit its properties.

Outline of the Paper

The rest of the paper is organized as follows. The next section introduces the definition of collaborative norms and develops some general properties which play a direct role when computing optimality conditions of regularized problems. In Section [\ref=sec:VTV] we summarize the current literature on different definitions for extending the TV to multichannel images. All of them are analyzed as special cases of the proposed approach. We investigate in Section [\ref=sec:singVectors] which channel coupling leads to the strongest correlation, makes the most prior assumptions and has the greatest potential to reduce color artifacts. In Section [\ref=sec:numerics], we give detailed explanations on how to determine minimizers of typical image processing problems using CTV as a prior. Particularly, we write down the proximity operators for all types of regularizations discussed in this paper. We compare different CTV methods in numerical experiments for denoising, deblurring and inpainting of color images in Section [\ref=sec:results], before we draw conclusions in Section [\ref=sec:conclusions].

Collaborative Total Variation Regularization

In the following, we introduce a novel regularization family which we use to solve inverse problems in vector-valued image processing within a variational setting. The proposed models are based on the use of collaborative sparsity enforcing norms, which will be abbreviated as collaborative norms, that are defined below.

Definition of Collaborative Norms

By considering the derivatives of a color image as a linear operator, one obtains a three-dimensional matrix or tensor with one dimension corresponding to the pixels in the image, one dimension corresponding to the directional derivatives, and one dimension corresponding to the color channels.

For illustrative purposes, suppose that a color image given on a rectangular domain of size Nw  ×  Nh has been rearranged from left to right and from top to bottom into a matrix [formula]. Consider K to be the standard gradient computed via forward differences along x -  and y - directions. Then, the two-dimensional submatrix obtained by fixing the n - th pixel in the first dimension is

[formula]

Let us see how a neighbourhood filter fits in our framework for a color image with four pixels. Let K be defined as the nonlocal gradient with respect to a weighting function w, which measures the similarity between two pixels in the image. In this case, we have N = 4, M = 4, and C = 3. Contrary to the previous example, we fix here the color dimension to the k - th channel. Therefore, the remaining two-dimensional submatrix along pixel and derivative dimensions is

[formula]

In general, the previous matrix is of size N  ×  N. However, one usually uses a few nonzero weights in practical applications.

Although in the literature only [formula] and [formula] norms have been mainly used so far, it makes sense to look at vectorial TV as applying the more and more popular mixed norms to the gradient of the image (see [\cite=EsserMoeller2013] [\cite=HeinsMoeller2014] [\cite=Kowalski2009] and references therein). For a general tensor A∈Y, we introduce the following family of norms that we call collaborative norms.

Let [formula] be any vector norm and [formula] any matrix norm. Then, the collaborative norm of [formula], which will be denoted by [formula], is defined as

[formula]

where Ai,:,: is the (two-dimensional) submatrix obtained by staking the second and third dimensions of A at each i - th position in the first dimension.

We note that the examples given in [\eqref=eq:lpqr] and [\eqref=eq:Splq] follow from the above definition. Indeed, the [formula] norm arises from taking [formula] as the matrix [formula] norm and [formula] as the [formula] norm. On the contrary, the [formula] norm is obtained when one considers [formula] to be the matrix Schatten-p norm, that is penalizing the [formula] norm of the singular values of the submatrix Ai,:,:, and [formula], the [formula] norm.

Since the collaborative norms defined in [\eqref=eq:matrixnorm] are non invariant to permutations of the dimensions, we propose to denote [formula] for first applying the matrix norm [formula] to the submatrix obtained by fixing each pixel and looking at the remaining derivative and channel dimensions, and then using the vectorial norm [formula] along the pixel dimension. Importantly, note that our framework covers any transform along each of the dimensions, in particular, allows us to incorporate color space transforms before applying any collaborative norm.

General Properties of Collaborative Norms

It is well known that duality plays a direct role in computing optimality conditions of several regularized problems. The following result characterizes the dual norm to any collaborative norm.

Let [formula] and [formula] denote the dual norms to [formula] and [formula], respectively. Consider [formula] and define [formula] such that [formula] for each [formula]. If [formula] only depends on the absolute values of vi's, then the dual norm to [formula], denoted by [formula], is

[formula]

In other words, the dual norm of the composite is the composite of the dual norms.

We aim at proving that

[formula]

where [formula] is defined in [\eqref=eq:matrixnormdual]. Let [formula] satisfying [formula] be fixed but arbitrary, and define [formula] and [formula] for each [formula]. Applying Hölder inequality for both [formula] and [formula] norms yields The proof reduces now to show that there exists some [formula] satisfying [formula] for which the equality holds.

Since [formula] is the dual norm to [formula], there exists some [formula], [formula], such that [formula]. We can additionally assume that zi  ≥  0 for all [formula]. Indeed, suppose that zj < 0 for some [formula] and define [formula] with [formula] for i  ≠  j and [formula]. Since [formula] only depends on the absolute values of the zi's, it follows that [formula] meets [formula]. If [formula], then one deduces that [formula], which contradicts the definition of [formula]. If [formula], then [formula] so that we need only to take [formula] instead of z.

On the other hand, since [formula] is the dual norm to [formula], there exists [formula], [formula], such that [formula] for all [formula].

Now, it follows from the definitions of [formula] and each [formula] that

[formula]

from where [formula] by choosing Bi,j,k  =  ziyij,k. Furthermore,

[formula]

Let [formula], [formula], be fixed but arbitrary, then

[formula]

which implies [formula]. This means that we found [formula], [formula], such that [formula], which concludes the proof.

Theorem [\ref=thm:dualnorm] states that the [formula] norm is dual to [formula], where p*, q*, and r* denote the Hölder conjugate exponents of p, q, and r, respectively. Similarly, the dual norm of the Schatten [formula] norm is [formula]. Furthermore, we have implicitly proved a Hölder's inequality for collaborative norms.

Under conditions of Theorem [\ref=thm:dualnorm], we have

[formula]

for any [formula].

We also furnish ourselves with the subdifferential of the proposed collaborative norms that will be useful for computing their proximal mappings.

Consider [formula] and define [formula] such that [formula] for each [formula]. If [formula] only depends on the absolute values of vi's, then the subdifferential of [formula] is given by

[formula]

Since [formula] is positively one-homogeneous, it is well-known that its subdifferential is given by

[formula]

Recall now that the Legendre-Fenchel transform of a proper convex function is defined as [formula]. Furthermore, the Legendre-Fenchel transform of a norm [formula] turns to be the indicator function on the unit ball of the dual norm:

[formula]

We refer the reader to [\cite=Hiriart1996] [\cite=Rockafellar1997] for more details. Therefore, taking the supremum over all [formula] in [formula] yields f*(B)  ≤  0. Due to Theorem [\ref=thm:dualnorm], we necessarily have that [formula], which ends the proof.

Vectorial TV Revisited

The collaborative norms defined in the previous section support most of pre-existing definitions of TV for vector-valued images, the most relevant of which are displayed in Table [\ref=tab:VTVOverview]. For nonlocal TV based models, we refer the reader to our conference paper [\cite=DuranMoellerNLTV2015].

Approaches to defining vectorial TV regularizations can roughly be divided into two classes. The first class of methods extend the definition of the scalar case [\eqref=scalarTV] to vector-valued images by introducing a suitable channel coupling. The second class of approaches emerges when considering the Riemann geometry of the image manifold. All of them are analyzed below as special cases of CTV. We formally use continuous notations even though our framework is given in the discrete setting.

Vectorial TV Models from Channel Coupling

The first known extension of the total variation to vector-valued images is due to Blomgren and Chan [\cite=Blomgren1998]. They applied the Euclidean norm to the vector obtained from the TV contributions across channels, that is,

[formula]

From the Euler-Lagrange equation associated to [\eqref=eq:VTVBlomgren], one easily observes that there is a global weak channel coupling so that the same per-channel weight is used for all pixels. Consequently, this model favours the restoration of images for which similar noise is measured in each channel. In our framework, the vectorial TV proposed in [\cite=Blomgren1998] can be written as an [formula] penalty.

Probably, the most simple way to introduce multichannel TV is to sum up the contributions of each channel separately [\cite=Attouch2006], which leads to

[formula]

Depending on the coupling used along the derivative dimension, one obtains the isotropic version, [formula], which was the one originally proposed in [\cite=Attouch2006], or the anisotropic version, [formula]. As pointed out by Goldluecke et al. [\cite=Goldluecke2012], the drawbacks underlying this approach are color smearing and edge distortion because of the missing channel coupling. We can expect [\eqref=eq:VTVAttouch] to be a good choice if there is no particular relation between channels.

In [\cite=BressonChan2008], the isotropic vectorial TV with a local [formula] channel coupling is proposed:

[formula]

which is equivalent to the collaborative norm [formula]. Blomgren and Chan [\cite=Blomgren1998] noted that this method actually favours gray-value images over colored ones, which leads to color smearing in denoising applications.

The inclusion of additional color transforms has been proposed to improve the performance of vectorial TV methods. It is well known that RGB channels of natural images are highly correlated. In view of this, some researchers incorporated different color transforms into the definition of vectorial TV and penalized the gradient of each component in the new basis separately [\cite=ChanKang2001] [\cite=Condat2012]:

[formula]

where [formula] is an orthonormal transform between color spaces. The key idea is to choose ψ such that it provides effective reduction of the correlation among channels. Note that [\eqref=eq:VTVCondat] is equivalent to penalize the collaborative norm [formula] for the anisotropic variant and [formula] for the isotropic variant.

Vectorial TV Models from Riemann Geometry

A color image can be considered as a parametric two-dimensional manifold embedded in a C - dimensional space [\cite=DiZenzo1986]. In this framework, the metric tensor of the manifold is analogous to the structure tensor of the image, that is, [formula]. Therefore, the eigenvectors of [formula] determine the directions of maximal and minimal change and the eigenvalues, which will be respectively denoted by λ+ and λ-, give their rate of change.

In this setting, Sapiro [\cite=Sapiro1996] introduced the following general vectorial TV model:

[formula]

where Σ denotes the image manifold and f is a suitable scalar-valued function. In general, [\eqref=eq:VTVSapiro] is defined for differentiable functions, but only for special cases one has dual formulations that extend it to locally integrable functions. This is the case of the Frobenius norm of the gradient given by

[formula]

which follows from [\eqref=eq:VTVSapiro] by considering [formula]. Note that [\eqref=eq:VTVFrobenius] is equal to the definition of the vectorial TV given in [\eqref=eq:VTVBresson] and, thus, either [formula] or [formula] can be used in our framework.

Based on the class of methods presented by Sapiro, Goldluecke et al. [\cite=Goldluecke2012] showed that the natural choice for vectorial TV arising from geometric measure theory is to penalize the largest singular value of the Jacobian:

[formula]

where σ1 is the largest singular value of [formula] or, equivalently, the largest eigenvalue of the structure tensor [formula]. The regularization introduced in [\cite=Goldluecke2012] is known as the spectral or Schatten-    ∞   norm and fits in our framework as [formula].

Recently, Holt [\cite=Holt2014] interpreted [\eqref=eq:VTVGoldluecke] as a special case of spatially-local coupling models. The author proposed to smoothen a differentiable function [formula] by penalizing its Jacobian matrix:

[formula]

where [formula] denotes the Jacobian matrix of [formula], so [formula]. This Jacobian framework is closely related to [\eqref=eq:VTVSapiro], since the structure tensor is given by [formula] at each point in the image. Note that [\eqref=eq:VTVAttouch] and [\eqref=eq:VTVBresson] are special cases of [\eqref=eq:VTVHolt], however, any method using spatially-global coupling such as [\eqref=eq:VTVBlomgren] is not covered by Holt's approach. In [\cite=Holt2014], the author considered only functions that are written in terms of the singular values of [formula]. Therefore, the Frobenius norm [\eqref=eq:VTVFrobenius] follows from [formula], the spectral norm [\eqref=eq:VTVGoldluecke] follows from [formula], and the nuclear norm [\cite=Lefkimmiatis2013] follows from [formula]. In our framework, the regularizations arising from [\eqref=eq:VTVHolt] are given by [formula].

Another relevant approach based on Riemann geometry was pioneered in the framework by Kimmel, Malladi, and Sochen [\cite=KimmelMalladi2000] [\cite=Sochen1998], who considered the graph of an image embedded in a (C + 2) - dimensional space and proposed an area minimizing flow. This class of regularizations lead to diffusion equations with the direction given by the Beltrami flow. Roussos and Maragos [\cite=Roussos2010] generalized the Beltrami flow by using higher dimensional mappings which depend on image patches:

[formula]

where ψ is increasing with respect to both arguments, and λ+r and λ-r are the larger and smaller eigenvalues of the structure tensor [formula], with Kr being a non-negative, rotationally symmetric convolution kernel. In posterior works [\cite=LefkimmiatisRoussos2015] [\cite=Lefkimmiatis2013], a deeper analysis for the particular choice [formula] was developed. There, the tensor TV that arises when p = 1 is renamed as the nuclear norm, which can be written as [formula] in our case. In order to incorporate information from the vicinity of every point in the image domain as in [\eqref=eq:VTVBeltrami], we only have to incorporate the nonlocal gradient operator (see [\cite=DuranMoellerNLTV2015] for more details) and penalize the resulting structure with the help of the [formula] norm. Contrary to our approach, neither spatially-global coupling norms like [\eqref=eq:VTVBlomgren] nor TV with [formula] channel coupling are covered by [\eqref=eq:VTVBeltrami].

Other Vectorial TV Models

For the sake of completeness, we should also mention that there exist several further TV variants, such as nonconvex regularizations based on [formula] norms with p < 1 [\cite=Krishnan2009], and nonconvex extensions for minimizing the rank of submatrices in a TGV framework [\cite=Mollenhoff2015]. Additional work has been done on improving TV with the help of Bregman iteration [\cite=MoellerBrinkmann2014] [\cite=Osher2005]. The study of the previously mentioned classes of methods, however, goes beyond the scope of this paper.

Which Channel Coupling Disfavours Color Artifacts?

For discussing the question which CTV methods work better, we have to understand what kind of properties they try to impose on the reconstructed image. In this section, we analyze the differences between a color coupling in the [formula], [formula] and [formula] fashion with the help of the generalized concept of singular vectors [\cite=BenningBurger2013]. The question whether a strong or a weak coupling leads to better results depends on the type of correlation in the data. Our investigation explains why the [formula] norm leads to the strongest relation, makes the most prior assumptions and has the greatest potential to reduce color artifacts.

Benning and Burger developed in [\cite=BenningBurger2013] a generalization of the concept of singular vectors and singular values for arbitrary convex regularizations, and showed that a signal can be restored particularly well if it is a singular vector to the regularization for which is used. The authors also showed that, even in the case of noisy data, an exact reconstruction (up to a loss of contrast) is possible under certain conditions. In this sense, they provided a theoretical basis for explaining that TV regularization works particularly well for piecewise constant images.

In order to analyze the behaviour of collaborative norms for vectorial TV, we restrict ourselves to the case of image denoising modelled by anisotropic vectorial TV, namely comparing [formula], [formula] and [formula] norms. Let D denote the usual local discrete gradient operator such that [formula], and consider only the energy due to the regularization, that is, [formula]. We fix M = 2 since only x -  and y - derivatives are considered. Furthermore, let (x,y) denote any pixel of the image, with x being the row and y the column in the rectangular domain. We provide below the definitions of singular value and singular vector for image denoising problems.

Let J be a convex functional with [formula] at every [formula]. Then, every function [formula] satisfying [formula] and [formula] is called a singular vector of J with corresponding singular value λ.

In the case of J being one-homogeneous we even have that [formula] is equivalent to [formula], which easily follows from Euler's identity [\cite=YangWei2008]: [formula] for any [formula]. Note that, for any [formula], one can define [formula] and [formula] such that [formula] is a singular vector. We will therefore omit λ and focus on the construction of [formula] satisfying [formula]. Since [formula], the latter condition is met if [formula] can be written as [formula] for some [formula] which, by applying Theorem [\ref=thm:subdiffnorm], is equivalent to

[formula]

In what follows, all mathematical proofs have been moved to Appendix [\ref=app:singVectors]. We aim at finding some [formula] satisfying [\eqref=eq:subdiff1] to determine [formula]. Motivated by [\cite=BenningBurger2013], it makes sense to consider piecewise linear funtions whose changes happen only at { - 1, + 1}. More specifically, we choose

[formula]

for some [formula], and lrk having the following properties: |lrk(x)|  ≤  1 for all x, lrk piecewise linear, and the linearity changing at x only if |lrk(x)| = 1. The details for why these functions have to look like this are left for the proof in Appendix [\ref=app:singVectors]. We simply illustrate examples for z1k and z2k in Figure [\ref=fig:zExamples]. It is remarkable that singular vectors to the CTV methods under consideration can all be written in the form of [\eqref=eq:zEquation] and only differ in two aspects. First, the [formula] case allows different lrk for different color channels, while the [formula] and [formula] norms do not. Second, the coefficients crk are different for each regularization.

Table [\ref=tab:singularVectors] shows the precise construction of singular vectors. The results displayed there meet what we would expect based on the regularization behavior of the different methods. For the [formula] case, each channel can have its own lrk such that jumps can be at different positions in the different channels. Since no relation on the positions of the jumps in different channels is imposed, we can expect the [formula] norm to not suppress color artifacts and not change the position of the edges. This is a theoretical explanation for what we saw in Figure [\ref=fig:SyntheticEdge]. Both [formula] and [formula] couplings require the lrk to be independent of k, that is, jumps in different color channels are encouraged to be at the same position. The difference between them is that the size of the jumps, corresponding to the coefficients crk, are allowed to be arbitrary in the [formula] case, while they have to be either zero or of equal magnitude in the [formula] norm. Equal magnitude of the jumps in all three color channels leads to a grayscale image. This tells us that the regularization based on [formula], opposed to [formula], encourages jumps that occur in all three channels to only change the intensity but not the color of the image. Looking at the results in Figure [\ref=fig:SyntheticEdge], we can see again that the singular vector analysis confirms exactly what we observed in practice.

For illustration purposes, Figure [\ref=fig:singularVectors] shows some examples of singular vectors. Depending on the type of jumps in the data, that is, jumps in different color channels being independent of one another, jumps being at the same position but changing the color, or jumps being at the same position and likely not changing the color, the [formula], the [formula] or the [formula] norms will show a superior performance. Interestingly, our numerical results in Section [\ref=sec:results] indicate that a suppression of color artifacts by using [formula] is more important than making weaker and more general assumptions on the types of jumps in natural images.

Numerical Minimization

It is remarkable that all variants of different norms imposed on the three-dimensional structure can be solved very efficiently by using splitting techniques. The only thing that changes when changing the regularization is the proximity operator, which is discussed below.

Recall that the proximity operator of a proper, convex, and l.s.c. function f is

[formula]

where α > 0 is a scalar parameter. Furthermore, Moreau's identity connects the proximity operator and its Legendre-Fenchel transform in the following way:

[formula]

Proximal Map of CTV Regularizers

Theorem [\ref=thm:subdiffnorm] allows us to write the optimality condition to [\eqref=def:proxop] as

[formula]

for any A∈Y. In this setting, [formula] denotes the Euclidean norm applied to the vectorial structure obtained by rearranging the original three-dimensional matrix into a vector. When it is not possible to obtain an explicit solution from [\eqref=eq:proxformula], one usually invokes duality through Moureau's identity [\eqref=eq:Moreauidentity]:

[formula]

where [formula] denotes the projection operator onto the dual ball of radius τ.

We now display the proximal mappings of the regularizations based on [formula] norms which will be used in the experimental section.

The proximity operator of the [formula] norm decouples in all variables and each problem just contains an absolute value penalty:

[formula]

By a short computation, one obtains the proximal mapping of the [formula] norm as the (generalized) shrinkage:

[formula]

as well the proximal mapping of the [formula] norm:

[formula]

Whenever the supremum norm is involved, it is more convenient to use [\eqref=eq:proxformuladual] to express the proximity operator by the proximity operator of its dual. For the [formula] norm, one has

[formula]

where |Ai,j,:| denotes the component-wise absolute value of vector Ai,j: and [formula], the projection onto the unit [formula] norm ball. Similarly, we obtain the proximity operator of the [formula] norm as

[formula]

with [formula] denoting the projection operator onto the unit [formula] ball. Finally, the proximity operator of the [formula] norm is

[formula]

where [formula] denotes the projection operator onto the unit [formula] ball.

Let us now discuss the proximity operator of the [formula] norm. For that purpose, we require a previous result that states the chain rule for subdifferentials. The proof is outlined in Appendix [\ref=app:ThmSubdif].

Let [formula] be a vector-valued function such that [formula] is proper and convex for each [formula]. Let [formula] be convex, proper and nondecreasing in each argument. Then,

[formula]

at any [formula]. If further [formula] and all fj are locally l.s.c., then the inclusion in [\eqref=eq:chainRule1] becomes an equality.

Although it seems to be difficult to compute the proximal mapping of the [formula] norm at first glance, Theorem [\ref=th:chainRule] leads to a particularly interesting observation regarding functionals having an [formula] norm as an inner regularization. The following result will provide us the key for computing this class of proximal operators.

Let [formula] be defined as

[formula]

and let [formula] be any proper, convex function that is nondecreasing in each argument. Then, the proximity operator of [formula] is

[formula]

where vi, [formula], are the components of the vector [formula] given by

[formula]

The optimality condition arising from [\eqref=def:proxop] yields

[formula]

Let us define û as

[formula]

where vi, [formula], are the components of the vector [formula] solving [\eqref=eq:sFormula]. We aim at proving that û satisfies [\eqref=eq:sol]. For that purpose, note that û in [\eqref=eq:compositionL2Prox] can be stated as the solution of a weighted [formula] regularized problem:

[formula]

In view of [\eqref=eq:sol] and [\eqref=eq:sol1], we only need to prove that the matrix with columns vizi is in [formula]. Due to the chain rule stated in Theorem [\ref=th:chainRule], this follows whenever zi∈∂fi(û), which is true by definition of zi, and v∈∂g(f(û)). In order to prove the latter, note that [\eqref=eq:sFormula] yields the optimality condition

[formula]

for some t∈∂g*(v) or, equivalently, v∈∂g(t). It is thus sufficient to show that [formula]. From [\eqref=eq:tDefinition], we see that [formula] for each [formula]. Since g is nondecreasing in each argument, then its proximity operator is nonnegativity preserving and so ti  ≥  0. Consequently, if [formula], then [\eqref=eq:compositionL2Prox] implies [formula] and, thus, ti = 0. Otherwise, it follows that

[formula]

which completes the proof.

By Theorem [\ref=thm:compositionL2Prox], the proximity operator of the [formula] norm is

[formula]

where

[formula]

In the above formula, [formula] denotes the vector we obtain by stacking [formula] for all [formula]. Note that the proximal mappings associated to [formula] and [formula] can also be computed by means of Theorem [\ref=thm:compositionL2Prox].

Finally, the proximal mapping associated to the [formula] norm is a simple combination of a singular value decomposition followed by the proximity operator of the corresponding [formula] norm. Since the regularizations considered in this paper, which base on [formula] and [formula] norms, have an outer [formula] norm, then the computation of their proximity operators decouples at each pixel. By denoting [formula], we are thus left with a problem of the form

[formula]

the solution of which is given in the following proposition.

Let UΣ0VT be the singular value decomposition of a matrix [formula]. Then, the proximity operator of the Sp  -  norm is given by

[formula]

where Σ†0 denotes the pseudo-inverse matrix of Σ0 and [formula].

In the following example, we show the proximal mappings of the CTV regularizations using the Schatten norms we are interested in.

For [formula], the proximity operator of the [formula] norm is

[formula]

where [formula] is the singular value decomposition of [formula].

Solving the Minimization Problem

For solving the optimization problem [\eqref=eq:minproblem] that arises from the proposed collaborative TV, we use the primal-dual hybrid gradient (PDHG) method [\cite=ChambollePock2011] [\cite=EsserZhang2010] [\cite=GoldsteinEsser2013] [\cite=Zhu2008], a powerful optimization algorithm that breaks complex problems into simple sub-steps and can handle non-smoothness of the energy functional.

By introducing an auxiliary variable [formula] and the constraint [formula] in [\eqref=eq:minproblem], then we obtain the following formulation of the original problem:

[formula]

Now, consider the Lagrangian [formula], then the associated primal-dual problem is

[formula]

The PDHG algorithm for solving [\eqref=eq:minproblem] iteratively computes the solution of the associated saddle-point problem [\eqref=eq:primaldualproblem2] by means of where n  ≥  0 is the iteration number, and τn,σn > 0 are the step-size parameters. The algorithm basically consists of alternating a gradient descent in the primal variables [formula] and [formula], and a gradient ascent in the dual variable [formula].

Applications to Image Processing

We present an extensive performance evaluation of different CTV based methods on several inverse problems in color imaging such as denoising, deblurring, and inpainting. In these cases, one typically introduces a positive weighting constant λ  ≥  0 that controls the trade-off between G, which forces the solution of the optimization problem to be close to some given data, and the regularization term:

[formula]

For the sake of consistency among comparisons, we solved each problem with a range of different values of λ and only reported the best result for each regularization and each degradation condition in terms of the highest peak signal-to-noise ratio (PSNR). Furthermore, we chose the linear operator K to be the discrete local gradient computed via forward differences. In all tests, we used images from the Kodak collection (), and all results were saved in integer values relative to the intensity range

[formula]

Image Denoising: [formula] Model

We propose to extend the widely mentioned ROF model to color images by using CTV regularization. The primal problem is therefore given by

[formula]

The [formula] norm is the most suitable choice for suppressing Gaussian noise, since the energy [\eqref=eq:TVL2denoising] corresponds to the maximum a posteriori estimate. The proximity operator of the fidelity term [formula] is

[formula]

To determine the general behaviour of several CTV regularizations with respect to changing the balancing parameter, Figure [\ref=fig:psnrvslmb] shows the plots of the PSNR each method achieved for certain values of λ. For these tests, we artificially added zero-mean Gaussian noise of standard deviation 25 to a noise-free color image. One observes that the peaks of the PSNR curves of the regularizations using [formula], [formula], [formula], and [formula] norms achieve the highest values. Interestingly, although [formula] shows one of the lowest performances in terms of the maximal PSNR, its corresponding curve seems to drop slower as one overestimates λ. As it is well known, the optimal value of λ does not always lead to a complete noise removal. However, a huge reduction of the balancing parameter provides an over-smoothed result and, thus, significant information is lost. In the end, the optimal value in terms of the PSNR is obtained as a compromise between removing noise and preserving signal content.

As an example of our experiments on [formula] denoising, we artificially added Gaussian noise with standard deviation 30 to the twenty-third Kodak image and computed the PSNR value for each reconstruction by comparing to the noise-free image. Picking the optimal value of λ in terms of the PSNR for each method, we obtained the results shown in Figure [\ref=fig:denoisingL2]. We clearly observe that the CTV regularization based on the [formula] norm provides the best PSNR value, and its denoised image is superior to the others in visual quality. Indeed, see the strong color artifacts on the parrot's cheek for all results except for the [formula] norm. Although the [formula] norm shows nice denoising properties, a derivative matrix which has two derivative vectors being equal to zero also has rank one such that colored edges are not actively suppressed. The large inter-channel correlation of images in the Kodak dataset explains why the [formula] norm, which encourages jumps that occur in all channels in the sense given in Section [\ref=sec:singVectors], performs visually the best. On the other hand, [formula] shows one of the worst performances since it neither couples the colors nor the derivatives. Furthermore, [formula] does not work very well. It seems that imposing jumps of different color channels to point into the same direction can more effectively be enforced by the convex relaxation [formula] than having a single direction in the dual variable as in the [formula] approach. Finally, the isotropic [formula] is beaten by the anisotropic [formula], and the new-proposed [formula] outperforms [formula] in terms of both PSNR and visual quality assessment.

A more detailed comparison analysis on color image denoising by the CTV[formula] model, supporting software and an online demo will be made available soon.

Image Denoising: [formula] Model

If we replace the [formula] norm in the data-penalty term of [\eqref=eq:TVL2denoising] by the more robust [formula] norm, the [formula] model arises:

[formula]

Some well-known advantages of [\eqref=eq:TVL1denoising] over the classical ROF model are contrast invariance and more effectiveness in removing noise containing strong outliers such as the salt-and-pepper type noise. In this case, the proximity operator of the fidelity term [formula] is

[formula]

Note that the [formula] model poses a nonsmooth optimization problem, which is also treatable by the PDHG algorithm.

Given the probability α∈[0,1] that a pixel is corrupted, we introduced salt-and-pepper noise by setting a fraction of [formula] randomly selected pixels to black, and another fraction of [formula] randomly selected pixels to white. We display in Figure [\ref=fig:denoisingL1] the optimal result each method provided on parts of the fifth Kodak image for α = 0.15. At first glance, the regularization using the newly-proposed [formula] norm is the most successful in suppressing color spots. The numerical results confirm the previous visual inspection, since the PSNR value associated to the denoised image given by [formula] is clearly superior to all others. In fact, this is the unique method that actively suppresses the input noise and preserves sharp edges. For instance, observe that the edges separating saturated regions, such as the contours of the green and yellow front mudguards, are specially damaged with all regularizations except [formula]. Finally, it is worth stressing that [formula] clearly outperforms [formula].

Image Deblurring

The extension of the variational ROF model for image deblurring involves the minimization of the primal energy

[formula]

where A is a linear operator modeling the degradation of [formula] caused by blur and possibly noise. For the following experiments, we focus on image deconvolution, which refers to the case where the blur to be removed is linear and shift-invariant so that it may be expressed as a convolution of the image with a point spread function. Accordingly, the linear operator is given by [formula], where φ is a Gaussian convolution kernel.

The proximal mapping of the fidelity term [formula] is given by

[formula]

Note that the above formula requires to compute (I  +  τλA*A)- 1, which is huge time consuming in the spatial domain for large values of the standard deviation of the kernel. This drawback is solved by working in the Fourier domain where the convolution becomes a mere multiplication. Hence, using the convolution theorem of Fourier transforms, the solution of [\eqref=eq:proxblur] can be efficiently computed as

[formula]

where F and F- 1 denote the Fast Fourier Transform (FFT) and the inverse FFT, respectively. Note that all operations in the above formula are componentwise.

We tested all CTV regularizations on the third Kodak image. The degraded data was simulated by convolving the ground truth with a Gaussian kernel of standard deviation 2 and further adding white Gaussian noise of standard deviation 0.5. The quality of the restored images with optimal values of λ can be evaluated both visually and numerically in Figure [\ref=fig:deblurring]. We observe that the blur has been almost suppressed in all cases even though some geometry and texture cannot be recovered from the corrupted data. As expected from any TV based model, the restored images tend to be piecewise smooth. In general terms, it seems that isotropic regularization is more suitable for image deblurring - at least with very little noise - than anisotropic filtering. Indeed, [formula] and the new-proposed [formula] provide the best PSNR values together with the nuclear norm [formula]. On the other hand, one realizes that [formula] and [formula] are superior in removing color artifacts at the text on the cap. In the end, the nuclear norm compromises between removing blur and avoiding color spots.

Image Inpainting

Image inpainting is the process of filling-in lost data in a known region of an image. Although during the last years a lot of effort has been put into the development of powerful image priors, we are interested in the TV based image inpainting model [\cite=ChanShen2001], which is limited to inpainting the geometric structure at unknown pixels.

Let [formula] be the inpainting domain, that is, the set of all pixels in the image where the intensity value of all color channels is unknown. Therefore, the primal problem we focus on is given by

[formula]

where [formula] denotes the Euclidean norm at known pixels. We see that the proximity operator of [formula] is

[formula]

For the comparative quality assessment in image inpainting, we used a mask with random scribbles. In Figure [\ref=fig:inpainting] we show the optimal result in terms of the highest PSNR provided by each CTV regularization on parts of the twentieth Kodak image. Since the image domain which is to be filled in is thin, pretty good numerical results are in general obtained. Indeed, all methods exhibit excellent PSNR since an increase of about 20 dB is reached (the value of the input data is 20.58). Concerning [formula] norms, one realizes that isotropic regularization performs significantly better than anisotropic filtering. In this setting, observe that [formula], [formula], and [formula] provide the lowest PSNR values as well the worst inpainted images from visual quality assessment. On the other hand, CTV methods based on [formula], [formula], [formula], and [formula] norms are significantly superior to all other regularizations both visually - compare the results at the edge separating the two gray regions with different color scheme - and in terms of the metric. Accordingly, TV-based inpainting prefers straight contours as they have minimal total variation, but it is less successful for recovering curved boundaries. In this setting, one sees that all methods perfectly recover the color edge in the propeller of the plane, but they fail at its yellow boundary.

CIE-[formula] space. All previous experiments were performed using the standard RGB color space. The CIE-[formula] is a perceptually uniform color space, a property which the common RGB model does not have, describing all the colors visible to the human eye. The three coordinates L*, a* and b* represent the lightness of the color, its position between red/magenta and green, and its position between yellow and blue, respectively. Contrary to RGB color systems, in this space the color differences which one perceives correspond to distances when measuring colorimetrically.

Figure [\ref=fig:cielab] shows the results of minimizing [\eqref=eq:TVinpainting] on both RGB and CIE-[formula] color spaces by means of [formula] regularization, which benefits from the superiority of isotropic diffusion as demonstrated in Figure [\ref=fig:inpainting]. We observe that the choice of the uniform color space leads to a slight but visually noticeable improvement. Indeed, the bleeding of red across edges in RGB space vanishes when transforming the image into CIE-[formula] before inpainting. Accordingly, the PSNR gain is not negligible.

Conclusions

Considering the discrete setting, we have proposed to view the gradient of a multispectral image as a three dimensional matrix or tensor with the dimensions corresponding to the spatial extend, the directional derivatives considered as linear operators containing the differences to other pixels, and the color channels. We have then introduced collaborative total variation as the regularization that arises from taking different norms along each dimension. In particular, we have proposed to use collaborative norms such as [formula] and [formula], leading to very different properties of the regularization. We have provided relevant mathematical characterizations of the dual norm, the subdifferential and the proximal mapping of the proposed penalizations, which play a direct role in computing optimality conditions of several regularized problems. We have further proved, using the generalized concept of singular vectors, than an [formula] coupling leads to the strongest channel correlation, makes the most prior assumptions, and has the greatest potential to reduce color artifacts.

In experiments, we have demonstrated the wide applicability of the collaborative total variation to general inverse problems like denoising, deblurring and inpainting. For the numerical computation of the solution we have used the primal-dual hybrid gradient algorithm and stated all proximity operators of the considered CTV regularizations. From the above standards, we have exhibited the superiority of the [formula] norm for a stronger suppression of color artifacts, and of the isotropic regularizations for filling in thin regions.

Singular Vector Analysis

We give here the mathematical details regarding the construction of singular vectors as discussed in Section [\ref=sec:singVectors]. Let us remark that the following analysis could be done in a continuous setting with weak derivatives and distributions as long as there is a finite number of points at which the linearity of the functions l changes. Since our whole discussion about collaborative norms has been dealing with the discrete case, we limit the proofs in this section to the discrete setup, too.

Let l:{x1,...,xN}  →  [ -  1,1] be a discretization of a piecewise linear function such that the piecewise linearity only changes at { - 1,1}. More precisely, define the slope as well as the discrete derivative operator at each point as si: = Dxl(xi)  =  l(xi) - l(xi - 1). Let DTx denote the adjoint operator of Dx defined by analogy with the continuous setting: 〈DTxl,f〉  =  〈l,Df〉. One checks easily that DTxl(xi) = l(xi) - l(xi + 1). Then, we require either si + 1 = si, which means that we are in the piecewise linear part, or |l(xi)| = 1, which means that we are at a point where the type of linearity changes. As a first step, let us state the following lemma which will be needed in all following proofs.

Using definitions and notations above, si - si + 1 > 0 implies l(xi) = 1, and si - si + 1 < 0 implies l(xi) =  - 1. In particular, l(xi)DxDTxl(xi)  =  |si - si + 1| and [formula] whenever si  ≠  si + 1.

If si - si + 1 > 0, then |l(xi)| = 1 due to definition of l. Let us suppose that l(xi) =  - 1. From |l(xj)|  ≤  1 for all [formula], it follows that l(xi - 1)  ≥   - 1 and, as a consequence, si  ≤  0. This means that si + 1  =  l(xi + 1) - l(xi) < 0, that is, l(xi + 1) <  - 1, which contradicts |l(xi + 1)|  ≤  1. We thus deduce that l(xi) = 1. The proof for the case si - si + 1 < 0 can be done in a similar fashion.

The additional statement is a simple consequence of the first part along with DxDTxl(xi)  =  si - si + 1 by definition of the operators.

For each CTV regularization, the following results show that if z1k and z2k have some specific expressions, then the associated image [formula] is a singular vector of the energy [formula].

For each [formula], let l1k and l2k be discretizations of arbitrary piecewise linear functions in

[formula]

We aim at proving [formula] with [formula]. Based on the characterization of the subdifferential of J given in [\eqref=eq:subdiff1], we have to show that [formula], which is obvious due to its construction, together with [formula] and [formula] for all (xi,yj) at which Duk(xi,yj)  ≠  0. First, we can assume that c1k  ≠  0 since, otherwise, the statement is trivially satisfied. Now, observe that where DxDTyl2k(yj)  =  0 since DTyl2k(yj) does not depend on x. Hence, Duk(xi,yj)  ≠  0 implies that si  ≠  si + 1 and, thus, [formula] by Lemma [\ref=lem:signOfLinearFunction]. It follows that

[formula]

where in the second transition from last we have used [formula] derived from c1k∈{ - 1, + 1}. The proof of [formula] is similar and yields the assertion [formula].

Let l1 and l2 be discretizations of arbitrary piecewise linear functions in

[formula]

Similar to Theorem [\ref=thm:singular111], we have to check that [formula], which follows easily from [formula] and |lr(x)|  ≤  1, as well as [formula]. Using Lemma [\ref=lem:signOfLinearFunction], we see that On the other hand, it follows that Therefore, we have obtained [formula] and, similarly, [formula]. These equalities prove that [formula], which yields the result.

Let l1 and l2 be discretizations of arbitrary piecewise linear functions in

[formula]

z(x,y) = { .

[formula]

z(x,y) = { .

[formula]

Once more, we need to show that [formula], which follows from |lr(x)|  ≤  1 and [formula] due to crk∈{0,  ±  1}, and [formula]. The latter is achieved if [formula]. In the nontrivial case, [formula], we obtain as well as where we used [formula] because of crk∈{0,  ±  1}. Similarly, one shows that [formula], which ends the proof.

Proof of Theorem [\ref=th:chainRule]

We first prove [\eqref=eq:chainRule1]. Let [formula] be, with [formula] and vj∈∂fj(x0). From q∈∂g(f(x0)) one has that

[formula]

and each condition vj∈∂fj(x0) yields

[formula]

By using the above inequalities, we finally obtain

[formula]

Assume now that [formula] and fj is locally l.s.c for all [formula]. Let ∂, [formula] and ∂∞ denote the regular, general and horizon subdifferentials [\cite=Rockafellar1998], respectively. For [formula], we introduce the notation [formula]. Since f and g are proper and convex functions, [\cite=Rockafellar1998] implies (qf)(x0) = ∂(qf)(x0), g(f(x0))  =  ∂g(f(x0)), and [formula]. Furthermore, the properties of fj allow applying the same proposition to see

[formula]

which is equivalent to f being strictly continuous by [\cite=Rockafellar1998]. Note that [\cite=Rockafellar1998] also yields

[formula]

from where one deduces ∂∞g(f(x0)) = {0} due to [formula]. Putting it all together, [\cite=Rockafellar1998] applies and so Finally, the previous two inclusions along with the equivalence of regular and general subdifferentials lead to the equality in [\eqref=eq:chainRule1].