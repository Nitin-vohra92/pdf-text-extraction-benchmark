On the weak limit law of the maximal uniform k-spacing

Introduction and the main result

Both the distributional and asymptotic theories of spacings between consecutive order statistics of a sample of i.i.d. random variables play a central role in classical probability theory and mathematical statistics, see [\cite=Pyke], [\cite=SW] and the references therein. A deep understanding of this subject has been achieved over the past decades. In particular, [\cite=Devroye] [\cite=Deheuvels] give a very fine description of the almost sure behaviour (as the sample size tends to infinity) of the maximal spacing between the ordered statistics of uniform random variables. The laws of iterated logarithms proved in these papers for the maximal spacings are further extended in [\cite=DD] to analogous statements on the maximum of k consecutive spacings (called k-spacings).

In this note we prove a weak limit theorem for the maximal k-spacings. To the best of our knowledge, no result of this type was available in the past; it is truly surprising that this problem was not even mentioned in [\cite=DD].

More precisely, let [formula] be i.i.d. random variables that are uniformly distributed on

[formula]

U ≤ ≤ U

[formula]

n M - log n G,

[formula]

that contains k - 1 uniform points:

[formula]

Our main result is as follows.

We will use the following well-known fact: the uniform spacings are represented as

[formula]

where [formula] are i.i.d. standard exponential random variables; moreover, the random vector on the right-hand side is independent of the sum [formula], see e.g. [\cite=Pyke].

To discuss the statement of Theorem [\ref=Thm_main], consider the simplest case that k = 2 on the largest interval straddling a single uniform point. It is not hard to show that An: =  max 1  ≤  i  ≤  n(X2i - 1  +  X2i), Bn: =  max 1  ≤  i  ≤  n(X2i  +  X2i + 1), which are maxima of i.i.d. gamma random variables, satisfy [formula] and [formula].

The crucial observation is that An  -   log n  -   log  log n and Bn  -   log n  -   log  log n are asymptotically independent. Then

[formula]

and hence the law of large numbers and the continuous mapping theorem imply

[formula]

where G1 and G2 are i.i.d. random variables with a standard Gumbel distribution. Since [formula], Theorem [\ref=Thm_main] follows in the case that k = 2.

The asymptotic independence of An and Bn is non-trivial and somewhat unexpected. Our initial approach to the proof of Theorem [\ref=Thm_main] rested on establishing this property using the specific structure of these random variables. However, once the classical result [\cite=Watson] on the maxima of m-dependent stationary sequences came to our attention, we understood that our Theorem [\ref=Thm_main] can be established as a direct consequence. We describe this shorter and easier proof in the next section.

Proofs

We start by recalling the result from [\cite=Watson]. Random variables [formula] are said to be m-dependent if |i - j| > m implies that Yi and Yj are independent.

The theorem says that the maximum of m-dependent stationary random variables has the same weak limit as the maximum of an i.i.d. sequence with the same common distribution. Although the actual theorem of [\cite=Watson] makes a more restrictive assumption [formula] for all n  ≥  1, which may even be impossible to satisfy for certain ξ, the presented version easily follows by the monotonicity of distribution functions and the continuity of exp ( - ξ).

The aim is to apply Theorem [\ref=thm:Watson] to the (k - 1)-dependent stationary sequence of moving sums

[formula]

and the numbers

[formula]

for any fixed real x.

Note first that Yi are gamma random variables with densities fk, where fθ(y): = yθ - 1e- y  /  Γ(θ) for any positive y and θ. Then it is straightforward to check using L'Hopital's rule that

[formula]

(where by ~   we mean that the ratio tends to 1), hence [\eqref=eq:As2] holds by

[formula]

It remains to check the assumption [\eqref=eq:As1]. For any integer 1  ≤  a  ≤  k - 1, we have

[formula]

Hence

[formula]

where the three random variables in the r.h.s. are mutually independent and Za has a gamma distribution with density fa. By [\eqref=eq:_tail], for any ε  >  0 there exists an R > 0 such that

[formula]

Then [\eqref=eq:As1] follows as for such y,

[formula]

Thus we showed that Theorem [\ref=thm:Watson] applies to the sequence [formula] defined in [\eqref=eq:Def_Y], hence combined with [\eqref=eq:seq_cn] this implies

[formula]

Then by [\eqref=eq:representation], we find

[formula]

Now Theorem [\ref=Thm_main] follows by [\eqref=eq:_max_Y], the law of large numbers, the continuous mapping theorem, and the relation

[formula]

which itself holds by the law of large numbers, and the central limit theorem.