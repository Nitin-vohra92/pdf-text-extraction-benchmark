Theorem Lemma Proposition Corollary

Definition Conjecture Example

Remark Remarks Note Case Open questions

A T(b) Theorem on Product Spaces

Introduction

The study of the T(1)/T(b) type theorems in the multi-parameter setting can be dated back to 1985, when Journé [\cite=Jo] proved the first multi-parameter T(1) theorem by treating the singular integral operator as a vector-valued one-parameter operator. The result itself is very elegant except that some partial boundedness of the operator needs to be assumed. More recently, Pott and Villarroya in [\cite=PV] prove a new bi-parameter T(1) theorem with much weaker assumptions on the operator, where they formed different types of mixed conditions instead of assuming the partial boundedness. This is the point of view taken by Martikainen in [\cite=Ma], where he proved a representation theorem for bi-parameter singular integral operators which then implies a T(1) result, and in his joint work with Hytönen [\cite=HM2], where they showed a bi-parameter T(1) theorem in spaces of non-homogeneous type.

In this paper, for the first time, we prove a T(b) theorem in product spaces, which is a natural extension of the work we have mentioned above.

A function [formula] is called pseudo-accretive if there is a constant C such that for any rectangle R in [formula] with sides parallel to axes, [formula].

We will only discuss the case when [formula], where b1 and b2 are in [formula] and [formula], respectively. Then, the pseudo-accretivity and boundedness of b imply that there exists a constant C, such that for any cubes [formula], [formula] and [formula], i.e. b1 and b2 are both pseudo-accretive in the classical sense. Although this seems to be too restrictive, it is actually quite natural. Note that b = 1 falls in this class. Moreover, in all of the papers mentioned above, some partial structures on the operator are required in order to treat those mixed problems risen in the bi-parameter setting. In other words, the singular integral operator itself we are looking at behaves like a tensor product in some sense. It is essential in our argument for b to be a tensor product, otherwise, even defining Tb would become a problem.

Just as in the situation for the bi-parameter T(1) theorems, we still need to assume that besides T,T*, the partial adjoints of T also map b to a BMO function, an assumption shown by Journé [\cite=Jo] to be unnecessary for T to be L2 bounded. A more detailed discussion can be found in Section 6 of [\cite=Jo].

The main technique of the proof is to decompose L2 functions into sums of martingale differences adapted to b, analyze each part of the sums, and show that they have good enough decay to be summed up. The advantage of analyzing martingale differences is that they are supported on dyadic rectangles, constant on each of their children, and have orthogonality. Martikainen followed a similar strategy in [\cite=Ma], using Haar functions. However, when we treat b instead of 1, we have to create a bi-parameter b-adapted martingale difference decomposition, which makes the estimate of each part of the sum much less transparent. In the one-parameter setting, the idea of using such b-adapted martingale difference operators is well known and has been discussed by many authors in their proofs of different types of Tb theorems, such as David, Journé and Semmes [\cite=DJS], Coifman, Jones and Semmes [\cite=CJS], Nazarov, Treil and Volberg [\cite=NTV], Hytönen and Martikainen [\cite=HM]. But in the bi-parameter case, the b-adapted martingale difference has never been treated before.

The operator T studied in this paper is initially defined as a continuous linear map from [formula] to its dual. In order to justify the convergence of pairings of martingale differences, we also assume a priori that T is bounded on [formula], although we will show that quantitatively the operator norm of T is bounded by some constant depending only on the weak assumptions introduced in the following, but has nothing to do with the assumed L2  →  L2 norm. Note that although this a priori assumption is often unnecessary, it appears as a hypothesis in the proofs of some T(1) theorems: many authors have added this assumption ([\cite=Ma], [\cite=HM2]), even in the one-parameter setting ([\cite=NTV], [\cite=Hy]). It is not a consequence of involving b, but results from the fact that one has an initially continuously defined operator which is treated dyadically. Thus, we are more interested in showing how those weak assumptions quantitatively control the L2  →  L2 norm of T. However, in some specific examples that we will mention later, this a priori assumption can be removed.

The plan for the paper is the following. First, we introduce the assumptions on the operators as well as necessary preliminary on bi-parameter b-adapted martingale differences. Second, before stating and proving the T(b) theorem, we discuss some types of bi-parameter b-adapted paraproducts, which will be used later. Next, we give an averaging formula in the same flavor as in [\cite=Ma], which enables us to use the concept of "goodness" of cubes in our estimate. Then, we will move on to the main body of this paper, prove the T(b) theorem by a case by case estimate of terms in the averaging formula.

Acknowledgement

The author would like to thank Jill Pipher for guiding her into this area, suggesting the topic and the numerous fruitful discussions. The author is also grateful to Michael Lacey and Brett Wick for useful discussions during her visit to Georgia Institute of Technology.

Assumptions on the operator

Bi-parameter b-adapted martingale differences

As a preliminary, we begin with a quick introduction of the martingale difference decomposition adapted to our problem.

Let [formula], where ωni∈{0,1}n. Let Dn0 be the standard dyadic grid on [formula]. We define the shifted dyadic grid [formula], where [formula]. There is a natural probability structure on [formula], which gives us a random dyadic grid Dnωn in [formula]. When there is no need to specify what is the ωn, most of the time, we just write Dn for short. Interested readers can find more detailed discussion of random dyadic grids in [\cite=Hy] or [\cite=Ma].

Given a pseudo-accretive function [formula], and two fixed dyadic grids Dn,Dm in [formula], respectively. For each [formula], let Dnp be the collection of cubes of side length 2- p in Dn, we have Similarly, we have Eb2q and Eb2J defined for each [formula]. Then their composition is a b-adapted double expectation operator:

Let Δb1p = Eb1p + 1 - Eb1p, Δb1I  =  χIΔb1p for each I∈Dnp, and similarly for the other variable. The b-adapted double martingale difference is defined as

The following properties can be easily checked:

ΔbI  ×  Jf is supported on the dyadic rectangle I  ×  J, and is a constant on each of its children;

[formula];

Δbp,qΔbk,l = 0 unless p = k,q = l, and in this case it equals Δbp,q;

If [formula], then [formula] with convergence in L2, and

Property (4) can be verified by iteration of the one-parameter martingale difference argument in [\cite=NTV].

Moreover, we observe that and hence where Mbf = bf is the multiplication operator by b.

We now introduce the assumptions on T that we will need throughout the argument. Fix two pseudo-accretive functions [formula]. For simplicity, denote [formula] and [formula], then obviously d,d' are also pseudo-accretive.

Full Calderón-Zygmund structure

If [formula] and [formula] with [formula], [formula], [formula] and [formula], then we have the full kernel representation

The kernel [formula] is assumed to satisfy

Size condition

Hölder conditions

whenever |y1 - y1'|  ≤  |x1 - y1| / 2 and |y2 - y2'|  ≤  |x2 - y2| / 2,

whenever |x1 - x1'|  ≤  |x1 - y1| / 2 and |x2 - x2'|  ≤  |x2 - y2| / 2,

whenever |y1 - y1'|  ≤  |x1 - y1| / 2 and |x2 - x2'|  ≤  |x2 - y2| / 2,

whenever |x1 - x1'|  ≤  |x1 - y1| / 2 and |y2 - y2'|  ≤  |x2 - y2| / 2.

Mixed Hölder-size conditions

whenever |x1 - x1'|  ≤  |x1 - y1| / 2,

whenever |y1 - y1'|  ≤  |x1 - y1| / 2,

whenever |x2 - x2'|  ≤  |x2 - y2| / 2,

whenever |y2 - y2'|  ≤  |x2 - y2| / 2.

Partial Calderón-Zygmund structure

We also need some C-Z structure on [formula] and [formula] separately to deal with the case when f,g are only separated on one variable. If [formula] and [formula], then we have the partial kernel representation

The partial kernel Kf2,g2 defined on [formula] is assumed to satisfy the following standard estimates:

Size condition

[formula]

Hölder conditions

[formula]

whenever |x1 - x1'|  ≤  |x1 - y1| / 2,

[formula]

whenever |y1 - y1'|  ≤  |x1 - y1| / 2.

This assumption is in the same flavor of [\cite=Ma], and is important of defining T(b). In fact, we can weaken this by assuming the above only for the cases when for any cube [formula], and uV being a V-adapted function with zero-mean (i.e. uV  ⊂  V, |uV|  ≤  1 and [formula]).

We also need to assume that there exists a universal constant C, such that

It is easily shown that both full and partial kernel representations also hold when f,g are finite linear combinations of characteristic functions, or even tensor products of compactly supported L∞ functions, as long as for the required variable, they are still disjointly supported. To see this, when taking those functions, following from the standard condition on the kernels, both integrals are still convergent. We can use them to define the corresponding bilinear forms. After we finally show that T is bounded on L2 (here we don't even need the boundedness assumption on T a priori), use the density of C∞0 functions and Lebesgue dominated convergence theorem, we can show that the bilinear form has to be equal to the kernel representation, hence is well defined.

The partial C-Z structure assumption is natural. Recall how Journé defined his class of operators in [\cite=Jo]. Rephrasing in terms of our definition, Journé assumed that the partial kernel Kf2,g2(x1,y1) is a bilinear form associated with a [formula] valued standard C-Z kernel, which then implies the size and Hölder conditions ([\ref=parsize]), ([\ref=parH1]), ([\ref=parH2]). In the bi-parameter setting, the partial C-Z structure assumptions are required to both define Tb and to handle the "mixed cases". That arise because of the independent behavior in each variable. (See Section 6, 7, 9, 12 for discussions of different "mixed cases"). As far as we know, all the previous literature in this area needs some assumptions about the partial C-Z structure of the operator. For example, in Pott and Villarroya's most recent version of [\cite=PV], they included such an assumption on the operator so that they can fully justify the definition of T1. Although it is formulated a little differently, but is in spirit the same as ours. Martikainen ([\cite=Ma]) also requires a similar assumption. (See Section 2 of [\cite=Ma]).

Note that in the case f,g are separated in both variables, i.e. when we have the full kernel representation, the partial kernels are just and both of the size and Hölder conditions follow easily.

We also assume that the symmetric partial kernel representation and corresponding conditions on kernel Kf1,g1 in the case [formula].

Weak boundedness property

We assume that there exists a constant C such that, for any cube [formula] and [formula],

BMO conditions

We assume [formula], where T1 is the partial adjoint of T defined by

Here, by assuming that they are in [formula], equivalently, we mean that they are in [formula], the dyadic BMO space for any dyadic grid. It is proved by Pipher and Ward [\cite=PW] that in the bi-parameter setting, the product BMO is the average of dyadic BMO. This result is then reproved and extended to multi-parameter by Treil [\cite=Tr] through a different method. We now run into a problem of defining Tb (and similarly for the other three functions). In order to do this, we are going to show that Tb lies in the dual of some properly selected subspace A of [formula], i.e. the bilinear form 〈g,Tb〉 is well defined for any g∈A.

Let A be the space consisting of all the functions where [formula], I∈Dn,J∈Dm and we are summing over a finite number of terms. It is easily seen that A is indeed a subspace of [formula]. Hence, by linearity, it suffices to define 〈b'Δb'1IΔb'2Jf,Tb〉.

Divide the bilinear form into four parts:

Part one: Δb�1IΔb�2Jf is a finite linear combination of characteristic functions. For each Ii∈(I),Jj∈(J),

and In the above, the first term makes sense due to the weak boundedness property. The second and third terms can be dealt with using partial kernel representation. Finally, the last term can be defined using full kernel representation.

Part two (and similarly for part three): Write Then for each term in the above, since the functions have good separation on one variable, we know that in the case that everything is compactly supported, it has a partial kernel representation:

While the integrand is not compactly supported, and the Hölder condition for partial kernels implies that the integral is convergent, it can be used to serve as the definition of the bilinear form on the left hand side.

Part four: In this part, the functions have good separations on both variables. As above, although we don't have a full kernel representation for the bilinear form directly due to the fact that the integrand is not compactly supported, we can define it as follows: and prove that the integral does converge. To see this last fact, we change K(x,y) to by cancellation. Then the Hölder condition for the full kernel will imply the convergence of the integral.

Note that in parts two, three and four, we don't give an arbitrary definition to those bilinear forms. A simple limiting argument shows that they are well defined. Consider part four for example. Let φ be a cut-off function, such that φ = 1 on I  ×  J, and φ = 0 outside 3I  ×  3J. Denote dilation Dk1,k2φ(x) = φ(x1k- 11,x2k- 12). Since Δb'1IΔb'2Jf is a finite linear combination of characteristic functions, by the linearity of bilinear forms and full kernel representations, we have Changing the kernel and using the Hölder condition for the full kernel as above, together with the boundedness of f and φ, we can show that the integrand is uniformly bounded by a constant multiple of Then the Lebesgue dominated convergence theorem implies that And it's easily seen that the above definition is independent of the choice of φ.

Hence, Tb lies in the dual of A. By saying that it belongs to [formula], we mean that it is bounded on A and can be boundedly extended to a functional defined on the whole [formula]. And we can use the same technique above to give meanings to the other three objects similarly. Note that we can actually weaken this BMO assumption by only assuming that T(b) is a functional on A, and similarly for the other three (but with differently chosen subspaces of [formula]). We will see in the following that this is all we need.

Diagonal BMO conditions

There exists constant C such that, for any cube [formula], [formula], and any zero-mean functions aK, bV which are K, V adapted, respectively, the following hold:

[formula]

[formula]

[formula]

[formula]

Bi-parameter b-adapted paraproducts

In this section, we will discuss the boundedness of three different kinds of bi-parameter b-adapted paraproducts that will be used in the proof of our T(b) theorem.

Partial paraproducts

By partial paraproduct we mean a classical one-parameter b-adapted paraproduct with respect to one variable.

Let [formula]. Then, for two fixed pseudo-accretive functions [formula], the operator πb'2,b2a is a partial paraproduct, acting on functions on [formula]: Similarly, there is a symmetric partial paraproduct with respect to the other variable for fixed pseudo-accretive functions [formula], acting on functions on [formula].

Partial paraproducts are bounded operators on L2. Specifically, and a similar inequality holds for the symmetric one.

We only prove the first inequality. For any [formula], where the fourth and fifth lines follow from Hölder inequality. Hence, it suffices to show that To see this, by the boundedness of b'2, Hence, it suffices to prove Observing the above inequality, we see that by Carleson embedding theorem, all we need is to show that [formula] is a Carleson sequence with constant [formula], i.e. And this is not hard to prove since the b-adapted martingale differences satisfy the L2 property by [\cite=NTV]. Indeed, since [formula], for any fixed dyadic J, where the last equality is because Δb2I maps any constant function to 0. And this completes the proof.

Full paraproducts

We now introduce a "real" bi-parameter b-adapted paraproduct, which is a natural generalization of the classical one-parameter one.

For [formula], operator πb',ba is called full paraproduct, defined as

Full paraproducts are bounded operators on [formula]. Specifically,

To prove this proposition, we need to first consider the space [formula], containing those functions f such that [formula]. It is easy to check that the dual space of [formula] is [formula], containing functions f such that [formula]. It is well known that H1 can be characterized using both martingale maximal function and square function with the norms being equivalent ([\cite=CFS]). Similarly, if we define a b-adapted maximal function then, we have the following fact

A function f belongs to [formula] if and only if [formula].

Now, define a b-adapted square function as and let the space [formula] consist of all the functions f such that [formula]. We then have the following theorem.

If [formula], then [formula]. Moreover, for all f∈K1b, [formula].

To prove Theorem [\ref=squaremax], we use the idea of double martingale by Bernard and a technique involving atomic decomposition. See [\cite=Be].

First, in our b-adapted case, the well known equivalence of L2 norm between martingale maximal function and square function is still true. More specifically, we have

If function [formula], then both f*b and Sbf are in L2, and their norms are equivalent to [formula].

Iteration of a well known one-parameter L2 result (see [\cite=NTV]) gives Hence, For martingale maximal function, f  ≤  f*b  a.e. gives [formula]. On the other hand, by accretivity and the strong maximal function is bounded on L2, it implies [formula].

For simplicity, denote fp,q = Eb1pEb2qf, and for each pair [formula], let Fp,q be the σ-algebra generated by all the dyadic rectangles of size 2- p  ×  2- q.

The function [formula] is called a stopping time if {x:  (p,q)∈τ(x)} is Fp,q-measurable.

[formula] is an atom of K1b if there exists a stopping time τ such that

[formula];

Let [formula], then [formula];

[formula].

Note that if we call [formula], then from property (2) in the definition, both a*b and Sba are supported on F. Also, such functions are called atoms because they have the following property.

If a is an atom, then [formula], where [formula] is the unit ball in H1b or K1b, and C is a universal constant independent of a.

Using the supports of a*b and Sba, Hölder inequality implies and

We now state the theorem of atomic decomposition.

Given [formula], there exists a sequence of atoms an and a sequence of scalars λn such that

[formula]

[formula].

Before stating the proof of Theorem [\ref=atom], we show that this atomic decomposition result will imply Theorem [\ref=squaremax].

(of Theorem [\ref=squaremax]) It suffices to show the result holds for f∈L2. For any such function, atomic decomposition implies Then, which implies

We turn to the prove of Theorem [\ref=atom].

(of Theorem [\ref=atom]) For any [formula], let Fn  =  {x:  Sbf(x) > 2n}, and where Et is the classical expectation operator. It is easy to check that τn is a stopping time, and τn  ⊂  τn + 1.

For each n, define a new function [formula], then Using this, define We claim that such an and λn satisfy all the properties required in the theorem.

To check property (2): In the above, the second line follows from Chebyshev Inequality, and the fourth line uses the L2 boundedness of the classical martingale maximal function.

To check property (1): It suffices to check that For the first limit, Chebyshev Inequality implies that So as n  →    ∞  , |Fn|  →  0 monotonically. Hence, [formula]. By Fatou's Lemma, which implies lim n  →    ∞|Et(χFn)| = 0  a.e. uniformly in t. So when n is large enough, [formula], i.e. fτn = f.

For the second limit, if x is such that Sbf(x) = 0, then [formula]. Hence, [formula]. Also, in this case, [formula] fixed, since [formula], And similarly for Eb1pEb2q + 1f(x). So Eb1pΔb2qf(x) = Eb1p - 1Δb2qf(x) =  lim p  →    -    ∞Eb1pΔb2qf(x) = 0, which means A similar limiting argument for the other variable implies [formula]. Hence, Then the convergence is automatically true.

If x is such that Sbf(x) > 0, then for small enough n, Sbf(x) > 2n, i.e. [formula]. Also, We claim that all the terms appearing in the sum are 0, hence lim n  →    -    ∞fτn(x) = 0.

For any [formula], we have [formula]. Let n  →    -    ∞  , Say R = I  ×  J of size 2- t1  ×  2- t2 is the rectangle containing x of generation t. Then R has nonempty intersection with Xc since otherwise Et(χX)(x) = 1. For any [formula], since Sbf(y) = 0, we have [formula].

However, since Δbt - 1f(x) = Δbt - 1f(y), it implies Δbt - 1f(x) = 0, which proves the claim.

Then the only thing left to check is that all the an defined are indeed atoms.

To see this, firstly, an∈L2. Indeed,

Secondly, just as how we argued for the second property above, we see that [formula].

Thirdly, if t + 1∈τn, for any double integer s not satisfying s  ≤  t, by a simple computation, we have On the other hand, if s  ≤  t, then s∈τn, hence, which implies ant = Ebt(an) = 0.

Finally, to show [formula], it suffices to show which is equivalent to Write The first term can be dealt with trivially, For the second term, let Dt denote all those dyadic rectangles of generation t, then In the above, the second lines follows from the fact that Δbt - 1f is a constant on each R, and the third line uses t∈τn + 1. Combining I and II gives us which completes our proof for the theorem of atomic decomposition.

With the result of Theorem [\ref=squaremax], we return to the full paraproducts, and give a proof of Proposition [\ref=fullpara].

(of Proposition [\ref=fullpara]) For any [formula], where the last step in the above follows from Theorem [\ref=squaremax]. Hence, it suffices to show that

To see this, notice that where MS(f) is the strong maximal function, which is bounded on L2. Since Sb is also bounded on L2, we have

Mixed paraproducts

Since we are working in the bi-parameter setting, there appears a new mixed type of b-adapted paraproducts which requires particular attention. Basically, it means we have an average on a, and a difference on f with respect to one variable, and conversely with respect to the other.

For [formula], operator b',ba is called a mixed paraproduct, defined as

Mixed paraproducts are bounded operators on [formula]. Specifically,

Since we already have the b-adapted square function characterization of H1b, this proposition can be proved in the same way as a similar result in [\cite=PV].

For any [formula],

We claim that

To see this, note that where the last two operators are just formally defined, but not the compositions of the square functions and maximal functions. Since pointwisely, |Mb'1(Sb2g)|  ≤  |Sb2(Mb'1g)|, by symmetry, it suffices to prove that Sb1Mb'2:  L2  →  L2. And this is true because In the above, M2 means the Hardy-Littlewood maximal function with respect to the second variable. In the fourth line, we used the Fefferman-Stein inequality. And in the sixth line, the operator Sb1 is the one-parameter b1-adapted square function, defined as [formula]. It is straightforward to see that Sb1 is an L2 isometry up to some constant, which implies the seventh line in the above, where fy(x) denotes f(x,y).

Hence, the L2 boundedness of the mixed paraproduct is fully justified.

Main theorem and the strategy

We return to the main theorem of this paper. We will prove that, under the assumptions stated in Section [\ref=assump], T is bounded on [formula] with the operator norm depending only on the constants appearing in the above weak assumptions. By density and boundedness of b,b', it suffices to show that for any C∞0 functions f,g, there is a universal constant C such that

To prove this, recall that Martikainen [\cite=Ma] gave an averaging formula for the bilinear form 〈Tf,g〉 using a probabilistic concept called "goodness" of cubes. Here, if we decompose f using the new defined b-adapted martingale difference instead, there is a natural generalization of the averaging formula as follows.

To understand the above formula, recall that in [\cite=Hy], a cube I∈Dnωn is called bad if there exists Ĩ∈Dnωn so that [formula] and [formula]. γn  =  δ / (2n  +  2δ), where δ  >  0 appears in the kernel estimates. And [formula] is independent of I∈Dn0. By lemma 2.3 in [\cite=Hy], the parameter r can be chosen large enough such that [formula]. Moreover, for a fixed I∈Dn0 the position of [formula] depends on ωni with [formula], while the goodness of [formula] depends on ωni with [formula]. Hence, they are independent. The proof of Proposition [\ref=avefor] is identical to the proof of Proposition 2.1 in [\cite=Ma], which we omit here.

Note that as in [\cite=Hy] and [\cite=Ma], we do need to justify that the sum on the right hand side converges to the left hand side, which is the only place throughout the paper where we use the a priori L2  →  L2 boundedness of T. Indeed, by the convergence of expectation operators in L2, the boundedness of T will easily imply the convergences in the formula. However, when dealing with specific operators in practice, sometimes we can prove the convergence of the formula without assuming the boundedness assumption.

For example, if T is canonically associated with a standard antisymmetric kernel K(x,y), in the sense that and K satisfies all the size and Hölder conditions.

Then for any [formula], is well defined. Hence, we automatically have the full and partial kernel representations. Also, by antisymmetry, which corresponds to the weak boundedness property for b = b' = 1. With these observations in mind, it is not hard to show that for any f,g∈C∞0 and any fixed dyadic grid, So the a priori boundedness of T is not necessary any more.

With the averaging formula, it suffices to bound the sum on the right hand side uniformly for any fixed random grids, to do which, we will divide the sum into different parts according to the relative positions of the cubes, and discuss different cases one by one. By symmetry, except for one mixed case ([formula]), all the other cases are symmetric to [formula], which we will start with.

For the relative position of I1,I2, there are four different cases: separated (i.e. [formula]), inside (i.e. [formula]), equal, nearby (i.e. [formula]). Similarly, there are also four different cases for the second variable. Again using symmetry, it suffices to analyze the following ten cases:

separated/separated, separated/inside, separated/equal, separated/nearby,

inside/inside, inside/equal, inside/nearby,

equal/equal, equal/nearby, nearby/nearby.

In preparation, we state two control lemma here which will be repeatedly used when we deal with different cases in the following. For simplicity of notation, write where K∈Dn and [formula].

For fixed [formula] and any [formula], [formula],

It follows as a consequence of Hölder inequality. In the last step above, we used the L2 property of b-adapted double martingale difference.

For fixed [formula] and any [formula], [formula], and

These two inequalities are symmetric, and they can both be derived using a similar technique as for the above lemma. The only difference here is that we need to use the L2 property of the b-adapted martingale difference of only one variable instead.

Before we move on to the main part of the proof of the theorem, i.e. the case by case estimate of summands in the averaging formula, let's look at an example to see how our theory fits into some known results of boundedness of bi-parameter singular integral operators.

Consider operators associated with antisymmetric standard kernels. Journé, in [\cite=Jo], proved that if K = LÃ, the bicommutator of Calderón-Coifman type, where L is any standard antisymmetric function, and for some [formula] such that ∂212A∈L∞, then, the L2  →  L2 boundedness of the operator associated to L implies T1∈BMO, as well as the other BMO conditions. It is also not hard to verify directly that T satisfies the weak boundedness property and the four diagonal BMO assumptions. (All of them are actually zero!). Hence, by our main theorem, T is bounded on L2 with operator norm controlled by the weak assumptions.

Separated/Separated: [formula]

Define [formula], i.e. the smallest K such that [formula], and similarly for [formula]. Then since both of them are separated and I1,J1 are good, it is proved in [\cite=Hy] by Hytönen that [formula] and [formula].

Hence, we can write

The main goal of this section is to show that the following inequality holds.

If this is true, then by the full control lemma we stated in the beginning, [formula] can be bounded by [formula].

Since the two functions are well separated on both variables, by the full kernel representation,

Using the cancellation properties of the martingale differences, we can replace K(x,y) in the above by

[formula]

Since [formula], and similarly |y2 - cJ1|  ≤  |x2 - cJ1| / 2, by the full Hölder condition, where for the third inequality we used [formula] and [formula]. Then, by Hölder inequality and the boundedness of b,b', this implies

Separated/Inside: [formula]

Since [formula], J1 is contained in some child of J2, which we denote by J2,1. Then Δb'1I2Δb'2J2g is constant with respect to x2 on J2,1, and we have where 〈f〉b2J denotes the b2-adapted average of f over J with respect to the second variable: [formula].

Write

Part [formula]

In order to bound [formula] by [formula], by the full control lemma, it suffices to prove the following.

Case 1: [formula].

The two functions in the pairing are separated in both variables, which enables us to use the full kernel representation: Since in this case, the size of J1 is "significantly" small compared with J2, by the goodness of J1, [formula], which implies good separation on both variables. Hence, using the cancellation property in y variable, we can change the kernel K(x,y) in the above to By Hölder condition and a similar computation as in the Separated/Separated case, where in the third line, J2,j denotes all the children of J2 except J2,1, and we used the fact that Δb'1I2Δb'2J2g is constant with respect to x2 on each child of J2. And the fourth line follows from the estimate of those averages of Δb'1I2Δb'2J2g.

Case 2: [formula].

Let's further split I into two parts:

In I'', we still have good separation on both variables, so following from exact the same computation in Case Separated/Separated and the fact that now the size of J1,J2 are comparable,

Hence, the only thing left to deal with is I'. Since now the separation in the second variable is not good enough, we have to use the mixed Hölder-size condition instead. Again, in the full kernel representation, by cancellation property we can change the kernel to K(x,y) - K(x,cI1,y2), then In the above, the fifth line is because Δb1I1Δb2J1f is a constant on each child of I1  ×  J1, and the last line follows from the fact that the size of J1,J2 are comparable. This completes the proof of the proposition.

Part [formula]

For the part [formula], we are going to rewrite it into a form containing a partial b-adapted paraproduct. Rewrite and first look at the innermost sum.

Notice that Δb1I1f,Δb'1I2g are constant with respect to x1 on each child of I1,I2, respectively. If we decompose the above pairing into parts that are restricted on children of I1,I2, then where [formula], and the following lemma guarantees that the partial paraproduct is well defined.

hI1,t,I2,k is in [formula], and satisfies

We will assume the lemma to be true for the moment and prove it at the end of this section. The above pairing can be further rewritten as:

Then,

We claim that for any t,k,

[formula]

To see this, first observe that since b' is pseudo-accretive, for any L2 function h, And we have

Hence by linearity, LHS of ([\ref=parpara]) is comparable to Since [formula], and by Lemma [\ref=hBMO], [formula], the RHS of the above inequality where the last step follows from the first partial control lemma we stated in the beginning.

Then, to complete this section, we give a proof of Lemma [\ref=hBMO].

(of Lemma [\ref=hBMO]) It suffices to show that for any cube [formula], and any function a satisfying [formula], there holds

To see this,

For (2), since the two functions in the pairing have good separation on both variables, and [formula], use full kernel representation and change the kernel to Then, by Hölder condition,

For (1), there is good separation on only one variable, so we need to use the partial kernel representation. In the last step of the above, we used the partial C-Z assumption that [formula].

Separated/Equal: [formula]

In this part, By the full control lemma, it suffices to prove the following proposition.

For (2), the partial kernel representation gives

For (1), the full kernel representation and the mixed Hölder-size condition give which completes the proof.

Separated/Nearby: [formula]

In this part, we still want to use the full control lemma to bound the pairing. Notice that since J1,J2 are near, from a simple lemma proved by Hytönen in [\cite=Hy], the cube [formula] satisfies [formula], hence the size of J1, J2 and V are comparable. Since and [formula], in order to bound [formula], it suffices to show

To see this, since now both variables are separated but only the first separation is good, by the full kernel representation and the mixed Hölder-size condition, where the last step follows from the fact that the size of J1, J2 and V are comparable.

Inside/Inside: [formula]

This part is comparably difficult to deal with, and is also the first place where the assumed BMO conditions stated in the beginning come into play. We will also see that the boundedness of full paraproducts will play an important role in our estimates. To begin with, we first do the following decomposition. Let [formula], then

Part II,III

These two parts are symmetric, so it suffices to estimate one of them, say part III. This can be similarly dealt with as the second part in section Separated/Inside, where we used partial paraproducts. where [formula], [formula]. Note that although formally, sI1,t,I2,k is exactly the hI1,t,I2,k we've encountered in section Separated/Inside, but here since the relative position of I1,I2 has changed, they are actually different functions. And we will prove later that although sI1,t,I2,k is still in [formula], the estimate of its norm is different from hI1,t,I2,k. More specifically,

Let's assume this to be true right now. Then

Note that part (1) is exactly the same as the pairing appeared in [formula], except that here the partial paraproduct is defined using a different BMO function. Hence, following exactly the same argument, for any t,k, we have where again, in the last step, we used the first partial control lemma.

Similarly, although in part (2), the form of the pairing is a little bit different, however, when dealing with [formula], we only need to bound it by and since the norm of the BMO function has the same bound, so all the rest of the argument for part (1) still works here. i.e. This part satisfies the same estimate as part (1) does.

In conclusion,

And we are only left to prove Lemma [\ref=sBMO]:

(of Lemma [\ref=sBMO]) We only prove the inequality for sI1,t,I2,k, since the other one follows from exactly the same argument. Let cube [formula], a is any function supported on V such that [formula]. It suffices to show [formula].

In the case [formula], we have [formula], i.e. the separation of I1 and I2,k is good enough. Then following from the same reasoning in the proof of Lemma [\ref=hBMO], and note that now I2 = K, we have [formula].

Now let's assume [formula]. Then the size of I1,I2 are comparable, i.e. 2- i1  ≈  C, so it suffices to show [formula]. Split

By the partial kernel representation and size condition for the partial kernel,

By the partial kernel representation and Hölder condition for the partial kernel,

By the full kernel representation and mixed Hölder-size condition,

By the full kernel representation and Hölder condition,

Hence, the proof is complete.

Part I

In part I, since the functions in the pairing are separated on both variables, by an argument similar to what we did in the section Separated/Inside, which combined with the full control lemma, will give the boundedness of part I. (Note that in order to prove the above inequality, we need to discuss four different cases depending on whether [formula] and whether [formula], and use size, Hölder, or mixed Hölder-size conditions accordingly in each case.)

Part IV

To deal with this part, we need to use the b-adapted full paraproducts and its L2  →  L2 boundedness. Write

By assumption, [formula], then use the L2 boundedness of the full paraproduct, we have

Inside/Equal and Inside/Nearby: [formula]

The ways to estimate these two parts are similar, so we only explain the first one as an example. Let [formula], split

To bound [formula]. In the case [formula], it can be dealt with similarly as in the case Separated/Equal. In the case [formula], we claim that then the full control lemma implies the correct bound.

In order to prove the claim, further split

In part (1) and (2), both variables are separated, so we use the full kernel representation. And by the size condition and the mixed Hölder-size condition, respectively, they are bounded. In part (3) and (4), only the first variable is separated, so we need the partial kernel representation. By the size condition and Hölder condition for the partial kernel, respectively, they are bounded as well. We omit the details.

Now we deal with [formula], which needs the partial paraproduct argument, but is much easier than the cases we've seen before. As before, rewrite where [formula] is a BMO function whose norm satisfies the following lemma.

We postpone the proof, and assume this bound for the moment. Then

By a similar argument as in the previous two partial paraproducts, involving the estimate of the BMO norm of rVt,Vk and the L2 boundedness of the partial paraproduct, it is not hard to show that for any t,k, which completes the estimate of part [formula].

(of Lemma [\ref=rBMO]) For any cube [formula] and any function a supported on K such that [formula], we claim that [formula].

To see this, write

For part (1), write If s  ≠  k, use partial kernel representation and size condition for the partial kernel, If s = k, by the first diagonal BMO condition,

For part (2) and (3), write and similarly for (3).

If s  ≠  k, since both variables are separated, we can use full kernel representation, and mixed Hölder-size condition for (2), size condition for (3). If s = k, we use partial kernel representation, and Hölder condition for (2), size condition for (3). The details can be carried out similarly as for (1), and we omit them.

Equal/Equal, Equal/Nearby and Nearby/Nearby: σ=  /  =

We discuss these three cases together. When J1,J2 are near each other, the sizes of [formula] are comparable, similarly for the other variable. So by the full control lemma, in either of these three cases, it suffices to show

We only prove the above for the case Equal/Equal, which is the most difficult one since there is no separation on either variable. Note that for Equal/Nearby, one can use partial kernel representation and size condition to prove it, and for Nearby/Nearby, the full kernel representation and size condition will do.

Write I1 = I2 = K,J1 = J2 = V, and decompose the pairing into restrictions on each pair of their children,

If i  ≠  s,j  ≠  t, by the full kernel representation and size condition,

If i  ≠  s,j = t, by the partial kernel representation and size condition for the partial kernel, The case i = s,j  ≠  t is symmetric to this one.

If i = s,j = t, by the weak boundedness property,

This completes this section, as well as all the cases when [formula]. Moreover, the cases when [formula] can be dealt with symmetrically.

Mixed cases

We now consider the mixed cases. It suffices to analyze the case when [formula], and the only sub-case which is not symmetric to any of the above is the mixed Inside/Inside, which involves the boundedness of mixed paraproducts. By assumption, [formula]. Suppose [formula] and [formula]. Split

Part I,II,III can be similarly estimated as the corresponding parts in the Inside/Inside case discussed above. Note that for part II,III, we need to use the partial adjoint operator T1 to rewrite it into a form having partial paraproduct in it, and estimate some new one-parameter BMO functions, which can be achieved by the same techniques we've seen before.

To estimate part IV, we need to apply the boundedness of mixed paraproducts.

Recall that by assumption, [formula], so the above is and [formula] is one of our BMO assumptions. This completes the estimate of the mixed cases.