Definition Proposition Lemma Corollary Algorithm Question Assumptions

Remark Example

A variational approach to stochastic minimization of convex functionals

Introduction

In the present paper we study convex integral functionals on a locally compact Hadamard space (H,d). The reader who is not interested in this level of generality may consider the underlying space to be Euclidean. Let (S,μ) be a probability space and assume that a function f:H  ×  S  →  ( -   ∞  ,  ∞  ] satisfies

f(  ·  ,ξ) is a convex lsc function for each ξ∈S,

f(x,  ·  ) is a measurable function for each x∈H.

Then define

[formula]

We will assume that F(x) >  -   ∞   for every x∈H and that F is lsc (which can be assured, for instance, by Fatou's lemma).

The aim of stochastic minimization is to minimize the function F by using the marginal functions f(  ·  ,ξ). Stochastic (sub)gradient methods originated in the seminal work of H. Robbins and S. Monro [\cite=robbins-monro] and keep attracting significant attention [\cite=kushner-yin]. In those algorithms, each approximation step consists of choosing randomly ξ∈S and moving in the direction of a (sub)gradient of the function f(  ·  ,ξ). In contrast, the stochastic proximal point algorithm (PPA) appeared only very recently in [\cite=wang-bertsekas] and the aim of our paper is to further extend this approach. Recall that the basic proximal point algorithm is due to Martinet [\cite=martinet], Rockafellar [\cite=rocka] and Brézis&Lions [\cite=brezis].

The stochastic PPA is based on resolvent mappings associated with the marginal functions where λ > 0 is a given parameter. Note that in Hilbert spaces one has [formula] In Hadamard spaces, the resolvent of a convex function was first studied by J. Jost [\cite=jost95] and U. Mayer [\cite=mayer]. The stochastic proximal point algorithm is defined as follows. We prove the convergence of the sequence [formula] to a minimizer of F under weaker assumptions than in the existing literature and moreover we demonstrate the applicability of the stochastic PPA into several classical optimization problems in Euclidean space as well as a recent statistical model for phylogenetic inference [\cite=benner], where the underlying space is Hadamard. In all these examples, the resolvents of marginal functions are easy to compute in a closed form, which makes the algorithm readily usable in practice. The PPA as an implicit minimization method has better stability and convergence properties than gradient descent methods (see [\cite=bertsekas] for detailed and authoritative arguments), which makes our algorithm attractive even in Euclidean space. Moreover, in Hadamard spaces without a differentiable structure, gradient descent methods cannot be used and the stochastic PPA is therefore the only possible option. Our choice of a Hadamard space setting in the present paper is, inter alia, justified by the minimization problem in Example [\ref=exa:bhv] below. The relevance of Hadamard spaces for analysis and optimization is described in [\cite=mybook]. In particular, minimization algorithms are discrete time analogs of gradient flows, which in Hadamard spaces originated independently in [\cite=jost-ch] and [\cite=mayer] and were later generalized into much more general singular metric spaces [\cite=ags].

In the remainder of the Introduction, we describe the relation of our work to the existing literature. D. Bertsekas [\cite=bertsekas] was the first to introduce the proximal point algorithm for convex optimization problems with objective functions of the form

[formula]

where [formula] are all convex and continuous. This is a special case of [\eqref=eq:form]. Bertsekas' work [\cite=bertsekas] has been very influential: the algorithm was generalized into locally compact Hadamard space [\cite=mm] and subsequently applied in computational phylogenetics [\cite=benner]. S. Ohta and M. Pálfia [\cite=ohta-palfia] then continued along these lines and proved convergence in some positively curved metric spaces (also considering marginal functions over general probability space). The algorithm has also been extended into the 1-dimensional sphere [formula] and applied in image restoration [\cite=bergmann-etal] [\cite=bw1] [\cite=bw2]; with further developments following in [\cite=imaging]. For a survey, see G. Steidl's paper [\cite=steidl]. Another interesting result on the PPA in Hadamard spaces is due to S. Banert [\cite=banert].

M. Wang and D. Bertsekas [\cite=wang-bertsekas] also minimize a convex function of the form [\eqref=eq:form] by the stochastic proximal point algorithm, but their goals and means are somewhat different from ours. Namely, we work in locally compact Hadamard spaces whereas [\cite=wang-bertsekas] requires [formula] and moreover, our growth conditions on the marginal functions f(  ·  ,ξ) are weaker and allow applications like [\eqref=eq:leastsquares], whereas [\cite=wang-bertsekas] requires the existence of a common Lipschitz constant L in [\cite=wang-bertsekas] and a Lipschitz-like condition with constant L on all subgradients, which excludes important applications such as Example [\ref=exa:e3]. This makes our results new even in Euclidean spaces.

An implicit stochastic minimization has also recently emerged in statistics [\cite=toulis2] [\cite=toulis1].

In conclusion, the present paper can be viewed as an continuation of and improvement upon [\cite=mm] for allowing general probability distributions as well as weaker growth conditions on the marginal functions. Function [\eqref=eq:form] and [\eqref=eq:sumfun] are sometimes called expected risk and empirical risk, respectively. Naturally, we want to minimize expected risk rather than empirical risk provided the former is available (for instance, if we can sample arbitrary amount of data from μ). Hence the present paper enables an expected risk minimization, whereas the results of [\cite=mm] applied to empirical risk only.

Our convergence theorem as well as its proof is ispired by Lyapunov's stability theory of dynamical systems. Specifically, the distance function squared (which is strongly convex in Hadamard spaces) plays the role of a Lyapunov function and we need to arrive at estimate [\eqref=eq:superm] in order to apply the Robbins-Siegmund lemma. Futhermore, our Lipschitz-like growth condition [\eqref=i:sppa:lips] from Theorem [\ref=thm:conv] is also familiar from the theory of dynamical systems.

Preliminaries

For a background in Hadamard space theory, the reader is referred to [\cite=mybook] [\cite=bh] [\cite=jost2]. Here we recall that a complete metric space (H,d) is called a Hadamard space if for each pair of points x,y∈H there exists a mapping γ:  →  H, called a geodesic, such that γ(0) = x,γ(1) = y, and for each s,t∈[0,1], and if for each point z∈H, geodesic γ:  →  H, and t∈[0,1], we have

[formula]

We say that a function f:H  →  ( -   ∞  ,  ∞  ] is convex if [formula] is a convex function.

We shall need the following well known lemma.

If h:H  →  ( -   ∞  ,  ∞  ] is a convex lsc function and [formula] stands for its resolvent, then for every x,y∈H.

See [\cite=mybook].

Like in the above listed literature [\cite=mm] [\cite=bertsekas] [\cite=wang-bertsekas], our proof of Theorem [\ref=thm:conv] uses the famous Robbins-Siegmund theorem [\cite=robbins-siegmund].

Let [formula] be a filtered probability space. Assume [formula] and [formula] are sequences of nonnegative real-valued random variables defined on Ω and assume that

Uk,Yk,Zk,Wk are Fk-measurable for each [formula]

[formula] for each [formula]

[formula] and [formula]

Then the sequence [formula] converges to a finite random variable Y almost surely, and [formula] almost surely.

[\cite=robbins-siegmund].

Main convergence theorem

In this Section we prove that if the marginal functions f(  ·  ,ξ) satisfy a rather mild growth condition, the stochastic PPA converges to a minimizer of the convex integral functional in question. Notice that the growth condition in [\eqref=i:sppa:lips] is somewhat delicate, because there is no absolute value on the left hand side. It is also weaker than [\cite=wang-bertsekas], which requires the existence of a constant L > 0 such that for almost every ξ∈S, the subgradients of f(  ·  ,ξ) satisfy a Lipschitz-like condition with Lipschitz constant L.

Assume that

a function F is of the form [\eqref=eq:form] and has a minimizer,

there exists p∈H and an L2-function L:S  →  (0,  ∞  ) such that whenever x,y∈H,

[formula] and [formula]

Then there exists a random variable [formula] such that for almost every ω∈Ω the sequence [formula] given by [\eqref=eq:sppa] converges x(ω).

Denote [formula] We claim that for each y∈H there exits a constant Cy,p > 0, depending also on p, such that

[formula]

almost surely and for every [formula] Here of course the sequence xi depends on ω∈Ω and one should write xi(ω) instead of xi to be more precise. We will now prove this claim.

Let us fix [formula] By Lemma [\ref=lem:estim] we have Taking the conditional expectation with respect to Fi gives If we denote by xξi the result of the algorithm at the i-th step if ξi(ω) = ξ we get

[formula]

By the assumptions we have

[formula]

since Thus, for each y∈H, there exits a constant Cy,p > 0 such that We hence finally obtain which finishes the proof of [\eqref=eq:superm].

Next, choose a countable dense subset [formula] of [formula] This is possible because [formula] is a locally compact Hadamard space, its closed balls are therefore compact by the Hopf-Rinow theorem [\cite=bh] and consequently it is separable. Fix vn for a moment and for each [formula] apply [\eqref=eq:superm] with y = vn to obtain

[formula]

for every ω from a full measure set Ωvn  ⊂  Ω. Theorem [\ref=thm:rs] immediately gives that [formula] converges and that

[formula]

for every ω∈Ωvn. Next denote which is by countable subadditivity again a set of full measure. For each ω∈Ω∞, we have from [\eqref=eq:fromrs] that

[formula]

Since [formula] is bounded, it has a cluster point x(ω)∈H. By the lower semicontinuity of F and by [\eqref=eq:liminf] we obtain that [formula]

We will now show that, given [formula] the sequence [formula] converges. Indeed, for each ε > 0 there exists [formula] such that [formula] Because the sequence [formula] converges, there exists [formula] such that for each i,j  ≥  k we have Therefore, for each i,j  ≥  k. Hence, the sequence [formula] converges and consequently also xi(ω)  →  x(ω).

As the measurability of x is obvious, the proof is complete.

Applications

Here we apply our theorem to a few classical optimization problems (Examples [\ref=exa:e1],[\ref=exa:e2],[\ref=exa:e3]) as well as a recent statistical model for phylogenetic inference (Example [\ref=exa:bhv]). In all these examples, the resolvents of the marginal functions have a simple form and can thus be evaluated exactly. Since implicit methods are preferable to explicit ones for their better stability [\cite=bertsekas], one can conclude that Theorem [\ref=thm:conv] provides us with a more powerful tool than the stochastic gradient method. In Example [\ref=exa:bhv] the underlying space is a CAT(0) cubical complex without a differentiable structure, which means that minimization methods based on (sub)gradients are not applicable at all. The minimization problem in Example [\ref=exa:e3] can be solved by the stochastic PPA thanks to Theorem [\ref=thm:conv], the convergence theorems by other authors mentioned in the Introduction do not apply for their too restrictive growth conditions.

In the following examples we identify a Hadamard space H, probability space S and random variable ξ in order to make a connection with the previous sections.

Let [formula] be a random variable and set [formula] along with [formula] Hence [formula] We are to minimize the function One can easily verify that the Assumptions of Theorem [\ref=thm:conv] are satisfied and the resolvent of f(  ·  ,ξ) is easy to compute. A minimizer of F is called a median.

Let [formula] and [formula] be random variables and set [formula] along with [formula] Hence [formula] Here the objective function is The growth condition [\eqref=i:sppa:lips] is satisfied provided a∈L2.

Again, the resolvents can be expressed in a closed form. If a = 0, then [formula] for every [formula] Otherwise,

[formula]

for every [formula] See [\cite=bergmann-etal] for an explicit calculation.

Let [formula] and [formula] be random variables and set [formula] along with [formula] Hence [formula] We obtain the function

[formula]

It is straightforward to show that if a2,ba∈L2, then the condition [\eqref=i:sppa:lips] is satisfied and one can also check that

[formula]

for every [formula] see [\cite=bergmann-etal].

In particular, this applies into the classical least squares: given a matrix [formula] and vector [formula] minimize [formula] If we denote the k-th row of A by ak and the k-th entry of b by bk, then the loss function is

[formula]

and hence [formula] with [formula]

One can also use a regularization of the objective function F, that is, to minimize a new function [formula] where μ > 0, and Theorem [\ref=thm:conv] still applies and the resolvents are equally easy to compute. Recall that regularizations are used in statistics and machine learning as a standard tool against overfitting the data under consideration, as well as in optimization to handle ill-posed problems.

Let Tn be the BHV tree space whose orthant dimension is n - 2. This space was constructed and proved to be a CAT(0) cubical complex (hence a locally compact Hadamard space) in [\cite=bhv]. Further details and the original phylogenetic motivation can be found either in the original paper [\cite=bhv] or in [\cite=mybook].

A recent statistical model for phylogenetic inference [\cite=benner] relies upon minimizing the function where μD stands for a posterior distribution given data D and q∈{1,2}. In [\cite=benner] the above function F was approximated by empirical averages and they were minimized. Thanks to Theorem [\ref=thm:conv] however, one can now minimize the function F directly, since it is possible generate samples from μD on-the-fly. Again, the resolvents of the marginal functions are easy to compute in a closed form [\cite=mm] [\cite=mybook] [\cite=benner]. To put this example into the perspective of Theorem [\ref=thm:conv], note that S = Tn and μ  =  μD. For recent developments in statistics in the BHV tree space, the interested reader is referred also to [\cite=barden-le-owen] [\cite=miller-owen-provan] [\cite=nye].