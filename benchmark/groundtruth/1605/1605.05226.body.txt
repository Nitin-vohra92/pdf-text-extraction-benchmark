Algorithm

On two-generator subgroups in [formula], [formula], and [formula]

Introduction: two theorems of Sanov

Denote [formula] In an old paper [\cite=Sanov], I. N. Sanov proved two simple yet remarkable theorems:

The subgroup of [formula] generated by A(2) and B(2) is free.

The subgroup of [formula] generated by A(2) and B(2) consists of all matrices of the form [formula] with determinant 1, where all ni are arbitrary integers.

These two theorems together yield yet another proof of the fact that the group [formula] is virtually free. This is because the group of all invertible matrices of the form [formula] obviously has finite index in [formula]. Thus, we have:

The group [formula] is virtually free.

There is another interesting corollary of Theorem [\ref=th2]:

The membership problem in the subgroup of [formula] generated by A(2) and B(2) is solvable in constant time.

We note that this is, to the best of our knowledge, the only example of a natural (and nontrivial) algorithmic problem in group theory solvable in constant time. In fact, even problems solvable in sublinear time are very rare, see [\cite=Sublinear], and in those that are, one can typically get either "yes" or "no" answer in sublinear time, but not both. Complexity of an input in our case is the "size" of a given matrix, i.e., the sum of the absolute values of its entries. In light of Theorem [\ref=th2], deciding whether or not a given matrix from [formula] belongs to the subgroup generated by A(2) and B(2) boils down to looking at residues modulo 2 or 4 of the entries. The latter is decided by looking just at the last one or two digits of each entry. We emphasize though that solving this membership problem in constant time is only possible if input matrices are known to belong to [formula]; otherwise one would have to check that the determinant of a given matrix is equal to 1, which cannot be done in constant time, although can still be done in sublinear time with respect to the complexity |M| of an input matrix M, as defined in the next Section [\ref=results], see Corollary [\ref=complexity].

Our results

In this paper, we show that what would be a natural generalization of Sanov's Theorem [\ref=th2] to A(k) and B(k), [formula], is not valid for k  ≥  3 and moreover, the subgroup generated by A(k) and B(k) has infinite index in [formula] if k  ≥  3.

The subgroup of [formula] generated by A(k) and B(k), [formula], has infinite index in the group of all matrices of the form [formula] with determinant 1.

The group of all matrices of the above form, on the other hand, obviously has finite index in [formula].

Our main technical result, proved in Section [\ref=Peak], is the following

Let [formula] be a matrix from [formula]. Call "elementary operations" on M the following 8 operations: multiplication of M by either A(k)±  1 or by B(k)±  1, on the right or on the left.

(a) If [formula] and M belongs to the subgroup of [formula] generated by A(k) and B(k), then it has the form [formula] for some integers ni.

If [formula] and M belongs to the subgroup of [formula] generated by A(k) and B(k), then it has the form [formula] where all ni are integers and all exponents on k are positive integers.

(b) Let [formula]. If [formula] and no elementary operation reduces [formula], then either M is the identity matrix or M does not belong to the subgroup generated by A(k) and B(k).

We also point out a result, similar to Theorem [\ref=peak], about the monoid generated by A(k) and B(k) for k > 0. Unlike Theorem [\ref=peak] itself, this result is trivial.

Let [formula] be a matrix from [formula]. Call "elementary operations" on M the following 4 operations: multiplication of M by either A(k)- 1 or by B(k)- 1, on the right or on the left.

(a) If [formula] and M belongs to the monoid generated by A(k) and B(k), then it has the form [formula] for some nonnegative integers ni.

If [formula] and M belongs to the monoid generated by A(k) and B(k), then it has the form [formula] where all ni are nonnegative integers and all exponents on k are positive integers.

(b) Let [formula]. If M is a matrix from [formula] with nonnegative entries and no elementary operation reduces [formula], then either M is the identity matrix or M does not belong to the monoid generated by A(k) and B(k).

Thus, for example, the matrix [formula] does not belong to the monoid generated by A(2) and B(2), although it does belong to the group generated by A(2) and B(2) by Sanov's Theorem [\ref=th2].

Theorem [\ref=peak] yields a simple algorithm for the membership problem in the subgroup generated by A(k) and B(k) in case [formula] We note in passing that in general, the subgroup membership problem for [formula] is open, while in [formula] it is solvable since [formula] is virtually free. The general solution, based on the automatic structure of [formula] (see [\cite=Epstein]), is not so transparent and has quadratic time complexity. For our special subgroups we have:

Let [formula], and let the complexity |M| of a matrix [formula] be the sum of all |mij|. There is an algorithm that decides whether or not a given matrix [formula] is in the subgroup of [formula] generated by A(k) and B(k) (and if it does, finds a presentation of M as a group word in A(k) and B(k)) in time O(n  ·   log n), where n = |M|.

Similar statement holds for the monoid generated by A(k) and B(k), for any [formula].

The O(n  ·   log n) is the worst-case complexity of the algorithm referred to in Corollary [\ref=complexity]. It would be interesting to find out what the generic-case complexity (in the sense of [\cite=KMSS]) of this algorithm is. Proposition 1 in [\cite=BSV] tacitly suggests that this complexity might be, in fact, sublinear in n = |M|, which would be a really interesting result, so we ask:

Is the generic-case complexity of the algorithm claimed in Corollary [\ref=complexity] sublinear in |M|?

We note that, unlike the algorithms with low generic-case complexity considered in [\cite=KMSS], this algorithm has a good chance to have low generic-case complexity giving both "yes" and "no" answers, see our Section [\ref=Corollary] for more details.

Finally, we note that if M is in the subgroup generated by A(k) and B(k), k  ≥  2, then the presentation of M as a group word in A(k) and B(k) is unique since the group generated by A(k) and B(k) is known to be free for any [formula], see e.g. [\cite=JP]. On the other hand, the group generated by A(1) and B(1) (i.e., the whole group [formula]) is not free. This implies, in particular, that for any integer n  ≥  1, the group generated by [formula] and [formula] is not free because it contains both matrices A(1) and B(1). Many examples of rational k,  ~  0  <  k  <  2, for which the subgroup of [formula] generated by A(k) and B(k) is not free were found over the years, starting with [\cite=L-U]; see a recent paper [\cite=Gutan] for more references. (We can single out the paper [\cite=Beardon] where the question of non-freeness for this subgroup was reduced to solvability of particular Diophantine equations.) In particular, it is known that for any k,  ~  0  <  k  <  2, of the form [formula] or [formula], the group generated by A(k) and B(k) is not free. This includes [formula], etc. Also, if the group is not free for some k, then it is not free for any [formula].

The following problem, however, seems to be still open:

(Yu. Merzlyakov [\cite=Problems], [\cite=Kourovka]) For which rational k,  ~  0  <  k  <  2, is the group generated by A(k) and B(k) free? More generally, for which algebraic k,  ~  0  <  k  <  2, is this group free?

To the best of our knowledge, there are no known examples of a rational k,  ~  0  <  k  <  2, such that the group generated by A(k) and B(k) is free. On the other hand, since any matrix from this group has the form [formula] for some polynomials pij(k) with integer coefficients, this group is obviously free if k is transcendental. For the same reason, if r and s are algebraic numbers that are Galois conjugate over [formula], then the group generated by A(r) and B(r) is free if and only if the group generated by A(s) and B(s) is. For example, if [formula], then A(r) and B(r) generate a free group because this r is Galois conjugate to [formula]. More generally, A(r) and B(r) generate a free group for [formula], and therefore also for [formula], with arbitrary positive [formula]. This implies, in particular, that the set of algebraic r for which the group is free is dense in [formula] because [formula] can be arbitrarily close to 0. All these r are irrational though.

Peak reduction

Here we prove Theorem [\ref=peak] from Section [\ref=results]. The method we use is called peak reduction and goes back to Whitehead [\cite=Wh], see also [\cite=L-S]. The idea is as follows. Given an algorithmic problem that has to be solved, one first somehow defines complexity of possible inputs. Another ingredient is a collection of elementary operations that can be applied to inputs. Thus, we now have an action of the semigroup of elementary operations on the set of inputs. Usually, of particular interest are elements of minimum complexity in any given orbit under this action. The main problem typically is to find these elements of minimum complexity. This is where the peak reduction method can be helpful. A crucial observation is: if there is a sequence of elementary operations (applied to a given input) such that at some point in this sequence the complexity goes up (or remains unchanged) before eventually going down, then there must be a pair of subsequent elementary operations in this sequence (a "peak") such that one of them increases the complexity (or leaves it unchanged), and then the other one decreases it. Then one tries to prove that such a peak can always be reduced, i.e., if there is such a pair, then there is also a single elementary operation that reduces complexity. This will then imply that there is a "greedy" sequence of elementary operations, i.e., one that reduces complexity at every step. This will yield an algorithm for finding an element of minimum complexity in a given orbit.

In our situation, inputs are matrices from [formula]. For the purposes of the proof of Theorem [\ref=peak], we define complexity of a matrix [formula] to be the maximum of all |mij|. Between two matrices with the same max |mij|, the one with the larger [formula] has higher complexity. We will see, however, that in case of 2  ×  2 matrices with determinant 1, the "greedy" sequence of elementary operations would be the same as if we defined the complexity to be just [formula].

Elementary operations in our situation are multiplications of a matrix by either A(k)±  1 or by B(k)±  1, on the right or on the left. They correspond to elementary row or column operations; specifically, to operations of the form (row1  ±  k  ·  row2), (row2  ±  k  ·  row1), (column1  ±  k  ·  column2), and (column2  ±  k  ·  column1).

We now get to

Proof of Theorem [\ref=peak]. We are going to consider various pairs of subsequent elementary operations of the following kind: the first operation increases the maximum of |mij| (or leaves it unchanged), and then the second one reduces it. We are assuming that the second elementary operation is not the inverse of the first one.

In each case like that, we show that either the maximum of |mij| in the given matrix could have been reduced by just a single elementary operation, or [formula] could have been reduced by a single elementary operation leaving the maximum of |mij| unchanged. Because of a "symmetry", it is sufficient to consider the following cases.

First of all, we note that since the determinant of M is equal to 1, there can be 0, 2, or 4 negative entries in M. If there are 2 negative entries, they can occur either in the same row, or in the same column, or on the same diagonal. Because of the symmetry, we only consider the case where two negative entries are in the first column and the case where they are on the main diagonal. Also, cases with 0 and 4 negative entries are symmetric, so we only consider the case where there are no negative entries.

It is also convenient for us to single out the case where M has two zero entries, so we start with

Case 0. There are two zero entries in M. Since the determinant of M is 1, these zero entries should be on a diagonal, and nonzero entries should be equal to ±  1. Then, unless M is the identity matrix, it is going to have a finite order, in which case it cannot belong to the subgroup generated by A(k) and B(k), k  ≥  2, since this subgroup is free.

In what follows, we assume that all matrices under consideration have at most one zero entry. Even though we use strict inequalities for all entries of a matrix, the reader should keep in mind that one of the inequalities may be not strict; this does not affect the argument.

Case 1. There are 2 negative entries, both in the first column. Thus, m11 < 0,m21 < 0,m12 > 0,m22 > 0.

Case 1a. Two subsequent elementary operations reducing some entry after increasing it are both (column1  +  k  ·  column2). If this pair reduces some |mij|, then obviously just one of them will reduce the same |mij|. The same goes for the case where both operations are (row1  +  k  ·  row2), or (row1  -  k  ·  row2), or (column1  -  k  ·  column2).

Case 1b. Two subsequent elementary operations are: (row1  +  k  ·  row2), followed by (column1  +  k  ·  column2). The result of applying these two operations to the matrix M is: [formula]. This case is nontrivial only if the first operation increases the absolute value of the element in the top left corner (or leaves it unchanged), and then the second operation reduces it. But then the second operation should also reduce the absolute value of m21 for the determinant to remain unchanged. This means a single operation (column1  +  k  ·  column2) would reduce |m21| to begin with, and this same operation should also reduce |m11| for the determinant to remain unchanged. Thus, a single elementary operation would reduce the complexity of M.

The same argument takes care of any of the following pairs of subsequent elementary operations: (row1  ±  k  ·  row2), followed by (column1  ±  k  ·  column2), as well as (row1  ±  k  ·  row2), followed by (column2  ±  k  ·  column1).

Case 1c. Two subsequent elementary operations are: (row1  +  k  ·  row2), followed by (row2  +  k  ·  row1). The result of applying these two operations to the matrix M is: [formula]. In this case, obviously |(k2 + 1)m21  +  k  ·  m11|  >  |m21| and |(k2 + 1)m22  +  k  ·  m12|  >  |m22|, so we do not have a decrease, i.e., this case is moot.

Case 1d. Two subsequent elementary operations are: (row1  +  k  ·  row2), followed by (row2  -  k  ·  row1). The result of applying these two operations to the matrix M is: [formula]. If [formula], then | - (k2 - 1)m21  -  k  ·  m11|  >  |m21| and | - (k2 - 1)m22  -  k  ·  m12|  >  |m22|, so we do not have a decrease, i.e., this case is moot, too.

Case 1e. Two subsequent elementary operations are: (row1  -  k  ·  row2), followed by (row2  +  k  ·  row1). The result of applying these two operations to the matrix M is: [formula]. If the first operation increases |M| (or leaves it unchanged) and then the second one reduces it, then the second operation should reduce |m21| or |m22|. Assume, without loss of generality, that |m21|  ≥  |m22|.

We may assume that |m11 - k  ·  m21|  ≥  |m11|  =   - m11 and |m12 - k  ·  m22|  ≥  |m12|  =  m12 because otherwise, the complexity of M could be reduced by a single operation (row1  -  k  ·  row2).

Now we look at the inequality |k  ·  m11 - (k2 - 1)  ·  m21|  <  |m21| =  - m21. Re-write it as follows: |k  ·  (m11 - k  ·  m21)  +  m21|  <   - m21. We may assume that m11 - k  ·  m21 > 0 because otherwise, a single operation (row1  -  k  ·  row2) would reduce the complexity of M. We also know that |m11 - k  ·  m21|  ≥   - m11 (see the previous paragraph). Thus, m11 - k  ·  m21  ≥   - m11. This inequality, together with |k  ·  (m11 - k  ·  m21)  +  m21|  <   - m21, yield | - k  ·  m11  +  m21|  <   - m21. This means a single operation (row2  -  k  ·  row1) would reduce |m21|.

Case 1f. Two subsequent elementary operations are: (row1  -  k  ·  row2), followed by (row2  -  k  ·  row1). The result of applying these two operations to the matrix M is: [formula]. If the first operation increases |M| (or leaves it unchanged) and then the second one reduces it, then the second operation should reduce |m21| or |m22|.

We may assume that m12  -  k  ·  m22  <  0 because otherwise, a single operation (row1  -  k  ·  row2) would reduce |m12| and therefore also |m11| for the determinant to remain unchanged in this case. Now look at the element in the bottom right corner: (k2 + 1)  ·  m22  -  k  ·  m12  =  k  ·  (k  ·  m22 - m12)  +  m22. Since k  ·  m22 - m12 > 0, we have |(k2 + 1)  ·  m22  -  k  ·  m12|  >  |m22|, a contradiction.

Case 1g. Two subsequent elementary operations are: (column1  +  k  ·  column2), followed by (column2  +  k  ·  column1). The result of applying these two operations to the matrix M is: [formula]. If the first operation increases |M| (or leaves it unchanged) and then the second one reduces it, then the second operation should reduce |m12| or |m22|. Let us assume here that |m22|  ≥  |m12|.

Now look at the element in the bottom right corner: (k2 + 1)  ·  m22  +  k  ·  m21  =  k  ·  (m21  +  k  ·  m22)  +  m22. We may assume that m21  +  k  ·  m22  >  0 because otherwise, a single operation (column1  +  k  ·  column2) would reduce |m21|. In that case, however, we have |(k2 + 1)  ·  m22  +  k  ·  m21|  =  k  ·  (m21  +  k  ·  m22)  +  m22  >  m22  =  |m22|, a contradiction.

Case 1h. Two subsequent elementary operations are: (column1  +  k  ·  column2), followed by (column2  -  k  ·  column1). The result of applying these two operations to the matrix M is: [formula]. If the first operation increases |M| (or leaves it unchanged) and then the second one reduces it, then the second operation should reduce |m12| or |m22|. Assume here that |m22|  ≥  |m12|. Then we should have |(1 - k2)  ·  m22  -  k  ·  m21|  <  |m22|  =  m22.

We may assume that m21  +  k  ·  m22  >  0 because otherwise, a single operation (column1  +  k  ·  column2) would reduce |m21| while keeping the element in this position negative. Then this same operation should reduce |m11|, too, for the determinant to remain unchanged. Also, since the first operation was supposed to increase |M| (or leave it unchanged), we should have, in particular, |m21  +  k  ·  m22|  =  m21  +  k  ·  m22  ≥  |m21|  =   - m21. This, together with the inequality in the previous paragraph, gives |(1 - k2)  ·  m22  -  k  ·  m21|  =  |m22  -  k  ·  (m21  +  k  ·  m22)|  ≥  |k  ·  m22  +  m21|. Therefore, we should have |k  ·  m22  +  m21|  <  |m22|  =  m22. Since k  ≥  2, this implies |m21|  >  |m22|, contradicting the assumption of m22 having the maximum absolute value in the matrix M.

Case 1i. Two subsequent elementary operations are: (column1  -  k  ·  column2), followed by (column2  +  k  ·  column1). The result of applying these two operations to the matrix M is: [formula]. Since k  ≥  2, we have |(1 - k2)  ·  m22  +  k  ·  m21|  >  |m22|, so this case is moot.

Case 1j. Two subsequent elementary operations are: (column1  -  k  ·  column2), followed by (column2  -  k  ·  column1). The result of applying these two operations to the matrix M is: [formula]. Since |(1 + k2)  ·  m22  -  k  ·  m21|  =  |m22  -  k  ·  (m21  -  k  ·  m22)|  >  |m22|, this case is moot, too.

Case 2. Two negative entries are on a diagonal. Without loss of generality, we assume here that m11 > 0,m22 > 0,m12 < 0,m21 < 0. Because of the "symmetry" between row and column operations in this case, we can reduce the number of subcases (compared to Case 1 above) and only consider the following.

Case 2a. Two subsequent elementary operations are: (row1  +  k  ·  row2), followed by (column1  +  k  ·  column2). The result of applying these two operations to the matrix M is: [formula]. This case is nontrivial only if the first operation increases the absolute value of the element in the top left corner (or leaves it unchanged), and then the second operation reduces it. First let us look at the element m21 + k  ·  m22. If m21 + k  ·  m22 < 0, then a single operation (column1  +  k  ·  column2) would reduce m21 while keeping that element negative. In that case, this operation would reduce m11, too, while keeping it positive because otherwise, the determinant would change. Thus, a single operation (column1  +  k  ·  column2) would reduce the complexity of M in that case. The same argument shows that m12 + k  ·  m22  ≥  0 because otherwise, a single operation (row1  +  k  ·  row2) would reduce the complexity of M.

If m21 + k  ·  m22  ≥  0 and m12 + k  ·  m22  ≥  0, then m11  +  k  ·  m21 + k  ·  m12  +  k2m22  ≥  0 for the determinant to be equal to 1. But then the second operation should also reduce the absolute value of m21 for the determinant to remain unchanged. This means a single operation (column1  +  k  ·  column2) would reduce |m21| to begin with, and this same operation should also reduce |m11| for the determinant to remain unchanged, so this single operation would reduce the complexity of M.

The same argument takes care of any of the following pairs of subsequent elementary operations: (row1  ±  k  ·  row2), followed by (column1  ±  k  ·  column2), as well as (row1  ±  k  ·  row2), followed by (column2  ±  k  ·  column1).

Case 2b. Two subsequent elementary operations are: (row1  +  k  ·  row2), followed by (row2  +  k  ·  row1). The result of applying these two operations to the matrix M is: [formula]. If the first operation increases |M| (or leaves it unchanged) and then the second one reduces it, then the second operation should reduce |m21| or |m22|. Assume, without loss of generality, that |m21|  ≥  |m22|.

Thus, we have |(k2 + 1)m21  +  k  ·  m11|  <  |m21|  =   - m21. At the same time, we may assume that |m11 + k  ·  m21|  ≥  |m11|  =  m11 because otherwise, a single operation (row1  +  k  ·  row2) would reduce the complexity of M.

Then, if m11 + k  ·  m21 > 0, then a single operation (row1  +  k  ·  row2) would reduce |m11|, and therefore also |m12|. Thus, we may assume that m11 + k  ·  m21 < 0.

Now let us look at the inequality |(k2 + 1)m21  +  k  ·  m11|  <   - m21. We know that m11 + k  ·  m21 < 0. Therefore, k  ·  m11 + k2  ·  m21 < 0. Now |(k2 + 1)m21  +  k  ·  m11  =  |k  ·  m11 + k2  ·  m21  +  m21|  >   - m21. This contradiction completes Case 2b.

Case 2c. Two subsequent elementary operations are: (row1  +  k  ·  row2), followed by (row2  -  k  ·  row1). The result of applying these two operations to the matrix M is: [formula]. The analysis here is similar to the previous Case 2b. First we note that we may assume m11 + k  ·  m21 < 0, so - k  ·  m11 - k2  ·  m21 > 0. On the other hand, we may assume that |m11 + k  ·  m21|  =   - m11 - k  ·  m21  ≥  m11 because otherwise, a single operation (row1  +  k  ·  row2) would reduce |m11|. Therefore, - k  ·  m11  -  k2  ·  m21  ≥  k  ·  m11.

This, together with the inequality | - (k2 - 1)m21  -  k  ·  m11|  =  | - k  ·  m11 - k2  ·  m21  +  m21|  <  |m21|  =   - m21, implies |k  ·  m11  +  m21|  <  |m21|, in which case a single operation (row2  +  k  ·  row1) would reduce |m21|.

Case 2d. Two subsequent elementary operations are: (row1  -  k  ·  row2), followed by (row2  +  k  ·  row1). The result of applying these two operations to the matrix M is: [formula]. If k2 > 2, here we obviously have | - (k2 - 1)m22  +  k  ·  m12|  >  |m22|, and | - (k2 - 1)m21  +  k  ·  m11|  >  |m21|. Thus, this case is moot.

Case 2e. Two subsequent elementary operations are: (row1  -  k  ·  row2), followed by (row2  -  k  ·  row1). The result of applying these two operations to the matrix M is: [formula]. Here again we obviously have |(k2 + 1)m22  -  k  ·  m12|  >  |m22| and |(k2 + 1)m21  -  k  ·  m11|  >  |m21|, so this case is moot, too.

Case 3. There are no negative entries. Because of the obvious symmetry, it is sufficient to consider the following cases.

Case 3a. Two subsequent elementary operations are both (column1  +  k  ·  column2), (column2  +  k  ·  column1), (row1  +  k  ·  row2) or (row2  +  k  ·  row1). Since all the entries are positive, the second operation cannot decrease the complexity in this case.

Case 3b. Two subsequent elementary operations are (column1  +  k  ·  column2), followed by (column2  -  k  ·  column1), give the matrix

[formula]. If the first operation increases |M| (or leaves it unchanged) and then the second operation reduces it, then the second operation should reduce, say, |m12| = m12 (assuming that m12  ≥  m22). After the first operation we note that |m11 + k  ·  m12| = m11 + k  ·  m12  ≥  |m12| = m12. After the second operation, assuming that complexity was reduced, we have |(1 - k2)m12 - k  ·  m11|  ≤  |m12| = m12, which can be rewritten as |m12 - k(m11 + k  ·  m12)|  ≤  m12. Since all the entries are positive, we have m11 + k  ·  m12  ≥  m12, and hence in order for the second operation to reduce |m12|, the following inequality should hold: - m12  ≤  (1 - k2)m12 - k  ·  m11  ≤  0. Subtracting m12, multiplying each part by - 1 and factoring out k we get 2m12  ≥  k(m11  +    ·  m12)  ≥  m12. Divide by k: [formula]. However, k  ≥  2 implies that m11 + k  ·  m12  ≤  m12, which brings us to a contradiction.

Case 3c. Two subsequent elementary operations are (column1  -  k  ·  column2), followed by (column2  +  k  ·  column1). The resulting matrix is

[formula]. If the first operation increases |M| (or leaves it unchanged) and then the second one reduces it, then the second operation should reduce, say, |m12| = m12 (assuming that m12  ≥  m22).

Also, after the first operation we can observe that m11  ≤  |m11 - k  ·  m12| =  and m21  ≤  |m21 - k  ·  m11| because otherwise, a single operation (column1  -  k  ·  column2) would reduce |m11| and |m21|. This implies that m11 - k  ·  m12  ≤   - m11 and m21 - k  ·  m22  ≤   - m21.

Consider the inequality |(1 - k2)m12 + k  ·  m11|  ≤  m12. Rewrite it in the following way: |m12 - k  ·  (k  ·  m12 - m11)|  ≤  m12. Combining this with the previous inequalities we get |m12 - k  ·  m11|  ≤  |m12 - k  ·  (k  ·  m12 - m11)|  ≤  m12. Therefore, a single operation (column2  -  k  ·  column1) reduces |m12|.

Case 3d. Two subsequent elementary operations are (column1  -  k  ·  column2) followed by (column2  -  k  ·  column1). The resulting matrix is

[formula]. If the first operation increases |M| (or leaves it unchanged) and then the second operation reduces it, then the second one should reduce, say, |m12| = m12 (assuming that m12  ≥  m22).

We may assume that m11 - k  ·  m12  ≤  0 because if m11 - k  ·  m12 > 0, then for the determinant to be unchanged after the first operation, we would have also m21 - k  ·  m22 > 0, but then a single operation (column1  -  k  ·  column2) would reduce the complexity of M.

Thus, |m11 - k  ·  m12|  =  k  ·  m12  -  m11. If the first operation (column1  -  k  ·  column2) did not reduce the complexity of M, then m11  ≤  k  ·  m12  -  m11, which implies that m11 - k  ·  m12  ≤   - m11.

Now consider the inequality |(1 - k2)m12 - k  ·  m11|  ≤  m12. After rewriting it we get |m12 - k  ·  (k  ·  m12 - m11)|  ≤  m12. Combining it with the inequality in the previous paragraph, we get |m12 - k  ·  m11|  ≤  |m12 - k  ·  (k  ·  m12 - m11)|  ≤  m12. Therefore, a single elementary operation (column2  -  k  ·  column1) reduces |m12|.

Proof of Theorem [\ref=infinite]

Let [formula]. Denote [formula]. It is straightforward to check that:

(1) M(k,m) has determinant 1;

(2) M(k,m) = M(k,1)m;

(3) No elementary k-operation reduces the absolute value of any of the entries of M(k,m).

Since the cyclic group generated by M(k,1) is infinite, the result follows from Theorem [\ref=peak].

Proof of Corollary [\ref=complexity]

We assume in this section that k  ≥  3 because for k = 2, the membership problem in the subgroup of [formula] generated by A(k) and B(k) is solvable in constant time, see Corollary [\ref=corollary2] in the Introduction.

First of all we check that a given matrix M from the group [formula] has the form [formula] for some integers ni. Then we check that M has at most one zero entry. If there are more, then M does not belong to the subgroup in question unless M is the identity matrix. We also check that max |mij|  >  1. If max |mij|  =  1, then M does not belong to the subgroup in question unless M is the identity matrix. Indeed, the only nontrivial cases here are M = A(  ±  1) and M = B(  ±  1). Then Mk = A(k)±  1 or Mk = B(k)±  1. This would give a nontrivial relation in the group generated by A(k) and B(k) contradicting the fact that this group is free.

Now let max |mij|  >  1. If no elementary operation either reduces max |mij| or reduces [formula] without increasing max |mij|, then M does not belong to the subgroup generated by A(k) and B(k). If there is an elementary operation that reduces max |mij|, then we apply it. For example, suppose the elementary operation (row1 - k  ·  row2) reduces |m11|. The result of this operation is the matrix [formula]. If |m11| here has decreased, then |m12| could not increase because otherwise, the determinant of the new matrix would not be equal to 1. Thus, the complexity of the matrix M has been reduced, and the new matrix belongs to our subgroup if and only if the matrix M does. Since there are only finitely many numbers of the form [formula] with bounded absolute value, this process should terminate either with a non-identity matrix whose complexity cannot be reduced or with the identity matrix. In the latter case, the given matrix was in the subgroup generated by A(k) and B(k); in the former case, it was not.

To estimate the time complexity of this algorithm, we note that each step of it (i.e., applying a single elementary operation) takes time O( log m), where m is the complexity of the matrix this elementary operation is applied to. This is because if k is an integer, multiplication by k amounts to k - 1 additions, and each addition of integers not exceeding m takes time O( log m). Since the complexity of a matrix is reduced at least by 1 at each step of the algorithm, the total complexity is [formula]. This completes the proof. [formula]

As for generic-case complexity of this algorithm (cf. Problem [\ref=generic] in our Section [\ref=results]), we note that, speaking very informally, a "random" product of A(k)±  1 and B(k)±  1 is "close" to a product where A(k)±  1 and B(k)±  1 alternate, in which case the complexity of the product matrix grows exponentially in the number of factors (see e.g. [\cite=BSV]), so the number of summands in the sum that appears in the proof of Corollary [\ref=complexity] will be logarithmic in n, and therefore generic-case complexity of the algorithm should be O( log 2n) in case the answer is "yes" (i.e., an input matrix belongs to the subgroup generated by A(k) and B(k)). Of course, a "random" matrix from [formula] will not belong to the subgroup generated by A(k) and B(k) with overwhelming probability. This is because if k  ≥  3, this subgroup has infinite index in [formula]. It is, however, not clear how fast (generically) our algorithm will detect that; specifically, whether it will happen in sublinear time or not.

Note that, unlike the algorithms with low generic-case complexity considered in [\cite=KMSS], this algorithm has a good chance to have low generic-case complexity giving both "yes" and "no" answers.

Finally, we note that generic-case complexity depends on how one defines the asymptotic density of a subset of inputs in the set of all possible inputs. This, in turn, depends on how one defines the complexity of an input. In [\cite=KMSS], complexity of an element of a group G was defined as the minimum word length of this element with respect to a fixed generating set of G. In our situation, where inputs are matrices over [formula], it is probably more natural to define complexity as the sum of the absolute values of the entries, like we did in this paper.

Acknowledgement. We are grateful to Norbert A'Campo, Ilya Kapovich, and Linda Keen for helpful comments.

pt