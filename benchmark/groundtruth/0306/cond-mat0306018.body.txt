Published in: Lecture Notes in Computer Science 4131, 710-717 (2006). Processing of information in synchroneously firing chains in networks of neurons

Two seminal concepts were introduced by Abeles [\cite=abeles81] [\cite=abeles82] [\cite=abeles91]: A quantitative model for uncorrelated activity in the cortex in absence of external stimulation, and the concept of the synfire chain, a spatiotemporal pattern of synchroneous activity of neurons being active in the same cortical task.

Synchroneous spiking, as a refinement of averaged firing rates, has been used as an equivalent mathematical basis for neural models [\cite=gerstnerBC93] [\cite=herrmannhertzbennett95]. The experimental and theoretical aspects of synfire chains remain a field of active research [\cite=ikeda03] [\cite=sougne01] and also provide a conceptual basis for neural computing architectures [\cite=wermter02]. This paper analyzes the extension to formulate processing and propagation of information in such a network.

The Abeles model of cortical activity

The model of uncorrelated cortical activity given by Abeles [\cite=abeles81], here referred to as Abeles Model, is a direct approach to understand why randomly firing by self-excitation can be a stationary and robust firing mode in a neural network. The underlying experiments are interpreted in the following way: Even if the cortex is not excited by sensory input, the neurons are firing randomly (Poisson process) and excite each other. Obviously, this is to be interpreted as a "ground state" of the cortical network. An interesting question is whether random firing is a stable mode of a network or not. Because 99% of the inputs to the cortex are coming from the same or other cortical areas [\cite=braitenberg], we shall at first neglect the 1% (sensory) input and therefore consider a network with 100% feedback.

Definition of the Abeles model

The defining assumptions to the Abeles Model are [\cite=abeles81]:

Each postsynaptic potential has the shape of a falling exponential (for [formula]:

[formula]

or,

[formula]

This assumption does not only include an idealization of the waveform, it also includes that the values of synaptic strength A and the time constants τ are the same for all neurons.

All postsynaptic potentials sum up in a linear fashion giving the intracellular potential; the neuron generates a spike if the intracellular potential   reaches a threshold T.

All neurons are firing independently. This, however, is eqivalent to: No information is processed.

Each neuron has N synaptic inputs which can be excitatory or inhibitory in any proportion.

The neurons fire at an average rate of λ spikes per second.

The self-consistence equation for the average firing rate

For high rates of inputs, the input spikes add up to nearly random fluctuations of the intracellular potential; the probability density of the intracellular potential   therefore is Gaussian. This means: The firing rate of a cell is proportional to the probability for the intracellular potential   to be above threshold:

[formula]

where K is an unknown constant and σ2 is the variance of the intracellular potential, which can be calculated as follows:

Each postsynaptic potential contributes a variance of

[formula]

Nota bene, excitatory and inhibitory connections here contribute equally.

The independent linear superposition of N  ·  λ spikes (per second) gives the total variance

[formula]

or

[formula]

This means: For random firing at a constant average firing rate we have to satisfy a self-consistence-equation

[formula]

which still has K and T / A as free parameters to be fitted to the experimental data. Abeles' estimation for T / σ is as follows: If the neuron fires at a rate λ and each spike is generated if the membrane potential is approximately 1 (  ≈  0.4τ) above threshold, the probability of the intracellular potential   for being above threshold is approximately λ  ·  1  =  0.005, which is numerically equivalent to T / σ being 2.58. Therefore only one parameter (K) is free, it can be evaluated by solving equation ([\ref=eq:selbstkon]) for K.

The main results of the Abeles Model are quantitative estimations of network parameters from realistic neurophysiological properties. Using N  =  20000,λ  =  5s- 1,τ  =  2.5 K  =  1000- 1, one obtains [\cite=abeles82]:

[formula]: The variance of the intracellular potential   is 11 times bigger than the amplitude of a single spike.

[formula]: Only 29 synchroneous excitatory spikes will lift the membrane potential to threshold. (This is a small value compared with Nλ  =  100000 spikes that every cell receives per second.)

A single spike has no detectable effect on the output rate: The firing rate increases from 5 per second to 6.4 per second, but relaxes back to 5 per second with the time constant τ. This causes only 0.003 extra output spikes.

To conclude, synaptic strength seems weak for detecting a single spike, but fairly strong for detecting coincidence inputs. This is a consequence of the highly nonlinear error function, which determines by ([\ref=eq:abeles1]) the firing rate λ. As analyzed in the appendix, below a critical firing rate λc random firing is unstable, so that a certain level of activity is required to transmit information.

How can we describe processing of information? - Extension of the Abeles model

As one of the fundamental assumptions of the Abeles model is the randomly firing of all neurons, which means that all spikes are completely uncorrelated, it is a priori unable to describe information transfer.

If the number of spikes carrying the information is much less than the number of random spikes [formula] the probability density of the intracellular potential   can be assumed to be approximately Gaussian, so that the mechanism is still the same: The fluctuations converging to each neuron raise the intracellular potential   to threshold. Remarkably this condition does not explicitely restrict the correlated activity of a single neuron, so it can be involved constantly in information processing.

How can we understand simple processing of information in a real network, whose 'ground state' is randomly firing at a rather low rate? The concept given by Abeles is the 'synfire chain': Groups of synchroneously firing neurons are carrying the information; their number must be sufficiently high (at least 10-20) to excite the following neurons.

A possible quantitative description of processing of information within this concept is given by the model described in the remainder of this paper. The basic properties of the extended model [\cite=claussen89] are defined as follows:

All input spikes -same as in the Abeles model- are assumed to share the common waveform of a falling exponential, xi(t) = Aie- (t - t0) / τ(for  t  ≥  0), which may idealize the signal through the axon.

The synaptic strength, which was a constant A in the Abeles model, may be inhibitory (Ai < 0) or excitatory (Ai > 0), and is assumed to have different values for each neuron. In general, we may assume the synaptic weights also to be time-dependent, so that synaptic plasticity can be described. However, this time-dependence takes place on a much larger time-scale than the spike dynamic.

All postsynaptic (episynaptic) potentials are assumed to sum up to the intracellular potential:

[formula]

In addition to the Abeles Model we consider synchroneous and random inputs seperately:

[formula]

As the number of randomly firing inputs is large, the difference in synaptic strength will not disturb the Gaussian distribution, and we can write for the second sum

[formula]

This is the same property as in the Abeles Model, although the firing rate may have a slightly different value.

For the synchroneous inputs, we now only consider one group of firing neurons, so all these inputs have the same t0, so we can assume t0 = 0, and we have, writing xi(t) = Xi  ·  e- t / τ:

[formula]

where the Xi are 'digital' values (0 for no spike, 1 for a spike correlated with the synfire chain). Hence we can interprete the synchroneous inputs converging to the cell as a time-dependent lowering of the potential threshold T:

[formula]

Therefore, the firing rate is given by (all sums in the following text are sums only over the synfire chain inputs):

[formula]

where xi(t) = Xi  ·  e- t / τ. We shall write for the input sum:

[formula]

If we ask: What is the total number of extra spikes, generated by an input X  ≠  0, i.e., Δλ(t): = λX  ≠  0(t)  -  λX  =  0(t)? - We have to integrate the firing rate,

[formula]

but this expression counts all extra spikes from t = 0 to t =   ∞  . However, if the output shows too much time delay, it will not be correlated to the synfire chain any more. As the time constant of the exponential is τ, we only take into account the outputs between t = 0 and t = Δt, where Δt is a time constant which may have a similar or smaller value than τ. So the average number of correlated output spikes 〈Y〉 to a given input X is given by:

[formula]

Here we have not subtracted the accidental output spikes, for their value is finite and rather small in this short time interval. For X  →  ( -   ∞  ) the average output vanishes, which is the limit of strong inhibitory inputs. For X  →  ( +   ∞  ), which is equivalent to strong excitation, we obtain:

[formula]

If we choose our free parameter [formula] the function f(x): = 〈Y(X)〉, as defined by equation ([\ref=eq:transferfn]), is a function of sigmoid type and describes the probability that an output spike is generated. For X = 0 we have the probability of 0.005, which is the probability of accidental output spikes.

We recognize this result as the McCulloch-and-Pitts [\cite=mccullochpitts] Neuron Model, but in a fairly new light: Patterns of synchroneously firing neurons can be transferred and processed in a quasi-digital manner even in a randomly firing network, and the fluctuations are necessary to understand the sigmoidal character of the response function.

Conclusions and Outlook

Within the framework based on the activity model [\cite=abeles82] and the concept of synfire chains, it has been shown how processing of information can be described quantitatively. Considering correlated and uncorrelated neural activity seperately, it is possible to describe information processing by synfire chains through a network of (in ground state) randomly firing neurons in a quantitative manner.

The crudest idealizations concern the waveform of the spikes. The stochastic description of the firing process and the representation of 'one bit' by more than one neuron are essential in the network for error-tolerance and the ability to generalization.

For synchroneously firing groups of neurons the 'quasi-digital' McCulloch-and-Pitts neuron Model is valid; the fluctuations of the other neurons determine the input-output characteristic to be sigmoidal.

The extended model can be generalized in a straightforward manner to describe also inhibitiory synapses and spatio-temporal aspects of real networks by use of (on larger time-scales) time-dependent values Ai(t) of synaptic strength. Acknowledgment: The author gratefully acknowledges partial financial support by Deutsche Forschungsgemeinschaft (DFG) within SFB 654.

Appendix: Stability analysis of the Abeles model

We now investigate whether the fixed point satisfying the self-consistence-equation ([\ref=eq:selbstkon]) is stable or instable. Although we do not know the exact dynamical properties of the network, we can answer this question. A small change in λ will lead to a change in σ, the variance of the intracellular potential, where σ(λ(t),t) is given by ([\ref=eq:abeles2]). The changed variance of the intracellular potential   will cause a change in the firing rate, given by ([\ref=eq:abeles1]). However, this will need a certain delay Δt, so that the stationary equation ([\ref=eq:abeles1]) has to be modified to the iterative expression

[formula]

Therefore we can approximate the real dynamics by the iteration

[formula]

and we obtain the answer to an increase of λ by the amount of Δλ:

[formula]

which means that every iteration stretches Δλ by the factor

[formula]

Since

[formula] and

[formula]

we obtain

[formula]

For sufficiently small Δλ the iteration values λi are close to the start value λ0, so that the Liapunov exponent of the iteration is given by L = |α(λ0)|. Obviously the fixed point, which is assumed to represent a 'ground state' of randomly firing, is a stable one if and only if the Liapunov exponent is negative, which means that |α| < 1. Using the experimental values given by Abeles for the cortex of the cat, T / σ = 2.58, K = 1000s- 1, and λ = 5s- 1, we obtain the Liapunov exponent L =  - 2.02 or α = 0.13, which is much less than 1. In this fixed point the network gives strong damping to both fluctuations and external stimulus. This includes also sufficient stability of the 'Randomly Firing Mode': Neither a fade-out nor a collective 'explosion' of the firing can be generated by small perturbations. To understand the effects of strong perturbations, we will take a short view on the stability function α(T / σ). Using equation ([\ref=eq:alpha1]), we have to remember that λ / K is a function of T / σ, so that we can use the expression (x: = T / σ):

[formula]

Two limiting cases can be considered: For x  →  0, which is the limes of very high firing rates, α(x) is asymptotic to [formula] so that α(x) decreases to zero. This expresses the damping of avalanche effects. For x  →    ∞  , which is the limes of very low firing rates, the integral is asymptotic to [formula] therefore α(x) is asymptotic to x2. As α(x) is continuous, there must exist a critical firing rate λc, where α(λc) = 1. It is the point where the Liapunov exponent changes its sign. If the firing rate is higher than λc, we still have damping, same as in the ground state itself. If the firing rate is lower than the critical value, the cortical feedback amplifies any fluctuations of the firing rate, so that the fluctuations lead to a fade-out of the network. To conclude, if the firing rate is lower than a critical firing rate λc, randomly firing cannot be a stable mode of a neural network.