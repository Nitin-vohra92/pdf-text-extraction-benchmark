Proof. [formula]

On the Optimality of Quantum Encryption Schemes

Introduction

Secure transmission of information is a subject that has been studied extensively. In this model, Alice wants to securely transmit a message to Bob using a secret key that they both share, in such a way that any eavesdropper gets absolutely no information about the message sent. In the classical world, Shannon [\cite=Sha48] [\cite=Sha49] has shown that for the perfect encryption of n classical bits, it is necessary and sufficient to use n bits of classical entropy (one-time pad). By performing a bitwise XOR between the n-bit message and the n-bit secret key, the view of any eavesdropper that has no knowledge of the key is just a uniformly random n-bit string. Ambainis, Mosca, Tapp and de Wolf [\cite=AMTW00] showed that 2n classical bits of entropy are necessary and sufficient for the transmission of n quantum bits.

Let us briefly sketch how one can perfectly encrypt a quantum bit. Let ρ be the state of an arbitrary qubit and let I,X,Y,Z be the four Pauli matrices. Then, by using two bits of classical entropy we can uniformly pick one of the four matrices and apply it to our qubit. The state of the qubit after the encryption is

[formula]

It's easy to verify that for all states ρ, [formula] and hence the view of the eavesdropper is the completely mixed state, i.e. she gets no information about the encrypted state ρ. The scheme easily generalizes to n-qubit states by using 2n classical bits of entropy.

The entropy needed for the perfect encryption of quantum states is two times what is needed for the perfect encryption of classical bits. Interestingly, this is no longer true, when we look at approximate encryption. Let [formula] be the state of a ( log d)-qubit message, [formula] be a set of N unitary operations acting on log d qubits and [formula] be a distribution on

[formula]

The Optimal Pauli Encryption Scheme

The input state to our encryption scheme is a quantum bit which can be described by a density matrix ρ, i.e. a hermitian matrix with unit trace

[formula]

where [formula] is a unit vector, and the four Pauli matrices are

[formula]

Let us denote + 1 eigenvectors of the matrices X,Y and Z by [formula] and [formula].

A Pauli encryption scheme for single qubits is described by a probability distribution on the four Pauli matrices, i.e. by a probability vector D = (w,x,y,z), such that the encryption of a qubit ρ is given by

[formula]

Without loss of generality, we can assume the weights {w,x,y,z} obey w  ≥  z  ≥  x  ≥  y  ≥  0. The reason for this is that these four unitaries are freely interchangeable by picking a suitable [formula]. If the original qubit ρ was encoded by E(ρ), with weights {w,x,y,z}, we can achieve the same encoding E'(ρ') on the transformed qubit ρ', just with {w,x,y,z} permuted.

The classical entropy used by the encryption scheme is the entropy of the probability distribution, i.e. [formula].

To test how good the encryption scheme is, we want to know how much the encrypted state differs from the completely mixed state in the 2- and the operator norm. For any d-dimensional matrix A, the 2- and operator norm are related to the eigenvalues of the matrix, namely

[formula]

Thus, for the operator norm we need to examine the maximum of the absolute value of the eigenvalues of

[formula]

Note, that since the matrix I(ρ) has trace equal to 0, the two eigenvalues are of the form ±  λ and hence, the 2-norm is maximized simultaneously with the operator norm.

The maximum eigenvalue of I(ρ)

After applying the channel ([\ref=encoding]) to the density matrix described by ([\ref=densitymatrix]), we obtain

[formula]

where the new parameters can be easily determined from ([\ref=encoding]) using the anticommutation relations for Pauli matrices.

[formula]

This shows that the parameters rx,ry and rz shrink according to the above relations. The factors can be negative, but because have w  ≥  z  ≥  x  ≥  y and w + z + x + y = 1, with a little work one can verify that the magnitude of the shrinking factor |2(w + z) - 1| in front of rz is the largest of the three.

Using the geometric description ([\ref=densitymatrix]) of ρ, we can express the matrix I(ρ) as

[formula]

Its eigenvalues are then simply

[formula]

Our goal is to find the maximum eigenvalue |λI(ρ)| over all states ρ as a function of the probability distribution D = (w,z,x,y) and then pick the distribution that minimizes it. Already knowing that the shrinking factor in front of rz is the largest, we can maximize [formula] by picking ρ with [formula]. This gives us [formula], and

[formula]

Note that w and z are the two largest weights and therefore we always have [formula].

We thank the referees for pointing out a geometric view of the Pauli encoding in [\cite=NCbook], which simplified the proof in this section.

The optimal trade-off between approximation and entropy

In Section [\ref=subsecMaxeigenvalue], we found an upper bound on the maximum eigenvalue of I(ρ) as a function of the probability distribution used by the Pauli encryption scheme. Note also that equation ([\ref=precision]) shows that for a perfect encryption the only possible scheme is the one that uses a uniform distribution over the four Pauli matrices.

The natural question is to find the optimal Pauli encryption scheme when we can only use a fixed amount H of classical entropy. Turning the question around, we fix the approximation parameter ε and calculate the necessary entropy to achieve it.

Let us fix ε = maxρ|λ| = w + z - 1 / 2. In addition, the condition w  ≥  z implies that 1 / 4 + ε / 2  ≥  z. Our goal is to minimize the classical entropy needed to achieve approximation ε:

[formula]

Keeping x, y and ε fixed, the entropy as a function of z is concave, with a maximum at z = w. Because z  ≤  w, the entropy decreases with decreasing z. Specifically, if z > x + y, one can decrease the entropy by setting z = x + y (and increasing w accordingly, to keep ε fixed). Without loss of generality, one can then assume that z  ≤  x + y for the optimal D. Now, let us minimize the entropy as a function of x. It is concave in x, with a maximum at x = y = (1 - w - z) / 2 and possible minima at the endpoints. Because x  ≥  y, we want to pick x as large as possible. Because x  ≤  z and z  ≤  x + y, this results in x = z. The weights that minimize the entropy for a fixed ε thus are (as a function of z)

[formula]

To find the optimal H(ε), one thus needs to minimize

[formula]

with respect to z, remembering the constraints collected so far (w  ≥  z  ≥  x  ≥  y  ≥  0, x + y  ≥  z):

[formula]

We perform this minimization in Appendix A.1 and conclude that for ε  ≤  1 / 6, picking the three larger weights to be equal is the entropy-minimizing strategy. For 1 / 6  ≤  ε  ≤  ε0, picking only three unitaries, with two of the lower weights equal is the best choice. For ε0  ≤  ε  ≤  1 / 2, it is optimal to pick the three smaller weights to be equal.

Turning the argument around - given entropy H, what is the optimal Pauli encryption scheme? There is a unique way to pick the probability distribution with the given entropy that minimizes the parameter ε.

[formula]

Note that the weights are in descending order and that the approximation ε is given by the sum of the largest two weights minus [formula]. Also, one should not expect the optimal distribution parameters to be continuous at H0. These two ways of picking the weights come from different regions in the parameter space {w,z,x,y}, and the choice of the optimal distribution is simply a numerical minimum of these two functions. The point H0 (or equivalently ε0) does not have an obvious special meaning.

The optimality of Pauli Encryption Schemes

In this section we give an elementary constructive proof that the Pauli encryption schemes are no worse than any general encryption scheme. For any encryption scheme [formula] with arbitrary unitaries and weights, we give a Pauli encryption scheme with weights {w,z,x,y} that has lower entropy, and is no worse than E(ρ). We show this by finding a density matrix ρ0, for which the maximum eigenvalue of I(ρ0) is the same as in ([\ref=precision]), which is the worst case for the newly found Pauli scheme. Hence, the Pauli encryption scheme of section [\ref=sectionPauli] is optimal amongst all possible encryption schemes.

After completion of this work, we learned of an alternative proof of optimality of Pauli encryption for a single qubit by Bouda and Ziman [\cite=BoudaZiman]. They investigated perfect encryption of a subspace of the Bloch sphere, while we are interested in approximate encryption of the whole Bloch sphere. Their proof uses the Kraus representation of the quantum channel, showing that the representation of a channel using orthogonal matrices requires the least amount of entropy. We also thank the anonymous referee for providing us with another shorter proof. Using the fact that every channel can be expressed also as a Pauli channel ([\cite=Ruskai]), we can utilize a clever trick by Nielsen ([\cite=Nielsen1]) to prove that the weights of this Pauli channel majorize the weights of the original channel. Knowing that the entropy is concave, we can conclude that the Pauli realization of the channel requires the least amount of entropy. The details of this proof are given in Appendix A.2. Let us now continue with our proof.

Let T be an encryption scheme with distribution [formula] over N unitaries Uk, where the weights are in decreasing order. We parametrize the unitaries as [formula], where [formula] and [formula]. The phases αk are not important in our analysis and hence, we denote the parametrization of Uk only as [formula].

We have the following three cases:

Case 1: w1 + w2 - 1 / 2  ≤  0

We show that the entropy H of the encryption scheme T is greater or equal to 2, and for H = 2, we already know a perfect encoding with four unitaries and wk = 1 / 4. It is clear, that if w1  <  1 / 4 then the entropy is larger than 2. Let us assume that w1  ≥  1 / 4. From the concavity of the Shannon entropy, we know that the entropy of a distribution that contains two weights (wk,wl) with wk  ≥  wl decreases if we change them into (wk  +  Δ,wl  -  Δ).

Hence we can decrease the entropy of the initial distribution [formula] by increasing the weight w2 to make it equal to w2'  =  1 / 2 - w1 and decreasing some of the smaller weights. We can further decrease the entropy by making the middle weights all equal, i.e [formula]. Picking w1  =  x fully determines the distribution, giving w2'  =  1 / 2 - x and wN  =  (4 - N) / 2 + (N - 3)x. The constraints 1 / 2  ≥  w1  ≥  w2  ≥  wN  ≥  0 give us:

[formula]

The entropy as a function of x is concave (the second derivative is negative) and therefore, we look for the minimum entropy at the endpoints, given in ([\ref=xconstraint]). These endpoints correspond to choosing the distribution as [formula] with w2 = (1 - w1) / (N - 1). The entropy of such distributions as a function of N is

[formula]

It's easy to see that this function is a monotone, growing function of N with a minimum for H(4) = 2. We conclude that any encryption scheme with n  ≥  5 unitaries and w1 + w2 - 1 / 2 < 0 uses entropy H  ≥  2 and hence is worse than the perfect encryption scheme with four unitaries.

Case 2: w1 + w2 - 1 / 2  ≥  0 and [formula].

We show that there exists a Pauli encryption scheme that is no worse than T and uses less entropy. Let P be the Pauli scheme that uses the distribution {w1,w2,w2,w'3}. This is possible by the constraint [formula] and from the concavity of the entropy, P uses less entropy. We also know from equation ([\ref=precision]) that for the encryption scheme P

[formula]

Without loss of generality, when encoding an input density matrix ρ with the set of unitaries

[formula]

one can equivalently analyze the encoding of the density matrix [formula] with a related set of unitaries:

[formula]

The approximation parameter ε of the encoding scheme is basis independent, it is now convenient to pick a basis in which the unitaries are of the form

[formula]

where x2k + y2k + z2k = 1, and Zα2 denotes a rotation about the z-axis, namely [formula].

Let us now check how well the [formula] state is encoded.

[formula]

Note that since ρ is an eigenstate of Z, it commutes with Zα2. After some algebraic manipulations we have:

[formula]

where

[formula]

The eigenvalues of I(ρ) are now

[formula]

We know that w1 + w2  -  1 / 2  ≥  0 and Ak  ≥  0. Thus we can bound the eigenvalues as

[formula]

with w1 and w2 the two largest weights. The equality is achieved if we pick our unitaries with zk = 0 and cos αk = 0, which imply Ak = Bk = 0.

This is the same result as in equation ([\ref=precision]) and hence no matter how we pick the unitaries, the encryption cannot be better than in the Pauli Encryption scheme.

Case 3: w1 + w2 - 1 / 2  ≥  0 and [formula].

Since w1 + w2  ≥  1 / 2, we conclude that [formula] and so, it's possible to consider the Pauli scheme P that uses the distribution [formula]. Moreover, the constraint [formula] implies that [formula] and hence from the concavity of the entropy, P uses less entropy than T. From equation [\ref=precision], we know that for the encryption scheme P

[formula]

In what follows, we calculate how well the states [formula] and [formula] are encrypted by T and prove that at least one of them is encoded worse than in the Pauli scheme P.

We pick the unitaries of T to be

[formula]

Similarly to Case 2, the [formula] state is encoded no better than with

[formula]

where we named zk  =   cos βk, xk  =   sin βk cos γk and yk  =   sin βk sin γk Let us now check how well the [formula] state is encoded.

[formula]

where Dk  =  ( - 1 + 2 cos 2αk + 2 sin 2αk sin 2βk cos 2γk) and Ck,Ek are functions of αk,βk,γk which do not affect the bounds. The encoding of ρx becomes

[formula]

where [formula] and [formula]. We are ready to bound the eigenvalue:

[formula]

Using the same type of computation as above, we encode the [formula] state and obtain a bound for the eigenvalues of [formula]:

[formula]

Summing the three inequalities of the eigenvalues, we obtain that

[formula]

which implies that at least one of the three λ is greater or equal to ([\ref=Pcase3]). This means the Pauli encryption scheme P is no worse than T, while using less entropy.

This concludes the proof that Pauli Encryption schemes are no worse than general encryption schemes. This also concludes the proof of Theorem 1.

N-qubit independent encryption schemes

In this section we consider n-qubit encryption schemes which are composed of independent single-qubit schemes, each using H amount of classical entropy. By independent we mean that the encryption has the form [formula].

Let P be the single-qubit Pauli encryption scheme, which achieves the optimal approximation ε for the given entropy H. Then, the optimal n-qubit independent encryption scheme R(ρ) is the same for both the 2- and the ∞  -norm and has the following properties:

[formula].

[formula]

[formula]

We first employ a result by King [\cite=King] to show that product states are the worst encoded states for independent encryption schemes. King proved that the p-norm of a product of unital channels is multiplicative, i.e. for p  ≥  1,

[formula]

This shows that the norm [formula] is maximized by a product state [formula], where ξi is the state of the i-th qubit. In our encryption schemes we measure the quality of the approximation by the maximum of the norm [formula], for p = 2 and p =   ∞  . Let λk be the eigenvalues of R(ρ); then, the eigenvalues of [formula] are (λk - 1 / 2n) and we have

[formula]

It is clear, that the norm of [formula] is maximized when the norm of R(ρ) is maximized and therefore, for any independent encryption scheme the worst encoded state is a product state.

Hence, in order to find the optimal independent encryption scheme, one needs to find the scheme that encrypts product states optimally. The encryption of a product state [formula] is also a product state and the eigenvalues of [formula] are simply products of the eigenvalues of Rk(ξk). Without loss of generality, let us now encrypt a state [formula] using [formula]. The eigenvalues of the single-qubit encryption R1(ξ1) can be expressed as μ1,2 = (1  ±  ε1) / 2 and the eigenvalues of [formula] as [formula]. Hence, the eigenvalues and 2-norm of [formula] are

[formula]

The last expression is a growing function of ε1 and therefore, the optimal n-qubit encryption scheme has to be optimal (i.e. Pauli) on the first qubit, giving the smallest possible upper bound on ε1. After going through this procedure for all qubits, we see that the optimal encryption scheme for product states in the 2-norm is the Pauli scheme [formula]. It is straightforward to obtain the same statement for the ∞  -norm using [\eqref=producteigs]. This concludes the proof that the optimal n-qubit independent encryption scheme for both the 2- and the operator norm is the Pauli scheme [formula].

We now prove tight upper bounds for the quality of the approximation of the Pauli encryption scheme. For the 2-norm, equation [\eqref=kingresult] and induction imply

[formula]

Let us pick ξ to be the worst encoded single-qubit state for P. The eigenvalues of P(ξ) are (1  ±  ε) / 2 and therefore:

[formula]

From equation [\eqref=tworelation], we bound the 2-norm of [formula] as

[formula]

For the ∞  -norm, multiplicativity of norms [\eqref=kingresult] implies

[formula]

and therefore equation [\eqref=iiirelation] gives us

[formula]

Note that both bounds are tight and achieved for product states.

Since the bounds in Theorem 2 are tight, any good independent encryption scheme requires that the approximation parameter for each single qubit is [formula] for the 2-norm and [formula] for the ∞  -norm. Hence, from equation [\eqref=Htwo] we conclude that the amount of entropy needed for the encryption of n-qubit states is 2n - o(n).

General N-qubit Encryption Schemes

In the previous section, we found the optimal way to independently compose single-qubit encryption schemes in order to encrypt n-qubit states. However, one can do better with encryption schemes that do not act independently on each qubit. For example, the encryption scheme in [\cite=HLSW04] uniformly picks an n-qubit unitary from a set of O(n2n) random ones and hence it is not an independent encoding. Note also that it only uses n +  log n + O(1) bits of entropy.

Ambainis and Smith ([\cite=AS04]) managed to derandomize the encryption scheme of [\cite=HLSW04] by explicitly describing the set of unitaries. In particular, they use a set of 2n-bit strings, where each string corresponds to a product of n Pauli matrices (the bits {2j - 1,2j} define the Pauli matrix for the j-th qubit). They prove that if the set of strings is a small-bias set of size O(n2n), then picking a random unitary from this set gives an [formula] encryption scheme in the 2-norm.

A δ-biased set is a set of k-bit strings such that for all possible subsets of bits, the probability over the set that the parity of the subset is 0, is

[formula]

Acknowledgements

We would like to thank Eddie Farhi and Debbie Leung for stimulating discussions, and the journal referees for pointing out references [\cite=Nielsen1] and [\cite=Ruskai] and for the simplified proofs in Section II.1 and Appendix A.2. IK acknowledges professor Peter w. Shor who has supported his research from his appointment as the holder of the H. A. Morss and H. A. Morss, Jr. Professorship and from NSF CCF-0431787. DN gratefully acknowledges support from the National Security Agency (NSA) and Advanced Research and Development Activity (ARDA) under Army Research Office (ARO) contract W911NF-04-1-0216.

Appendix

Minimization of the entropy H(ε,z)

Here, we provide the details for the minimization of the function H(ε,z) with respect to z that concludes the proof of the optimal trade-off between approximation and entropy. Recall that

[formula]

and the constraints are

[formula]

The entropy as a function of z is again a concave function and hence, in order to find the minimum we investigate the endpoints of the allowed interval for z. There are two cases: Case 1: for ε  ≤  1 / 6, the constraint ([\ref=zconstraint1]) is tighter. The left endpoint is [formula], giving

[formula]

The right endpoint is [formula], giving

[formula]

At ε = 0, H1 = H2 = 2. At ε = 1 / 6, H1  ≤  H2. The derivative of H2 - H1 is always negative,

[formula]

so we conclude that H1 is the best choice for ε  ≤  1 / 6. At ε = 1 / 6, H1 achieves the value of log 23, which means only three equally weighed unitaries are used.

Case 2: for ε  ≥  1 / 6, the constraint ([\ref=zconstraint2]) is tighter, changing the left endpoint of z to z = 1 / 2 - ε. This sets y = 0, which is the regime of using only three unitaries, i.e. the distribution is [formula] and the entropy

[formula]

The second derivative of H3 - H2 is always negative,

[formula]

so the function H3  -  H2 is concave. That allows for only two points where H3 = H2. One of them is at ε = 1 / 2, the other is found numerically to be ε0  ≈  0.287 with H0  ≈  1.41. We conclude that for 1 / 6  ≤  ε  ≤  ε0, the choice of H3 is optimal, whereas for ε0  ≤  ε  ≤  1 / 2, the best choice is H2.

Another proof of optimality of Pauli Encryption Schemes

It is known [\cite=Ruskai] that every unital channel E with weights {wk} and unitaries Uk is equivalent to a Pauli channel with some other weights {xm}, that is

[formula]

This channel is an ε-randomizing map. We will prove that the Pauli realization of it has smaller entropy.

Suppose we act with this channel on one half of the Bell state [formula]. The first definition of E will give us

[formula]

where [formula] are pure states. On the other hand, the second realization of E (with Pauli operations) acting on one half of the state |  ψ+〉 will transform it into a state with density matrix diagonal in the Bell basis, ρ'  =  (x1,x2,x3,x4).

In [\cite=Nielsen1], Nielsen showed that when a density matrix can be expressed as [formula], where [formula] are normalized states, the (ordered) vector of probabilities wk is majorized by the vector of eigenvalues of ρ', that is [formula].

In our case, the vector of eigenvalues of ρ' is (xm), and the majorization [formula] means [formula] for any n  ≥  1. Note that if the length of (wk) is greater than four, we pad the vector (xm) by zero entries to make the lengths of the vectors equal.

The entropy function is concave. Because the vector of weights for the Pauli realization (xk) majorizes the vector of weights for the original realization (wk), the Pauli realization of the channel has smaller entropy, S({xk})  ≤  S({wk}). This means the Pauli channel is the optimal (entropy-wise) realization of any unital channel.