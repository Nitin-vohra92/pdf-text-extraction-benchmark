=4

Testing Order Constraints: Qualitative Differences Between Bayes Factors and Normalized Maximum Likelihood

Model Selection with Bayes Factors and Normalized Maximum Likelihood

Although all model selection methods address the inevitable trade-off between goodness-of-fit and complexity, the manner in which they measure and penalize model complexity can differ substantially. In popular information criteria such as AIC or BIC, model complexity is measured solely by the number of free parameters. Alternative approaches reflect a more subtle view on model complexity and consider -explicitly or implicitly- not only the dimensionality of a model, but also order constraints on parameters and their functional form. Here we compare two model comparison methods that are based on very different statistical philosophies: Bayes factors for belief revision and normalized maximum likelihood for data compression.

The first method under consideration, the Bayes factor, is defined as the ratio of two marginal likelihoods [\citep=Kass1995]:

[formula]

where the marginalization occurs over the prior distribution, [formula]. Complex models make many predictions; by averaging the adequacy of these predictions for the observed data over the prior, the Bayes factor automatically and implicitly penalizes for model complexity. An order constraint results in a larger marginal probability if it reduces the parameter space to areas of high likelihood. From the perspective of belief revision, Bayes factors measure the extent to which the data mandate a change from prior to posterior model odds. As such, Bayes factors represent "the standard Bayesian solution to the hypothesis testing and model selection problems" [\citep=LewisRaftery1997].

The second method under consideration, normalized maximum likelihood, is an instantiation of the minimum description length (MDL) principle [\citep=Rissanen1978] [\citep=Grunwald2007]. According to MDL, a statistical model may be interpreted as a method to compress data. If a model captures structural patterns in a data set, it can be used for compressing that data set, resulting in a shorter code length. However, the model itself also has to be encoded, thereby inducing a premium on parsimony. The solution to the problem of finding the optimal encoding is to select the model with the largest normalized maximum likelihood [\citep=Rissanen2001],

[formula]

where y,i is the maximum likelihood (ML) estimator for data y and model Mi. The normalizing integral in ([\ref=nml]) ranges over the entire sample space X; hence, NML measures complexity explicitly, by integrating over the sample space, and models are punished to the extent that they are able to provide a good fit to a wide range of possible observations. Adding order constraints to a model reduces the fit in some areas of the data space and thereby results in a smaller penalty term.

Often, the normalizing integral in ([\ref=nml]) is not defined. As a solution, the more general luckiness NML [\citep=Grunwald2007] was developed, in which the likelihood function p(y|θ) in ([\ref=nml]) is replaced by the weighted likelihood

[formula]

where a(θ) is a continuous luckiness function. This function specifies subspaces of the parameter space where model selection by means of LNML will be more efficient (i.e., one might 'get lucky' in compressing the data). Note that LNML reduces to the standard NML if a constant, nonzero luckiness function a(θ) = c is used.

Model selection by NML is asymptotically indistinguishable from model selection by Bayes factors with Jeffreys' prior [\citep=Rissanen1996]. Moreover, with the introduction of LNML, it is possible to define luckiness functions for LNML that match the priors of Bayes factors and will yield identical asymptotic results [\citep=Grunwald2007]. For some statistical models such as one-dimensional Gamma or Gaussian models, multiple regression, and Gaussian process models, the two methods yield identical results for all sample sizes [\citep=Bartlett2013] [\citep=Kakade2006].

However, the philosophy that underlies the two approaches is markedly different. Whereas MDL aims at data compression, the Bayes factor is concerned with belief revision. Moreover, in LNML, the complexity of a model is defined as an explicit value (as an integral over the sample space), independent of the data set under consideration. In contrast, Bayes factors consider complexity implicitly by integrating the adequacy of a model's predictions for the observed data across the parameter space, weighted by the prior.

Here, we show how these general differences between Bayes factors and NML are reflected in two specific qualitative differences when testing order constraints. Insights about the way how both methods account for order constraints are important because many information criteria cannot be used for this kind of problem. Specifically, we provide an existence proof by considering a simple test for an order constraint on a binomial rate parameter.

Example: Evaluating an Order Constraint for a Binomial Rate Parameter

Under the full model M1, N binary observations are assumed to be binomially distributed with rate parameter θ, that is, [formula]. The competing model M0 has the additional order constraint θ  ≤  z for a fixed value z∈(0,1). Note that both models feature a single free parameter, necessitating the use of a model comparison approach that measures complexity by more than just the number of free parameters.

Bayes Factor

We assign θ a uniform prior under both models M0 and M1. Because the priors for θ under both models are proportional for θ  ≤  z, the Bayes factor in favor of the constraint can be computed as the ratio of posterior to prior mass of the full model M1 over the range θ∈[0,z] [\citep=Klugkist2007]:

[formula]

where Be(a,b) denotes the beta function. With equal prior odds, the posterior model probability in favor of the constrained model is

[formula]

Luckiness Normalized Maximum Likelihood

According to [\citet=Grunwald2007], LNML with the luckiness function a(θ) is asymptotically identical to the Bayes factor with prior p(θ|M) if

[formula]

where I(θ) is the Fisher information. For the two binomial models under scrutiny, I(θ)  =  θ- 1(1 - θ)- 1 and hence the luckiness function

[formula]

matches the uniform prior in ([\ref=bf4]) for both models.

For our simple scenario, the discrete sample space X can easily be enumerated to compute the LNML normalizing integral

[formula]

Specifically, the LNML normalizing integral equals the sum of the weighted likelihood values for all possible data sets in X. The estimator Ly,1 of the full model maximizes the luckiness-weighted likelihood pL(y|θ),

[formula]

and is identical to that of the constrained model if Ly,1  ≤  z. Otherwise, the order constraint is violated and Ly,0 = z.

As a measure of the degree to which LNML prefers a model over its competitors, the probability of model i being the best model at hand can be computed using LNML model weights,

[formula]

The model weights [formula] are conditional on the data and are analogous to posterior model probabilities. Therefore, they provide a way to directly compare model preference between Bayes factors and LNML. Note that the two qualitative differences emerge for both LNML and standard NML.

Results: Qualitative Differences Between Bayes Factors and LNML

Data Dependence

If the estimator of the full model M1 satisfies the order constraint of M0 (i.e., Ly,1  ≤  z), the numerator pL(y|Ly,i) of LNML in ([\ref=nml]) is identical for both models. In this situation, LNML model selection no longer depends on the observed data y, since

[formula]

Note that this result holds for testing order constraints in general and is not restricted to the binomial model. Figure [\ref=Ftheta] shows how the model weight [formula] changes depending on the observed data. The data independence of LNML results in a constant model weight whenever Ly,1  ≤  z. In contrast, model selection by the Bayes factor is always sensitive to the observed data, including data with Ly,1  ≤  z. In such cases, the more the constraint is satisfied, the larger the Bayes factor in favor of the restriction becomes.

The data dependence of the Bayes factor results in different convergence rates to the maximum possible weight in favor of the order constraint. For the Bayes factor, it follows from ([\ref=bf.calc]) that under uniform priors on θ,

[formula]

and thus, that B01  <  1 / z. Accordingly, the maximum posterior probability in favor of the order constraint is [formula]. Given that the constraint holds, the Bayes factor will converge to this model weight. However, Figure [\ref=Fn] shows that the speed of convergence to this maximum depends on the exact data. For instance, if y,1 = .9z, larger samples are required to obtain evidence in favor of the order constraint compared to less ambiguous data with y,1 = .6z. Because of the matching luckiness function a(θ) in ([\ref=luckiness]), LNML converges to the same maximum model weight. However, if the order constraint is satisfied, the speed of convergence does not depend on the exact data. For unambiguous data, LNML might therefore require larger samples to support the order constraint than the Bayes factor.

In sum, whenever the estimator for the constrained model equals that of the full model (i.e., the order constraint is satisfied), LNML no longer depends on the observed data. In contrast, the Bayes factor remains sensitive to the observed data.

Model Preference

Figure [\ref=FthetaN] shows data for which the Bayes factor and LNML prefer a different model. In these cases, LNML selects the constrained model, whereas the Bayes factor based on uniform priors prefers the full model. For a boundary of z  =  0.8, for instance, the Bayes factor sometimes prefers the full model even though the ML estimator satisfies the order constraint. This occurs when the posterior for θ under M1 has less mass over the range θ  ≤  .8 than the prior for θ under M1 (cf. Eq. [\ref=bf4]). Figure [\ref=FratioBF] illustrates this counterintuitive result.

The proportion of possible data sets with diverging results increases with z. For example, with N = 20 and z = 0.2, only 5% of possible data sets lead to diverging model preferences, increasing to 10% for z = 0.5 and 15% for z = 0.8. However, for larger sample sizes, the differences in model preference between Bayes factors and LNML decrease; for example, when N = 1000, the proportions of critical data sets fall to 1.2%, 1.8%, and 1.9%, respectively. Note that in all of these critical cases, the model weights of both methods only show weak preferences for or against the order constraint (i.e., all wL0 < 0.77 and all wB0 > 0.16). Therefore, this qualitative difference might only have minor consequences for model selection in practice.

In sum, for most data sets both LNML and the Bayes factor will prefer the same model even in small samples. However, for ambiguous data where the ML estimator is near the order constraint, LNML and the Bayes factor may prefer different models.

Discussion

We identified two qualitative differences between Bayes factors and LNML in testing order constraints, which also apply to standard NML as a special case. First, if the order constraint is satisfied, LNML is independent of the observed data, whereas the Bayes factor remains dependent on the observed data. This implies that the speed of evidence accumulation in favor of an order constraint is constant for LNML, but depends on how well the constraint is satisfied for the Bayes factor. Second, in some cases, the Bayes factor may favor the full model while LNML prefers the constrained model. Whereas the data independence of LNML holds for tests of order constraints in general (cf. Eq. [\ref=independence]), differences in model preference might depend on the exact model. However, we expect that preferences are more likely to differ close to the boundary and decrease for larger samples, similarly as for the binomial model.

One common advantage of Bayes factors and NML concerns their ability to take order constraints into consideration, contrary to model selection tools such as AIC or BIC. Although several authors have stressed the similarities between Bayes factors and NML [\citep=Grunwald2007] [\citep=Bartlett2013] [\citep=Kakade2006], a detailed study of order-constrained inference shows that what is good for belief revision (Bayes) is not necessarily good for data compression (NML).