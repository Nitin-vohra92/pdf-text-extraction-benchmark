Leonard pairs and the Askey-Wilson relations

Corollary Lemma Proposition Definition Remark Example

There exists a basis for V with respect to which the matrix representing A is irreducible tridiagonal and the matrix representing A* is diagonal.

There exists a basis for V with respect to which the matrix representing A* is irreducible tridiagonal and the matrix representing A is diagonal.

Introduction

We begin by recalling the notion of a Leonard pair [\cite=TD00] [\cite=shape] [\cite=LS99] [\cite=qSerre] [\cite=LS24] [\cite=conform] [\cite=lsint] [\cite=Terint] [\cite=TLT:split] [\cite=TLT:array] [\cite=qrac]. We will use the following terms. Let X denote a square matrix. Then X is called tridiagonal whenever each nonzero entry lies on either the diagonal, the subdiagonal, or the superdiagonal. Assume X is tridiagonal. Then X is called irreducible whenever each entry on the subdiagonal is nonzero and each entry on the superdiagonal is nonzero.

We now define a Leonard pair. For the rest of this paper [formula] denotes a field.

[\cite=LS99] Let V denote a vector space over [formula] with finite positive dimension. By a Leonard pair on V we mean an ordered pair (A,A*), where A:V  →  V and A*:V  →  V are linear transformations which satisfy the following two properties:

There exists a basis for V with respect to which the matrix representing A is irreducible tridiagonal and the matrix representing A* is diagonal.

There exists a basis for V with respect to which the matrix representing A* is irreducible tridiagonal and the matrix representing A is diagonal.

According to a common notational convention, A* denotes the conjugate transpose of A. We are not using this convention. In a Leonard pair (A,A*) the linear transformations A and A* are arbitrary subject to the conditions (i) and (ii) above.

Leonard pairs occur in combinatorics [\cite=Cau] [\cite=CurNom] [\cite=TD00] [\cite=TersubI] [\cite=lsint], representation theory [\cite=GYZnature] [\cite=Zhed] [\cite=GYZlinear] [\cite=Koelink3] [\cite=cite37] [\cite=cite38] [\cite=cite39] [\cite=cite40] [\cite=Rosengren] [\cite=lsint], and the theory of orthogonal polynomials [\cite=BanIto] [\cite=Leon] [\cite=lsint] [\cite=TLT:array] [\cite=qrac]. The connection to polynomials is as follows: there is a natural correspondence between Leonard pairs and a class of orthogonal polynomials consisting of the q-Racah polynomials [\cite=AWil] [\cite=GR] and some related polynomials of the Askey-scheme [\cite=KoeSwa] [\cite=TLT:array] [\cite=qrac]. This correspondence is illustrated in the following example.

Let d denote a nonegative integer and define a set [formula]. Let V denote the vector space over the complex field [formula] consisting of all functions from Ω to [formula]. The cardinality of Ω is d + 1 so dim V = d + 1. Consider the Krawtchouk polynomials [\cite=KoeSwa]:

[formula]

We view [formula] as elements of V. The Krawchouk polynomials satisfy the following three-term recurrence. For 0  ≤  n  ≤  d and for x∈Ω,

[formula]

where y- 1(x) = 0 and yd + 1(x) = 0. The Krawtchouk polynomials satisfy the following difference equation. For 0  ≤  n  ≤  d and for x∈Ω,

[formula]

where yn( - 1) = 0 and yn(d + 1) = 0. We now define linear transformations A:V  →  V and A*:V  →  V. We begin with A. For f∈V, Af is the element of V which satisfies

[formula]

We now define A*. For f∈V, A*f is the element in V which satisfies

[formula]

for x∈Ω. We mentioned the polynomials [formula] are elements of V. These elements form a basis of V since they are linearly independent. According to ([\ref=krawrec]), the matrix representing A in this basis is irreducible tridiagonal:

[formula]

According to ([\ref=krawdif]), the matrix representing A* in this basis is [formula]. For 0  ≤  n  ≤  d let y*n denote the element of V which satisfies

[formula]

where δnx is the Kronecker delta. The sequence [formula] forms a basis of V. With respect to this basis the matrix representing A is [formula] and the matrix representing A* is irreducible tridiagonal:

[formula]

Therefore (A,A*) is a Leonard pair on V.

In order to motivate our main result we cite a theorem of Terwilliger.

[\cite=LS99] Let V denote a vector space over [formula] with finite positive dimension. Let (A,A*) denote a Leonard pair on V. Then there exists a sequence of scalars β,γ,γ*,ϱ,ϱ* taken from [formula] such that both

[formula]

Here

[formula]

The equations ([\ref=askwilb1]), ([\ref=askwilb2]) are called the tridiagonal relations [\cite=TersubIII]. See [\cite=TD00] [\cite=TersubI] [\cite=TersubII] [\cite=LS99] [\cite=qSerre] for more information on these relations.

The main result of this paper is the following extension of Theorem [\ref=tdptheorem].

Let V denote a vector space over [formula] with finite positive dimension. Let (A,A*) denote a Leonard pair on V. Then there exists a sequence of scalars β,γ,γ*,ϱ,ϱ*, ω,η,η* taken from [formula] such that both

[formula]

The sequence is uniquely determined by the pair (A,A*) provided the dimension of V is at least 4.

As far as we know, the relations ([\ref=askwil1]), ([\ref=askwil2]) first appeared in [\cite=Zhidd]. In that article it is shown that the Askey-Wilson polynomials give a pair of infinite matrices which satisfy ([\ref=askwil1]), ([\ref=askwil2]). See [\cite=GYZnature] [\cite=Zhed] [\cite=GYZlinear] [\cite=ZheCart] for related work. In these articles the relations ([\ref=askwil1]), ([\ref=askwil2]) are called the Askey-Wilson relations and we shall also use this term. One of the relations ([\ref=askwil1]), ([\ref=askwil2]) shows up in work of Grünbaum and Haine on the "bispectral problem" [\cite=GH1] where it is called a q-analog of the string equation. See [\cite=GH4] [\cite=GH5] [\cite=GH7] [\cite=GH6] [\cite=GH3] [\cite=GH2] for related work.

The plan for the rest of this paper is as follows. We will first give a proof of Theorem [\ref=tdptheorem] which is considerably shorter than the one in [\cite=LS99]. We will then display some formulae which can be used to compute the scalars from Theorem [\ref=tdptheorem]. After this we will use Theorem [\ref=tdptheorem] to obtain Theorem [\ref=lptheorem]. We will then display some formulae which can be used to compute the scalars from Theorem [\ref=lptheorem]. Finally we will illustrate Theorem [\ref=lptheorem] using Example [\ref=krawtchouk].

Preliminaries

In this section we review some notation and basic concepts. Let d denote a nonnegative integer. Let V denote a vector space over [formula] with dimension d + 1. We let (V) denote the [formula]-algebra consisting of all linear transformations from V to V. For A∈(V), by an eigenvalue of A we mean a root of the characteristic polynomial of A. The eigenvalues of A are contained in the algebraic closure of [formula]. We say that A is multiplicity-free whenever it has d + 1 distinct eigenvalues, all of which lie in [formula]. Assume A is multiplicity-free. Let [formula] denote an ordering of the eigenvalues of A, and for 0  ≤  i  ≤  d put

[formula]

where I denotes the identity in (V). By elementary algebra,

[formula]

Let D denote the [formula]-subalgebra of (V) generated by A. Using ([\ref=acomei])-([\ref=sumei]) we find [formula] form a basis for the [formula]-vector space D. We refer to Ei as the primitive idempotent of A associated with θi. We have

[formula]

For 0  ≤  i  ≤  d, EiV is the (one-dimensional) eigenspace of A associated with the eigenvalue θi, and Ei acts on V as the projection onto this eigenspace. We remark that {Ai|0  ≤  i  ≤  d} is a basis for the [formula]-vector space D, and that [formula].

Later in this paper we will encounter sequences of scalars which satisfy a certain recurrence. We take a moment to discuss this recurrence. Let d denote a nonnegative integer and let [formula] denote a sequence of scalars taken from [formula]. Given β∈, we say the sequence [formula] is β-recurrent whenever

[formula]

for 2  ≤  i  ≤  d - 1. Given scalars β,γ in [formula], we say the sequence [formula] is (β,γ)-recurrent whenever

[formula]

for 1  ≤  i  ≤  d - 1. Observe that for β∈ the following are equivalent: (i) the sequence [formula] is β-recurrent; (ii) there exists γ∈ such that [formula] is (β,γ)-recurrent. We also have the following.

Let d denote a nonnegative integer and let [formula] denote a sequence of scalars taken from [formula]. Let β,γ denote scalars in [formula]. Then the following (i), (ii) hold.

Assume [formula] is (β,γ)-recurrent. Then there exists ϱ∈ such that

[formula]

Assume there exists ϱ∈ such that ([\ref=eq:3form]) holds. Further assume [formula] for 1  ≤  i  ≤  d - 1. Then the sequence [formula] is (β,γ)-recurrent.

Proof. Let pi denote the left-hand side of ([\ref=eq:3form]) and observe

[formula]

for 1  ≤  i  ≤  d - 1. Our assertions (i), (ii) are routine consequences of this.

General setting

In this section we establish some basic results concerning Leonard pairs. We begin with a comment.

[\cite=LS99] Let V denote a vector space over [formula] with finite positive dimension. Let (A,A*) denote a Leonard pair on V. Then each of A, A* is multiplicity-free.

Proof. Set d + 1 =  dim V. Recall that there exists a basis for V with respect to which the matrix representing A is diagonal. Hence the eigenvalues of A are in [formula]. Moreover the degree of the minimal polynomial of A is equal to the number of distinct eigenvalues of A. Recall there exists a basis for V with respect to which the matrix representing A is irreducible tridiagonal. From the shape of this matrix we find that [formula] are linearly independent. Therefore the degree of the minimal polynomial of A is equal to d + 1. It follows that the eigenvalues for A are mutually distinct. We have now shown that A is multiplicity-free. Applying this argument to the Leonard pair (A*,A) we find that A* is multiplicity-free.

For the rest of this paper we adopt the following notational convention.

Let d denote a nonnegative integer and let V denote a vector space over [formula] with dimension d + 1. Let (A,A*) denote a Leonard pair on V. Let [formula] denote a basis for V which satisfies condition (ii) of Definition [\ref=deflp]. For 0  ≤  i  ≤  d the vector vi is an eigenvector of A; let θi (resp. Ei) denote the corresponding eigenvalue (resp. primitive idempotent). Let [formula] denote a basis for V which satisfies condition (i) of Definition [\ref=deflp]. For 0  ≤  i  ≤  d the vector v*i is an eigenvector of A*; let θ*i (resp. E*i) denote the corresponding eigenvalue (resp. primitive idempotent). Let the sequence [formula] denote the diagonal of the matrix which represents A with respect to [formula]. Let the sequence [formula] denote the diagonal of the matrix which represents A* with respect to [formula]. We remark ai  =  (E*iA) and a*i  =  (EiA*) for 0  ≤  i  ≤  d.

With reference to Definition [formula], the following (i), (ii) hold.

[formula].

[formula].

Proof. Assertion (i) follows from the irreducible tridiagonal shape of the matrix representing A in the basis [formula]. Assertion (ii) is similarly obtained.

With reference to Definition [formula], the following (i), (ii) hold.

E*iAE*i = aiE*i,  0  ≤  i  ≤  d.

EiA*Ei = a*iEi,  0  ≤  i  ≤  d.

Proof. (i) Abbreviate [formula]. Observe [formula] is a 1-dimensional subspace of the [formula]-vector space [formula]. The element E*i is nonzero and contained in [formula] so it spans [formula]. Observe [formula], so there exists αi∈ such that E*iAE*i  =  αiE*i. In this equation we take the trace of both sides and use (XY) = (YX) to obtain αi = ai. The result follows. (ii) Similar to the proof of (i) above.

The following lemma gives some consequences of Lemma [\ref=leosystem] which we will find useful. Of course Lemma [\ref=leosystem] has similar consequences.

With reference to Definition [formula], the following (i)-(iii) hold for 0  ≤  i,j  ≤  d.

E*i  Ar  E*j = 0    0  ≤  r < |i - j|.

[formula].

For 0  ≤  r,s  ≤  d,

[formula]

Proof. These are routine consequences of the irreducible tridiagonal shape of the matrix A in the basis [formula].

The proof of Theorem 1.4

In this section we establish Theorem [\ref=tdptheorem]. We start in a fashion similar to [\cite=LS99].

[\cite=LS99] With reference to Definition [formula], let D denote the [formula]-subalgebra of (V) generated by A. Then

[formula]

Proof. For notational convenience set E- 1 = 0 and Ed + 1 = 0. We claim that for 0  ≤  i  ≤  d,

[formula]

where [formula]. To see this, observe by ([\ref=sumei]) and Lemma [\ref=leosystem] that for 0  ≤  j  ≤  d both

[formula]

Summing both ([\ref=ejas12p1]) and ([\ref=asej12p1]) over [formula], and taking the difference between these two sums gives ([\ref=eiei12p1]). We mentioned earlier that [formula] form a basis for the [formula]-vector space D. From this we find [formula] form a basis for D. We may now argue

[formula]

and we are done.

In order to state the next lemma we introduce some notation.

Given scalars β,γ,ϱ in [formula] we define a polynomial

[formula]

Given scalars β,γ*,ϱ* in [formula] we define a polynomial

[formula]

Let β,γ,ϱ denote scalars in [formula]. Then with reference to Definition [formula] and Definition [formula],

[formula]

if and only if P(θi - 1,θi) = 0 for 1  ≤  i  ≤  d.

Proof. Let C denote the expression on the left in ([\ref=askwilb1pre]) and observe

[formula]

For 0  ≤  i,j  ≤  d we evaluate EiCEj using ([\ref=acomei]), ([\ref=askwilb1pre]) and get

[formula]

First assume ([\ref=askwilb1pre]) holds, so that C = 0. We show P(θi - 1,θi) = 0 for 1  ≤  i  ≤  d. Let i be given. Observe Ei - 1CEi = 0 so (θi - 1  -  θi)P(θi - 1,θi)Ei - 1A*Ei = 0 in view of ([\ref=eq:cpiece]). Observe [formula] by Lemma [\ref=multfree] and [formula] by Lemma [\ref=leosystem], so P(θi - 1,θi) = 0. We have now proved the lemma in one direction. To obtain the converse, assume P(θi - 1,θi) = 0 for 1  ≤  i  ≤  d. Since P(x,y) is symmetric in x,y we have P(θi,θi - 1) = 0 for 1  ≤  i  ≤  d. We show C = 0. By ([\ref=eq:csum]) it suffices to show EiCEj = 0 for 0  ≤  i,j  ≤  d. Let i,j be given. We show at least one of the factors on the right in ([\ref=eq:cpiece]) is zero. If |i - j| > 1 then EiA*Ej = 0 by Lemma [\ref=leosystem]. If |i - j| = 1 then P(θi,θj) = 0. If i = j then θi  -  θj = 0. We have now shown at least one of the factors on the right in ([\ref=eq:cpiece]) is zero. Therefore EiCEj = 0. Now each term on the right in ([\ref=eq:csum]) is zero so C = 0. We now have ([\ref=askwilb1pre]).

Let β,γ,γ*,ϱ,ϱ* denote scalars in [formula]. Then with reference to Definition [formula] and Definition [formula], the following (i), (ii) are equivalent.

The sequence β,γ,γ*,ϱ,ϱ* satisfies ([\ref=askwilb1]) and ([\ref=askwilb2]).

for 1  ≤  i  ≤  d both

[formula]

Proof. Apply Lemma [\ref=paul12p2] to both (A,A*) and (A*,A).

Proof of Theorem [\ref=tdptheorem]. Set d + 1 =  dim V. For 0  ≤  i  ≤  d, let θi and Ei (resp. θ*i and E*i) denote the eigenvalues and the primitive idempotents of A (resp. A*) as in Definition [\ref=primdef]. Let D denote the [formula]-subalgebra of (V) generated by A.

We first assume that d  ≥  3. By Lemma [\ref=paul12p1] (with X = A2 and Y = A) there exists Z∈D such that

[formula]

Recall D has a basis [formula] so there exists a polynomial p∈ which has degree at most d and satisfies Z = p(A). Let k denote the degree of p.

We show k = 3. We first suppose k > 3 and obtain a contradiction. We multiply each term in ([\ref=asliebpa]) on the left by E*k and on the right by E*0. We evaluate the result using ([\ref=acomei]) and Lemma [\ref=eiarej] to find [formula], where c denotes the leading coefficient of p. The scalars c and θ*0  -  θ*k are nonzero by the construction. Moreover E*kAkE*0 is nonzero by Lemma [\ref=eiarej]. Therefore [formula] for a contradiction. We have now shown k  ≤  3. We next assume k < 3 and obtain a contradiction. We multiply each term in ([\ref=asliebpa]) on the left by E*3 and on the right by E*0. We evaluate the result using ([\ref=acomei]) and Lemma [\ref=eiarej] to find [formula]. The scalar θ*1  -  θ*2 is nonzero. Moreover E*3A3E*0 is nonzero by Lemma [\ref=eiarej]. Therefore [formula] for a contradiction. We have now shown k = 3.

We divide both sides of ([\ref=asliebpa]) by c. The result is

[formula]

where β = c- 1 - 1 and where γ,ϱ are appropriate scalars in [formula]. From ([\ref=prebrack]) we routinely obtain ([\ref=askwilb1]). Concerning ([\ref=askwilb2]), pick any integer i (2  ≤  i  ≤  d - 1). We multiply each term in ([\ref=askwilb1]) on the left by E*i - 2 and on the right by E*i + 1. We evaluate the result using ([\ref=acomei]) and Lemma [\ref=eiarej] to find E*i - 2A3E*i + 1 times

[formula]

is zero. Observe [formula] by Lemma [\ref=eiarej] so ([\ref=eq:brecur]) is zero. Apparently the sequence [formula] is β-recurrent. Therefore there exists γ*∈ such that [formula] is (β,γ*)-recurrent. By Lemma [\ref=lem:pre] there exists ϱ*∈ such that P*(θ*i - 1,θ*i) = 0 for 1  ≤  i  ≤  d, where P* is from Definition [\ref=def:poly]. By this and Lemma [\ref=paul12p2] we find β,γ*,ϱ* satisfy ([\ref=askwilb2]).

We have now shown there exists a sequence of scalars β,γ,γ*,ϱ,ϱ* taken from [formula] which satisfies ([\ref=askwilb1]), ([\ref=askwilb2]). We show this sequence is unique. Let β,γ,γ*,ϱ,ϱ* denote any sequence of scalars taken from [formula] which satisfies ([\ref=askwilb1]), ([\ref=askwilb2]). Applying Lemma [\ref=paul12p2] we find P(θi - 1,θi) = 0 for 1  ≤  i  ≤  d, where P is from Definition [\ref=def:poly]. By this and Lemma [\ref=lem:pre] we find [formula] is (β,γ)-recurrent. Therefore [formula] is β-recurrent. By these remarks and since d  ≥  3 we find each of β,γ,ϱ is uniquely determined. Interchanging A,A* in this argument we find each of γ*,ϱ* is uniquely determined. We have now proved the theorem for the case d  ≥  3.

Next assume d  ≤  2. Let β denote any scalar in [formula]. If d = 2 define γ  =  θ0  -  βθ1  +  θ2 and if d  ≤  1 let γ denote any scalar in [formula]. If d  ≥  1 define

[formula]

and if d = 0 let ϱ denote any scalar in [formula]. Observe [formula] is (β,γ)-recurrent; applying Lemma [\ref=lem:pre] we find P(θi - 1,θi) = 0 for 1  ≤  i  ≤  d. Applying Lemma [\ref=paul12p2] we find β,γ,ϱ satisfy ([\ref=askwilb1]). Interchanging A,A* in the above argument we find there exists scalars γ*,ϱ* in [formula] such that β,γ*,ϱ* satisfy ([\ref=askwilb2]).

We finish this section with a comment.

[\cite=qSerre] Let d denote a nonnegative integer and let V denote a vector space over [formula] with dimension d + 1. Let (A,A*) denote a Leonard pair on V. Let the scalars θi,θ*i be as in Definition [formula]. Let β,γ,γ*,ϱ,ϱ* denote a sequence of scalars taken from [formula] which satisfies () and (). Then the following (i)-(v) hold.

The expressions

[formula]

are both equal to β + 1 for 2  ≤  i  ≤  d - 1.

γ  =  θi - 1  -  βθi  +  θi + 1,  1  ≤  i  ≤  d - 1.

γ*  =  θ*i - 1  -  βθ*i  +  θ*i + 1,  1  ≤  i  ≤  d - 1.

ϱ  =  θ2i - 1  -  β  θi - 1  θi  +  θ2i  -  γ  (θi - 1  +  θi),  1  ≤  i  ≤  d.

ϱ*  =  θ* 2i - 1  -  β  θ*i - 1  θ*i  +  θ* 2i  -  γ*  (θ*i - 1  +  θ*i),  1  ≤  i  ≤  d.

Proof. (iv), (v) By Corollary [\ref=lpscalars1] we have P(θi - 1,θi) = 0 and P*(θ*i - 1,θ*i) = 0 for 1  ≤  i  ≤  d, where P and P* are from Definition [\ref=def:poly]. (ii) Combine Lemma [\ref=lem:pre] with part (iv) of this lemma. (iii) Similar to the proof of (ii) above. (i) The sequence [formula] is (β,γ)-recurrent by (ii) so this sequence is β-recurrent. The sequence [formula] is (β,γ*)-recurrent by (iii) so this sequence is β-recurrent. The result follows.

The proof of Theorem 1.5

In this section we prove Theorem [\ref=lptheorem]. We begin with an extension of Lemma [\ref=paul12p2].

Let β,γ,ϱ,γ*,ω,η denote scalars in [formula]. Then with reference to Definition [formula] and Definition [formula],

[formula]

if and only if both

[formula]

Proof. Let L (resp. R) denote the expression on the left (resp. right) in ([\ref=thawnew]). Observe

[formula]

Observe further that for 0  ≤  i,j  ≤  d both

[formula]

First assume ([\ref=thawnew]), so that L = R. We show ([\ref=eq:cond1]), ([\ref=eq:cond2]). Concerning ([\ref=eq:cond1]), for 1  ≤  i  ≤  d we have Ei - 1REi = 0 by ([\ref=eq:r]) so Ei - 1LEi = 0. By this and ([\ref=eq:l]) we find P(θi - 1,θi)Ei - 1A*Ei = 0. Recall [formula] by Lemma [\ref=leosystem] so P(θi - 1,θi) = 0. We now have ([\ref=eq:cond1]). Concerning ([\ref=eq:cond2]), for 0  ≤  i  ≤  d we have EiLEi = EiREi. Evaluating this using ([\ref=eq:l]), ([\ref=eq:r]) and Lemma [\ref=lem:ais] we find a*iP(θi,θi) = γ*θ2i  +  ωθi  +  η. We now have ([\ref=eq:cond2]). We have now proved the lemma in one direction. To obtain the converse, assume ([\ref=eq:cond1]), ([\ref=eq:cond2]). We show L = R. By ([\ref=RLmain]), it suffices to show EiLEj = EiREj for 0  ≤  i,j  ≤  d. For 0  ≤  i  ≤  d we have EiLEi = a*iP(θi,θi)Ei by Lemma [\ref=lem:ais] and ([\ref=eq:l]). Moreover EiREi = (γ*θ2i  +  ωθi  +  η)Ei by ([\ref=eq:r]) so EiLEi = EiREi in view of ([\ref=eq:cond2]). For 1  ≤  i  ≤  d we have Ei - 1LEi = 0 by ([\ref=eq:cond1]), ([\ref=eq:l]) and Ei - 1REi = 0 by ([\ref=eq:r]) so Ei - 1LEi  =  Ei - 1REi. For 0  ≤  i,j  ≤  d with |i - j| > 1, recall EiA*Ej = 0 by Lemma [\ref=leosystem] so EiLEj = 0 in view of ([\ref=eq:l]). Also EiREj = 0 by ([\ref=eq:r]) so EiLEj  =  EiREj. Apparently EiLEj  =  EiREj for 0  ≤  i,j  ≤  d. By this and ([\ref=RLmain]) we find L = R. We now have ([\ref=thawnew]).

Let β,γ,γ*,ϱ, ϱ*,ω,η,η* denote scalars in [formula]. Then with reference to Definition [formula] and Definition [formula], the following (i), (ii) are equivalent.

The sequence β,γ,γ*,ϱ,ϱ*,ω,η,η* satisfies ([\ref=askwil1]) and ([\ref=askwil2]).

For 1  ≤  i  ≤  d both

[formula]

and for 0  ≤  i  ≤  d both

[formula]

Proof. Apply Lemma [\ref=paulth14] to both (A,A*) and (A*,A).

Proof of Theorem [\ref=lptheorem]. Set d + 1 = V. For d = 0 the result is trivial so assume d  ≥  1. For 0  ≤  i  ≤  d, let θi and Ei (resp. θ*i and E*i) denote the eigenvalues and the primitive idempotents of A (resp. A*) as in Definition [\ref=primdef]. Let D denote the [formula]-subalgebra of (V) generated by A. By Theorem [\ref=tdptheorem] there exists scalars β,γ,γ*,ϱ,ϱ* in [formula] which satisfy ([\ref=askwilb1]), ([\ref=askwilb2]). We show there exist scalars ω,η,η* in [formula] such that the sequence β,γ,γ*,ϱ,ϱ*,ω,η,η* satisfies ([\ref=askwil1]), ([\ref=askwil2]). Define

[formula]

By ([\ref=askwilb1]) the element U commutes with A. By this and since A is multiplicity-free we find U∈D. Recall D has a basis [formula] so there exists a polynomial f∈ which has degree at most d and satisfies U = f(A). Let h denote the degree of f. We show h  ≤  2. To do this we assume h > 2 and get a contradiction. We multiply each term in U = f(A) on the left by E*h and on the right by E*0. We evaluate the result using ([\ref=acomei]) and Lemma [\ref=eiarej] to find 0 = αE*hAhE*0, where α denotes the leading coefficient of f. The scalar α is nonzero by the construction and [formula] by Lemma [\ref=eiarej]. Therefore [formula] for a contradiction. We have now shown h  ≤  2, so there exist scalars λ,ω,η in [formula] such that U = λA2  +  ωA + ηI.

For the moment assume d = 1. In this case A2 is linearly dependent on I,A, so λ,ω,η can be chosen such that λ  =  γ*. Next assume d  ≥  2. We show λ  =  γ*. To do this, we multiply each term in U = λA2  +  ωA + ηI on the left by E*2 and on the right by E*0. We evaluate the result using ([\ref=acomei]) and Lemma [\ref=eiarej] to find

[formula]

Observe [formula] by Lemma [\ref=eiarej]; by this and ([\ref=eq:2a0]) we find θ*0  -  βθ*1  +  θ*2  =  λ. Setting i = 1 in Theorem [\ref=thm:lastcom] we find θ*0  -  βθ*1  +  θ*2  =  γ*. We now see λ  =  γ*.

Now β,γ,ϱ,γ*,ω,η satisfy ([\ref=askwil1]). Interchanging the roles of A and A* in the argument so far, we find there exist scalars ω*,η* in [formula] such that

[formula]

We show ω*  =  ω. We proceed as follows. We first find the commutator of each side of ([\ref=askwil1]) with A*. The result is

[formula]

We next find the commutator of each side of ([\ref=askwil2a]) with A. The result is

[formula]

Adding the last two equations and simplifying the result we obtain

[formula]

Observe that [formula] since

[formula]

is nonzero. By ([\ref=omegas]) and since [formula] we find ω*  =  ω. Hence β,γ*,ϱ*,γ,ω,η* satisfy ([\ref=askwil2]).

We have now shown there exists a sequence of scalars β,γ,γ*,ϱ,ϱ*,ω,η,η* taken from [formula] which satisfies ([\ref=askwil1]), ([\ref=askwil2]). We now assume d  ≥  3 and show this sequence is unique. Let β,γ,γ*,ϱ,ϱ*,ω,η,η* denote any sequence of scalars in [formula] which satisfies ([\ref=askwil1]), ([\ref=askwil2]). Then the sequence β,γ,γ*,ϱ,ϱ* satisfies ([\ref=askwilb1]), ([\ref=askwilb2]) and is therefore uniquely determined by Theorem [\ref=tdptheorem]. By ([\ref=askwil1]) and since I,A are linearly independent we find ω,η are uniquely determined. By ([\ref=askwil2]) we find η* is uniquely determined. We have now shown the sequence β,γ,γ*,ϱ,ϱ*,ω,η,η* is uniquely determined.

We finish this section with a comment. Let V denote a vector space over [formula] with finite positive dimension and let (A,A*) denote a Leonard pair on V. Let β,γ,γ*,ϱ,ϱ*,ω,η,η* denote a sequence of scalars taken from [formula] which satisfies ([\ref=askwil1]), ([\ref=askwil2]). Observe the scalars β,γ,γ*,ϱ,ϱ* satisfy (i)-(v) in Theorem [\ref=thm:lastcom]. Concerning ω,η,η* we have the following.

Let d denote a positive integer and let V denote a vector space over [formula] with dimension d + 1. Let (A,A*) denote a Leonard pair on V. Let β,γ,γ*,ϱ, ϱ*,ω,η,η* denote a sequence of scalars taken from [formula] which satisfies (), (). Let the scalars θi,θ*i,ai,a*i be as in Definition [formula]. For notational convenience, let θ- 1 and θd + 1 (resp. θ*- 1 and θ*d + 1) denote scalars in [formula] which satisfy Theorem [formula](ii) (resp. Theorem [formula](iii)) for i = 0 and i = d. Then the following (i)-(iv) hold.

ω  =  a*i  (θi  -  θi + 1) + a*i - 1  (θi - 1  -  θi - 2) - γ*  (θi  +  θi - 1),  1  ≤  i  ≤  d.

ω  =  ai  (θ*i  -  θ*i + 1) + ai - 1  (θ*i - 1  -  θ*i - 2) - γ  (θ*i  +  θ*i - 1),  1  ≤  i  ≤  d.

η  =  a*i  (θi  -  θi - 1)  (θi  -  θi + 1)  -  γ*  θ2i  -  ω  θi,  0  ≤  i  ≤  d.

η*  =  ai  (θ*i  -  θ*i - 1)  (θ*i  -  θ*i + 1)  -  γ  θ* 2i  -  ω  θ*i,  0  ≤  i  ≤  d.

Proof. (iii) Let i be given. We claim

[formula]

where P is from Definition [\ref=def:poly]. To verify ([\ref=extraeq2]) for 1  ≤  i  ≤  d, first eliminate θi + 1 using θi - 1  -  βθi  +  θi + 1  =  γ. Evaluate the result using P(θi,θi) = (2 - β)θ2i - 2γθi  -  ϱ and P(θi - 1,θi) = 0. To verify ([\ref=extraeq2]) for 0  ≤  i  ≤  d - 1, first eliminate θi - 1 using θi - 1  -  βθi  +  θi + 1  =  γ. Evaluate the result using P(θi,θi) = (2 - β)θ2i - 2γθi  -  ϱ and P(θi,θi + 1) = 0. We now have ([\ref=extraeq2]). Combining ([\ref=extraeq2]) with ([\ref=Pcond1]) we obtain the desired formula. (iv) Similar to the proof of (iii) above. (i) Subtract (iii) (at i) from (iii) (at i - 1) and simplify. (ii) Similar to the proof of (i) above.

Concluding remarks

We illustrate Theorem [\ref=lptheorem] by computing the Askey-Wilson relations for the Leonard pair in Example [\ref=krawtchouk].

Let (A,A*) denote the Leonard pair from Example [\ref=krawtchouk]. Referring to that example, in the basis [formula] the matrices for A and A* have diagonal entries

[formula]

In the basis [formula] the matrices for A and A* have diagonal entries

[formula]

Define β = 2, γ  =  γ* = 0, ϱ  =  ϱ* = 1, ω = 1 - 2p, η = pd, η* =  - pd. One readily verifies these scalars satisfy Corollary [\ref=lp2scalarsint]. Applying that corollary we find

[formula]

These are the Askey-Wilson relations for (A,A*).

We conclude this paper with a kind of converse to Theorem [\ref=lptheorem].

Let V denote a vector space over [formula] with finite positive dimension. Let A:V  →  V and A*:V  →  V denote linear transformations. Suppose that:

There exists a sequence of scalars β,γ,γ*,ϱ,ϱ*,ω,η,η* taken from [formula] which satisfies ([\ref=askwil1]), ([\ref=askwil2]).

q is not a root of unity, where q + q- 1  =  β.

Each of A and A* is multiplicity-free.

There does not exist a subspace W  ⊆  V such that [formula], [formula], AW  ⊆  W, A*W  ⊆  W.

Then (A,A*) is a Leonard pair on V.

Proof. By [\cite=qSerre] the pair (A,A*) is a tridiagonal pair on V in the sense of [\cite=TD00]. Now by [\cite=qSerre] and since each of A,A* is multiplicity-free, we find (A,A*) is a Leonard pair on V.

Paul Terwilliger Department of Mathematics University of Wisconsin 480 Lincoln Drive Madison, WI 53706 USA email: terwilli@math.wisc.edu

Raimundas Vidunas Dept. Mathematics and Computer Science RUCA, Antwerp University Middelheimlaan 1 2020 Antwerp, Belgium email: Raimundas.Vidunas@ua.ac.be