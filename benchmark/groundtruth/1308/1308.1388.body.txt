=1

Bayesian sequence assembly and assessment by Markov Chain Monte Carlo sampling

Most current methods for de novo genome assembly generate point estimates of the genome sequence without explicit statistical information about confidence in this particular estimate, or its support relative to other alternative assemblies supported by the same sequence data[\cite=howison_2013]. Recently, several probabilistic approaches have been proposed to quantify assembly certainty and address these limitations. The Computing Genome Assembly Likelihood (CGAL) tool approximates the likelihood of an assembly given the sequence reads and a generative model learned from the data[\cite=rahman_cgal:_2013]; the Log Average Probability (LAP) tool approximates the likelihood under a similar model of sequence read generation[\cite=ghodsi_2013]; and the Assembly Likelihood Evaluation (ALE) framework uses an empirical Bayesian approach to estimate the posterior probability of a particular assembly (or components of that assembly)[\cite=clark_ale:_2013].

Here we present an alternative Bayesian approach to approximating posterior probabilities, using Markov Chain Monte Carlo (MCMC) sampling[\cite=gilks_markov_1995] to generate an entire posterior distribution of assembly hypotheses. An MCMC framework for sequence assembly addresses many of the general problems of accommodating assembly uncertainty, and provides a probabilistic understanding of the support for an assembly as a whole, as well as for particular features of the assembly that the investigator has special interest in. For example, it may be that a particular attribute of an assembly has low confidence, but that the other assemblies that together account for 100% of the alternatives are all still consistent with a broader-scale hypothesis, such as the order of a set of genes or existence of a specific regulatory element.

To demonstrate the feasibility of the MCMC approach, we have implemented a prototype assembler called Genome Assembly by Bayesian Inference (GABI, ). Because our approach is computationally expensive, our current tests are limited to the small but well-studied genome of the ΦX174 phage (which has NCBI Reference Sequence NC_001422.1). Our input data consist of 2,000 read-pairs drawn from Illumina ΦX174 sample data (, estimated mean insert size of 357bp). These 250bp reads, available as Supplementary Data 1, provide approximately 85×   coverage of the ΦX174 genome.

Conveniently, our approach has technical parallels and similar conceptual advantages as the advances made over the past 15 years in the application of Bayesian approaches to phylogenetic analysis[\cite=holder_phylogeny_2003] [\cite=Ronquist2003] [\cite=Lartillot2009]. As in phylogenetics and other fields, designing an MCMC sampling strategy that achieves good mixing and convergence poses a variety of challenges and opportunities. For sequence assembly, the challenge is to design a mechanism for proposing new assemblies, a means of calculating the likelihood of a proposed assembly under an explicit model of read generation, and the specification of a prior probability distribution that describes some prior beliefs about the assembly before the sequence data were collected. To implement an MCMC sequence assembler, we made the following choices:

To evaluate the mixing and convergence of our MCMC sampler, we ran three independent chains and compared their traces and split frequencies, as is common practice for other applications of MCMC[\cite=Nylander2008]. Our results show that our design achieves good mixing when using a simple Metropolis sampler[\cite=Metropolis1953] without any burn-in or thinning (Fig. 1a). The cumulative frequencies of the individual edges have mostly stabilized after 8,000 accepted samples (Fig. 1b). Those with weak support were likely assembled from reads with sequencing errors. Other edges are more ambiguous, with a cumulative frequency that hovers at an intermediate value or varies across samples. Overall, the standard deviation in edge frequencies between the chains decreases with additional sampling, indicating that independent chains are converging to the same posterior distribution (Fig. 1c). The split frequencies among three independent chains are mostly correlated after the last sample (Fig. 1d). We also tested the sampler with flat priors, with no likelihood calculations (priors only), and with different choices of the scaling parameter for the gamma distributions (Supplementary Fig. 3). Our acceptance rate is 42.2%, which is higher than the heuristic of 25% that can be considered optimal for general Metropolis sampling[\cite=Roberts1997]. Aggregated across all three chains, the mean compute time per sample was 1.6 seconds and total compute time was 25,324.5 CPU-hours.

GABI provides multiple ways for summarizing the results of an MCMC analysis and is built on top of BioLite, a light-weight bioinformatics framework with rich diagnostics and reporting capabilities[\cite=howison_biolite_2012]. The assembly graph can be annotated with the approximated posterior probabilities (Fig. 2a), or a consensus assembly can be extracted, for instance a majority-rule consensus that shows all edges occurring with frequency > 50% (Fig. 2b). The report includes a FASTA file for the majority-rule consensus, annotated with the posterior probabilities of its components. A detailed report created with the D3js data visualization toolkit[\cite=Bostock2011] provides an interactive animation of the sampling for each MCMC chain. This report is provided for all chains as Supplementary Data 2 (and also at ).

GABI includes a tool to assign posterior probabilities to features of external assemblies that correspond to features in its own assembly graph. This provides an explicit and unified statistical framework for comparison of assemblies produced by multiple methods and software tools. Here, we compare NCBI Reference Sequence NC_001422.1 and de novo point-estimate assemblies generated by the String Graph Assembler[\cite=Simpson2012] and Velvet[\cite=Zerbino2008]. We require exact matches to identify corresponding features, and this conservative strategy means that there is not an exact correspondence between the NCBI reference sequence and the GABI graph (Fig. 2e). For this simple assembly problem, there is nearly universal agreement among the assemblies: both the majority rule consensus (Fig. 2b) and NCBI reference sequence (Fig. 2e) are proper subsets of the two de novo point-estimate assemblies (Fig. 2c-d). The one notable difference is that the SGA assembly contains two contigs that choose alternate paths in one of the bubbles, and these alternate paths have similar posterior probabilities (yellow highlight in Fig. 2).

A challenge to scaling MCMC assembly is that the combinatorial complexity of larger assembly graphs could become prohibitive for full de novo Bayesian assembly of large genomes. There are several ways to address this, such as applying more sophisticated sampling methods like Metropolis-coupled MCMC[\cite=Geyer1991] or bridging states[\cite=Lin2012] that can explore larger combinatorial spaces more efficiently; constraining the assembly graph to focus on particular assembly hypotheses instead of attempting full de novo assembly; or pruning the assembly graph using additional data from restriction site mappings[\cite=lam_genome_2012]. Another promising application is transcriptome assembly, since the assembly graphs for individual transcripts should be less complex and can be sampled independently.

Like existing assemblers, GABI can be used to assemble a point estimate of a genome, but unlike most other assemblers, the resulting assembly will have been chosen according to explicit statistical criteria (posterior probability) and will have associated information on the confidence in various aspects of its sequence and structure. In addition, MCMC assembly provides new opportunities for investigators who are interested not only in the certainty of a particular inference (e.g. an ALE[\cite=clark_ale:_2013] estimate of posterior probability for a given assembly), but in the many alternative hypotheses that are also supported by the data. The MCMC approach addresses many of the general problems of summarizing assembly uncertainty and will allow assembly uncertainty to be propagated to downstream analyses[\cite=howison_2013].

Compute resources.

All tests were run at the Center for Computation and Visualization, Brown University, on IBM iDataPlex nodes, each equipped with 16-core, dual-socket Intel Xeon E5-2670 (2.6Ghz) processors and 64GB of memory. CPU-hours were calculated as total walltime across all nodes, multiplied by 16 CPUs per node.

Subset of ΦX174 sample data.

We started with 8.36 Gb of paired-end reads of length 250 bp from Illumina ΦX174 sample data ( and , accessed April 26, 2013). Using the illumina_filter tool from BioLite, we chose the first 2,000 read pairs that did not contain known Illumina adapter sequences and that had mean quality score greater than 37 (Phred-33 scoring). This procedure is available in the script .

SGA and Velvet assemblies.

To assemble the 2,000 read ΦX174 subset with SGA, we followed the example provided for an assembly of E. coli from similar MiSeq reads (). To assemble with Velvet, we used the included VelvetOptimiser tool to sweep coverage and cutoff parameters for a k-mer size of 99. The estimated mean and standard deviation of the insert size reported earlier were obtained from VelvetOptimiser's output. This procedure is available in the script

De Bruijn graph reduction.

First, we recursively and completely trimmed all tips (edges with an incidence of one), because our target ΦX174 genome is circular (for a linear target, a softer tip trimming threshold would be more appropriate). Next, we merged all simple paths through the graph, similar to the process of reducing an overlap graph to a string graph[\cite=myers_fragment_2005]. We annotated the new edge with the accumulated overlap of the merged nodes' k-mers, which accumulates one additional nucleotide for each merged edge. Finally, we split the graph into weakly connected components and choose the largest one. A cyclical path of edges through the graph spells a contig by concatenating the annotations on the edges. For a linear path, the contig starts with the k-mer at the initial node, followed by the concatenated edge annotations.

Odds ratio.

To determine whether to accept a proposed assembly hypothesis, we calculate the odds ratio[\cite=Metropolis1953] of the posterior probabilities of the old assembly, P(H|D), and the new perturbed assembly, P(H*|D), as:

[formula]

If this ratio is greater than 1, the new assembly is automatically accepted. If it is less than 1, it is accepted with probability R. The process is then repeated until there is a stationary distribution of assemblies in the sample, which occurs when the frequency of assembly attributes does not change with additional sampling.