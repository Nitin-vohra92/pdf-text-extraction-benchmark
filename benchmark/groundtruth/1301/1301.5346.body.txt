= 2mu plus 0mu minus 2mu = 2.3mu plus 1mu minus 2.3mu = 2.6mu plus 2mu minus 2.6mu

Calculations based on proximity relations with nearest neighbors appear in a wide variety of astronomical problems. The distance to N-th nearest neighbor can be converted into a measure of density by means of simple inversion. Pioneering uses of this technique in astronomy include von Hoerner (1963) and Dressler (1980). It is known (Casertano and Hut 1985) that such conversion biases density estimates by a factor of N / (N - 1) and increases their variance by N / (N - 2), where N is the number of considered nearest points. Density estimators based on N = 1 or N = 2 are therefore of little use and at N = 4 half of the available information is lost. Details of procedures applied in practice and the relative merits of various choices of N are reviewed by Schmeja (2011), Haas (2012) and Muldrew (2012). It turns out that the adopted value of N is typically between 3 and 10. The most frequently used values are 3, 4, and 5, where the effect of diminishing accuracy is large. However, the investigators have a good reason to keep N small. When the density varies in space, its estimate based on the nearest neighbors method is effectively an average over the volume set by the N-th nearest neighbor and differs from the local value. This smoothing bias is unavoidable in the case of variable density and independent of the rarely mentioned reciprocity bias described by Casertano and Hut (1985). Choosing small N limits the influence of the smoothing bias for the price of increasing the variance. Another way of diminishing the smoothing bias was introduced by Ivezi (2005) and Cowan and Ivezi (2008) who take a "Bayesian" approach to combine contributions from all N nearest neighbors. The net effect is, again, lower bias at the cost of increased variance. Here we propose a new method of dealing with the smoothing bias that captures the information on density variations contained in distances to all N nearest neighbors using the Legendre series expansion.

In this section we rederive the formula for the mean density in the case of a uniform point distribution. In our derivation we particularly emphasize an alternative, and in fact more natural, approach to the problem that adopts the volume per point instead of the mean density of points as the basic unknown. This also serves as an introduction to the non-uniform case described in the next section.

Let us consider a metric space with an arbitrary number of dimensions. We will assume that the space is populated by randomly distributed pointlike objects in such a way that the expectation value of the number of objects n contained in an arbitrarily chosen subspace of volume v is proportional to the volume v with a proportionality constant ρ0. So the expected number of objects contained in volume v is 〈n(v)〉  =  ρ0v, and ρ0 that can be defined as the density of our pointlike objects is the unknown to be found. An alternative treatment of our problem, which is the case of the nearest neighbors method, consists of finding the volume corresponding to a predefined number of points N. The expected value of volume 〈v〉 is then proportional to the number of points with a proportionality constant μ defined as the volume per point. So the expected volume over N points is 〈vN〉  =  μN. In this case μ is the basic unknown.

Let us fix the origin of cartesian coordinates at an arbitrarily chosen point and imagine a series of N hyperspheres centered on the origin such that only one pointlike object resides on the surface of each hypersphere. The sequence is ordered according to increasing volume [formula]. It is easy to see that the problem is identical to the well known case of events occuring randomly but at a constant average rate (e.g. Eadie et al. 1982). Examples often presented in statistical textbooks are radioactive decay, telephone calls, or recording photons arriving from a faint astronomical object. In our case the volume plays the role of time. It is worthwhile to point out that the variables in any pair of vi values are not statistically independent because the central part of the larger hypersphere is identical with the smaller one. In order to deal with statistically independent observables we will consider the first order differences of consecutive volumes

[formula]

with vo  =  0. Random variables xi are mutually statistically independent and their probability distribution is exponential. Therefore, the corresponding probability density can be written as

[formula]

For a uniform distribution of our pointlike objects all μ values are identical and equal to μ0. Therefore the joint probability density of all xi is

[formula]

We can find a maximum likelihood estimator for the volume per point 〈μ0〉

[formula]

This estimator is based solely on the position of the most distant neighbor in the sample. Under the assumption of constant density, this estimator is sufficient and unbiased, i.e. it already includes all information on density contained in our sample. Exact positions of less distant neighbors are irrelevant.

The probability density of the random variable vN follows the Gamma distribution

[formula]

with expectation value 〈vN〉  =  μ0N, variance σ2(vN)  =  μ20N, and standard deviation [formula]. The corresponding values for the estimated value of μ are 〈μ〉  =  μ0, variance σ2(μ)  =  μ20 / N and standard deviation [formula]. It is worth noting that the variance of the estimated volume per point μ is exactly equal the lowest possible value set by the sampling statistics because it is inversely proportional to the number of independent observations N and the variance is defined for all values of N starting with N = 1.

The probability density of vN is given by Equation 5. We can treat all the remaining volumes vi with i < N as random variables uniformly distributed between 0 and vN. We can now write the joint probability density of volumes vi for uniform point distributions

[formula]

where 1 / vN is the conditional probability density of any point other than N-th given that the volume vN is fixed.

Casertano and Hut (1985) derived analogous formulae for the alternative case of point density estimation. They had to consider an inverse value of directly observable vN that led to the use of the inverse Gamma probability distribution instead of the Gamma distribution, and consequently to a loss of information. The estimator of density is

[formula]

and the variance expressed in terms of the estimated density is

[formula]

Therefore the above approach should only be used for N > 2. The variance of this estimator is larger than the sampling statistics limit, even drastically so for very small N. Evaluating density at a location coinciding with one of the pointlike objects is no different. Points at the origin of coordinates should not be counted.

The optimal properties of the vN estimator degrade for density profiles with progressively larger deviations from a uniform distribution. The smoothing bias is increasing. In addition, the random variables xi are no longer mutually statistically independent and now the exact positions of less distant neighbors, normalized to the value of vN, carry information that can be used to limit the influence of smoothing bias. An approximation formula based on power series expansion is a natural choice and coefficients can be estimated using least squares. A less complicated approach is to use orthogonal functions constructed from the power series of the same order. In the latter case the unknown coefficients can be determined by convolutions, which is both simpler and faster.

Let us consider the sequence of normalized volumes yi  =  vi / vN with the exception of the last element taken as normalization. Spherical volumes in D dimensions are computed as vi  =  rDiπD / 2  /  Γ(D / 2 + 1), where ri is the distance to the i-th nearest neighbor. In the uniform case [formula] are uniformly distributed over the interval (0,vN). Observed deviations from the uniform distribution can tell us something about the density distribution inside the volume defined by the N-th point. We will search for this something with the help of the Legendre polynomial expansion of order k. In the following derivation we make use of the shifted Legendre polynomials [formula] which are orthogonal on the interval (0,1) and are obtained from the regular Legendre functions Pl defined over the interval

[formula]