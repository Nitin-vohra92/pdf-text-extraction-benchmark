Lemma Corollary Proposition Definition

Limit theorems for some adaptive MCMC algorithms with subgeometric kernels: Part II

Aug. 2009

Introduction

This work is a sequel of [\cite=atchadeetfort08] and develops central limit theorems for adaptive MCMC (AMCMC) algorithms. Previous works on the subject include [\cite=andrieuetal06] and [\cite=saksmanvihola09] where central limit theorems are proved for certain AMCMC algorithms driven by geometrically ergodic Markov kernels. There is a need to understand the sub-geometric case. Indeed, many Markov kernels routinely used in practice are not geometrically ergodic. For example, if the target distribution of interest has heavy tails, then the Random Walk Metropolis algorithm (RWMA) and the Metropolis Adjusted Langevin algorithm (MALA) result in sub-geometric Markov kernels ([\cite=jarneretroberts201]).

We consider adaptive MCMC algorithms driven by Markov kernels {Pθ,  θ∈Θ} such that each kernel Pθ enjoys a polynomial rate of convergence towards π and satisfies a drift condition of the form PθV  ≤  V - cV1 - α + b for some α∈(0,1] (uniformly in θ over compact sets). We obtain a central limit theorem when α < 1 / 2 under some additional stability conditions. This result is very close to what can be proved for Markov chains under similar conditions. Indeed, it is known ([\cite=jarneretroberts101]) that irreducible and aperiodic Markov chains for which the drift condition [formula] hold for some small set C satisfy a central limit theorem when α  ≤  1 / 2. The slight loss of efficiency in our case (α < 1 / 2 versus α  ≤  1 / 2) is typical of martingale approximation-based proofs. The proof of the central limit theorem is based on a martingale approximation technique initiated by [\cite=kipnisetvaradhan86] and [\cite=mw00]. The method is a Poisson equation-type method but where the Poisson's kernel is replaced by a more general resolvent kernel. We have used a variant of the same technique in [\cite=atchadeetfort08] to study the strong law of large numbers for AMCMC.

Adaptive MCMC has been studied in a number of recent papers. Beside the above mentioned papers, results related to the convergence of marginal distributions and the law of large numbers can be found e.g. in ([\cite=rosenthaletroberts05] [\cite=bai:2008]). For specific examples and a review of the methodological developments, see e.g. [\cite=robertsetrosenthal06] [\cite=andrieu:thoms:2008] [\cite=atchadeetal09].

The rest of the paper is organized as follows. The main CLT result is presented in Section [\ref=sec:CLTresults]. Adaptive MCMC driven by stochastic approximation is considered in Section [\ref=sec:SA]. To illustrate, we apply our theory to an adaptive version of the Metropolis adjusted Langevin algorithm (MALA) with a heavy tailed target distribution (Section [\ref=sec:ex]). Most of the proofs are postponed to Section [\ref=sec:proofs].

Statement of the results

Notations

We start with some notations that will be used through the paper. For a transition kernel P on a measurable general state space [formula], denote by Pn, n  ≥  0, its n-th iterate defined as

[formula]

δx(dt) stands for the Dirac mass at {x}. Pn is a transition kernel on [formula] that acts both on bounded measurable functions f on [formula] and on σ-finite measures μ on [formula] via [formula] and [formula].

If [formula] and {an,  n  ≥  0} as in the statement of the theorem. Denote [formula]. Without any loss of generality, we will assume that |f|Vβ  ≤  1. We have

[formula]

By Theorem [\ref=thm2], [formula] converges in [formula]-probability to zero.

Note that ξk = 0 signals a re-projection at time k. By Proposition [\ref=propboundga] (i) applied with κ > 1,

[formula]

and the rhs is finite [formula]-a.s. We then conclude that [formula] converges to zero [formula]-a.s..

Define [formula], where [formula]. It is straightforward to see that {(Mn,k,Fk),  1  ≤  k  ≤  n} is a martingale array. We will show that

[formula]

[formula]

where

[formula]

is finite [formula]-almost surely and that for any ε > 0,

[formula]

By the central limit theorem for martingales (see e.g. [\cite=halletheyde80], Corollary 3.1), ([\ref=eq:TBS1])-([\ref=eq:TBS3]) implies that Mn,n converges weakly to Z ([formula]) where Z is a random variable with characteristic function [formula]. This will end the proof.

Proof of ([\ref=eq:TBS1])

It suffices to show that for all l  ≥  0, k,n  ≥  1,

[formula]

and to apply Lemma [\ref=lem:momentV]. By Proposition [\ref=propboundga] (i) (applied with both κ > 1 and δ > 0), [formula] since by assumption 2β  +  α(κ  +  δ)  ≤  1 - α. Thus for any l  ≥  0, k,n  ≥  1 and [formula],

[formula]

From Proposition [\ref=prop:useful] (i) we thus obtain

[formula]

Proof of ([\ref=eq:TBS2])

[formula]

The same argument as above shows that

[formula]

which converges almost surely to zero since Tν∞ is finite [formula]-almost surely, ζδ(an) = O(nρ(1 - δ)) and ρ(1 - δ) < 1 / 2.

For the first term, we note that [formula]. We thus have the decomposition:

[formula]

where

[formula]

[formula]

[formula]

[formula]

[formula]

[formula]

By assumption n- 1T(1)n converges in [formula]-probability to zero. We will use the same technique to study the term T(2)n to T(5)n. For example for T(2)n, the idea is to introduce its counterpart T̃(1)n,s in the space of the re-projection free process {(n,n),  n  ≥  0}, to show that [formula] for any l  ≥  0, δ > 0 and any [formula] and then to argue that [formula] for all δ > 0 using Lemma [\ref=prop:conv].

[formula] converges in probability to zero.

For l,s  ≥  0, define

[formula]

We show that for any μ > 0, and any [formula], [formula]. Then we can apply Lemma [\ref=prop:conv] to conclude that n- 1T(1)n converges in [formula]-probability to zero. As above, for any [formula] and by Proposition [\ref=propboundga] (i), we get

[formula]

The rest of the proof follows from the usual bounds on the V-moments.

n- 1T(4)n converges in probability to zero.

For l,s  ≥  0, define

[formula]

Again, for any [formula] and by Proposition [\ref=propboundga] (ii) we get

[formula]

The rest of the proof is similar to the above upon noticing that for κ > 1, aζκ - 1(a)  →  0 as a  →  0.

n- 1T(5)n converges [formula]-almost surely to zero.

By Proposition [\ref=propboundgaga] (ii), there exists a finite constant [formula] such that for any [formula], [formula] and any a∈(0,1 / 2]

[formula]

Therefore

[formula]

Let ε > 0. Since aζκ - 1(a)  →  0 as a  →  0, we can find a0∈(0,1 / 2] such that a0ζκ - 1(a0) < ε. Then for [formula]-almost every sample path

[formula]

Since ε > 0 is arbitrary and [formula], we are finished.

n- 1T(6)n converges in probability to zero.

We would like to apply the law of large number (Theorem [\ref=thm2]) to show that n- 1T(6)n converges to zero. By Proposition [\ref=propboundga] (ii), for any compact subset [formula] of Θ, [formula] and 2β  +  ακ < 1 - α. To check ([\ref=diminish]), it is enough to find ε > 0 such that

[formula]

But by Proposition [\ref=propboundgaga] (ii), there exists a finite constant [formula] such that for any [formula], [formula] and any a∈(0,1 / 2]

[formula]

We let a depend on k by taking a = ak, therefore

[formula]

We can then find ε > 0 such that nεanζκ - 1(an) + n- 1 + εa- 1n = O(n-  ε) and ([\ref=eqintermed:TBS2]) follows.

Proof of ([\ref=eq:TBS3])

It is suffices to show that

[formula]

in [formula]-probability. We will do so by applying Lemma [\ref=prop:conv] again. By a lemma due to Dvoretzky (Lemma 9 of [\cite=andrieuetal06])

[formula]

where

[formula]

It is thus enough to show that for any s,l  ≥  0, any [formula],

[formula]

Take p > 2 such that p(β  +  α / 2) < 1 - α. Then

[formula]

It follows that

[formula]

and since ρ < 1, we are done.

Proof of Proposition [\ref=ExMC]

Denote [formula], Ha(x,y) = ga(y) - Pga(x) and write g and H respectively when a = 0. Denote L2(π   ×   P) the L2-space with respect to the joint measure π(dx)P(x,dy) on [formula]. It is shown by [\cite=mw00] (Proposition 1) that if f∈L2(π) and [formula] then there exists [formula] such that [formula].

Under ([\ref=rateconv]) and with f∈LVβ, β∈[null] where ρ∈(0,1) is as in the statement of the Proposition. For 1  ≤  n  ≤  l and p  ≥  0, we introduce the partial sum

[formula]

where θ(x) = Υθ(x) - h(θ). Under B[\ref=B2], Υθ admits an approximate Poisson equation a for any j  ≥  1 and we have j(j) = (1 - aj)- 1aj(j,j) - Pjaj(j,j). Using this and following the same approach as in the proof of Theorem [\ref=thm1], we decompose [formula] as

[formula]

where

[formula]

[formula]

[formula]

[formula]

[formula]

[formula]

We deal with each of these terms using similar techniques as in the proofs of Theorem [\ref=thm1] and Theorem [\ref=thm3]. Some of the details are thus omitted. Let δ > 0 arbitrary.

On Term T(1)n,l

Take κ > 1 such that η  +  ακ < 1 - α. Then Proposition [\ref=propboundga] yields [formula] on [formula]. Then by Markov's inequality, we have

[formula]

The last inequality uses Proposition [\ref=lem:sumdrift] and Proposition [\ref=prop:useful] (i).

On Term T(2)n,l

Let ε > 0, κ > 1 such that ε∈(ρ,(1 - α)(η  +  κα)- 1 - 1). That is (1 + ε)(η  +  ακ) < 1 - α and ε  >  ρ. Then

[formula]

On Term T(3)n,l

Take κ > 1 and δ > 0 such that 2η  +  α(κ  +  δ) < 1 - α and η  +  α(κ  +  δ) < 1 / 2. By Proposition [\ref=propboundgaga] and B[\ref=B2] [formula]. Then by Markov's inequality

[formula]

From B[\ref=B2] and the structure of the algorithm we compute that

[formula]

It follows

[formula]

On Term T(4)n,l

By Markov's inequality,

[formula]

On Term T(5)n,l

Take κ∈(1,2) such that η  +  ακ < 1 - α. One can check as in Proposition [\ref=propboundgaga] that for any compact [formula] [formula]. And for [formula], [formula]. Hence, by Markov's inequality, we get:

[formula]

On Term T(6)n,l

Let κ > 1 such that 2(η  +  ακ / 2) < 1 - α. Consider the term [formula] so that [formula]. We note that Dj is a martingale difference and by Doob's inequality we get:

[formula]

By combining ([\ref=eq2:proofpropcvSA2])-([\ref=proofpropcvSA2eq2]) and ([\ref=eq1thm3]), we get ([\ref=proofpropcvSA2TBS]) as claimed.

Proof of the results of Section [\ref=sec:ex]

Proof of Proposition [\ref=proplyapEx]

The function a(θ) is of class C1. Hence by Assumption C[\ref=C1] and the Mean Value Theorem [formula] is not empty. It also follows from C[\ref=C1] that the function [formula] is bounded from below; so we can find K1 such that [formula]. Moreover (a(u) - )w'(θ) =  -  cosh (θ)(a(θ) - )2  ≤  0 with equality iif θ∈L. By Sard's theorem w(L) has an empty interior. Again from C[\ref=C1], it follows that L is included in a bounded interval of [formula] and since lim θ  →    ±    ∞w(θ) =   ∞  , we can find M0 such that [formula] and WM is bounded thus compact for any M > 0.

Proof of Proposition [\ref=propstabEx]

A straightforward calculation using the boundedness of [formula] implies that for any [formula],

[formula]

for some finite constant [formula]. It follows that

[formula]

We do a change of variable y = b(x) + eθ / 2z, where [formula] and using the boundedness of [formula], we get:

[formula]

where g is the density of the mean zero d-dimensional Gaussian distribution with covariance matrix Id. The stated result follows by an application of the Mean Value Theorem.

Acknowledgment: We are grateful to Michael Woodroofe for helpful discussions on martingale approximation techniques and to Shukri Osman for helpful conversations.