Notation Lemma Proposition Theorem Corollary Remark Example Assumption Algorithm Notation

[formula]

Linear Solving for Sign Determination

Introduction

Let [formula] be a real closed field. A basic problem in computational real algebraic geometry is, given a finite set [formula] and a finite list [formula] of polynomials in [formula], to determine the list of sign conditions realized by P on Z.

A general scheme in most algorithms dealing with the sign determination problem consists on the computation of the Tarski-query (also known as Sturm-query) for Z of many products of the given polynomials, in order to relate through a linear system this quantities with the number of elements in Z satisfying each possible sign condition. For instance, the naive approach were the Tarski-query of each of the 3s polynomials of type [formula] with ei  =  0,1,2 for [formula] is computed, leads to a linear system of size 3s  ×  3s. Nevertheless, if m  =    #  Z at most m sign conditions will be feasible, and then at most m of the coordinates of the solution of the considered linear system will be different from 0.

In [\cite=BeKoRe], the exponential complexity arising from the number of Tarski-query computations and the resolution of the linear system in the approach described above is avoided. This is achieved by means of a recursive algorithm where the list P is divided in two sublists, the feasible sign conditions for each sublist is computed, and then this information is combined. Such combination is obtained by computing at most m2 Tarski-queries and solving a linear system of size at most m2  ×  m2.

In [\cite=RoySzp], [\cite=Cann] and [\cite=BasuPollackRoy], the methods in [\cite=BeKoRe] are further developed. In [\cite=RoySzp], an algorithm is given where the number of points in Z satisfying each feasible sign condition for the list [formula] is computed sequentially for [formula], following the idea that, at each step, each feasible sign condition for [formula] may be extended in at most 3 ways. To deal with the addition of the polynomial Pi to the considered list, at most 2m Tarski-queries are computed and a linear system of size at most 3m  ×  3m is solved. In [\cite=Cann], a more explicit way to choose the polynomials whose Tarski-query is to be computed is given. In [\cite=BasuPollackRoy], also the feasible sign conditions for Pi on Z are computed at step i, in order to discard beforehand some non-feasible sign conditions for [formula] on Z extending feasible sign conditions for [formula] on Z.

Depending on the setting, the Tarski-queries may be computed in different ways, taking a different number of operations in the field [formula], or in a proper domain D containing the coefficients of the polynomials in P and polynomials defining the finite set Z. As treated with general methods, the linear solving part can be done within O(m2.376) operations in [formula] (see [\cite=CopWin]). In [\cite=Cann], where the univariate case is considered, the cost of linear solving dominates the overall complexity. In this work, we fix this situation by giving a specific method to solve with quadratic complexity the linear systems involved (Theorem [\ref=Algo_res]). Even though this method can be used as a subroutine whenever these systems arise, we emphasize the result of its use in the univariate case. Following the complexity analisis in [\cite=Cann] we obtain:

Given [formula], [formula], deg Pi  ≤  d for [formula], the feasible sign conditions for [formula] on {P0  =  0} (and the number of elements in {P0  =  0} satisfying each of these sign conditions) can be computed within O(sd2 log 3d) operations in R. Moreover, if P0 has m real roots, this can be done within O(smd log (m) log 2(d)) operations in R.

The motivation for this work also comes from probabilistic algorithms to determine feasible sign conditions in the multivariate case ([\cite=JePeSa]), which produce a geometric resolution of a set of sample points. In this reduction to the univariate case, the degree of the polynomials obtained equals the Bézout number of some auxiliary polynomial systems, and the complexity of the algorithm depends quadratically on this quantity. Using Corollary [\ref=coro_emp], the treatment of the univariate case to find the feasible sign conditions for the original multivariate polynomials can be done without increasing the overall complexity.

Preliminaries and Notation

We will follow mostly the notation in [\cite=BasuPollackRoy]. In this reference the approach described in Section [\ref=intro] is followed with the minor difference that the polynomials [formula] are introduced one at each step from back to front; therefore, the notation is adapted to this order.

For [formula], we call Pi the list [formula], and, at step i, we are given a list [formula] of elements in {0,1, - 1}Pi with [formula] ([formula]) containing, may be properly, all the feasible sign condition for Pi on Z and we are to compute the exact list of feasible sign condition for Pi on Z and the number of elements in Z satisfying each of these sign conditions. Note that the inequality r  ≤  3m holds at every step.

For [formula], we note c(P  =  0,Z),c(P  >  0,Z) and c(P  <  0,Z) the number of elements in Z satisfying the condition P  =  0,P  >  0 and P  <  0 respectively. Recall that the Tarski-query of a polynomial P for Z is the number

[formula]

For σ∈{0,1, - 1}Pi, we note c(σ,Z) the number of elements x in Z satisfying sign(Pj(x))  =  σj for [formula] and, for a list [formula] of elements in {0,1, - 1}Pi, we note c(Σ',Z) the vector whose components are [formula]. We also note σ̂ the element of {0,1, - 1}Pi + 1 obtained from σ by deleting the coordinate corresponding to Pi and ' the list [formula].

We divide the given list Σ in 12 ordered sublists as follows: for [formula] with [formula] and for b∈B, the list [formula] is composed by those σ∈Σ such that σ(Pi)  =  b and the set

[formula]

equals B. For simplicity, we note Σ0,Σ1 and Σ- 1 for Σ00,Σ11 and Σ- 1- 1 respectively. In addition, since [formula] is the same list for every b∈B, we note [formula] for any such list.

We also divide the list Σ in 3 ordered sublists as follows: Σ(1) is the merge of lists Σ0,Σ1,Σ- 1, Σ001, Σ00 - 1, Σ- 11 - 1 and Σ001 - 1, Σ(2) is the merge of lists Σ101,Σ- 10 - 1,Σ11 - 1 and Σ101 - 1 and Σ(3) is the same list than Σ- 101 - 1.

Consider also the list [formula] of elements in {0,1,2}Pi (which represents a list of multidegrees) defined recursively by:

[formula]

For a list [formula] of elements in {0,1,2}Pi and a list [formula] of elements in {0,1, - 1}Pi, we note [formula] the [formula] matrix defined by

[formula]

for [formula] and [formula], with the understanding that 00  =  1.

Following this notation, we have that:

[formula]

and the r  ×  r matrix Mat(Ada(Σ),Σ) is invertible (see [\cite=Cann] or [\cite=BasuPollackRoy]).

For a matrix M with rows indexed by a list A of multidegrees and columns indexed by a list Σ' of sign conditions, and for any sublists A' of A and Σ'' of Σ', we will note, if convenient, MA',MΣ'' and MA',Σ'' the submatrices obtained from M by taking only the rows in A', only the columns in Σ'', and only the rows in A' and the columns in Σ'' respectively. We will use a similar notation for vectors whose coordinates are indexed by a list of multidegrees or a list of sign conditions.

The specific method for linear solving

Note that a different order in Σ would lead to a permutation of columns in the matrix [formula] and the elements of the vector c(Σ,Z). To explain our method in a simpler way, we will suppose that we change the order in Σ in such a way that we find first the elements in Σ(1), then those in Σ(2) and finally those in Σ(3). Nevertheless, this change of order is not actually necessary in the execution of the linear solving algorithm.

If i  =  s, we have that either r  =  1; r  =  2 and Σ  =  0,1; r  =  2 and Σ  =  0, - 1; r  =  2 and Σ  =  1, - 1 or r  =  3. Depending on which of these conditions holds, [formula] is one of the following matrices:

[formula]

If i  <  s, consider the matrices [formula], [formula] and [formula]. Then, [formula] is the matrix:

[formula]

where:

M1' is the matrix formed with the columns of M1 corresponding to sign conditions in 01,0 - 1,1 - 1 and 01 - 1,

M1'' is the matrix formed with the columns of M1 corresponding to sign conditions in 01 - 1,

2 is the matrix obtained from M2 multiplying by - 1 the columns corresponding to sign conditions in 0 - 1,

M2' is the matrix formed with the columns of M2 corresponding to sign conditions in 01 - 1,

[formula] and [formula].

The only non-zero columns in matrices X and Y are those corresponding to sign conditions in Σ1,Σ- 1 and Σ- 11 - 1.

The following relations are satisfied:

[formula]

Since (3) is included in (2), Ada((3)) is included in Ada((2)) and then we have:

[formula]

In order to describe our method to solve linear system ([\ref=igualdad]), we define the following matrices:

[formula]

[formula]

[formula]

where I1,I2 and I3 denote the identity matrices which size is the length of Σ(1),Σ(2) and Σ(3) respectively and, if we index the columns of I1,I2 and I3 with (1),(2) and (3):

Ĩ2 is the matrix obtained from I2 multiplying by - 1 the columns corresponding to sign conditions in 0 - 1 and by [formula] the columns corresponding to sign conditions in 1 - 1,

[formula] is the matrix obtained from Z multiplying by 0 the columns corresponding to sign conditions in Σ11 - 1,

I2' is the matrix formed with the columns of I2 corresponding to sign conditions in 01 - 1,

I1' is the matrix formed with the columns of I1 corresponding to sign conditions in 01,0 - 1,1 - 1 and 01 - 1,

I1'' is the matrix formed with the columns of I1 corresponding to sign conditions in 01 - 1.

The matrix Mat(Ada(Σ),Σ)- 1 equals the product [formula].

First, note that

[formula]

Because of the first item of Remark [\ref=relabloq] we can conclude that

[formula]

and using the first and second items of Remark [\ref=relabloq], we can conclude that

[formula]

where [formula] is the matrix obtained from M2 multiplying by - 1 the columns corresponding to sign conditions in 0 - 1 and by 2 the columns corresponding to sign conditions in 1 - 1. With all these relations, the proof can be done by simple computation of the product [formula].

The decomposition of [formula] as a product of several matrices in Proposition [\ref=descompo] leads us to the following recursive algorithm:

Algorithm: Auxlinsolve

Input: [formula].

Output: c(Σ,Z).

Procedure:

If i  =  s, return [formula].

If i  <  s:

Initialize [formula].

cΣ(1)  =   Auxlinsolve((1),cΣ(1)).

[formula]

[formula]

cΣ(2)  =   Auxlinsolve((2),cΣ(2)).

cΣ- 10 - 1  =    -  cΣ- 10 - 1;

[formula].

[formula].

cΣ(3)  =   Auxlinsolve((3),cΣ(3)).

[formula].

cΣ101 - 1  =  cΣ101 - 1  +  cΣ(3).

cΣ001  =  cΣ001  -  cΣ101;

cΣ00 - 1  =  cΣ00 - 1  -  cΣ- 101;

cΣ- 11 - 1  =  cΣ- 11 - 1  -  cΣ11 - 1;

cΣ001 - 1  =  cΣ001 - 1  -  cΣ101 - 1  -  cΣ(3).

Return c.

Algorithm Auxilinsolve solves linear system ([\ref=igualdad]) within 2r2 operations in [formula].

The correctness of the algorithm follows since, for [formula], after Step 2.j we have computed

[formula]

To bound the number of operations needed, we proceed by induction on i. If i  =  s, the result follows, since the inverse of the 5 possible matrices [formula] is pre-computed and the product by [formula] takes r(2r - 1) operations in [formula].

Suppose now i  <  s. For [formula] note by [formula] the size of the list [formula] for any b∈B. Using the inductive hypothesis, the number of operations in each step is bounded in the following way:

2(r0  +  r1  +  r- 1  +  r01  +  r0 - 1  +  r1 - 1  +  r01 - 1)2.

2(r01  +  r0 - 1  +  r1 - 1  +  2r01 - 1)(r1  +  r- 1  +  r1 - 1).

2(r01  +  r0 - 1  +  r1 - 1  +  r01 - 1)2.

r0 - 1  +  r1 - 1.

2r01 - 1(r01  +  r0 - 1  +  r01 - 1).

2r201 - 1.

r01 - 1.

r01 - 1.

r01  +  r0 - 1  +  r1 - 1  +  2r01 - 1.

Since the sum of all this numbers is always lower than or equal to 2r2  =  2(r0  +  r1  +  r- 1  +  2r01  +  2r0 - 1  +  2r1 - 1  +  3r01 - 1)2, the result follows.

The third item of Remark [\ref=relabloq] implies that Step 2.2 could be replaced in the following way:

v  =  Mat(1  ×  Ada((2)),Σ1)cΣ1;

v'  =  Mat(1  ×  Ada((2)),Σ- 1)cΣ- 1;

v''  =  Mat(1  ×  Ada((2)),Σ- 11 - 1)cΣ- 11 - 1;

cΣ(2)  =  cΣ(2)  -  v  -  v'  -  v'';

cΣ(3)  =  cΣ(3)  -  v1  ×  Ada(Σ(3))  +  v'1  ×  Ada(Σ(3))  +  v''1  ×  Ada(Σ(3)).

which takes a smaller number of operations than Step 2.2.