Musical Genres: Beating to the Rhythms of Different Drums

Introduction

Musical databases have increased in number and size continuously, paving the way to large amounts of online music data, including discographies, biographies and lyrics. This happened mainly as a consequence of musical publishing being absorbed by the Internet, as well as the restoration of existing analog archives and advancements of web technologies. As a consequence, more and more reliable and faster tools for music content analysis, retrieval and description, are required, catering for browsing, interactive access and music content-based queries. Even more promising, these tools, together with the respective online music databases, have open new perspectives to basic investigations in the field of music.

Within this context, music genres provide particularly meaningful descriptors given that they have been extensively used for years to organize music collections. When a musical piece becomes associated to a genre, users can retrieve what they are searching in a much faster manner. It is interesting to notice that these new possibilities of research in music can complement what is known about the trajectories of music genres, their history and their dynamics [\cite=LENA2008]. In an ethnographic manner, music genres are also particularly important because they express the general identity of the cultural foundations in which they are comprised [\cite=Holt2007]. Music genres are part of a complex interplay of cultures, artists and market strategies to define associations between musicians and their works, making the organization of music collections easier [\cite=SCARINGELLA2006]. Therefore, musical genres are of great interest because they can summarise some shared characteristics in music pieces. As indicated by [\cite=AUCOUNTURIER2005], music genre is probably the most common description of music content, and its classification represents an appealing topic in Music Information Retrieval (MIR) research.

Despite their ample use, music genres are not a clearly defined concept, and their boundaries remain fuzzy [\cite=SCARINGELLA2006]. As a consequence, the development of such taxonomy is controversial and redundant, representing a challenging problem. Pachet and Cazaly [\cite=PACHET2000] demonstrated that there is no general agreement on musical genre taxonomies, which can depend on cultural references. Even widely used terms such as rock, jazz, blues and pop are not clear and firmly defined. According to [\cite=SCARINGELLA2006], it is necessary to keep in mind what kind of music item is being analysed in genre classification: a song, an album, or an artist. While the most natural choice would be a song, it is sometimes questionable to classify one song into only one genre. Depending on the characteristics, a song can be classified into various genres. This happens more intensively with albums and artists, since nowadays the albums contain heterogeneous material and the majority of artists tend to cover an ample range of genres during their careers. Therefore, it is difficult to associate an album or an artist with a specific genre. Pachet and Cazaly [\cite=PACHET2000] also mention that the semantic confusion existing in the taxonomies can cause redundancies that probably will not be confused by human users, but may hardly be dealt with by automatic systems, so that automatic analysis of the musical databases becomes essential. However, all these critical issues emphasize that the problem of automatic classification of musical genres is a nontrivial task. As a result, only local conclusions about genre taxonomy are considered [\cite=PACHET2000].

As other problems involving pattern recognition, the process of automatic classification of musical genres can usually be divided into the following three main steps: representation, feature extraction and the classifier design [\cite=COSTA2001] [\cite=DUDA2001]. Music information can be described by symbolic representation or based on acoustic signals [\cite=CATALTEPE2007]. The former is a high-level kind of representation through music scores, such as MIDI, where each note is described in terms of pitch, duration, start time and end time, and strength. Acoustic signals representation is obtained by sampling the sound waveform. Once the audio signals are represented in the computer, the objective becomes to extract relevant features in order to improve the classification accuracy. In the case of music, features may belong to the main dimensions of it including melody, timbre, rhythm and harmony.

After extracting significant features, any classification scheme may be used. There are many previous works concerning automatic genre classification in the literature [\cite=LI2009] [\cite=MOSTAFA2009] [\cite=WANG2008] [\cite=SONG2008] [\cite=PANAGAKIS2008] [\cite=HONG2008] [\cite=HOLZAPFEL2007] [\cite=CATALTEPE2007] [\cite=SILLA2007] [\cite=SCARINGELLA2005] [\cite=SHAO2004] [\cite=BURRED2003].

An innovative approach to automatic genre classification is proposed in the current work, in which musical features are referred to the temporal aspects of the songs: the rhythm. Thus, we propose to identify the genres in terms of their rhythmic patterns. While there is no clear definition of rhythm [\cite=SCARINGELLA2006], it is possible to relate it with the idea of temporal regularity. More generally speaking, rhythm can be simply understood as a specific pattern produced by notes differing in duration, pause and stress. Hence, it is simpler to obtain and manipulate rhythm than the whole melodic content. However, despite its simplicity, the rhythm is genuine and intuitively characteristic and intrinsic to musical genres, since, for example, it can be use to distinguish between rock music and rhythmically more complex music, such as salsa. In addition, the rhythm is largely independent on the instrumentation and interpretation.

A few related works that use rhythm as features in automatic genre recognition can be found in the literature. The work of Akhtaruzzaman [\cite=AKHTARUZZAMAN2008], in which rhythm is analysed in terms of mathematical and geometrical properties, and then fed to a system for classification of rhythms from different regions. Karydis [\cite=KARYDIS2006] proposed to classify intra-classical genres with note pitch and duration features, obtained from their histograms. In [\cite=GOUYON2005] [\cite=GOUYON2004], a review of existing automatic rhythm description systems are presented. The authors say that despite the consensus on some rhtyhm concepts, there is not a single representation of rhythm that would be applicable for different applications, such as tempo and meter induction, beat tracking, quantization of rhythm and so on. They also analysed the relevance of these descriptors by mesuring their performance in genre classification experiments. It has been observed that many of these approaches lack comprehensiveness because of the relatively limited rhythm representations which have been adopted [\cite=SCARINGELLA2006].

In the current study, an objective and systematic analysis of rhythm is provided. The main motivation is to study similar and different characteristics of rhythms in terms of the occurrence of sequences of events obtained from rhythmic notations. First, the rhythm is extracted from MIDI databases and represented as graphs or networks [\cite=ALBERT2002] [\cite=NEWMAN2003]. More specifically, each type of note (regarding their duration) is represented as a node, while the sequence of notes define the links between the nodes. Matrices of probability transition are extracted from these graphs and used to build a Markov model of the respective musical piece. Since they are capable of systematically modeling the dynamics and dependencies between elements and subelements [\cite=BOOTH1967], Markov models are frequently used in temporal pattern recognition applications, such as handwriting, speech, and music [\cite=ROHRMEIER2006]. Supervised and an unsupervised approaches are then applied which receive as input the properties of the transition matrices and produce as output the most likely genre. Supervised classification is performed with the Bayesian classifier. For the unsupervised approach, a taxonomy of rhythms is obtained through hierarchical clustering. The described methodology is applied to four genres: blues, bossa nova, reggae and rock, which are well-known genres representing different tendencies. A series of interesting findings are reported, including the ability of the proposed framework to correctly identify the musical genres of specific musical pieces from the respective rhythmic information.

This paper is organized as follows: section [\ref=sec:MatAndMethods] describes the methodology, including the classification methods; section [\ref=sec:ResAndDisc] presents the obtained results as well as their discussion, and section [\ref=sec:Conclusions] contains the concluding remarks and future works.

Materials and Methods

Some basic conceps about complex networks as well as the proposed methodology are presented in this section.

Systems Representation by Complex Networks

A complex network is a graph exhibiting intricate structure when compared to regular and uniformly random structures. There are four main types of complex networks: weighted and unweighted digraphs and weighted and unweighted graphs. The operations of simmetry and thresholding can be used to transform a digraph into a graph and a weighted graph (or weighted digraph) into an unweighted one, respectively [\cite=COSTA2007]. A weighted digraph (or weighted direct graph) G can be defined by the following elements:

- Vertices (or nodes). Each vertex is represented by an integer number i = 1,2,...,N; N(G) is the vertex set of digraph G and N indicates the total number of vertices [formula].

- Edges (or links). Each edge has the form (i,j) indicating a connection from vertex i to vertex j. The edge set of digraph G is represented by ε(G), and M is the total number of edges.

- The mapping ω:ε(G)  ↦  R, where R is the set of weight values. Each edge (i,j) has a weight ω(i,j) associated to it. This mapping does not exist in unweighted digraphs.

Undirected graphs (weighted or unweighted) are characterized by the fact that their edges have not orientation. Therefore, an edge (i,j) in such a graph necessarily implies a connection from vertex i to vertex j and from vertex j to vertex i. A weighted digraph can be represented in terms of its weight matrices W. Each element of W, wji, associates a weight to the connection from vertex i to vertex j. The table [\ref=tab:BasicConcepts] summarizes some fundamental concepts about graphs and digraphs [\cite=COSTA2007].

For weighted networks, a quantity called strength of vertex i is used to express the total sum of weights associated to each node. More specifically, it corresponds to the sum of the weights of the respective incoming edges ([formula]) (in-strength) or outgoing edges ([formula]) (out-strength) of vertex i.

Another interesting measurement of local connectivity is the clustering coefficient. This feature reflects the cyclic structure of networks, i.e. if they have a tendency to form sets of densely connected vertices. For digraphs, one way to calculate the clustering coefficient is: let mi be the number of neighbors of vertex i and li be the number of connections between the neighbors of vertex i; the clustering coefficient is obtained as cc(i)  =  li  /  mi(mi  -  1).

Data Description

In this work, four music genres were selected: blues, bossa nova, reggae and rock. These genres are well-known and represent distinct major tendencies. Music samples belonging to these genres are available in many collections in the Internet, so it was possible to select one hundred samples to represent each one of them. These samples were downloaded in MIDI format. This event-like format contains instructions (such as notes, instruments, timbres, rhythms, among others) which are used by a synthesizer during the creation of new musical events [\cite=MIRANDA2001]. The MIDI format can be considered a digital musical score in which the instruments are separated into voices.

In order to edit and analyse the MIDI scores, we applied the software for music composition and notation called Sibelius (). For each sample, the voice related to the percussion was extracted. The percussion is inherently suitable to express the rhythm of a piece. Once the rhythm is extracted, it becomes possible to analyse all the involved elements. The MIDI Toolbox for Matlab was used [\cite=Eerola2004]. This Toolbox is free and contains functions to analyse and visualize MIDI files in the Matlab computing environment. When a MIDI file is read with this toolbox, a matrix representation of note events is created. The columns in this matrix refer to many types of information, such as: onset (in beats), duration (in beats), MIDI channel, MIDI pitch, velocity, onset (in seconds) and duration (in seconds). The rows refer to the individual note events, that is, each note is described in terms of its duration, pitch, and so on.

Only the note duration (in beats) has been used in the current work. In fact, the durations of the notes, respecting the sequence in which they occur in the sample, are used to create a digraph. Each vertex of this digraph represents one possible rhythm notation, such as, quarter note, half note, eighth note, and so on. The edges reflect the subsequent pairs of notes. For example, if there is an edge from vertex i, represented by a quarter note, to a vertex j, represented by an eighth note, this means that a quarter note was followed by an eighth note at least once. The thicker the edges, the larger is the strength between these two nodes. Examples of these digraphs are showed in Figure [\ref=fig:exemplosredes]. Figure [\ref=fig:exemplosredes:a] depicts a blues sample represented by the music How blue can you get by BB King. A bossa nova sample, namely the music Fotografia by Tom Jobim, is illustrated in [\ref=fig:exemplosredes:b]. Figure [\ref=fig:exemplosredes:c] illustrates a reggae sample, represented by the music Is this Love by Bob Marley. Finally, Figure [\ref=fig:exemplosredes:d] shows a rock sample, corresponding the music From Me To You by The Beatles.

Feature Extraction

Extracting features is the first step of most pattern recognition systems. Each pattern is represented by its d features or attributes in terms of a vector in a d- dimensional space. In a discrimination problem, the goal is to choose features that allow the pattern vectors belonging to different classes to occupy compact and distinct regions in the feature space, maximizing class separability. After extracting significant features, any classification scheme may be used. In the case of music, features may belong to the main dimensions of it including melody, timbre, rhythm and harmony.

Therefore, one of the main features of this work is to extract features from the digraphs and use them to analyse the complexities of the rhythms, as well as to perform classification tasks. For each sample, a digraph is created as described in the previous section. All digraphs have 18 nodes, corresponding to the quantity of rhythm notation possibilities concerning all the samples, after excluding those that hardly ever happens. This exclusion was important in order to provide an appropriate visual analysis and to better fit the features. In fact, avoiding features that do not significantly contribute to the analysis reduces data dimension, improves the classification performance through a more stable representation and removes redundant or irrelevant information (in this case, minimizes the occurrence of null values in the data matrix).

The features are associated with the weight matrix W. As commented in section [\ref=ssec:CompNetworks], each element in W, wij, indicates the weight of the connection from vertex j to i, or, in other words, they are meant to represent how often the rhythm notations follow one another in the sample. The weight matrix W has 18 rows and 18 columns. The matrix W is reshaped by a 1 x 324 feature vector. This is done for each one of the genre samples. However, it was observed that some samples even belonging to different genres generated exactly the same weight matrix. These samples were excluded. Thereby, the feature matrix has 280 rows (all non-excluded samples), and 324 columns (the attributes).

An overview of the proposed methodology is illustrated in Figure [\ref=fig:blockdiagram]. After extracting the features, a standardization transformation is done to guarantee that the new feature set has zero mean and unit standard deviation. This procedure can significantly improve the resulting classification. Once the normalized features are available, the structure of the extracted rhythms can be analysed by using two different approaches for features analysis: PCA and LDA. We also compare two types of classification methods: Bayesian classifier (supervised) and hierarchical clustering (unsupervised). PCA and LDA are described in section [\ref=subsec:FeatureAnalysis] and the classification methods are described in section [\ref=subsec:ClassifMethodology].

Feature Analysis and Redundancy Removing

Two techniques are widely used for feature analysis [\cite=DEVIJVER1981] [\cite=DUDA2001] [\cite=WEBB2002]: PCA (Principal Components Analysis) and LDA (Linear discriminant Analysis). Basically, these approaches apply geometric transformations (rotations) to the feature space with the purpose of generating new features based on linear combinations of the original ones, aiming at dimensionality reduction (in the case of PCA) or to seek a projection that best separates the data (in the case of LDA). Figure[\ref=fig:pcalda] illustrates the basic principles underlying PCA and LDA. The direction x' (obtained with PCA) is the best one to represent the two classes with maximum overall dispersion. However, tt can be observed that the densities projected along direction x' overlap one another, making these two classes inseparable. Differently, if direction y', obtained with LDA, is chosen, the classes can be easily separated. Therefore, it is said that the directions for representation are not always also the best choice for classification, reflecting the different objectives of PCA and LDA. [\cite=Therrien1989]. [\ref=subsec:PCA] and [\ref=subsec:LDA] give more details about these two techniques.

Classification Methodology

Basically, to classify means to assign objects to classes or categories according to the properties they present. In this context, the objects are represented by attributes, or feature vectors. There are three main types of pattern classification tasks: imposed criteria, supervised classification and unsupervised classification. Imposed criteria is the easiest situation in classification, once the classification criteria is clearly defined, generally by a specific practical problem. If the classes are known in advance, the classification is said to be supervised or by example, since usually examples (the training set) are available for each class. Generally, supervised classification involves two stages: learning, in which the features are tested in the training set; and application, when new entities are presented to the trained system. There many approaches involving supervised classification. The current study applied the Bayesian classifier through discriminant functions ([\ref=sec:ALinearDiscFunc]) in order to perform supervised classification. The Bayesian classifier is based on the Bayesian Decision Theory and combines class conditional probability densities (likelihood) and prior probabilities (prior knowledge) to perform classification by assigning each object to the class with the maximum a posteriori probability.

In unsupervised classification, the classes are not known in advance, and there is not a training set. This type of classification is usually called clustering, in which the objects are agglomerated according to some similarity criterion. The basic principle is to form classes or clusters so that the similarity between the objects in each class is maximized and the similarity between objects in different classes minimized. There are two types of clustering: partitional (also called non-hierarchical) and hierarchical. In the former, a fixed number of clusters is obtained as a single partition of the feature space. Hierarchical clustering procedures are more commonly used because they are usually simpler [\cite=DUDA2001] [\cite=COSTA2001] [\cite=WEBB2002] [\cite=THEODORIDIS2006]. The main difference is that instead of one definite partition, a series of partitions are taken, which is done progressively. If the hierarchical clustering is agglomerative (also known as bottom-up), the procedure starts with N objects as N clusters and then successively merges the clusters until all the objects are joined into a single cluster (please refer to [\ref=sec:HierClust] for more details about agglomerative hierarchical clustering). Divisive hierarchical clustering (top-down) starts with all the objects as one single cluster, and splits it into progressively finer subclusters.

Performance Measures for Classification

To objectively evaluate the performance of the supervised classification it is necessary to use quantitative criteria. Most used criteria are the estimated classification error and the obtained accuracy. Because of its good statistical properties, as, for example, be asymptotically normal with well defined expressions to estimate its variances, this study also adopted the Cohen Kappa Coefficient [\cite=COHEN1960] as a quantitative measure to analyse the performance of the proposed method. Besides, the kappa coefficient can be directly obtained from the confusion matrix [\cite=CONGALTON1991] ([\ref=sec:AKappa]), easily computed in supervised classification problems. The confusion matrix is defined as:

[formula]

where each element cij represents the number of objects from class i classified as class j. Therefore, the elements in the diagonal indicate the number of correct classifications.

Results and Discussion

As mentioned before, four musical genres were used in this study: blues, bossa nova, reggae and rock. It was selected music art works from diverse artists, as presented in Tables [\ref=tab:BluesAndBossa] and [\ref=tab:ReggaeAndRock]. Different colors were chosen to represent the genres (color red for genre blues, green for bossa nova, cyan for reggae and pink for rock), in order to provide a better visualization and discussion of the results.

Once we want to reduce data dimensionality, it is necessary to set the suitable number of principal components that will represent the new features. Not surprisingly, in a high dimensional space the classes can be easily separated. On the other hand, high dimensionality increases complexity, making the analysis of both extracted features and classification results a difficult task. One approach to get the ideal number of principal components is to verify how much of the data variance is preserved. In order to do so, the l first eigenvalues (l is the quantity of principal components to be verified) are summed up and the result is divided by the the sum of all the eigenvalues. If the result of this calculation is a value equal or greater than 0.75, it is said that these number of components (or new features) preserves at least 75% of the data variance, which is often enough for classification purposes. When PCA was applied to the normalized rythm features, as illustrated in Figure [\ref=fig:pca], it was observed that 20 principal components preserved 76% of the variance of the data. That is, it is possible to reduce the data dimensionality from 364-D to 20-D without a significant loss of information. Nevertheless, as will be shown in the following, depending on the classifier and how the classification task was performed, different number of components were required in each situation in order to achieve suitable results. Despite the fact of preserving only 32% of the variance, Figure [\ref=fig:pca] shows the first three principal components, that is, the first three new features obtained with PCA. Figure [\ref=fig:pca12] shows the first and second features and Figure [\ref=fig:pca13] shows the first and third features. It is noted that the classes are completely overlapped, making the problem of automatic classification a nontrivial task.

In all the following supervised classification tasks, re-substitution means that all objects from each class were used as the training set (in order to estimate the parameters) and all objects were used as the testing set. Hold-out 70%-30% means that 70% of the objects from each class were used as the training set and 30% (different ones) for testing. Finally, in hold-out 50%-50%, the objects were separated into two groups: 50% for training and 50% for testing.

The kappa variance is strongly related to its accuracy, that is, how reliable are its value. The higher is its variance, the lower is its accuracy. Once the kappa coefficient is a statistics, in general, the use of large datasets improves its accuracy by making its variance smaller. This concept can be observed in the results. The smaller variance occurred in the re-substitution situation, in which all samples constitute the testing set. This indicates that re-substitution provided the best kappa accurary in the experiments. On the other hand, hold-out 70%-30% provided the higher kappa variance, once only 30% of the samples establishes the testing set.

The results obtained by the Quadratic Bayesian Classifier using PCA are shown in Table [\ref=tab:PCAQBayes] in terms of kappa, its variance, the accurary of the classification and the overall performance according to the value of kappa.

Table [\ref=tab:PCAQBayes] also indicates that the performance was not satisfactory for the Hold-Out (70%-30%) and Hold-Out (50%-50%). As the PCA is a not supervised approach, the parameter estimation performance (of covariance matrices for instance) is strongly degraded because of the small sample size problem.

The confusion matrix for the re-substitution classification task in Table [\ref=tab:PCAQBayes] is illustrated in Table [\ref=tab:MatConfPCA]. All reggae samples were classified correctly. In addition, many samples from the other classes were classified as reggae.

Table [\ref=tab:WrongsPCA] presents the misclassified art works of the confusion matrix in Table [\ref=tab:MatConfPCA].

With the purpose of comparing two different classifiers, the obtained results by the Linear Bayesian Classifier using PCA are shown in Table [\ref=tab:PCALBayes], again, in terms of kappa, its variance, the accurary of the classification and the overal performance according to its value. The performance of the Hold-Out (70%-30%) and Hold-Out (50%-50%) classification task increased slightly, mainly due to the fact that here a unique covariance matrix is estimated using all the samples in the dataset.

Figure [\ref=fig:Kappa] depicts the value of kappa depending on the quantity of principal components used in the Quadratic and Linear Bayesian Classifier. The last value of each graphic makes it clear that from this value onwards the classification can not be done due to singularity problems involving the inversion of the covariance matrices (curse of dimensionality). It can be observed that this singularity threshold is different in each situation. However, for the quadratic classifier this value is in the range of about 40-55 components; while, for the linear classifier, is in the range of about 86-115 components. The smaller quantity for the quadratic classifier can be explained by the fact that there are four covariance matrices, each one estimated from the samples for one respective class. As there are 70 samples in each class, singularity problems will occur in a smaller dimensional space when compared to the linear classifier, that uses all the 280 samples to estimate one unique covariance matrix. Therefore, the ideal number of principal components allowing the highest value of kappa should be those circled in red in Figure [\ref=fig:Kappa].

Keeping in mind that the problem of automatic genre classification is a nontrivial task, that in this study only one aspect of the rhythm is been analysed (the occurrence of the ryhthm notations), and that PCA is an unsupervised approach for feature extraction, the correct classifications presented in Tables [\ref=tab:PCAQBayes] and [\ref=tab:PCALBayes] for the re-substitution situation corroborate strongly the viability of the proposed methodology. In spite of the complexity of comparing differents proposed approaches to automatic genre classification discussed in the Introduction, these accuracy values are very close or even superior when compared to previous works [\cite=MOSTAFA2009] [\cite=WANG2008] [\cite=SONG2008] [\cite=HOLZAPFEL2007] [\cite=SCARINGELLA2006].

Similarly, Figure [\ref=fig:lda] shows the three components, namely the three new features obtained with LDA. As mentioned before, LDA approach has a restriction of obtaining only C - 1 nonzero eigenvalues, where C is the number of class. Therefore, only three components are computed. Once it is a supervised approach and the main goal is to maximize class separability, the four classes in Figure [\ref=fig:lda12] and Figure [\ref=fig:lda13] are clearer than in PCA, although still involving substantial overlaps. This result corroborates that automatic classification of musical genres is not a trivial task.

Table [\ref=tab:LDAQBayes] presents the results obtained by the Quadratic Bayesian Classifer using LDA. Differently from PCA, the use of hold-out (70%-30%) and hold-out (50%-50%) provided good results, what is notable and reflects the supervised characteristic of LDA, which makes use of all discriminant information available in the feature matrix.

Despite the value of kappa and its variance being the same using LDA with re-substitution and PCA with re-substitution, the two confusion matrix are strongly distinct each other. In the first case, demostrated in Table [\ref=tab:MatConfLDA], the misclassified art works are well distributed among the four classes, while with PCA (Table [\ref=tab:MatConfPCA]) they are concentrated in one class, represented by the reggae genre. The results obtained with LDA technique are particularly promising because they reflect the nature of the data. Although widely used, terms such as rock, reggae or pop often remain loosely defined [\cite=SCARINGELLA2006]. Yet, it is worthwhile to remember that the intensity of the beat, which is a very important aspect of the rhythm has not been considered in this work. This means that analysing rhythm only through notations, as currently proposed, could poise difficulties even for human experts. These misclassified art works have similar properties described in terms of rhythm notations and, as a result, they generate similar weight matrices. Therefore, the proposed methodology, although requiring some complementations, seems to be a significant contribution towards the development of viable alternative approach to automatic genre classification.

The misclassified art works of the confusion matrix in Table [\ref=tab:MatConfLDA] are identified in Table [\ref=tab:WrongsLDA].

The results for the Linear Bayesian Classifier using LDA are shown in Table [\ref=tab:LDALBayes]. In fact, they are closely similar to those obtained by the Quadratic Bayesian Classifier (Table [\ref=tab:LDAQBayes]).

As mentioned in section [\ref=subsec:LDA], linear discriminant analysis also allows us to quantify the intra and interclass dispersion of the feature matrix through functionals such as the trace and determinant computed from the scatter matrices [\cite=FUKUNAGA1990]. The overall intraclass scatter matrix, hence Sintra; the intraclass scatter matrix for each class, hence SintraBlues, SintraBossaNova, SintraReggae and SintraRock; the interclass scatter matrix, hence, Sinter; and the overall separability index, hence [formula], were computed. Their respective traces are:

trace(Sintra) =   499.526 trace(SintraBlues) =   138.615 trace(SintraBossaNova) =   119.302 trace(SintraReggae) =   98.327 trace(SintraRock) =   143.280 trace(Sinter) =   21.598 [formula] =   3.779

Two important observations are worth mentioning. First, these traces emphasise the difficulty of this classification problem: the traces of the intraclass scatter matrices are too high, and the trace of the interclass scatter matrix together with the overal separability index, too small. This confirms that the four classes are overlapping completely. Second, the smaller intraclass trace is related to the reggae genre (it is the most compact class). This may justify why in the experiments art works belonging to reggae were more frequently 90%-100% correctly classified.

The PCA and LDA approaches help to identify which features contribute the most to the classification. This is an interesting analysis that can be performed by verifying the strength of each element in the first eigenvectors, and then associating those elements with the original features. Within the current study, it was figured out that the first ten sequences of rhythm notations that most contributed to separation correspond to those illustrated in Figure [\ref=fig:autvetpcalda]. In the case of the first and second eigenvectors obtained by PCA and LDA, the ten elements with higher values were selected, and the indices of these elements were associated with the sequences in the original weight matrix. Figure [\ref=fig:PCAAutoVetor1] and [\ref=fig:PCAAutoVetor2] shows the resulting sequences according to the first and second eigenvectors of PCA. The thickness of the edges is set by the value of the corresponding element in the eigenvector. It is interesting that these sequences are those that mostly frequently happen in the rhythms from all four genres studied here. That is, they correspond to the elements that play the greatest role in representing the rhythms. Therefore, it can be said that these are the ten most representative sequences, when the first and second eigenvectors of PCA are taken into account. Triples of eighth and sixteenth notes are particularly important in blues and reggae genres. Similarly, Figure [\ref=fig:LDAAutoVetor1] and Figure [\ref=fig:LDAAutoVetor2] show the resulting sequences according to the first and second eigenvectors of LDA. Differently from those obtained by PCA, these sequences are not common to all the rhythms, but they must happen with distinct frequency within each genre. Thus, they are referred here as the ten most discriminative sequences, when the first and second eigenvectors of LDA are taken into account.

Clustering results are discussed in the following. The number of clusters was defined as being four, in order to provide a fair comparison with the supervised classification results. The idea of the confusion matrix in Table [\ref=tab:MatConfClustering] is to verify how many art works from each class were placed in each one of the four clusters. For example, it is known that art works from one to seventy belongs to the blues genre. Then, the first line of this confusion matrix indicates that four blues art works were placed in the cluster one, thirty three in the cluster two, seven in the cluster three and twenty six in the cluster four. It can also be observed that in cluster one reggae art works are the majority (nineteen), despite the small difference with the number of rock art works (fifteen); while in cluster two the majority are blues art works; in cluster three the majority are rock art works; and in cluster four the majority are bossa nova art works.

Comparing the confusion matrix in Table [\ref=tab:MatConfClustering] and the confusion matrix for the Quadradic Bayesian Classifier using PCA in Table [\ref=tab:MatConfPCA], it is interesting to notice that: in the former, the cluster four contains considerable art works from the four genres (twenty six from blues, fifty from bossa nova, thirty from reggae and thirty six from rock), in a total of one hundred forty two art works; in the later, a considerable number of art work from blues (twenty two), bossa nova (twenty one) and rock (twenty four) were misclassified as reggae, in a total of one hundred thirty seven art works belonging this class. This means that the PCA representation was not efficient in discriminating reggae from the other genres, while cluster four was the one that mostly intermixed art works from all classes.

Figure [\ref=fig:totaldendrogram] presents the dendrogram with the four identified clusters. Different colors were used for the sake of enhanced visual analysis. Cluster one is colored in green, cluster two in pink, cluster three in red, and cluster four in cyan. These colors were based on the dominant class in each cluster. For example, cluster one is colored in green because bossa nova art works are majority in this cluster.

The four obtained clusters are detailed in Figures [\ref=fig:dendrogramcluster4] to [\ref=fig:dendrogramcluster1], in which the legends presents the grouped art works from each cluster (blues art works are in red, bossa nova art works are in green, reggae art works in cyan and rock art works in pink).

As a consequence of working in a higher dimension feature space, the agglomerative hierarquical clustering approach could better separate the data when compared to the PCA and LDA-based approaches, which are applied over a projected version of the original measurements.

Concluding Remarks

Automatic music genre classification has become a fundamental topic in music research since genres have been widely used to organize and describe music collections. They also reveal general identities of different cultures. However, music genres are not a clearly defined concept so that the development of a non-controversial taxonomy represents a challenging, non-trivial taks.

Generally speaking, music genres summarize common characteristics of musical pieces. This is particular interesting when it is used as a resource for automatic classification of pieces. In the current paper, we explored genre classification while taking into account the musical temporal aspects, namely the rhythm. We considered pieces of four musical genres (blues, bossa nova, reggae and rock), which were extracted from MIDI files and modeled as networks. Each node corresponded to one rhythmc notation, and the links were defined by the sequence in which they occurred along time. The idea of using static nodes (nodes with fixed positions) is particularly interesting because it provides a primary visual identification of the differences and similarities between the rythms from the four genres. A Markov model was build from the networks, and the dynamics and dependencies of the rhythmic notations were estimated, comprising the feature matrix of the data. Two different approaches for features analysis were used (PCA and LDA), as well as two types of classification methods (Bayesian classifier and hierarchical clustering).

Using only the first two principal componentes, the different types of rhythms were not separable, although for the first and third axes we could observe some separation between three of the classes (blues, bossa nova and reggae), while only the samples of rock overlapped the other classes. However, taking into account that twenty components were necessary to preserve 76% of the data variance, it would be expected that only two or three dimensions would not be sufficient to allow suitable saparability. Notably, the dimensionality of the problem is high, that is, the rhythms are very complex and many dimensions (features) are necessary to separate them. This is one of the main findings of the current work. With the help of LDA analysis, another finding was reached which supported the assumption that the problem of automatic rhythm classification is no trivial task. The projections obtained by considering the first and second, and first and third axes implied in better discrimination between the four classes than that obtained by the PCA.

Unlike PCA and LDA, agglomerative hierarchical clustering works on the original dimensions of the data. The application of the methodology led to a substantially better discrimination, which provides a strong evidence of the complexity of the problem studied here. The results are promising in the sense that in each cluster is dominated by a different genre, showing the viability of the proposed approach.

It is clear from our study that musical genres are very complex and present redundancies. Sometimes it is difficult even for an expert to distinguish them. This difficulty becomes more critical when only the rhythm is taken into account.

Several are the possibilities for future research implied by the reported investigation. First, it would be interesting to use more measurements extracted from rhythm, especially the intensity of the beats, as well as the distribution of instruments, which is poised to improve the classification results. Another promising venue for further investigation regards the use of other classifiers, as well as the combination of results obtained from ensemble of distinct classifiers. In addition, it would be promising to apply multi-labeled classification, a growing field of research in which non-disjointed samples can be associated to one or more labels [\cite=TSOUMAKAS2007]. Nowadays, multi-labeled classification methods have been increasingly required by applications such as text categorization [\cite=KATAKIS2008], scene classification [\cite=BOUTELL2004], protein classification [\cite=DIPLARIS2005], and music categorization in terms of emotion [\cite=TROHIDIS2008], among others. The possibility of multigenres classification is particularly promising and probably closer to the human experience. Another interesting future work is related to the synthesis of rhythms. Once the rhythmic networks are available, new rhythms with similar characteristics according to the specific genre can be artificially generated.

Acknowledgments

Debora C Correa is grateful to FAPESP (2009/50142-0) for financial support and Luciano da F. Costa is grateful to CNPq (301303/06-1 and 573583/2008-0) and FAPESP (05/00587-5) for financial support.

Appendices

Multivariate Statistical Methods

Principal Component Analysis

Principal Component Analysis is a second order unsupervised statistical technique. By second order it is meant that all the necessary information is available directly from the covariance matrix of the mixture data, so that there is no need to use the complete probability distributions. This method uses the eigenvalues and eigenvectors of the covariance matrix in order to transform the feature space, creating orthogonal uncorrelated features. From a multivariate dataset, the principal aim of PCA is to remove redundancy from the data, consequently reducing the dimensionality of the data. Additional information about PCA and its relation to various interesting statistical and geometrical properties can be found in the pattern recognition literature, e.g. [\cite=HYVARINEN2001] [\cite=WEBB2002] [\cite=DUDA2001] [\cite=COSTA2001].

Consider a vector x with n elements representing some features or measurements of a sample. In the first step of PCA transform, this vector x is centered by subtracting its mean, so that [formula]. Next, x is linearly transformed to a different vector y which contains m elements, m   <   n, removing the redundancy caused by the correlations. This is achieved by using a rotated orthogonal coordinate system in such a way that the elements in x are uncorrelated in the new coordinate system. At the same time, PCA maximizes the variances of the projections of x on the new coordinate axes (components). These variances of the components will differ in most applications. The axes associated to small dispersions (given by the respectively associated eigenvalues) can be discarded without losing too much information about the original data.

Linear discriminant Analysis

Linear discriminantAnalysis (LDA) can be considered a generalization of Fisher's Linear discriminant Function for the multivariate case [\cite=DUDA2001] [\cite=WEBB2002]. It is a supervised approach that maximizes data separability, in terms of a simililarity criterion based on scatter matrices. The basic idea is that objects belonging to the same class are as similar as possible and objects belonging to distinct classes are as different as possible. In other words, LDA looks for a new, projected, feature space where that maximizes interclass distance while minimizing the intraclass distance. This result can be later used for linear classification, and it is also possible to reduce dimensionality before the classification task. The scatter matrix for each class indicates the dispersion of the features vectors within the class. The intraclass scatter matrix is defined as the sum of the scatter matrices of all classes and expresses the combined dispersion in each class. The interclass scatter matrix quantifies how disperse the classes are, in terms of the position of their centroids.

It can be shown that the maximization criterion for class separability leads to a generalized eigenvalue problem ([\cite=WEBB2002] [\cite=DUDA2001]). Therefore, it is possible to compute the eigenvalues and eigenvectors of the matrix defined by [formula], where Sintra is the intraclass scatter matrix and Sinter is the interclass scatter matrix. The m eigenvectors associated to the m largest eigenvalues of this matrix can be used to project the data. However, the rank of [formula] is limited to  - 1, where [formula] is the number of classes. As a consequence, there are  - 1 nonzero eigenvalues, that is, the number of new features is conditioned to the number of classes,   ≤   - 1. Another issue is that, for high dimensional problems, when the number of available training samples is smaller than the number of features, Sintra becomes singular, complicating the generalized eigenvalue solution.

More information about the LDA is [\cite=DEVIJVER1981] [\cite=Therrien1989] [\cite=DUDA2001] [\cite=WEBB2002].

Linear and Quadratic Discriminant Functions

If normal distribution over the data is assumed, it is possible to state that:

[formula]

The components of the parameter vector for class j, [formula], where [formula] and Σj are the mean vector and the covariance matrix of class j, respectively, can be estimated by maximum likelihood as follows:

[formula]

[formula]

Within this context, classification can be achieved with discriminant functions, gi, assigning an observed pattern vector [formula] to the class ωj with the maximum discriminant function value. By using Bayes's rule, not considering the constant terms, and using the estimated parameters above, a decision rule can be defined as: assign an object [formula] to class ωj if gj  >  gi for all i  ≠  j, where the discriminantfunction gi is calculated as:

[formula]

Classifying an object or pattern [formula] on the basis of the values of [formula], i  =  1,...,C (C is the number of classes), with estimated parameters, defines a quadratic discriminant classifier or quadratic Bayesian classifier or yet quadratic Gaussian classifier [\cite=WEBB2002].

The prior probability, [formula], can be simply estimated by:

[formula]

where ni is the number of samples of class ωi.

In multivariate classification situations, with different covariance matrices, problems may occur in the quadratic Bayesian classifier when any of the matrices i is singular. This usually happens when there are not enough data to obtain efficient estimative for the covariance matrices Σi, i  =  1,2,...,C. An alternative to minimize this problem consist of estimating one unique covariance matrix over all classes,   =  1  =  ...  =  C. In this case, the discriminantfunction becomes linear in [formula] and can be simplified:

[formula]

where [formula] is the covariance matrix, common to all classes. The classification rule remains the same. This defines a linear discriminant classifier (also known as linear Bayesian classifier or linear Gaussian classifier) [\cite=WEBB2002].

Agglomerative Hierarchical Clustering

Agglomerative hierarchical clustering groups progressively the N objects into C classes according to a defined parameter. The distance or similarity between the feature vectors of the objects are usually taken as such parameter. In the first step, there is a partition with N clusters, each cluster containing one object. The next step is a different partition, with N - 1 clusters, the next a partition with N - 2 clusters, and so on. In the nth step, all the objects form a unique cluster. This sequence groups objects that are more similar to one another into subclasses before objects that are less similar. It is possible to say that, in the kth step, C  =  N  -  k  +  1.

To show how the objects are grouped, hierarchical clustering can be represented by a corresponding tree, called dendrogram. Figure [\ref=fig:dendrogram] illustrates a dendrogram representing the results of hierarchical clustering for a problem with eight objects. The measure of similarity among clusters can be observed in the vertical axis. The different number of classes can be obtained by horizontally cutting the dendrogram at different values of similarity or distance.

Hence, to perform hierarchical cluster analysis it is necessary to define three main parameters. The first regards how to quantify the similarity between every pair of objects in the data set, that is, how to calculate the distance between the objects. Euclidean distance, which is frequently used, will be adopted in this work, but other possible distances are cityblock, cheesboard, mahalanobis and so on. The second parameter is the linkage method, which establishes how to measure the distance between two sets. The linkage method can be used to link pairs of objects that are similar and then to form the hierarchical cluster tree. There are many possibilities for doing so, some of the most popular are: single linkage, complete linkage, group linkage, centroid linkage, mean linkage and ward's linkage ([\cite=JAIN1988] [\cite=ANDERBERG1973] [\cite=ROMESBURG1990] [\cite=COSTA2001]). Ward's linkage uses the intraclass dispersion as a clustering criterion. Pairs of objects are merged in such a way to guarantee the smallest increase in the intraclass dispersion. This clustering approach has been sometimes identified as corresponding to the best hierarchical method [\cite=KUIPER1975] [\cite=BLASHFILED1976] [\cite=MOJENA1975] and will be used in this work. Actually, it is particularly interesting to analyse the intraclass dispersion in an unsupervised classification procedure in order to identify common and different characteristics when compared to the supervised classification. The third parameter concerns the number of desired clusters, an issue which is directly related to where to cut the dendrogram into clusters, as illustrated by C in Figure [\ref=fig:dendrogram].

The Kappa Coefficient

The kappa coefficient was first proposed by Cohen [\cite=COHEN1960]. In the context of supervised classification, this coefficient determines the degree of agreement a posteriori. This means that it quantifies the agreement between objects previously known (ground truth) and the result obtained by the classifier. The better the classification accuracy, the higher the degree of concordance, and, consequently, the higher the value of kappa. The kappa coefficient is computed from the confusion matrix as follows [\cite=CONGALTON1991]:

[formula]

where xi   +    is the sum of elements from line i, x   +   i is the sum of elements from column i, C is the number of classes (confusion matrix is C x C), and N is the total number of objects. The kappa variance can be calculated as:

[formula]

where

[formula]

This statistics indicates that, when   ≤  0 there is not any agreement, and when   =  1 the agreement is total. Some authors suggest interpretations according to the value obtained by the coefficient kappa. Table [\ref=tab:Kappa] shows one possible interpretation, proposed by [\cite=LANDIS1977].

References