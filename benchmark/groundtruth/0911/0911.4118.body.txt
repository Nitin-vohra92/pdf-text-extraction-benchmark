Theorem Lemma Corollary Remark Example Conjecture Problem Note Assumption Proposition Setup Notation

Thin Hessenberg Pairs

There exists a basis for V with respect to which the matrix representing A is Hessenberg and the matrix representing A* is diagonal.

There exists a basis for V with respect to which the matrix representing A is diagonal and the matrix representing A* is Hessenberg.

Introduction

This paper is about a linear algebraic object called a Hessenberg pair, which is a generalization of a tridiagonal pair [\cite=TD00] [\cite=TDRACAH]. We introduced Hessenberg pairs in [\cite=hess]. In the present paper, we continue our investigation of Hessenberg pairs by focusing on a special case said to be thin. To define this case, we will use the following term. A square matrix is called Hessenberg whenever each entry below the subdiagonal is zero and each entry on the subdiagonal is nonzero. Throughout the paper, [formula] will denote a field.

Let V denote a nonzero finite-dimensional vector space over [formula]. By a thin Hessenberg pair (or TH pair) on V, we mean an ordered pair of linear transformations A:V  →  V and A*:V  →  V which satisfy both (i), (ii) below.

There exists a basis for V with respect to which the matrix representing A is Hessenberg and the matrix representing A* is diagonal.

There exists a basis for V with respect to which the matrix representing A is diagonal and the matrix representing A* is Hessenberg.

It is a common notational convention to use A* to represent the conjugate-transpose of A. We are not using this convention. In a TH pair A,A* the linear transformations A and A* are arbitrary subject to (i), (ii) above.

We now briefly summarize the paper. Let A,A* denote a TH pair on V. We investigate six bases for V with respect to which the matrices representing A and A* are attractive. We display these matrices along with the transition matrices relating the bases. We introduce an "oriented" version of A,A* called a TH system. We classify the TH systems up to isomorphism. We will give a more detailed summary at the end of Section 2, after establishing some notations and reviewing some basic concepts.

TH systems

In our study of a TH pair, it is often helpful to consider a closely related object called a TH system. Before defining this notion, we make some definitions and observations. For the rest of the paper, fix an integer d  ≥  0 and a vector space V over [formula] with dimension d + 1. Let End(V) denote the [formula]-algebra of all linear transformations from V to V. Let [formula] denote the [formula]-algebra consisting of all (d + 1)  ×  (d + 1) matrices which have entries in [formula]. We index the rows and columns by [formula]. Suppose that {vi}di = 0 is a basis for V. For [formula] and Y∈End(V), we say X represents Y with respect to {vi}di = 0 whenever [formula] for 0  ≤  j  ≤  d. For A∈End(V) and W  ⊆  V, we call W an eigenspace of A whenever [formula] and there exists [formula] such that W = {v∈V  |  Av  =  θv}. In this case θ is called the eigenvalue of A corresponding to W. We say A is diagonalizable whenever V is spanned by the eigenspaces of A. We say A is multiplicity-free whenever A is diagonalizable and each eigenspace of A has dimension one.

Let A,A* denote a TH pair on V. Then each of A,A* is multiplicity-free.

Proof: Concerning A, recall by Definition [\ref=def:thinhess](ii) that there exists a basis for V consisting of eigenvectors of A. Consequently, the eigenvalues of A are all in [formula] and the minimal polynomial of A has no repeated roots. To show that the eigenvalues of A are distinct, we show that the minimal polynomial of A has degree d + 1. By Definition [\ref=def:thinhess](i), there exists a basis for V with respect to which the matrix representing A is Hessenberg. Denote this matrix by B. On one hand, A and B have the same minimal polynomial. On the other hand, using the Hessenberg shape of B, we find [formula] are linearly independent, so the minimal polynomial of B has degree d + 1. We conclude the minimal polynomial of A has degree d + 1, so the eigenvalues of A are distinct. Consequently A is multiplicity-free. The case of A* is similar. [formula]

We recall a few more concepts from linear algebra. Let A denote a multiplicity-free element of End(V). Let {Vi}di = 0 denote an ordering of the eigenspaces of A and let {θi}di = 0 denote the corresponding ordering of the eigenvalues of A. For 0  ≤  i  ≤  d, define Ei∈End(V) such that (Ei - I)Vi = 0 and EiVj = 0 for j  ≠  i (0  ≤  j  ≤  d). Here I denotes the identity of End(V). We call Ei the primitive idempotent of A corresponding to Vi (or θi). Observe that (i) [formula]; (ii) EiEj  =  δi,jEi (0  ≤  i,j  ≤  d); (iii) Vi = EiV (0  ≤  i  ≤  d); (iv) [formula]. Moreover

[formula]

Note that each of {Ai}di = 0, {Ei}di = 0 is a basis for the [formula]-subalgebra of (V) generated by A. Moreover [formula].

We now define a TH system.

By a thin Hessenberg system (or TH system) on V we mean a sequence

[formula]

which satisfies (i)-(v) below.

Each of A,A* is a multiplicity-free element of End(V).

{Ei}di = 0 is an ordering of the primitive idempotents of A.

{E*i}di = 0 is an ordering of the primitive idempotents of A*.

[formula].

[formula]

We call V the underlying vector space and say Φ is over [formula].

We comment on how TH pairs and TH systems are related. Let (A;{Ei}di = 0;A*;{E*i}di = 0) denote a TH system on V. For 0  ≤  i  ≤  d, let vi (resp. v*i) denote a nonzero vector in EiV (resp. E*iV). Then the sequence {vi}di = 0 (resp. {v*i}di = 0) is a basis for V which satisfies Definition [\ref=def:thinhess](ii) (resp. Definition [\ref=def:thinhess](i)). Therefore the pair A,A* is a TH pair on V. Conversely, let A,A* denote a TH pair on V. Then each of A,A* is multiplicity-free by Lemma [\ref=lem:multfree]. Let {vi}di = 0 (resp. {v*i}di = 0) denote a basis for V which satisfies Definition [\ref=def:thinhess](ii) (resp. Definition [\ref=def:thinhess](i)). For 0  ≤  i  ≤  d, the vector vi (resp. v*i) is an eigenvector for A (resp. A*); let Ei (resp. E*i) denote the corresponding primitive idempotent. Then (A;{Ei}di = 0;A*;{E*i}di = 0) is a TH system on V.

Let Φ  =  (A;{Ei}di = 0;A*;{E*i}di = 0) denote a TH system on V. Observe that A,A* is a TH pair on V. We say this pair is associated with Φ.

With reference to Definition [\ref=def:thpairassthsytem], conceivably a given TH pair is associated with many TH systems.

We now define the notion of isomorphism for TH systems.

Let Φ = (A;{Ei}di = 0;A*;{E*i}di = 0) denote a TH system on V. Let W denote a vector space over [formula] with dimension d + 1, and let Ψ: = (B;{Fi}di = 0;B*;{F*i}di = 0) denote a TH system on W. By an isomorphism of TH systems from Φ to Ψ we mean a vector space isomorphism γ:V  →  W such that

[formula]

We say Φ and Ψ are isomorphic whenever there exists an isomorphism of TH systems from Φ to Ψ.

We now define the dual of a TH system.

Let Φ = (A;{Ei}di = 0;A*;{E*i}di = 0) denote a TH system on V. Observe that Φ*: = (A*;{E*i}di = 0;A;{Ei}di = 0) is a TH system on V. We call Φ* the dual of Φ.

We recall some more terms. Let {vi}di = 0 denote a basis for V. By the inversion of {vi}di = 0 we mean the basis {vd - i}di = 0. A square matrix is called lower bidiagonal whenever each nonzero entry lies on either the diagonal or the subdiagonal, and each entry on the subdiagonal is nonzero. A square matrix is called upper bidiagonal whenever its transpose is lower bidiagonal.

We now give a detailed summary of the paper. Let Φ = (A;{Ei}di = 0;A*;{E*i}di = 0) denote a TH system on V. We investigate six bases for V that we find attractive. The first four are called the Φ-split basis, the Φ*-split basis, the inverted Φ-split basis, and the inverted Φ*-split basis. With respect to each of these bases, the matrix representing one of A,A* is lower bidiagonal and the matrix representing the other is upper bidiagonal. The other two bases in our investigation are called the Φ-standard basis and the Φ*-standard basis. A Φ-standard basis (resp. Φ*-standard basis) satisfies Definition [\ref=def:thinhess](i) (resp. Definition [\ref=def:thinhess](ii)), subject to a certain normalization. For each of the six bases, we display the matrices representing A and A*. We display some transition matrices relating these six bases. We associate with Φ a sequence of scalars called its parameter array. We show that Φ is determined up to isomorphism by its parameter array. Using this fact, we classify the TH systems up to isomorphism.

The eigenvalue sequences

Let Φ denote a TH system. In this section we associate with Φ two sequences of scalars called the eigenvalue sequence and the dual eigenvalue sequence. We describe some properties of these sequences that we will use later in the paper.

Let Φ = (A;{Ei}di = 0;A*;{E*i}di = 0) denote a TH system on V. For 0  ≤  i  ≤  d, let θi (resp. θ*i) denote the eigenvalue of A (resp. A*) corresponding to Ei (resp. E*i). We refer to {θi}di = 0 as the eigenvalue sequence of Φ. We refer to {θ*i}di = 0 as the dual eigenvalue sequence of Φ. We observe that {θi}di = 0 are mutually distinct and contained in [formula]. Similarly {θ*i}di = 0 are mutually distinct and contained in [formula].

Let A,A* denote a TH pair. By an eigenvalue sequence of A,A*, we mean the eigenvalue sequence of an associated TH system. By a dual eigenvalue sequence of A,A*, we mean an eigenvalue sequence of the TH pair A*,A. We emphasize that a given TH pair could have many eigenvalue and dual eigenvalue sequences.

Let A,A* denote a TH pair. Then the following (i), (ii) hold.

Let {θi}di = 0 and {θ'i}di = 0 denote eigenvalue sequences of A,A* such that θ0  =  θ'0. Then θi  =  θ'i for 0  ≤  i  ≤  d.

Let {θ*i}di = 0 and [formula] denote dual eigenvalue sequences of A,A* such that [formula]. Then [formula] for 0  ≤  i  ≤  d.

Proof: (i) For 0  ≤  i  ≤  d, let Vi (resp. Vi') denote the eigenspace of A corresponding to θi (resp. θ'i). It suffices to show that Vi  =  Vi' for 0  ≤  i  ≤  d. This follows once we show that Wi  =  Wi' for 0  ≤  i  ≤  d, where [formula] and [formula]. We prove this by induction on i. First assume that i = 0. Then W0  =  V0  =  V0'  =  W0' since θ0  =  θ'0. Next assume that 1  ≤  i  ≤  d. By induction, we have Wi - 1  =  Wi - 1'. By Definition [\ref=def:thinhess](ii) and since {θh}dh = 0 is an eigenvalue sequence of A,A*, we find A*Wi - 1  ⊆  Wi and [formula]. Therefore Wi - 1  +  A*Wi - 1  =  Wi. Similarly Wi - 1'  +  A*Wi - 1'  =  Wi'. Comparing these equations using Wi - 1  =  Wi - 1', we find Wi  =  Wi'. The result follows.

(ii) Apply (i) to Φ*. [formula]

Let A,A* denote a TH pair on V. Fix a basis for V and let B (resp. B*) denote the matrix in [formula] which represents A (resp. A*) with respect to that basis. Assume that B is Hessenberg and B* is upper triangular. Then the sequence of diagonal entries {B*ii}di = 0 of B* is a dual eigenvalue sequence of A,A*.

Proof: We assume that A,A* is a TH pair so A* is multiplicity-free. We assume that B* is upper triangular so the sequence {B*ii}di = 0 is an ordering of the eigenvalues of A*. We show that this sequence is a dual eigenvalue sequence of A,A*. For 0  ≤  i  ≤  d, let E*i denote the primitive idempotent of A* corresponding to the eigenvalue B*ii. It suffices to show that Definition [\ref=def:HS](v) holds. We make a few observations. Let {vi}di = 0 denote the basis for V in the statement of the lemma. For 0  ≤  i  ≤  d, let Wi denote the subspace of V spanned by {vh}ih = 0. The matrix B* is upper triangular so A*Wi  ⊆  Wi. The restriction of A* to Wi has eigenvalues {B*hh}ih = 0, so [formula]. Since B is Hessenberg, we have AE*jV  ⊆  Wj + 1 and [formula] for 0  ≤  j  ≤  d - 1. We can now easily show that Definition [\ref=def:HS](v) holds. Fix integers i,j (0  ≤  i,j  ≤  d) such that i - j  ≥  1. First assume that i - j > 1. From our observations above, E*iAE*jV  ⊆  E*iWj + 1  =  0. Therefore E*iAE*jV = 0 so E*iAE*j = 0. Next assume that i - j = 1. We show [formula]. By way of contradiction, assume that E*iAE*j = 0. By this and our earlier observations, we have E*hAE*j = 0 for i  ≤  h  ≤  d. Therefore [formula], so [formula]. This contradicts our above remarks so [formula]. The result follows. [formula]

The Φ-split basis

Let Φ denote a TH system on V. In this section we investigate a certain basis for V called the Φ-split basis. We will refer to the following notation.

Let Φ = (A;{Ei}di = 0;A*;{E*i}di = 0) denote a TH system on V. Let {θi}di = 0 (resp. {θ*i}di = 0) denote the eigenvalue (resp. dual eigenvalue) sequence of Φ.

With reference to Notation [\ref=not:aastar], in our study of Φ we will use the following term. By a decomposition of V we mean a sequence {Ui}di = 0 of one-dimensional subspaces of V such that

[formula]

For notational convenience, set U- 1 = 0 and Ud + 1 = 0. We now describe a certain decomposition of V associated with Φ. For 0  ≤  i  ≤  d, define

[formula]

By [\cite=split], the sequence {Ui}di = 0 is a decomposition of V. Moreover for 0  ≤  i  ≤  d, both

[formula]

Setting i = d in ([\ref=eq:defui]) we find Ud = E0V. Combining this with ([\ref=eq:lower]) we find

[formula]

Let η0 denote a nonzero vector in E0V. From ([\ref=eq:uialt]) we find that for 0  ≤  i  ≤  d, the vector [formula] is a basis for Ui. By this and since {Ui}di = 0 is a decomposition of V, the sequence

[formula]

is a basis for V.

With reference to Notation [\ref=not:aastar], a basis for V is said to be Φ-split whenever it is of the form

[formula]

where 0  ≠  η0∈E0V.

With reference to Notation [\ref=not:aastar], let {vi}di = 0 denote a Φ-split basis for V, and let {wi}di = 0 denote any vectors in V. Then the following are equivalent.

{wi}di = 0 is a Φ-split basis for V.

There exists [formula] such that wi  =  c  vi for 0  ≤  i  ≤  d.

Proof: Routine. [formula]

With reference to Notation [\ref=not:aastar], our next goal is to describe the matrices representing A,A* with respect to a Φ-split basis for V. We start with an observation. Let 1  ≤  i  ≤  d. By ([\ref=eq:lower]) we have (A*  -  θ*iI)Ui  =  Ui - 1, and by ([\ref=eq:raise]) we have (A - θd - i + 1I)Ui - 1  =  Ui. Therefore Ui is an eigenspace of (A - θd - i + 1I)(A*  -  θ*iI) and the corresponding eigenvalue is a nonzero element of [formula]. We denote this eigenvalue by φi. We call the sequence {φi}di = 1 the split sequence of Φ. For notational convenience, set φ0 = 0 and φd + 1  =  0.

With reference to Notation [\ref=not:aastar], let B (resp. B*) denote the matrix in [formula] which represents A (resp. A*) with respect to a Φ-split basis for V. Then

[formula]

where {φi}di = 1 is the split sequence of Φ. In particular, B is lower bidiagonal and B* is upper bidiagonal.

Proof: Follows from Definition [\ref=def:lbubbasis] and the discussion prior to this proposition. [formula]

We give an alternate description of the Φ-split basis. To motivate this, we set i = 0 in ([\ref=eq:defui]) and find U0 = E*0V. Combining this with ([\ref=eq:raise]) we find

[formula]

Let η*0 denote a nonzero vector in E*0V. From ([\ref=eq:uialtvar]) we find that for 0  ≤  i  ≤  d, the vector [formula] is a basis for Ui. By this and since {Ui}di = 0 is a decomposition of V, the sequence

[formula]

is a basis for V. This basis is not a Φ-split basis in general, but we do have the following result.

With reference to Notation [\ref=not:aastar], let {vi}di = 0 denote any vectors in V. Then the following are equivalent.

{vi}di = 0 is a Φ-split basis for V.

There exists 0  ≠  η*0∈E*0V such that

[formula]

where {φi}di = 1 is the split sequence of Φ.

Proof: Suppose that {vi}di = 0 is a Φ-split basis for V. Then by Proposition [\ref=prop:lbublooklike], the matrices representing A and A* with respect to {vi}di = 0 are as shown in ([\ref=eq:matrepaastar]). From the matrix on the right in ([\ref=eq:matrepaastar]) we find v0∈E*0V. Taking η*0  =  v0, we find ([\ref=eq:lbubbasisvar]) holds for i = 0. From the matrix on the left in ([\ref=eq:matrepaastar]), we find that ([\ref=eq:lbubbasisvar]) holds for 1  ≤  i  ≤  d. The result follows by Lemma [\ref=lem:scalar]. [formula]

We now give an alternate description of the split sequence of Φ.

With reference to Notation [\ref=not:aastar], let {φi}di = 1 denote the split sequence of Φ. Then for 1  ≤  i  ≤  d, φi is the eigenvalue of (A*  -  θ*iI)(A  -  θd - i + 1I) for the eigenspace Ui - 1, where {Ui}di = 0 is from ([\ref=eq:defui]).

Proof: Let {vj}dj = 0 denote a Φ-split basis for V. Recall that vj spans Uj for 0  ≤  j  ≤  d, so it suffices to show that (A*  -  θ*iI)(A  -  θd - i + 1I)vi - 1  =  φivi - 1. This follows by Proposition [\ref=prop:lbublooklike] and a routine matrix computation. [formula]

We now give three characterizations of the Φ-split basis.

With reference to Notation [\ref=not:aastar], let {vi}di = 0 denote a sequence of vectors in V, not all zero. Then this sequence is a Φ-split basis for V if and only if the following (i), (ii) hold.

vd∈E0V.

A*vi  =  θ*ivi  +  vi - 1 for 1  ≤  i  ≤  d.

Proof: Routine using Definition [\ref=def:lbubbasis]. [formula]

With reference to Notation [\ref=not:aastar], let {vi}di = 0 denote a sequence of vectors in V, not all zero. Then this sequence is a Φ-split basis for V if and only if the following (i), (ii) hold.

v0∈E*0V.

Avi  =  θd - ivi  +  φi + 1vi + 1 for 0  ≤  i  ≤  d - 1, where {φi}di = 1 is the split sequence of Φ.

Proof: Routine using Lemma [\ref=lem:lbubbasisvar]. [formula]

With reference to Notation [\ref=not:aastar], let {vi}di = 0 denote a basis for V, and let C (resp. C*) denote the matrix in [formula] which represents A (resp. A*) with respect to this basis. Then {vi}di = 0 is a Φ-split basis for V if and only if the following (i)-(iii) hold.

C is lower bidiagonal and C* is upper bidiagonal.

C*i - 1,i  =  1 for 1  ≤  i  ≤  d.

Cdd  =  θ0 and C*00  =  θ*0.

Proof: Suppose that {vi}di = 0 is a Φ-split basis for V. By Proposition [\ref=prop:lbublooklike], conditions (i)-(iii) above hold. We have proved the proposition in one direction. For the other direction, suppose that conditions (i)-(iii) above hold. To show that {vi}di = 0 is a Φ-split basis for V, we invoke Proposition [\ref=lem:lbubbasis]. We show that Proposition [\ref=lem:lbubbasis](i), (ii) hold. Since C is lower bidiagonal with Cdd  =  θ0, vd is an eigenvector of A corresponding to eigenvalue θ0. Therefore Proposition [\ref=lem:lbubbasis](i) holds. Since C is lower bidiagonal, C is Hessenberg. Since C* is upper bidiagonal, C* is upper triangular. Now apply Lemma [\ref=lem:trihess] to conclude that {C*ii}di = 0 is a dual eigenvalue sequence of A,A*. Therefore since C*00  =  θ*0, by Lemma [\ref=lem:eig] we have C*ii  =  θ*i for 0  ≤  i  ≤  d. Since C* is upper bidiagonal with C*i - 1,i  =  1 for 1  ≤  i  ≤  d, we have A*vi  =  θ*ivi  +  vi - 1 for 1  ≤  i  ≤  d. Therefore Proposition [\ref=lem:lbubbasis](ii) holds. The result follows. [formula]

Variations on the Φ-split basis

Let Φ denote a TH system on V. In the previous section we discussed the Φ-split basis for V. In this section we discuss three variations on this basis called the Φ*-split basis, the inverted Φ-split basis, and the inverted Φ*-split basis. The following lemma will be useful.

With reference to Notation [\ref=not:aastar], let {φi}di = 1 denote the split sequence of Φ. Then the split sequence of Φ* is {φd - i + 1}di = 1.

Proof: Routine using the definition of the split sequence of Φ and Lemma [\ref=lem:splitseqvar]. [formula]

We now discuss the Φ*-split basis.

With reference to Notation [\ref=not:aastar], let {vi}di = 0 denote any vectors in V. Then the following are equivalent.

{vi}di = 0 is a Φ*-split basis for V.

There exists 0  ≠  η*0∈E*0V such that

[formula]

There exists 0  ≠  η0∈E0V such that

[formula]

where {φi}di = 1 is the split sequence of Φ.

Proof: To prove (i) ↔   (ii) apply Definition [\ref=def:lbubbasis] to Φ*. To prove (i) ↔   (iii) apply Lemma [\ref=lem:lbubbasisvar] to Φ* and use Lemma [\ref=lem:splitseqdual]. [formula]

With reference to Notation [\ref=not:aastar], let B (resp. B*) denote the matrix in [formula] which represents A (resp. A*) with respect to a Φ*-split basis for V. Then

[formula]

where {φi}di = 1 is the split sequence of Φ. In particular, B is upper bidiagonal and B* is lower bidiagonal.

Proof: Apply Proposition [\ref=prop:lbublooklike] to Φ* and use Lemma [\ref=lem:splitseqdual]. [formula]

With reference to Notation [\ref=not:aastar], let {vi}di = 0 denote a Φ-split basis for V, and let {wi}di = 0 denote any vectors in V. Then the following are equivalent.

{wi}di = 0 is a Φ*-split basis for V.

There exists [formula] such that [formula] for 0  ≤  i  ≤  d, where {φi}di = 1 is the split sequence of Φ.

Proof: Compare ([\ref=eq:spbasis]) and ([\ref=eq:duallbubbasisvar]). [formula]

We now turn our attention to the inverted Φ-split basis.

With reference to Notation [\ref=not:aastar], let {vi}di = 0 denote any vectors in V. Then the following are equivalent.

{vi}di = 0 is an inverted Φ-split basis for V.

There exists 0  ≠  η0∈E0V such that

[formula]

There exists 0  ≠  η*0∈E*0V such that

[formula]

where {φi}di = 1 is the split sequence of Φ.

Proof: Routine using Definition [\ref=def:lbubbasis], Lemma [\ref=lem:lbubbasisvar], and the meaning of inversion. [formula]

With reference to Notation [\ref=not:aastar], let B (resp. B*) denote the matrix in [formula] which represents A (resp. A*) with respect to an inverted Φ-split basis for V. Then

[formula]

where {φi}di = 1 is the split sequence of Φ. In particular, B is upper bidiagonal and B* is lower bidiagonal.

Proof: Routine using Proposition [\ref=prop:lbublooklike] and the meaning of inversion. [formula]

With reference to Notation [\ref=not:aastar], let {vi}di = 0 denote a Φ-split basis for V, and let {wi}di = 0 denote any vectors in V. Then the following are equivalent.

{wi}di = 0 is an inverted Φ-split basis for V.

There exists [formula] such that wi  =  c  vd - i for 0  ≤  i  ≤  d.

Proof: Routine using Lemma [\ref=lem:scalar] and the meaning of inversion. [formula]

We now turn our attention to the inverted Φ*-split basis.

With reference to Notation [\ref=not:aastar], let {vi}di = 0 denote any vectors in V. Then the following are equivalent.

{vi}di = 0 is an inverted Φ*-split basis for V.

There exists 0  ≠  η*0∈E*0V such that

[formula]

There exists 0  ≠  η0∈E0V such that

[formula]

where {φi}di = 1 is the split sequence of Φ.

Proof: Routine using Lemma [\ref=lem:duallbubbasis] and the meaning of inversion. [formula]

With reference to Notation [\ref=not:aastar], let B (resp. B*) denote the matrix in [formula] which represents A (resp. A*) with respect to an inverted Φ*-split basis for V. Then

[formula]

where {φi}di = 1 is the split sequence of Φ. In particular, B is lower bidiagonal and B* is upper bidiagonal.

Proof: Routine using Proposition [\ref=prop:duallbublooklike] and the meaning of inversion. [formula]

With reference to Notation [\ref=not:aastar], let {vi}di = 0 denote a Φ-split basis for V, and let {wi}di = 0 denote any vectors in V. Then the following are equivalent.

{wi}di = 0 is an inverted Φ*-split basis for V.

There exists [formula] such that [formula] for 0  ≤  i  ≤  d, where {φi}di = 1 is the split sequence of Φ.

Proof: Routine using Lemma [\ref=cor:trans] and the meaning of inversion. [formula]

Classification of TH systems

In this section we classify the TH systems up to isomorphism.

Let Φ denote a TH system on V. In the previous sections we associated with Φ some sequences of scalars: the eigenvalue sequence, the dual eigenvalue sequence, and the split sequence. We now show that those sequences determine Φ up to isomorphism.

Let Φ and Φ' denote TH systems over [formula]. Then the following are equivalent.

Φ and Φ' are isomorphic.

Φ and Φ' share the same eigenvalue sequence, dual eigenvalue sequence, and split sequence.

Proof: (i) →   (ii). Clear.

(ii) →   (i). Without loss of generality, assume that Φ is the TH system from Definition [\ref=def:HS]. Write [formula]. Let V' denote the vector space underlying Φ'. Let {vi}di = 0 (resp. {vi'}di = 0) denote a Φ-split (resp. Φ'-split) basis for V (resp. V'). Let γ denote the vector space isomorphism from V to V' which sends vi to vi' for 0  ≤  i  ≤  d. Since Φ and Φ' share the same eigenvalue, dual eigenvalue, and split sequences, the matrix representing A with respect to {vi}di = 0 and the matrix representing A' with respect to {vi'}di = 0 are identical. Thus γA  =  A'γ. Similarly [formula]. Moreover, using ([\ref=eq:defEi]) we find γEi  =  Ei'γ and [formula] for 0  ≤  i  ≤  d. Therefore γ is an isomorphism of TH systems from Φ to Φ' and so Φ and Φ' are isomorphic. [formula]

Lemma [\ref=lem:paramsdetisoS99] motivates the following definition.

Let Φ denote a TH system on V. By the parameter array of Φ we mean the sequence ({θi}di = 0,{θ*i}di = 0,{φi}di = 1), where {θi}di = 0 (resp. {θ*i}di = 0) is the eigenvalue (resp. dual eigenvalue) sequence of Φ and {φi}di = 1 is the split sequence of Φ.

In the following theorem, we classify the TH systems up to isomorphism.

Let

[formula]

denote scalars in [formula]. Then there exists a TH system Φ over [formula] with parameter array ([\ref=eq:pa]) if and only if (i)-(iii) hold below.

[formula]  if [formula].

[formula]   if [formula].

[formula].

Moreover if (i)-(iii) hold above then Φ is unique up to isomorphism of TH systems.

Proof: To prove the theorem in one direction, let Φ = (A;{Ei}di = 0;A*;{E*i}di = 0) denote a TH system over [formula] with parameter array ([\ref=eq:pa]). We show that conditions (i)-(iii) above hold. Conditions (i), (ii) hold by Definition [\ref=def:evseq] and condition (iii) holds by the observation prior to Proposition [\ref=prop:lbublooklike]. We are done with the proof in one direction.

For the other direction, suppose conditions (i)-(iii) above hold. Consider the following matrices [formula].

[formula]

Let {ui}di = 0 denote a basis for V. Let A (resp. A*) denote the element of End(V) which is represented by B (resp. B*) with respect to {ui}di = 0. We observe that A (resp. A*) is multiplicity-free, with eigenvalues {θi}di = 0 (resp. {θ*i}di = 0). For 0  ≤  i  ≤  d, let Ei (resp. E*i) denote the primitive idempotent of A (resp. A*) corresponding to θi (resp. θ*i). We show that Φ = (A;{Ei}di = 0;A*;{E*i}di = 0) is a TH system on V. To do this, we show that Φ satisfies conditions (i)-(v) in Definition [\ref=def:HS]. Conditions (i)-(iii) are clearly satisfied, so it remains to prove conditions (iv), (v). To prove condition (iv), we make a claim. For 0  ≤  i  ≤  d, let [formula]. For notational convenience, set U- 1 = 0 and Ud + 1 = 0. Then

[formula]

To prove the claim, abbreviate [formula] and [formula]. We show that K = L. To obtain L  ⊆  K, set [formula], and observe that L = XV by elementary linear algebra. Observe that (A - θd - hI)Uh  =  Uh + 1 for 0  ≤  h  ≤  d and hence XUh  ⊆  K for 0  ≤  h  ≤  d. Since [formula] we have XV  ⊆  K. We now have L  ⊆  K. To obtain K  ⊆  L, set [formula], and observe that

[formula]

Since (A - θd - hI)Uh  =  Uh + 1 for 0  ≤  h  ≤  d, we have YUj = 0 for i  ≤  j  ≤  d, so YK = 0. Combining this with ([\ref=eq:Keraction]), we find K  ⊆  L. We now have K = L and the claim is proved. We now prove condition (iv). Fix integers i,j (0  ≤  i,j  ≤  d) such that i - j  ≥  1. First assume that i - j  >  1. Observe that (A*  -  θ*hI)Uh  =  Uh - 1 for 0  ≤  h  ≤  d. Using this fact and ([\ref=eq:vsumitod]), we find [formula]. Therefore [formula] so EiA*Ej  =  0. Next assume that i - j  =  1. We show that EiA*Ej  ≠  0. By way of contradiction, assume that EiA*Ej  =  0. Using these comments and ([\ref=eq:vsumitod]), we find [formula]. This contradicts our earlier remark that (A*  -  θ*d - jI)Ud - j  =  Ud - j - 1. Therefore EiA*Ej  ≠  0 and Definition [\ref=def:HS](iv) holds. The proof for Definition [\ref=def:HS](v) is similar and omitted. We have now shown that Φ is a TH system on V. By Definition [\ref=def:evseq], Φ has eigenvalue sequence {θi}di = 0 and dual eigenvalue sequence {θ*i}di = 0. By Proposition [\ref=thm:lbubbasisvsrep], {ui}di = 0 is a Φ-split basis for V. Therefore Φ has split sequence {φi}di = 1 by Proposition [\ref=prop:lbublooklike]. The TH system Φ is unique up to isomorphism by Lemma [\ref=lem:paramsdetisoS99]. [formula]

We finish this section with a comment.

Let Φ denote a TH system on V with parameter array ({θi}di = 0,{θ*i}di = 0,{φi}di = 1). Then the dual TH system Φ* has parameter array ({θ*i}di = 0,{θi}di = 0,{φd - i + 1}di = 1).

Proof: Immediate from Definitions [\ref=def:THdual], [\ref=def:evseq] and Lemma [\ref=lem:splitseqdual]. [formula]

The scalar ν

In this section we introduce a scalar ν that will help us describe TH systems. We start by updating Notation [\ref=not:aastar].

Let Φ = (A;{Ei}di = 0;A*;{E*i}di = 0) denote a TH system on V. Let ({θi}di = 0,{θ*i}di = 0,{φi}di = 1) denote the parameter array of Φ.

With reference to Notation [\ref=ass:updated], let D (resp. D*) denote the [formula]-subalgebra of End(V) generated by A (resp. A*). Fix 0  ≠  η0∈E0V and 0  ≠  η*0∈E*0V. Then each of the maps

[formula]

is an isomorphism of [formula]-vector spaces.

Proof: For the map on the left, use the fact that ([\ref=eq:duallbubbasis]) is a basis for V. For the map on the right, use the fact that ([\ref=eq:spbasis]) is a basis for V. [formula]

With reference to Notation [\ref=ass:updated], each of the maps

[formula]

is an isomorphism of [formula]-vector spaces.

Proof: Use Lemma [\ref=cor:eta0gen] and the fact that each of E0V,E*0V has dimension 1. [formula]

Consider the maps in Lemma [\ref=lem:eoeostar]. If we compose the map on the left with the map on the right, then the resulting map acts on E0V as a nonzero scalar multiple of the identity. Denote the scalar by α. If we now compose the map on the right with the map on the left, then the resulting map acts on E*0V as α times the identity. We define ν to be the reciprocal of α. Observe that ν is nonzero.

With reference to Notation [\ref=ass:updated], the following (i), (ii) hold.

νE0E*0E0  =  E0.

νE*0E0E*0  =  E*0.

Proof: Clear from the definition of ν. [formula]

We mention one significance of ν.

With reference to Notation [\ref=ass:updated], tr(E0E*0)  =  ν- 1.

Proof: Consider the equation in Lemma [\ref=lem:nutripleproduct](i). Take the trace of each side and then simplify using the fact that tr(E0)  =  1 and tr(E0E*0E0)  =  tr(E0E0E*0)  =  tr(E0E*0). The result follows. [formula]

We now express ν in terms of the parameter array of Φ.

With reference to Notation [\ref=ass:updated],

[formula]

Proof: Fix 0  ≠  η0∈E0V and let {vi}di = 0 denote the corresponding Φ-split basis for V from Definition [\ref=def:lbubbasis]. Observe that vd  =  η0. By Lemma [\ref=lem:nutripleproduct], we have νE0E*0E0  =  E0. Applying each side of this equation to vd and using vd∈E0V, we find νE0E*0vd  =  vd. By ([\ref=eq:defEi]) we have [formula], where [formula]. Similarly we have [formula], where [formula]. By Proposition [\ref=prop:lbublooklike], we find [formula], where [formula]. Similarly [formula]. Combining these facts, we find νφvd  =  ψψ*vd. Now νφ  =  ψψ* since vd  ≠  0. The result follows. [formula]

The Φ-standard basis

Let Φ denote a TH system on V. In this section we investigate a certain basis for V called the Φ-standard basis.

With reference to Notation [\ref=ass:updated], let 0  ≠  η0∈E0V. Then the sequence

[formula]

is a basis for V.

Proof: This follows from Lemma [\ref=cor:eta0gen] and the fact that {E*i}di = 0 is a basis for D*. [formula]

With reference to Notation [\ref=ass:updated], a basis for V is called Φ-standard whenever it is of the form ([\ref=eq:dst]), where 0  ≠  η0∈E0V.

With reference to Notation [\ref=ass:updated], let {vi}di = 0 denote a Φ-standard basis for V, and let {wi}di = 0 denote any vectors in V. Then the following are equivalent.

{wi}di = 0 is a Φ-standard basis for V.

There exists [formula] such that wi  =  c  vi for 0  ≤  i  ≤  d.

Proof: Routine. [formula]

With reference to Notation [\ref=ass:updated], let H (resp. D*) denote the matrix in [formula] which represents A (resp. A*) with respect to a Φ-standard basis for V.

Our next goal is to describe the matrices H and D*. We start with D*.

With reference to Notation [\ref=ass:updated] and Definition [\ref=not:ccstar], the matrix D* is diagonal with entries D*ii  =  θ*i for 0  ≤  i  ≤  d.

Proof: Recall A*E*i  =  θ*iE*i for 0  ≤  i  ≤  d. The result follows. [formula]

We now turn our attention to the matrix H. We recall some linear algebraic terms. Suppose we are given two bases for V, written {ui}di = 0 and {vi}di = 0. By the transition matrix from {ui}di = 0 to {vi}di = 0, we mean the matrix T in [formula] that satisfies [formula] for 0  ≤  j  ≤  d. We recall a few properties of transition matrices. Let T denote the transition matrix from {ui}di = 0 to {vi}di = 0. Then T- 1 exists, and equals the transition matrix from {vi}di = 0 to {ui}di = 0. Let {wi}di = 0 denote a basis for V, and let S denote the transition matrix from {vi}di = 0 to {wi}di = 0. Then TS is the transition matrix from {ui}di = 0 to {wi}di = 0. Let A∈End(V), and let M (resp. N) denote the matrix in [formula] which represents A with respect to {ui}di = 0 (resp. {vi}di = 0). Then M  =  TNT- 1.

With reference to Notation [\ref=ass:updated] and Definition [\ref=not:ccstar], let {ui}di = 0 denote a Φ-split basis for V, and let {vi}di = 0 denote a Φ-standard basis for V. Let B (resp. B*) denote the matrix in [formula] which represents A (resp. A*) with respect to {ui}di = 0. Let [formula] denote the transition matrix from {vi}di = 0 to {ui}di = 0. Then the following (i), (ii) hold.

H  =  TBT- 1.

D*  =  TB*T- 1.

Proof: Follows from the comments prior to this lemma. [formula]

Recall that we are trying to find the matrix H. To do this we use the equations in Lemma [\ref=lem:ttrans]. In these equations the matrices B and B* were found in Proposition [\ref=prop:lbublooklike] and the matrix D* was found in Lemma [\ref=lem:dstar]. We use Lemma [\ref=lem:ttrans](ii) to find the matrix T and then use Lemma [\ref=lem:ttrans](i) to find the matrix H.

With reference to Notation [\ref=ass:updated], fix 0  ≠  η0∈E0V. Let {ui}di = 0 denote the Φ-split basis for V as in ([\ref=eq:spbasis]), and let {vi}di = 0 denote the Φ-standard basis for V as in ([\ref=eq:dst]). Let [formula] denote the transition matrix from {vi}di = 0 to {ui}di = 0. Then T is upper triangular with entries

[formula]

Moreover T- 1 is upper triangular with entries

[formula]

for 0  ≤  i  ≤  j  ≤  d.

Proof: Observe that [formula] and so Tid  =  1 for 0  ≤  i  ≤  d. Moreover by Lemma [\ref=lem:ttrans](ii) we have D*T  =  TB*, where D* is from Lemma [\ref=lem:dstar] and B* is from Proposition [\ref=prop:lbublooklike]. Therefore by a routine matrix multiplication, we find θ*iTij  =  Ti,j - 1  +  θ*jTij for 0  ≤  i  ≤  d and 1  ≤  j  ≤  d. Rearranging we obtain Ti,j - 1  =  (θ*i  -  θ*j)Tij and ([\ref=eq:tij]) follows by a simple recursion. To prove our assertion about T- 1, let [formula] denote an upper triangular matrix with entries

[formula]

for 0  ≤  i  ≤  j  ≤  d. It suffices to show that TS  =  I. The matrices T and S are both upper triangular, so TS is upper triangular. By ([\ref=eq:tij]), ([\ref=eq:sij]) we find that for 0  ≤  i  ≤  d,

[formula]

so (TS)ii  =  1. We now show that (TS)ij = 0 for 0  ≤  i  <  j  ≤  d. Let i,j be given. It suffices to show that (θ*i  -  θ*j)(TS)ij  =  0, since {θ*h}dh = 0 are mutually distinct. Observe that

[formula]

since the two sums in ([\ref=eq:twosum]) are one and the same. We have now shown that (TS)ij  =  0 for 0  ≤  i < j  ≤  d. Combining our above arguments, we find TS = I. The result follows. [formula]

With reference to Notation [\ref=ass:updated] and Definition [\ref=not:ccstar], the matrix H is Hessenberg with entries

[formula]

for i  ≤  j + 1  (0  ≤  i,j  ≤  d), where [formula] and [formula]

Proof: By Lemma [\ref=lem:ttrans](i), H  =  TBT- 1, where B is the matrix on the left in ([\ref=eq:matrepaastar]) and T,T- 1 are from Lemma [\ref=lem:hdtolbubbasis]. By a routine matrix multiplication, we find that each entry below the subdiagonal of H is zero and the remaining entries of H are as claimed. To see that H is Hessenberg, it remains to show that each entry on the subdiagonal is nonzero. Using the above data, we find

[formula]

for 0  ≤  j  ≤  d - 1. Since {θ*i}di = 0 are mutually distinct and {φi}di = 1 are nonzero, Hj + 1,j is nonzero. Therefore H is Hessenberg and the result follows. [formula]

We give three characterizations of the Φ-standard basis.

With reference to Notation [\ref=ass:updated], let {vi}di = 0 denote a sequence of vectors in V, not all zero. Then this sequence is a Φ-standard basis for V if and only if the following (i), (ii) hold.

vi∈E*iV for 0  ≤  i  ≤  d.

[formula].

Proof: To prove the proposition in one direction, assume that {vi}di = 0 is a Φ-standard basis for V. By Definition [\ref=def:hdbasis], there exists 0  ≠  η0∈E0V such that vi  =  E*iη0 for 0  ≤  i  ≤  d. Apparently vi∈E*iV so (i) holds. Observe that [formula]. Applying both sides to η0 we find [formula] and (ii) follows. We have now proved the proposition in one direction. To prove the other direction, assume that {vi}di = 0 satisfy (i), (ii) above. We define [formula] and observe that η0∈E0V by (ii). Using (i) we find E*ivj  =  δijvj for 0  ≤  i,j  ≤  d and hence vi  =  E*iη0 for 0  ≤  i  ≤  d. Observe that η0  ≠  0 since at least one of {vi}di = 0 is nonzero. Now {vi}di = 0 is a Φ-standard basis for V by Definition [\ref=def:hdbasis]. [formula]

We recall some notation. For [formula] and [formula], X is said to have constant row sum α whenever [formula] for 0  ≤  i  ≤  d.

With reference to Notation [\ref=ass:updated], let {vi}di = 0 denote a basis for V. Let C (resp. C*) denote the matrix in [formula] which represents A (resp. A*) with respect to this basis. Then {vi}di = 0 is a Φ-standard basis for V if and only if the following (i), (ii) hold.

C has constant row sum θ0.

[formula].

Proof: Observe that [formula]. Recall E0V is the eigenspace of A corresponding to eigenvalue θ0. Apparently C has constant row sum θ0 if and only if [formula]. Recall that for 0  ≤  i  ≤  d, E*iV is the eigenspace of A* corresponding to eigenvalue θ*i. Apparently [formula] if and only if vi∈E*iV for 0  ≤  i  ≤  d. The result follows by Proposition [\ref=lem:eggechar]. [formula]

With reference to Notation [\ref=ass:updated], let {vi}di = 0 denote a basis for V, and let C (resp. C*) denote the matrix in [formula] which represents A (resp. A*) with respect to this basis. Then {vi}di = 0 is a Φ-standard basis for V if and only if the following (i), (ii) hold.

C is Hessenberg with constant row sum θ0.

C* is diagonal and C*00  =  θ*0.

Proof: Suppose that {vi}di = 0 is a Φ-standard basis for V. By Proposition [\ref=lem:hdlooklike], C is Hessenberg and by Proposition [\ref=lem:rowsum](i), C has constant row sum θ0. By Proposition [\ref=lem:rowsum](ii), C* is diagonal and C*00  =  θ*0. Therefore (i), (ii) above hold. We have proved the proposition in one direction. To prove the other direction, suppose that (i), (ii) above hold. Since C is Hessenberg and C* is diagonal, applying Lemma [\ref=lem:trihess] we find {C*ii}di = 0 is a dual eigenvalue sequence of A,A*. Since C*00  =  θ*0, applying Lemma [\ref=lem:eig] we find C*ii  =  θ*i for 0  ≤  i  ≤  d. Therefore [formula] and by Proposition [\ref=lem:rowsum], {vi}di = 0 is a Φ-standard basis for V. [formula]

The Φ*-standard basis

Let Φ = (A;{Ei}di = 0;A*;{E*i}di = 0) denote a TH system on V. In the previous section, we obtained several results related to the Φ-standard basis for V. Analogous results hold for the Φ*-standard basis for V. In this section, we display some of those results for use later in the paper. We begin by observing that a Φ*-standard basis for V has the form

[formula]

where 0  ≠  η*0∈E*0V.

With reference to Notation [\ref=ass:updated], let D (resp. H*) denote the matrix in [formula] which represents A (resp. A*) with respect to a Φ*-standard basis for V.

With reference to Notation [\ref=ass:updated] and Definition [\ref=not:ccstardual], the matrix D is diagonal with entries Dii  =  θi for 0  ≤  i  ≤  d.

Proof: Apply Lemma [\ref=lem:dstar] to Φ*. [formula]

With reference to Notation [\ref=ass:updated] and Definition [\ref=not:ccstardual], let {ui}di = 0 denote a Φ*-split basis for V, and let {vi}di = 0 denote a Φ*-standard basis for V. Let B (resp. B*) denote the matrix in [formula] which represents A (resp. A*) with respect to {ui}di = 0. Let [formula] denote the transition matrix from {vi}di = 0 to {ui}di = 0. Then the following (i), (ii) hold.

D  =  T*BT*  - 1.

H*  =  T*B*T*  - 1.

Proof: Apply Lemma [\ref=lem:ttrans] to Φ*. [formula]

With reference to Notation [\ref=ass:updated], fix 0  ≠  η*0∈E*0V. Let {ui}di = 0 denote the Φ*-split basis for V as in ([\ref=eq:duallbubbasis]), and let {vi}di = 0 denote the Φ*-standard basis for V as in ([\ref=eq:st]). Let [formula] denote the transition matrix from {vi}di = 0 to {ui}di = 0. Then T* is upper triangular with entries

[formula]

Moreover T*  - 1 is upper triangular with entries

[formula]

for 0  ≤  i  ≤  j  ≤  d.

Proof: Apply Lemma [\ref=lem:hdtolbubbasis] to Φ*. [formula]

With reference to Notation [\ref=ass:updated] and Definition [\ref=not:ccstardual], the matrix H* is Hessenberg with entries

[formula]

for i  ≤  j + 1  (0  ≤  i,j  ≤  d), where [formula] and [formula]

Proof: Apply Proposition [\ref=lem:hdlooklike] to Φ*. [formula]

Transition matrices between the Φ-standard basis and the Φ*-standard basis

In this section we describe the transition matrices between the Φ-standard basis for V and the Φ*-standard basis for V.

With reference to Notation [\ref=ass:updated], let Z denote the matrix in [formula] with entries

[formula]

for 0  ≤  i,j  ≤  d.

The following lemma gives the significance of Z.

With reference to Notation [\ref=ass:updated], let {vi}di = 0 denote a Φ-split basis for V as in ([\ref=eq:spbasis]), and let {wi}di = 0 denote a Φ*-split basis for V as in ([\ref=eq:duallbubbasis]) with η0,η*0 from those lines chosen so that η0 = E0η*0. Then the transition matrix from {vi}di = 0 to {wi}di = 0 is the matrix Z from Definition [\ref=def:zij].

Proof: The transition matrix from {vi}di = 0 to {wi}di = 0 is given by Lemma [\ref=cor:trans] for an appropriate value of the scalar c in that lemma. We now find that value. Setting i = 0 in Lemma [\ref=cor:trans](ii), we find w0  =  c  vd. Using ([\ref=eq:duallbubbasis]), we find [formula] and this equals [formula]. Using ([\ref=eq:spbasis]), we find vd  =  η0  =  E0η*0 by our choice of η0,η*0. Therefore [formula] and so [formula]. The result follows. [formula]

With reference to Notation [\ref=ass:updated], let Z* denote the matrix in [formula] with entries

[formula]

for 0  ≤  i,j  ≤  d.

The following lemma gives the significance of Z*.

With reference to Notation [\ref=ass:updated], let {vi}di = 0 denote a Φ-split basis for V as in ([\ref=eq:spbasis]), and let {wi}di = 0 denote a Φ*-split basis for V as in ([\ref=eq:duallbubbasis]) with η0,η*0 from those lines chosen so that η*0 = E*0η0. Then the transition matrix from {wi}di = 0 to {vi}di = 0 is the matrix Z* from Definition [\ref=def:zijstar].

Proof: Apply Lemma [\ref=lem:bdmatrix] to Φ*. [formula]

With reference to Notation [\ref=ass:updated] and Definitions [\ref=def:zij], [\ref=def:zijstar],

[formula]

where ν is the scalar above Lemma [\ref=lem:nutripleproduct].

Proof: Multiply Z and Z* and use Lemma [\ref=lem:nupa]. [formula]

With reference to Notation [\ref=ass:updated], let P (resp. P*) denote the transition matrix from ([\ref=eq:st]) to ([\ref=eq:dst]) (resp. ([\ref=eq:dst]) to ([\ref=eq:st])) with η0,η*0 from those lines chosen so that η*0 = E*0η0 (resp. η0 = E0η*0).

With reference to Notation [\ref=ass:updated] and Definition [\ref=def:ppstar],

[formula]

where T,T* are from Lemmas [\ref=lem:hdtolbubbasis], [\ref=lem:dhtolbubbasis] and Z,Z* are from Definitions [\ref=def:zij], [\ref=def:zijstar].

Proof: By Lemma [\ref=lem:hdtolbubbasis], T- 1 is the transition matrix from ([\ref=eq:spbasis]) to ([\ref=eq:dst]). Moreover by Lemma [\ref=lem:bdmatrixstar], Z* is the transition matrix from ([\ref=eq:duallbubbasis]) to ([\ref=eq:spbasis]) and by Lemma [\ref=lem:dhtolbubbasis], T* is the transition matrix from ([\ref=eq:st]) to ([\ref=eq:duallbubbasis]). Therefore, by the comments prior to Lemma [\ref=lem:ttrans], we find T*Z*T- 1 is the transition matrix from ([\ref=eq:st]) to ([\ref=eq:dst]) and hence equals P. We have proved the equation on the left. To prove the equation on the right, apply the equation on the left to Φ*. [formula]

With reference to Notation [\ref=ass:updated] and Definition [\ref=def:ppstar], the following (i), (ii) hold.

For 0  ≤  i,j  ≤  d, Pij is equal to

[formula]

times

[formula]

In particular Pi0 = 1 for 0  ≤  i  ≤  d.

For 0  ≤  i,j  ≤  d, P*ij is equal to

[formula]

times

[formula]

In particular P*i0 = 1 for 0  ≤  i  ≤  d.

Proof: Routine by Lemma [\ref=lem:ptrans] and matrix multiplication. [formula]

With reference to Notation [\ref=ass:updated] and Definition [\ref=def:ppstar],

[formula]

where ν is the scalar above Lemma [\ref=lem:nutripleproduct].

Proof: Evaluate the left hand sides using Lemma [\ref=lem:ptrans] and then simplify using Lemma [\ref=lem:nuzzstar]. [formula]

We finish this section with a comment.

With reference to Notation [\ref=ass:updated] and Definition [\ref=def:ppstar],

[formula]

where D*, H (resp. D, H*) are from Definition [\ref=not:ccstar] (resp. Definition [\ref=not:ccstardual]).

Proof: Recall from Definition [\ref=not:ccstar] (resp. Definition [\ref=not:ccstardual]) that H (resp. D) is the matrix in [formula] which represents A with respect to a Φ-standard (resp. Φ*-standard) basis for V. Moreover recall from Definition [\ref=def:ppstar] that P is a transition matrix from a Φ*-standard basis to a Φ-standard basis. Therefore the equation on the left holds by the comments prior to Lemma [\ref=lem:ttrans]. To prove the equation on the right, apply the equation on the left to Φ*. [formula]

Acknowledgement

This paper was written while the author was a graduate student at the University of Wisconsin-Madison. The author would like to thank his advisor Paul Terwilliger for his many valuable ideas and suggestions.

Ali Godjali Department of Mathematics University of Wisconsin Van Vleck Hall 480 Lincoln Drive Madison, WI 53706-1388 USA email: godjali@math.wisc.edu