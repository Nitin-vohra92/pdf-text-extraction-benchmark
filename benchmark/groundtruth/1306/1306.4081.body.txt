Computing the truncated theta function via Mordell integral

Dept. of Mathematics and Statistics York University 4700 Keele Street Toronto, ON M3J 1P3, Canada

Keywords: truncated theta function, Mordell integral, Riemann zeta function 2010 Mathematics Subject Classification : 11Y16, 11M06

Introduction and main results

The truncated theta function is defined as

[formula]

where [formula] and [formula]. We are interested in computing efficiently the truncated theta function Fn(z,τ) for large values of n. The motivation for developing such algorithms comes from computational Number Theory. One particularly important application is for computing the Riemann zeta function [formula] for large t. The classical result by Riemann and Siegel (see formula 4.17.5 in [\cite=Ti1986]) allows to evaluate [formula] to within ±  t-  λ in [formula] arithmetic operations (by an arithmetic operation we mean additions, multiplications, evaluations of the logarithm and of the complex exponential function). It is a very challenging task to prove that the number of operations can be reduced to O(tα) with some α < 1 / 2. It is an even harder problem to develop an algorithm which would not only have theoretical complexity O(tα), but would also be feasible for practical implementation. In the recent papers [\cite=Hiary_zeta] [\cite=Hiary_theta], Hiary has developed two new algorithms, which allow us to evaluate [formula] to within ±  t-  λ in [formula] and [formula]) arithmetic operations (we will refer to them as 1 / 3-algorithm and 4 / 13-algorithm). The 1 / 3-algorithm is particularly attractive compared with the 4 / 13-algorithm, as it is conceptually simpler, has no substantial storage requirements and should be easier to implement. And this brings us back to the truncated theta functions, as the 1 / 3-algorithm is fundamentally based on another result by Hiary (see [\cite=Hiary_theta]), which states that Fn(z,τ) and its derivatives can be computed to within ±  ε in [formula] arithmetic operations.

Let us summarize the main ideas behind Hiary's truncated theta function algorithm. The algorithm is based on the iterative application of the following two-step procedure. The first step is to "normalize" z and τ so that they lie in the intervals z∈[ -  1  /  2,1  /  2] and τ∈[ -  1  /  4,1  /  4]. This is easily achieved via the identities

[formula]

both of which follow directly from [\eqref=def_F]. If |τ|  <  1 / n, then we compute Fn(z,τ) by the Euler-Maclaurin summation (see Section 3.2 in [\cite=Hiary_theta]), otherwise we proceed to the second step of the algorithm, which is based on the following identity

[formula]

where τ > 0 and m = ⌊2nτ⌋. Here and everywhere in this paper [formula] denotes the floor function. A corresponding identity for τ < 0 can be derived by taking the conjugate of both sides of [\eqref=Hiary_main_formula] and using the fact that [formula].

Identity [\eqref=Hiary_main_formula] plays the central role in Hiary's algorithm. It is derived by applying the Poisson summation formula to [\eqref=def_F] and using the crucial self-similarity property of the Gaussian function (the fact that taking Fourier transform of exp ( - ax2 - bx - c) results in a function of the same form but with different parameters). The truncated theta function Fm(  ·  ,  ·  ) in the right-hand side of [\eqref=Hiary_main_formula] is the dominant contribution arising from the Poisson summation formula, while Rm,n(z,τ) can be considered as the remainder term. The key idea behind the second step in Hiary's algorithm is that the identity [\eqref=Hiary_main_formula] transforms a long sum with n terms into a short sum having m = ⌊2n|τ|⌋  ≤  n / 2 terms (recall that we have normalized τ so that |τ|  ≤  1 / 4). If m is smaller than a fixed power of ln (n / ε), then we compute Fm(  ·  ,  ·  ) by direct summation, otherwise we apply the same two-step procedure to Fm(  ·  ,  ·  ). It is clear that this algorithm will terminate after at most log 2(n) iterations (where log 2(  ·  ) denotes the logarithm with base two).

Our goal in this paper is to simplify Hiary's algorithm for computing the truncated theta function. In order to present our results, first we need to introduce Mordell integral, which is defined as

[formula]

We need to extend this definition for real values of τ. Assume that τ lies in the quadrant [formula] and [formula]. Then the following identity is true

[formula]

This result can be easily established by rotating the contour of integration [formula] in the integral [\eqref=def_hztau] and then changing the variable of integration [formula]. It is clear the integral in [\eqref=def_hztau_2] provides the analytic continuation of h(z,τ) into the domain [formula], [formula]. We will adopt this as the definition of h(z,τ) for τ > 0 and [formula], while for τ < 0 and [formula] we will define [formula].

Mordell integral and related functions have been studied for more than a century. One particular example of such integrals was used by Riemann to derive the functional equation for the zeta function (see section 2.10 in [\cite=Ti1986]), while some further special cases were investigated by Ramanujan [\cite=Ramanujan]. Mordell [\cite=Mordell] [\cite=Mordell2] has developed a general theory of h(z,τ) and some related integrals. Among many other results, Mordell has discovered the connections between h(z,τ) and theta functions, he has studied general modular transformations of h(z,τ) and has proved that h(z,τ) can be expressed in terms of the Gauss sums when τ is rational (more precisely, h(z,p / q) can be expressed in terms of functions Fq(z,p / (2q)) and Fp(z, - q / (2p)), see section 8 in [\cite=Mordell2]). Recently, the Mordell integral h(z,τ) was investigated by Zwegers in his Ph.D. thesis [\cite=Zwegers], and we will follow Zwegers's notation in our paper.

The following theorem is our first main result, and it is the basis for our simplified version of Hiary's algorithm for fast evaluations of Fn(z,τ).

For τ > 0, [formula] and [formula]

[formula]

where

[formula]

Using Theorem [\ref=thm_main] we are able to establish the following result (which should be compared with Theorem 1.1 in [\cite=Hiary_theta]).

There exists an algorithm such that for any [formula], any z,τ∈(0,1) and any integer n  ≥  1 the value of the function Fn(z,τ) can be evaluated to within ±  ε using [formula] arithmetic operations on numbers of [formula] bits. The algorithm requires [formula] bits of memory.

In the above result (and everywhere in this paper) we assume that [formula] and [formula] are constants, which are positive and absolute, in the sense that they do not depend on the values of any other parameters.

The paper is organized as follows: Section [\ref=sec_proofs] contains the proofs of Theorems [\ref=thm_main] and [\ref=thm_main2] and in Section [\ref=section_numerics] we discuss the practical implementation and some extensions of the algorithm.

Proof of the main results

For [formula] and τ > 0

[formula]

While the above identities are not new (see [\cite=Mordell2] and [\cite=Zwegers]), we present the sketch of the proof for the sake of completeness. Let us denote [formula] and assume that τ > 0. From the second integral representation in [\eqref=def_hztau_2] we obtain

[formula]

Evaluating the integral in the right-hand side of the above identity (use formula (3.323.2) in [\cite=Jeffrey2007]) gives us [\eqref=hztau_period_1].

In order to prove [\eqref=hztau_1_over_tau] we use formulas (3.323.2) and (3.511.4) in [\cite=Jeffrey2007] and evaluate the following two integrals: For [formula]

[formula]

Applying Parseval's Theorem for Fourier transform to the first integral in [\eqref=def_hztau_2] gives us

[formula]

Proof of Theorem [\ref=thm_main]: We take the conjugate of both sides of equation [\eqref=hztau_period_1] and obtain

[formula]

Iterating the above identity m times gives us

[formula]

which is equivalent to

[formula]

We change variables z = w / t, τ =  - 1 / t and m = n in [\eqref=proof_eq2], and then apply transformation [\eqref=hztau_1_over_tau] to both h-functions, which results in the following identity

[formula]

At the same time, changing variables z = w + nt - m + t / 2 - 1 / 2 and τ = t in [\eqref=proof_eq2] we obtain

[formula]

Eliminating [formula] from the two equations [\eqref=proof_eq3] and [\eqref=proof_eq4] gives us

[formula]

The above identity is equivalent to [\eqref=main_formula]. In order to verify this one would need to apply the transformation

[formula]

(which follows easily from [\eqref=def_F] by changing the index of summation k  ↦  m - k), then change the variables [formula] and t = 2τ and simplify the result.

Now we need to introduce several new objects. We define the sequence {Ẽk}k  ≥  0 as

[formula]

or, alternatively, Ẽk = Ek / k! where {Ek}k  ≥  0 are Euler numbers. We define the function fτ(z) and the sequence of polynomials {qk(τ)}k  ≥  0 as

[formula]

Using equation [\eqref=def_Bk_Ek2] it is easy to see that

[formula]

We introduce the sequence of functions {pk(x)}k  ≥  0, defined by

[formula]

For k  ≥  1, τ > 0 and [formula] we define

[formula]

where Φ(z) is the error function

[formula]

Finally, for z > 0 and [formula] we define

[formula]

where fτ(x) is given by [\eqref=def_f_tau_z].

For k  ≥  1, |z|  ≤  1 / 2 and τ∈(0,1)

[formula]

For ε > 0 let us denote [formula]. Then for any [formula], |z|  ≤  1 / 2 and τ∈(0,1)

[formula]

where |E| < ε.

Let us prove part (i). We denote [formula], use the second integral representation in [\eqref=def_hztau_2] and the identity

[formula]

and obtain

[formula]

The integrals in the sum in the right-hand side of [\eqref=prop_proof1] can be evaluated explicitly by applying formula (3.322.2) in [\cite=Jeffrey2007]; this gives us the terms Hk(z,τ) + Hk( - z,τ). To deal with the remaining integral in the right-hand side of [\eqref=prop_proof1], we rotate the contour of integration [formula] and change the variable of integration y = x / (πθ). This gives us

[formula]

and ends the proof of the identity [\eqref=hnztau_computing] and part (i) of the proposition.

Let us prove part (ii). We write

[formula]

Using the fact that |z|  ≤  1 / 2 and |fτ(x)| < 1 for x > 0, the second integral in the right-hand side of [\eqref=J_K_two_integrals] can be bounded from above as

[formula]

In order to deal with the first integral in the right-hand side of [\eqref=J_K_two_integrals], we expand fτ(x) in Taylor series in x (which converges for |x| < π / 2, see [\eqref=def_f_tau_z]) and obtain

[formula]

In order to estimate the tail of the above series, first we will need to establish an upper bound for qk(τ). From the following identity for Euler numbers (see formulas 9.652.3 and 9.655.3 in [\cite=Jeffrey2007])

[formula]

we conclude that [formula]. Using formula [\eqref=q_k_tau_formula] and the fact that |τ| < 1 we obtain

[formula]

Using the above result we estimate the tail of the series in [\eqref=tail_series] as follows

[formula]

Formulas [\eqref=J_K_two_integrals], [\eqref=estimate_second_integral], [\eqref=tail_series] and [\eqref=estimate_tail] show that for all |z|  ≤  1 / 2 and τ∈(0,1)

[formula]

where [formula]. The above statement combined with [\eqref=hnztau_computing] gives us the desired result [\eqref=formula_dzj_h_z_tau].

There exists an algorithm such that for any [formula] and [formula] the value of [formula] can be evaluated to within ±  ε using [formula] arithmetic operations on numbers of [formula] bits. The algorithm requires [formula] bits of memory.

Since [formula] is an odd function, we can restrict x to be a positive number. When x∈(0,1] we compute [formula] using Taylor series [\eqref=series_for_Phi]. Since this series is converging exponentially fast, it can be truncated after [formula] terms in order to achieve accuracy ±  ε.

Let us consider the case when x∈(1,  ∞  ). We will use the following result (see equations (3)-(6) in [\cite=Hunter_Regan]): For [formula] with [formula]

[formula]

where h > 0 and [formula]. Here [formula] if [formula] and R(z,h): = 0 otherwise. The error term E(z,h) can be bounded from above as

[formula]

Let us define [formula], [formula] and

[formula]

This choice of h implies [formula] and

[formula]

therefore

[formula]

Next, we define N = ⌈4γ2⌉ and we estimate the tail of the series in [\eqref=hunter_regan_n1] as

[formula]

The above results show that for every x > 1 we can choose h according to [\eqref=def_h_x] and obtain

[formula]

where |E| < ε. Since the number of terms in the above sum is [formula], this ends the proof of Proposition [\eqref=prop_Phi] in the case x∈(1,  ∞  ).

There exists an algorithm such that for any [formula], |z| < 10 and τ∈(0,1) the value of h(z,τ) can be evaluated to within [formula] using [formula] arithmetic operations on numbers of [formula] bits. The algorithm requires [formula] bits of memory.

All computations will be performed on numbers of [formula] bits, where A3 is the constant from Proposition [\ref=prop_Phi]. We set [formula]. The first step is to pre-compute and store in the memory the values of Ẽk for 0  ≤  k  ≤  2K. These numbers can be computed recursively (via formula 9.631 in [\cite=Jeffrey2007]), this computation will require O(K2) arithmetic operations and O(K2) bits of memory. The second step is to use identity [\eqref=hztau_period_1] and to normalize z so that |z|  ≤  1 / 2 (note that this will require O(|z|) arithmetic operations - we will need this fact later). The thid step is to apply formula [\eqref=formula_dzj_h_z_tau]. According to [\eqref=def_big_Hn_z_tau] and Proposition [\ref=prop_Phi], the computation of HK(  ±  z,τ) to the accuracy of [formula] can be achieved in O(K2) arithmetic operations using O(K) bits of memory. We claim that the computation of the finite sum in [\eqref=formula_dzj_h_z_tau] to the accuracy ±  ε can also be done in O(K2) arithmetic operations using O(K) bits of memory (provided that we are using the pre-computed values of Ẽk). This follows from the fact that the coefficients qk(τ) can be computed via [\eqref=q_k_tau_formula] in O(k) computations, while the values of pk(x) can be evaluated recursively via the identity

[formula]

which follows easily from [\eqref=def_pk_x] by integration by parts. Note that the above recurrence identity is numerically stable as long as |x|  ≥  k, which is true in formula [\eqref=formula_dzj_h_z_tau].

There exists an algorithm such that for any integer n  ≥  1, [formula], |z|  ≤  1 / 2 and |τ|  <  n- 4 the value of the function Fn(z,τ) can be evaluated to within ±  ε using [formula] arithmetic operations on numbers of [formula] bits. The algorithm requires [formula] bits of memory.

The main idea behind this algorithm is to expand the exponential function in Taylor series, however the details of the implementation will be different depending on whether |z| > n- 1 or |z| < n- 1. Let us consider the first case, when |z| > n- 1. We expand [formula] in Taylor series and obtain

[formula]

Since |τ| < n- 4, the absolute value of the sum in the square brackets is bounded from above by (n + 1). Therefore, the external sum in l is converging exponentially fast, and in order to achieve accuracy ±  ε we can truncate it after [formula] terms for some constant A10. We assume that L3  <  n, otherwise we will compute Fn(z,τ) by direct summation. Our goal is to show that the sum in the square brackets can be evaluated with accuracy ±  ε in O(L2) operations on numbers of O(L) bits using O(L2) bits of memory. The main idea is to rewrite this sum as follows

[formula]

Using Leibniz rule we find that

[formula]

where we have defined

[formula]

and

[formula]

While the computation of gj(z) is straighforward, the computation of fj(z) requires more work. First, we check by induction that

[formula]

where a0,1 = 1 and the remaining coefficients aj,k can be computed by the recursion

[formula]

From [\eqref=recursion_a_k_i] one can see by induction that |aj,k| < (4πj / n)j < 1 (recall that [formula]). Note that the condition n- 1 < |z|  ≤  1 / 2 implies

[formula]

since | sin (2πz)|  ≥  4|z| if |z|  ≤  1 / 4 and | cos (2πz) - 1| > 1 if 1 / 4 < |z| < 1 / 2. Given [\eqref=bound_sin_cos] and the above upper bound on the coefficients aj,k, it is clear that formula [\eqref=compute_f_j] provides a numerically stable way of computing fj(z) using numbers of O(L) bits. The memory requirement is O(L2) bits, since in order to compute the coefficients aj + 1,k, 1  ≤  k  ≤  j + 2 via [\eqref=recursion_a_k_i] we need to store at most 2L + 1 numbers aj,k, 1  ≤  k  ≤  j + 1.

When |z| < n- 1 the lower bound [\eqref=bound_sin_cos] is no longer valid, and we have to proceed by a different route. In this case we expand the exponential function [formula] in Taylor series and obtain

[formula]

Since |z| < n- 1 and |τ|  ≤  n- 4, the sum in the square brackets is bounded from above by (n + 1)2l. Therefore, the sum in l is converging exponentially fast, and in order to achieve accuracy ±  ε we can truncate it after [formula] terms. The sum in the square brackets in [\eqref=F_n_small_z_small_tau] can be computed as follows

[formula]

where we have defined [formula]. Formula (9.623.1) in [\cite=Jeffrey2007] gives us

[formula]

where Bi are the Bernoulli numbers [formula]. We will leave it to the reader to verify that the above three formulas provide the required algorithm for computing Fn(z,τ) to within ±  ε in O(L3) arithmetic operations on numbers of O(L) bits (one should precompute and store 2L values of Bi / i!, 0  ≤  i  ≤  2L, which can be done in O(L2) arithmetic operations using O(L2) bits of memory).

Proof of Theorem [\ref=thm_main2]: We are given z∈(0,1), τ∈(0,1), a positive integer n and a small positive number ε. We will describe the algorithm for computing the value of F = Fn(z,τ). In order to start the algorithm, we use identities [\eqref=identities_step_1] and normalize z and τ so that |z|  ≤  1 / 2 and |τ|  ≤  1 / 4; we define z1 and τ1 to be equal to these normalized values of z and τ. The algorithm is based on a recursion, and j will be the counter which keeps track of the steps of the recursion. We initialize j = 1, n1 = n, α1 = 1 and β1 = 0. All computations are performed on numbers of [formula] bits, where A5 and A8 are the constants appearing in Propositions [\ref=prop_compute_h_z_tau2] and [\ref=proposition_small_tau].

The algorithm:

If nj  ≤   ln (n)3 then we compute f = Fnj(zj,τj) by direct summation. Terminate the algorithm and return F = αjf  +  βj.

If |τj|  <  n- 4j then we compute f = Fnj(zj,τj) to the accuracy of ±  ε / n3 using the algorithm from Proposition [\ref=proposition_small_tau]. Terminate the algorithm and return F = αjf  +  βj.

If |τj|  ≥  n- 4j we set nj + 1  =  ⌊2nj|τj|⌋, [formula] and [formula]. Set zj + 1 and τj + 1 to be the normalized values of [formula] and [formula] (use identities [\eqref=identities_step_1]). If τj > 0, then

[formula]

while if τj < 0 then

[formula]

where Rm,n(z,τ) is given by by [\eqref=def_Rmnztau], and the values of the Mordell integral h(  ·  ,  ·  ) appearing in [\eqref=def_Rmnztau] are computed using the algorithm from Proposition [\ref=prop_compute_h_z_tau2] to the accuracy ±  ε / n3.

Increase the counter j  ↦  j + 1 and proceed to step (i).

Assume that this algorithm stops after J iterations. The fact that this algorithm returns the correct value of Fn(z,τ) can be verified by induction on J using identity [\eqref=main_formula]. Let us investigate the number of arithmetic operations required by this algorithm. At each iteration of the algorithm, provided that it does not terminate in steps (i) or (ii), we have the new value nj + 1 which satisfies nj + 1  =  ⌊2nj|τj|⌋  ≤  nj / 2 (recall that |τj|  ≤  1 / 4). This shows that the algorithm will either terminate in step (i) after at most log 2(n) iterations, or it will terminate in step (ii) before that. Let us denote [formula]. Step (ii) (resp. step (iii)) requires O(L3) (resp. O(L2)) arithmetic operations and both of these steps require O(L2) bits of memory (see Propositions [\ref=prop_compute_h_z_tau2] and [\ref=proposition_small_tau]). Since step (ii) will be executed at most once, and step (iii) at most log 2(n) times, it is clear that the algorithm requires O(L3) arithmetic operations and O(L2) bits of memory.

Finally, let us consider the accuracy of this algorithm. All numbers appearing in the algorithm are evaluated to the accuracy ±  ε / n3. Since the algorithm did not terminate at the iteration J - 1, we have nJ - 1 > 1 and |τJ - 1|  ≥  n- 4J - 1 > n- 4. Recall that for all j we have nj + 1  ≤  2nj|τj|, therefore

[formula]

and applying formulas [\eqref=formula_alpha_beta1] and [\eqref=formula_alpha_beta2] we obtain

[formula]

Assuming that the algorithm terminates in step (ii), then the final accuracy is at least [formula], which is smaller than the required accuracy ±  ε. On the other hand, if the algorithm terminates in step (i), then [formula], and the final accuracy is [formula], which is still smaller than ±  ε.

Remark 1: One may ask the following natural question: is the choice nj + 1  =  ⌊2nj|τj|⌋ in the above algorithm optimal? In other words, given that the identity [\eqref=main_formula] is true for all positive m and n, why can not we choose m = nj + 1  ≪  2nj|τj|, thus reducing the number of terms in the new sum Fm(  ·  ,  ·  )? The rationale for this choice is that the computation Rm,nj(  ·  ,  ·  ) in formula [\eqref=def_Rmnztau] requires the evaluation of the Mordell integral

[formula]

which involves more than |2nj|τj| - m| arithmetic operations (see step 2 in the proof of Proposition [\ref=prop_compute_h_z_tau2]). Therefore, while the choice of m = nj + 1  ≪  2nj|τj| will decrease the number of terms (and the computation time) of Fm(  ·  ,  ·  ), any gain will be canceled by the corresponding increase in the computation time of Rm,nj(  ·  ,  ·  ).

Practical implementation and extensions of the algorithm

As is often the case, the algorithm which can be analyzed analytically and which allows for rigorous error bounds is not necessarily the most efficient algorithm from the practical point of view. While it is certainly possible to perform practical computations of Fn(z,τ) using the algorithm described in the proof of Theorem [\ref=thm_main2], in this section we will explain how one could produce a more efficient algorithm with a certain amount of pre-computation and a few numerical experiments. This practical implementation is suitable in the case when we need to compute Fn(z,τ) to a fixed accuracy ±  ε for many different values of z, τ and n  ≤  N1 (for some fixed value of N1).

As we saw in the proof of Theorem [\ref=thm_main2], the main computational effort is spent in evaluating Fn(z,τ) for very small values of τ (when |τ| < n- 4) and in computing the Mordell integral h(z,τ). We do not see a way of making the former of these tasks much faster, however the latter task can certainly be done much more efficiently. Part (i) of Proposition [\ref=prop_compute_h_tau_z] shows that in order to compute h(z,τ) we need to be able to evaluate the error function [formula] for [formula] and to compute J(z,τ) defined by [\eqref=def_big_Jn_z_tau]. Let us first discuss the computation of the error function. Our approach to computing [formula] is to divide the interval (0,  ∞  ) into a number of sub-intervals [formula], and use the Chebyshev approximation on each sub-interval. On the infinite interval (x*,  ∞  ) we define the function f(σ) via [formula], where σ: = (x* / x)2 and we approximate f(σ) by the first few terms of the Chebyshev series. It is known (see [\cite=Nemeth]) that the coefficients of the corresponding Chebyshev series decay as [formula], therefore, by a proper choice of x* we can be sure that we need only a few terms of the Chebyshev series to obtain the required accuracy. Once we have chosen x*, we divide (0,x*) into m sub-intervals of equal length, and on each of them we compute the first few terms of the Chebyshev series. Note that on each finite interval (xi,xi + 1), 1  ≤  i < m, the Chebyshev series approximating [formula] must converge exponentially fast since Φ(z) is an entire functions. By choosing m large enough we can make sure that the number of significant terms in each Chebyshev series is small. For example, in our implementation of this algorithm we chose x* = 5 and m = 5, and on each subinterval we approximated [formula] by the first thirty terms of Chebyshev series. This approximation had absolute error ≤  10- 30 over all real values of x.

The second important problem is how to evaluate J(k + z,τ) efficiently. Our approach is based on the following formula

[formula]

which follows from [\eqref=def_big_Jn_z_tau] by changing the variable of integration x = y / (2k). For k  ≥  1, |z|  ≤  1 / 2 and τ∈(0,1) the function [formula] is bounded, and as k  →    +    ∞   it converges to gz,τ(0) = 1. Therefore, when k is reasonably large, the integral in [\eqref=J_practical_computing] can be computed to a very high-precision using the Gauss-Laguerre quadrature with the weight function e- y and M nodes. The problem is to decide what "reasonably large" means, and here one should do a number of numerical experiments to find the optimal values of k and M. If we take k to be a large number, then the function [formula] is very close to 1, and M - the number of nodes in Gauss-Laguerre quadrature - can be taken quite small in order to achieve the required accuracy. Of course, the disdvantage of choosing k to be large is that it would require many evaluations of the error function in [\eqref=def_big_Hn_z_tau], and it would increase the run-time of the algorithm. On the other hand, if we take k to be a small integer, then the function [formula] oscillates and M has to be very large in order to provide the required accuracy, which would again increase the run-time of the algorithm. Therefore, k and M have to be chosen so that the computation time of Hk(z,τ) it approximately equal to the computation time of J(k + z,τ).

In our examples we took k = 5 in formulas [\eqref=hnztau_computing], [\eqref=def_big_Hn_z_tau] and [\eqref=def_big_Jn_z_tau] and we have used the Gauss-Laguerre quadrature with M = 124 nodes (truncated to the smallest 40 nodes, see [\cite=Mastroianni]) to evaluate the integral in [\eqref=def_big_Jn_z_tau]. In order to verify the accuracy, we have computed h(z,τ) on a very fine regular grid of points in the rectangle |z|  ≤  1 / 2 and τ∈(0,1 / 2) using the above algorithm and we have checked that the relative error is always less than 10- 29 (when compared with the algorithm described in Proposition [\ref=prop_compute_h_z_tau2]). While the algorithm based on Gauss-Laguerre quadrature is very efficient, we were not able to provide rigorous error estimates. It is known that the error of the M-point Gauss-Laguerre quadrature can be bounded by a multiple of

[formula]

(see Theorem 3 in [\cite=Stroud_Chen]), but we were not able to obtain good upper bounds for this quantity.

The results of our numerical experiments are presented in Figure [\ref=fig2]. The algorithm was implemented in Fortran using the quadruple precision. Due to the fact that the number of iterations of the algorithm varies for different values of τ, we have tested the algorithm for 1000 random pairs (z,τ), sampled uniformly from the domain 0 < τ < 1 / 4 and - 1 / 2 < z < 1 / 2, and the results in Figure [\ref=fig2] represent the average run-time for a single evaluation of Fn(z,τ). Since we are working in fixed precision (which does not depend on n, as in the algorithm in the proof of Theorem [\ref=thm_main2]), these computations involve an unavoidable loss of precision, which becomes more pronounced as n increases. See the paragraph preceding Remark 1 on page , explaining the reason for this loss of precision. Our results indicate that the difference between the values of Fn(z,τ) computed via direct summation [\eqref=def_F] and our version of Hiary's algorithm is typically of the order of 10- 28 for n = 103 and around 10- 25 for n = 105. This loss of precision is still acceptable for practical purposes. Most importantly, the figures [\ref=fig2_fast] and [\ref=fig2_fast_log_scale] confirm that the run-time of the algorithm increases essentially logarithmically with n, and that the simplified version of Hiary's algorithm is much faster than the summation of n terms in [\eqref=def_F] even for moderately large n.

Finally, we will discuss a related problem of evaluating the finite sum of the form

[formula]

Hiary's result [\cite=Hiary_theta] states that Fn,j(z,τ) can be computed to the required accuracy ±  ε in poly-log time in n / ε (though the precise statement is slightly more complicated, as the implied constants also depend on j). Our results can also be adapted to give a simpler version of Hiary's poly-log time algorithm for computing Fn,j(z,τ). Below we will sketch the main ideas of the practical implementation of such an algorithm.

We will follow the same path as in the algorithm described in the proof of Theorem [\ref=thm_main2]. Our goal is to compute the values of Fn,j(z,τ) for 0  ≤  j  ≤  J. At each step of the recursion, we normalize the values of z and τ so that |z|  ≤  1 / 2 and |τ|  ≤  1 / 4. If |τ| < n- 4, then we compute Fn,j(z,τ) by expanding the exponential function in [\eqref=def_F_n_j] in Taylor series and applying similar ideas as in the proof of Proposition [\ref=proposition_small_tau]. If |τ|  ≥  n- 4, then we use the following identities

[formula]

which follow from [\eqref=main_formula] by applying Leibniz rule. These identities reduce the computation of Fn,j(z,τ) to the computation of Fm,j(  ·  ,  ·  ) with m = ⌊2nτ⌋ < n / 2 and 1  ≤  j  ≤  J, and complete the main step of the recursion.

Applying identities [\eqref=main_formula_derivatives] in practice will involve computing [formula], which is equivalent to evaluating [formula] and [formula] (see formulas [\eqref=def_big_Hn_z_tau], [\eqref=def_big_Jn_z_tau] and [\eqref=hnztau_computing]). Computing G1 does not pose a serious problem, as applying Leibniz rule to [\eqref=def_big_Hn_z_tau] would give us an explicit expression for G1, and since [formula] it is easy to see that this explicit expression would involve only elementary functions and the error function Φ(z). At the same time, when z is large it will be more efficient to compute [formula] directly by taking derivatives of the right-hand side of formula [\eqref=Phi_final_formula] (or by using the asymptotic expansion for this function, see formula 8.254 in [\cite=Jeffrey2007]). The value of [formula] can be computed using the generalized Gauss-Laguerre quadrature. Indeed, from [\eqref=def_big_Jn_z_tau] we find that

[formula]

where gz,τ(y) is defined in [\eqref=J_practical_computing]. Using the same strategy as discussed on page (following equation [\eqref=J_practical_computing]) the integral in the right-hand side of [\eqref=J_derivatives] can be evaluated using the generalized Gauss-Laguerre quadrature with the weight function xje- x and M nodes. By experimenting with different values of k and M (and choosing the optimal ones) we can compute [formula] very efficiently with the required accuracy.