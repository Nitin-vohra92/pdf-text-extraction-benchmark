mm mm mm cm cm

Lemma Proposition Corollary Theorem

[formula]

Simulation of Gene Regulatory Networks

Keywords: biochemical pathways; kinetics; master equation; diffusion processes; simulation

MSC: 80A30; 92C40

Introduction

This is intented as an introduction to the rapidly growing literature on the mathematical modelling of biochemical pathways. This subject links several, quite different areas of research. Depending on viewpoints, relevant articles can be found in Biology, Chemistry, Mathematics, or Informatics journals. Rather than seeking a hopeless exhaustivity, we have tried to illustrate some of the current approaches by a few recent references.

Inside the huge domain of biochemistry, we have focused on cell metabolism and its biochemical pathways, and more precisely on pathways linked to apoptosis of cancerous cells. On the other hand, mathematical modelling in genomics has used many different techniques, among which we chose to restrict our study to dynamic equations, insisting on stochastic models.

The paper is organized as follows. In the next section we shall review a few articles on biochemical pathways, enlighting the use of modelling and in silico experiments. Section 3 presents the basic mathematical models of chemical kinetics, with emphasis on stochastic models. Section 4 deals with the computer simulation of stochastic models, with emphasis on Gillespie's algorithm. Computer integration aspects are treated in section 5.

Biochemical pathways

In the ever growing literature on cell metabolism and biochemical pathways, we have selected a few references dealing with the targeting of regulatory pathways, in particular apoptosis pathways, and their mathematical modelling. The global human metabolic map has been reconstructed accounting for the functions of 1496 ORF's, 2004 proteins, 2766 metabolites, and 3311 metabolic and transport reactions [\cite=Duarteetal07]. A good review on apoptosis pathways is given by Elmore [\cite=Elmore07].

Among the most recent advances, Folger et al. [\cite=Folgeretal11] announce a genome-scaled network model of cancer metabolism that they validate by predicting 52 cytostatic drug targets. Shaughnessy et al. [\cite=Shaughnessy11] describe a way of artificially regulating MAP kinase cascades.

Clarke et al. [\cite=Clarkeetal08] use statistical model checking for analysing t-cell receptor signalling pathways.

Studies linking biochemical pathways to cancer outcomes include that of Chuang et al. [\cite=Chuangetal07] and Taylor et al. [\cite=Tayloretal09].

Devun et al. [\cite=Devunetal10] have recently identified a "mitochondrial permeability transition pore-dependent pathway to selective cell death". Teams who have used apoptosis pathways for cancer therapy include Chu and Chen [\cite=ChuChen08], Ghobrial et al. [\cite=Ghobrialetal05], Speirs et al. [\cite=Speirsetal11]. A success obtained by combining Haem oxygenase with fumarate hydratase has recently been announced by Frezza et al. [\cite=Frezzaetal11]. Yosef et al. [\cite=Yosefetal09] address the problem of optimizing gene networks, with application to apoptosis.

The ultimate goal to systematically predict through mathematical modelling, possible gene targets that could induce cancerous cell apoptosis has been pursued by several teams among which Legewie et al. [\cite=Legewieetal06], Ryu et al. [\cite=Ryuetal09], Huber et al. [\cite=Huberetal11].

Mathematical models

Many mathematical models have been applied to genomics. The interested reader is referred to Shmulevitch and Dougherty's book [\cite=ShmulevitchDougherty07] or the reviews by de Jong [\cite=deJong02], Goutsias and Lee [\cite=GoutsiasLee07], Karlebach and Shamir [\cite=KarlebachShamir08]. Here we will focus exclusively onto the most classical dynamic models which are those of chemical kinetics. The mathematical developments date back to the first half of the twentieth century (see the historical section of [\cite=McQuarrie67]), and are presented in many textbooks, in particular those of van Kampen [\cite=vanKampen81], Ethier and Kurtz [\cite=EthierKurtz05], Gardiner [\cite=Gardiner04], Wilkinson [\cite=Wilkinson06], or Kolokoltsov [\cite=Kolokoltsov10]. A short and clear introduction has been written by Higham [\cite=Higham08], from which we shall borrow the terminology regarding the main three "chemical equations". As examples, we shall use the simplest historic models of Yule [\cite=Yule25] and Michaelis-Menten [\cite=MentenMichaelis13] [\cite=JohnsonGoody11]. At the basis of the theory, modelling assumptions are made to ensure that the only quantities of interest be the number of molecules of each type of reactant simultaneously present: constant volume, well stirred medium, space homogeneity. As remarked by Higham [\cite=Higham08] section 9.3, these hypotheses could be questioned when applied in the biological context of the living cell. Nevertheless, they are usually considered as unavoidable, and the models have been theoretically established on a very firm physical and chemical base: see for instance Gillespie [\cite=Gillespie92]. A chemical reaction system is made of a certain number n of reactants (or chemical species), and another number m of reactions destroying or producing molecules of them. The n-dimensional state vector X(t) keeps track of the quantities of each species simultaneously present at time t: its i-th entry counts how many molecules of species i are in the solution at time t. According to the scale of time and numbers, three different models are considered.

Microscopic scale: the vector X(t) is a stochastic process with birth-and-death dynamics: reactions take place one at a time at random instants and modify X(t) by a few units added or substracted from some coordinates. The probabilities of all possible states are the solution of the Chapmann-Kolmogorov equations for the Markov process {X(t)}. That system of Ordinary Differential Equations (ODE's) is called the Chemical Master Equation.

Mesoscopic scale: when rescaling time and space, the Markov jump process {X(t)} converges to a continuous real-valued diffusion process, solution of a system of Stochastic Differential Equations (SDE's), called the Chemical Langevin Equation.

Macroscopic scale: when stochastic fluctuations are neglected, the quantities of molecules are viewed as derivable functions of time, solution of a system of ODE's, called the Reaction Rate Equations.

The Chemical Master Equation can be explicitly solved only in exceedingly simple, mostly irrelevant cases, such as the Yule model that we shall treat below (other examples are reviewed by McQuarrie in section III of [\cite=McQuarrie67]). The alternative approach is to simulate trajectories of X(t) through Gillespie's algorithm, that we shall examine in more detail in the next section. As pointed out in section 6 of Higham [\cite=Higham08], the so called "tau-leaping" method, which is the usual way of accelerating the algorithm, can be viewed as an approximate solution to the Chemical Langevin Equation. On the theoretical side, convergence of birth-and-death dynamics to diffusion processes has been proved by Kurtz at the end of the 70's: chapter 10 of [\cite=EthierKurtz05] gives a complete theoretical treatment of diffusion processes in chemical kinetics. Thus, from the modelling point of view, it can be considered that the microscopic and mesoscopic scales are not essentially different: discrepancies come from the mathematical or algorithmic treatment. The real opposition is between stochastic (microscopic and mesoscopic scales) and deterministic (macroscopic scale) modelling. It has been discussed at length in many references, see for instance Chen et al. [\cite=Chenetal10], Goutsias [\cite=Goutsias07], Liang and Qian [\cite=LiangQian10], Qian [\cite=Qian00] or Shahrezaei and Swain [\cite=Shahrezaei08]. The main reason why stochastic is usually preferred to deterministic for gene regulatory networks lies in the order of magnitude of the numbers of molecules involved. The proteins produced by mRNA can usually be counted by a few hundreds per second, far short from Avogadro's number (6.02 ~ 1023) which is the scale at which deterministic models work. We shall now introduce the main concepts of mathematical kinetics models, illustrating them on the two basic examples of the Yule and Michaelis-Menten models. The effect of reactions on species is usually described by symbolic equations of the type A + B  →  C, meaning that each time the reaction takes place or fires, one molecule of A and one molecule of B combine to form one molecule of C. For mathematical purposes, it is convenient to encode the effect of each reaction by two vectors of integers, called the stoichiometric vectors (from the Greek meaning "measure of elements"). To the j-th reaction correspond vectors ν-j and ν+j. Their entries are as follows.

ν-j(i) is the number of molecules of species i that are destroyed by reaction j,

ν+j(i) is the number of molecules of species i that are produced by reaction j.

For instance reaction A + B  →  C will be translated by two 3-dimensional vectors, with entries indexed by A B and C.

[formula]

The Yule model is a very basic population model used for instance in the case of bacteria population growth. Formally, it could be assimilated to a chemical equation with only one reactant: A  →  2A (one bacteria becomes two when the reaction/meiosis fires). The stoichiometric vectors only have one entry: ν- = 1 and ν+ = 2. The Michaelis-Menten equations involve four species:

a substrate S

an enzyme E

a complex C

a product P

Here are the three equations and the corresponding stoichiometric vectors, indexed by S,E,C,P in that order.

S + E  →  C: [formula], [formula].

C  →  S + E, [formula], [formula].

C  →  E + P, [formula], [formula].

Some textbooks use the more compact stoichiometric matrix that summarizes in its columns the vectors above. Here is that matrix for the Michaelis-Menten model.

[formula]

There are two reasons to prefer the vectors ν+ and ν-. One is that the matrix looses information when the same species appears on both sides of the equation (as in the Yule model). The other is that the propensities, to be defined later, depend only on the ν-j's and not on the ν+j's. Regarding the mathematical expression of the different models, we shall follow the introduction of Ball et al. [\cite=Balletal06]. For the stochastic version of Michaelis-Menten dynamics, see Qian [\cite=Qian02], Sanft et al. [\cite=Sanft11] and Higham [\cite=Higham08]. Once the stoichiometry of the system is known, the evolution of the state vector only depends on successive reaction firings. Denote by Rj(t) the number of times reaction j fires between 0 and t. Then:

[formula]

The {Rj(t)}'s are counting processes, whose instantaneous rates are called the propensities. Intuitively, during an interval of time

[formula]

λ(x) = κ   ν(i)!  ,

[formula]

R(t) = Y( λ(X(s))  s) ,

[formula]

= -κ n p(t) +κ(n-1)p(t) .

[formula]

p(t) = (1-) .

[formula]

λ(x) ≃ N κ c(i) .

[formula]

(c) = κ c(i) .

[formula]

= + Y( λ(X(s))  s)(ν-ν) .

[formula]

C(t) = C(0)+ Y( N(C(s))  s) (ν-ν) .

[formula]

lim = W(u) ,

[formula]

Y( N(C(s))  s) ≃ (C(s))  s + W( (C(s))  s) .

[formula]

a(t) = κ a(t)   t +   W

[formula]

Stochastic Simulation Algorithms

As already pointed out, there exists a structural reason to prefer stochastic models to deterministic ones for gene regulatory network modelling. For that reason, and also because numerical solvers for ODE's are well know and implemented in all mathematical softwares, we shall not present them here. Solutions to the stochastic models (either the CME or the CLE) can only be obtained through Monte-Carlo methods, i.e. by simulating the stochastic processes under consideration. The basic method of simulation is Gillespie's algorithm, also called Stochastic Simulation Algorithm in some references. Proposed in the context of chemical reactions by Gillespie [\cite=Gillespie76] [\cite=Gillespie77], it is a particular case of the general method for simulating Markov Jump Processes in continuous time through their imbedded Markov chain. The basic version simulates a trajectory of the state vector X(t) by translating the SIE introduced in the previous section: It should be understood as follows. At any time s, all m reactions have independent firing times, that of reaction j being exponentially distributed with parameter λj(X(s)). The next reaction will fire after a time which is the minimum of these random variables. From elementary properties of exponential random variables, it can be deduced that:

the next firing will occur after a random time, exponentially distributed with parameter [formula].

it will be the firing of reaction j with probability [formula].

The two elementary steps above are easily simulated. Any programming language has a Random function. Successive calls of that function output sequences of pseudo-random numbers that can be considered as realizations of independent random variables, uniformly distributed on the interval

[formula]

, output j.

When reaction j fires, the state vector X(s) is incremented using the stoichiometric vectors ν-j and ν+j. The pseudo-code of the Gillespie Algorithm can be written as follows. Higham [\cite=Higham08] provides a Matlab implementation of that algorithm. However, several reasons make it quite inefficient.

Billions of steps should be simulated to get a trajectory comparable to experimental results. Even though each one of these steps is relatively cheap, the computer time required for a full scale simulation is prohibitive.

Even with an arithmetic coprocessor, the log  function required to compute the random delay between firings is more expensive than additions and multiplication. Using it at each step is time consuming, and essentially useless: from the central limit theorem, it is known that a sum of independent random variables is asymptotically distributed as a normal variable with same expectation and variance. The expectation of an exponential with parameter λ is [formula] and its variance is [formula]. It is much more efficient to cumulate at each step [formula] and [formula], then update the time scale only at regular intervals (say after 104 firings), with a normal variable.

If the number of reactions is large (which is the case of gene regulatory networks), choosing a reaction with a given probability can be expensive. A lot of computer time is lost in updating probabilities and cumulating them. Moreover, comparing Random to the cumulated probabilities results in many useless tests, especially when the pi's have very different orders of magnitude. A lot of computer time can be saved by ranking the pi's in decreasing order. But this can be efficient only when the same probability vector is used many times.

At each step, the state vector is updated by a random vector which is equal to ν+j  -  ν-j with probability pj. But again the central limit theorem can be used. After a large number of steps, the state vector has been updated by a sum of independent random variables, the expectation and variance of which can be cumulated to simulate a normal approximation only at the end of the loop.

Updating the state vector and the propensities at each step is also time consuming and relatively inefficient, because when the numbers of molecules are large, changing them by a few units does not essentially modify the results.

The remarks above where made long ago and lead to the so called tau-leaping method (discussed by Gillespie himself in [\cite=Gillespie01]) that consists of considering propensities as constant for a certain (relatively large) interval of time τ, and updating the state vector by a normal random variable only after that time τ. In the pseudo-code below, we fixed a number of firings L instead of fixing a time interval τ, but the difference is not essential. We shall not detail the simulation code for normal distributions, which is routine. We call Normal(E,V) a function simulating normally distributed random variables with vector expectation E and covariance matrix V. As pointed out by Higham [\cite=Higham08] the tau-leaping method matches the Euler-Maruyama scheme for the Chemical Langevin Equation: It is a well know fact that the Euler-Maruyama scheme, like the Euler scheme for ODE's, tends to be numerically unstable. At the expense of a slight increase in computer time, one gets a better precision by using instead the Heun scheme. The book by Kloeden and Platen [\cite=KloedenPlaten97] is the indispensable reference on numerical schemes for SDE's.

Improvements on the Stochastic Simulation algorithms have generated many works, and Gillespie and his co-authors have been very active: Liu et al. [\cite=Lietal08] give a review of existing methods; Cao et al. [\cite=Caoetal04] investigate numerical stability of leaping methods; Gillespie et al. [\cite=Gillespieetal05b] [\cite=Gillespieetal05a] address the problem of accelerating the simulation when propensities have very different orders of magnitudes. In [\cite=Gillespieetal09] [\cite=Wuetal11], the approximations to the Michaelis-Menten equations are discussed, and the gain in computer time of leaping is evaluated. The same problem of multiple time scales has also been adressed by Ball et al. [\cite=Balletal06], Haseltine and Rawlings [\cite=HaseltineRawlings02], Liu and Vanden-Eijden [\cite=LiuVanden05], McColluma et al. [\cite=McCollumaetal05]. Other improvements include Bruck and Gibson's [\cite=BruckGibson00] study on simulation of large systems, and the works by Ramaswamy and his co-authors [\cite=Ramaswamy09] [\cite=Ramaswamy10] [\cite=Ramaswamy11a] on partial propensity. Elf and Ehrenberger [\cite=ElfEhrenberg03] replace simulation by an evaluation of fluctuations around the solution of the RRE using linear noise approximations. Zhou et al. [\cite=Zhouetal08] have applied a stochastic algorithm to coupled reactions with delays. Recently, Zeron and Santillan [\cite=ZeronSantillan11] published a numerical study of a gene network with negative feedback regulation, including the stability of steady state.

Computer integration

The "Virtual Cell" of Gunawardena et al. in Harvard or de Jong [\cite=deJong09] in Grenoble, is still a beautiful dream; yet significant steps toward its realization have been made.

Regarding biochemical pathways, the process of knowledge accumulation and sharing has long been very lively. The "Pathway Resource List", or "PathGuide" [\cite=Baderetal06] currently lists more than 400 databases on biological pathways and molecular interaction, most of them freely accessible. Examples include BiGG [\cite=Schellenbergeretal10] MetaCyc and BioCyc [\cite=Caspietal10], KEGG [\cite=Kanehishaetal04], TRANSPATH [\cite=Krulletal06], BioCyc [\cite=Krummenacker05], Reactome [\cite=Matthewsetal09], PANTHER [\cite=Mietal05], PID [\cite=Schaeferetal09]. Several databases now come with integrated environments that offer different vizualisations, like Cytoscape [\cite=Shannon03], or even simulate the archived models, like BioModels [\cite=Biomodels10] or Expasy [\cite=Gasteigeretal03]. Kitano [\cite=Kitano02] or Huang et al. [\cite=Huangetal09] review computational tools available in Systems Biology.

In the accumulation process, the standardization issue was raised very early. In 2000, Bader and Hogue [\cite=BaderHogue00] had already proposed BIND, a data specification adapted to pathways. In 2005, Cary et al. [\cite=Caryetal05] listed 170 existing databases and called for standard exchange formats to successfully integrate data on a large scale. These were already under development, and they integrate standard programming tools for the simulation and treatment of gene networks and pathways: BioPAX [\cite=Biopax10] SBML [\cite=Huckaetal04], CellML [\cite=Milleretal10], Biolingua [\cite=Massar05]. Other programming toolboxes include COBRA [\cite=Beckeretal07], GNA [\cite=deJongetal03], PATIKA [\cite=Demiretal02], and DIZZY [\cite=Ramsey05], the latest being more focused on stochastic simulation.

Together with software realizations, informatics theoretical researches attempted a formalization of languages and investigation procedures. Fisher and Henzinger [\cite=FisherHenzinger07] call "Executable Biology" that research area constructing computational models of biological systems. Kitano [\cite=Kitano03] proposes a graphical notation for biochemical networks. Danos and Laneve [\cite=DanosLaneve04] invent an abstract language for formal proteins. Berthoumieux et al. [\cite=Berthoumieuxetal11] study the identification of network models though incomplete high throughput datasets. For testing and experimenting purposes, Lok and Brent [\cite=LokBrent05] construct an automatic generation tool for cellular reaction networks. Monteiro et al. [\cite=Monteiroetal09] propose a service oriented architecture for integrated treatment of networks. Schultz et al. [\cite=Schulzetaletal11] discuss the clustering of computational models based on semantic annotations. Yamamoto et al. [\cite=Yamamotoetal10] have developped an Artificial Intelligence system, SOLAR, that includes reasonning tools for biological inference on pathways.