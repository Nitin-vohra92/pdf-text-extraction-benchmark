Automated Analysis of Behavioural Variability and Filial Imprinting of Chicks (G. gallus) using Autonomous Robots

Introduction

Many species of animal live in group and are capable of making decisions while maintaining group coherence [\cite=sumpter2010collective] [\cite=camazine2003self]. Animal living in groups are constrained by what they can perceive thus most of the time they cannot have a global view of the group and their environment. Yet those species are capable of remarkable group behaviours. The question arises as to understand what kind of mechanism allows the group to perform so well given their individual limitations. Several forms of social structures exists that go from all individuals apparently having the same weight in the group to various forms of leadership and social hierarchy.

Among the many group-living species, the chicken (Gallus gallus domesticus) is an interesting animal model: the chickens are social animals and chicks present a social attachment to their siblings and to their mother. Indeed, in precocial birds such as chickens, the formation of social attachments occurs in the first days after hatching. This process is used as a model for the study of learning [\cite=horn1985memory] because the chicks' environment and conditions prior to hatching can be controlled and standardized. Hence, the period immediately after hatching is likely to be particularly useful for studying social motivation and learning.

This social structure allows to address the question of the role of leadership in group decision-making. Chicks are attracted to each other and at the same time they tend to remain in a relatively close vicinity to their mother that they can also follow as a group. The question arises as to what makes the group coherent and what is the importance of the leader, the hen, in group decision making and group coherence. The development of filial behaviour can be separated in terms of two interacting processes: filial motivation and filial imprinting. Filial motivation causes chicks to approach and follow conspicuous objects with certain general properties like colours, shapes, sizes, and movement patterns. In a natural environment, chicks are attracted toward the hen and the other chicks of the group. Filial imprinting is a learning process through which the chick comes to restrict this behaviour to focus to particular stimuli [\cite=Bateson1966] [\cite=sluckin1970imprinting] [\cite=bolhuis1991mechanisms] [\cite=van1996framework]. As chicks become progressively more familiar with an object, they tend to approach this object more [\cite=horn1985memory]. Thus, filial motivation determines the propensity to make social attachments, while imprinting establishes preference.

In ethological studies one of the long-standing interests is to understand social communication, relationships and structures. Until recently, to study these mechanisms researchers had used simple specially designed mock-ups whose behaviour can be controlled so as to trigger a response of the animals. But nowadays availability of low-cost miniaturized computer chips, motors and sensors allowed these artificial models to become sophisticated and reliable robotic devices that can be used to test hypotheses [\cite=knight2005animal]. For instance, robots were used to study male territorial instinct in dart-poison frogs [\cite=narins2005cross] and mate selection in Tungara frogs [\cite=taylor2008faux], to test ideas about nest mate recognition in brush turkeys [\cite=goth2004social], and the predator avoidance by ground squirrels [\cite=rundus2007ground]. A number of recent works in ethology have successfully used robots to investigate individual and collective animal behaviours, in particular by creating mixed robot-animals societies: robots were mixed with chicks [\cite=Gribovskiy2010], cockroaches [\cite=sempo2006integration] [\cite=halloy2007social], fruit flies [\cite=zabala2012simple], killifish [\cite=phamduy2014fish] and zebrafish [\cite=polverino2013zebrafish].

Here, we address these questions by using a robot (cf. Fig. [\ref=Fig1]) that will become a surrogate mother to individual chicks. To build a social attachment between the chicks and the robot we use the filial imprinting mechanism. After hatching a critical period exists where the chick will learn to build social attachment to specific objects. Classical ethology has shown that this special form of learning works for any object remaining close to the chicks and presenting specific colour, movement and sound patterns. In this study, we develop an imprinting methodology involving autonomous robots to study individual behaviour of free moving animals. Thanks to this methodology we are able to quantify the individual behaviours and social responses to the robot. We also develop automated experimental methodologies that allow to make fast and efficient data analysis, and compare to existing ones [\cite=branson2009high] [\cite=kabra2012jaaba]. A workflow of this methodology is found in Fig. [\ref=Fig2]. The analysis is based on high throughput data allowing fine quantification of individual behavioural traits. Thanks to this method we can make quantitative assessment of individual variability of a large number of individuals.

We investigate whether the imprinting quality of chicks can be influenced by social bonding. After the imprinting process, the chicks are randomly put in groups of 6 individuals for 20 days. We then perform a new quantification of individual behaviour traits, and compare them to original results. Additional experiments include experiments during the period of time the chicks are put into groups, where entire groups of chicks interact with a robot, but the associated results are not investigated in this article. Here, we quantify the individual characteristics for 205 animals. The results show a large variability of behavioural patterns. One of the main variability is related to the success of imprinting. Three types of chicks are observed: imprinted, indifferent and avoiders. Among the successfully imprinted chicks we still observe a large variability of behavioural patterns. Finally we show that the use of autonomous robots and automated ethograms allow detailed quantitative studies of animal behavioural patterns as it has also been shown with Drosophila flies and bees [\cite=zabala2012simple] [\cite=landgraf2011analysis].

Results

Filial imprinting as a means of social bonding with robots

The first step in the behavioural analysis is to classify the chicks according to the success of the filial imprinting on the robot. Filial imprinting corresponds to the propensity of the chicks to be attracted by the robot and to follow it as if it was the hen mother. We observe two different kind of non-imprinted chicks: indifferent chicks that ignore the presence and movement of the robot, and avoiders that run along the walls, possibly running away from the robot. Imprinting success is assessed by looking at the behavioural response of the chicks towards the robot.

Figure [\ref=Fig3] shows both the speed of three different chicks depending of their spatial position in the arena, and the robot trajectories. The figure shows the three typical behaviour responses of a chick to the robot: a chick can be imprinted (Panel A), indifferent (Panel B), or avoider (Panel C). The distributions of chicks speed, their distance toward the robot, and their walking behaviour (whether they are walking or stopping), for 30 individuals, is shown in Fig. [\ref=Fig4]. Imprinted and avoider chicks tend to alternate a walking behaviour with small stops. Indifferent chicks stay in place in the arena, with very few apparent walking behaviour. Imprinted chicks tend to be close to the robot. Indifferent and avoider chicks tend to be distant from the robot. The three typical behaviour responses of a chick to the robot correspond to different distributions of chick speeds, as shown in Fig. [\ref=Fig5]: imprinted chicks move with variable speed, indifferent chicks do not move much, avoider chicks tend to move at higher speed than imprinted chicks.

The classification of the behavioural response of each chick toward the robot can be done by a human observer looking at all the videos. However, this represents a tedious and long qualitative work that would greatly benefit from automation. Only 31.22% of all experiments (64 individuals) is classified by a human observer. The rest of the experiments is classified automatically, using an algorithm to classify the data automatically extracted from the videos by image analysis.

Because it is possible for a human observer to classify with good accuracy the type of chick, we select a supervised learning method. We use a linear support vector machine (SVM) classifier, an algorithm often used to solve problems in classification, regression, and novelty detection [\cite=Vapnik1995] [\cite=Meyer2003] [\cite=Bishop2006]. This method is first trained on the human-classified dataset, separating experiments into three classes: imprinted, avoider, indifferent. The classification process used the following features: mean distance between a robot and a chick, mean speed of a chick, and its standard deviation. The results of the classification are presented in Fig. [\ref=Fig6]. Panel A shows the training dataset composed of 31.22% of the all data (64 individuals). The green points correspond to the imprinted chicks, the blue points to the indifferent chicks, and red points to the avoider chicks. The experiments have a duration of one hour, and were repeated for 205 different chicks. Panel B of Fig. [\ref=Fig6] shows the results of the trained classifier on the whole data set (205 individuals). The classifier present an accuracy of 98.05% (201/205). The crossed points corresponds to misclassification (4 individuals). These misclassification are the consequence of mixed behavioural pattern. Even for human observers, these individuals are difficult to categorize because, during the test, they present characteristics of imprinting or avoider behavioural traits.

As a result of individual tests we observed 55.12% (113/205) imprinted chicks, 36.10% (74/205) indifferent and 8.78% (18/205) of avoider chicks.

Automated Ethograms

Ethograms are typically used to describe animal behaviour. They are made usually by human experts consistently documenting behaviour from observations. The two main approaches are focal sampling (in which the human expert make systematic observation of the behaviour of an individual - it is a precise but time-expensive method) and scan sampling (in which the observer only uses observation recorded at regular intervals to classify behaviours - it is less time-consuming compared to focal sampling, but also less accurate). Ethograms done by human observation are time consuming and tedious if one wants to obtain quantitative results. We present a combined methodology that performs detailed quantitative studies of single individual repeated for a large number of animals (205 individuals).

Recently, a number of ethological studies have used similar methodologies to automatically generate ethograms of animal behaviour from behavioural data [\cite=anderson2014toward] [\cite=branson2009high] [\cite=kabra2012jaaba] [\cite=gerencser2013identification] [\cite=de2012computerized]. This process of automatic behaviours detection is call "Automated ethology", and produces "automated ethograms". It is usually done in two steps. The first step is called "Segmentation": the trajectories are split into segments. Each segment is labelled independently from the others, using either classification or clustering algorithms. In the second step, a label (or "class") is assigned to each segment, describing which kind of behaviour the chick is exhibiting as the corresponding time. Two kind of algorithms can be used for labelling: classification algorithms and clustering algorithms. For each segment, these algorithms use a set of features (statistical measures) of the observed individual to find a corresponding label. Before the labelling process, classification algorithms need to be trained with a training set of segments already labelled by a human. This training set is used as reference (or a priori knowledge) to guide the labelling process. Clustering algorithm do not need to be trained beforehand, and only uses the similarity of the segments' features to group them together into clusters. Each cluster correspond to a different label.

The segmentation strategy can impact the reliability of the labelling process of trajectories compared to a labelling done by humans. This is especially the case when segments incorporate periods of time when the chicks exhibit several different behaviour. On the other hand, when segments are too small, it can add noise into the features used for labelling. In an optimal segmentation, segments end when a chick changes its behaviour. A typical segmentation method used in the literature is the N-steps window segmentation: trajectories containing M time-steps are split into M / N segments each with a size of N time-steps. An extreme case is the 1-step window segmentation, where every time-step is a new segment. Note that the choice of N can influence the reliability of a segmentation: if N is too big, segments can include period of times where the chicks exhibit several different behaviours. On the other hand, N-step window segmentation with a low N can be more sensitive to noise.

We introduce a more robust segmentation method, the 'Threshold crossing' method. We make two hypothesises, supported by human observations: first, that chicks reduce their speed below a given threshold when they change behaviour; second, that chicks accelerate when they begin to exhibit a given behaviour, and decelerate when they change behaviour. This allow us to introduce an original segmentation method, that we call 'Threshold crossing'. This segmentation method is based on the speed and acceleration of a chick (Fig. [\ref=Fig7]): time-steps when the speed or acceleration of a chicks are below predefined thresholds are considered as stops.

The segments obtained are then labelled using state-of-the-art algorithms of the literature, either using classification algorithms: Decision Trees (DT), Decision Trees with Random Forest (DT/Forest), k-Nearest Neighbours (k-NN), Support Vector Machines (SVM); or a clustering algorithm: K-Means. These methods are described in detail in Sec. [\ref=sec:behaviouralMeasurments] and [\ref=sec:classificationAndClusteringOfTrajectories]. For each segment, the classification and clustering algorithms use the following features (statistical measures) to find a label (corresponding to the behaviour of the chick): the mean speed of the chick, the acceleration of the chick, the distance between the chick and the robot, the distance between the chick and the wall of the arena, and the distance traveled by the chick during the experiment.

Based on human observation, we separated chick behaviours into seven classes:

Note that the robot is programmed to constantly move, even if a chick is on its trajectory. This set of classes correspond to the labels used by the classification algorithms during the labelling process.

We validated the automated labelling of chicks trajectories by computing the error compared to human-labeled trajectories: the collection of human-labeled behavioural sequences was split into two parts: the first part was used during the training step (learning base), and the second part was used to perform this validation. As the observed error of classification is very low (0.04), we can say that the automated labelling is very close to the labelling done by humans.

We measured the reliability of the different methods of segmentation and labelling presented compared to human-labeled trajectories. In addition to the 'Threshold crossing' segmentation method, we also tested the N-step window segmentation for several values of N: N = 1 and N = 5. These results are compiled in Table. [\ref=table1] using Mean Absolute Percentage Error (MAPE) values. The MAPE values are computed using the formula: [formula] with At the human-labelled reference values and Ft the values obtained by classification methods. The best-performing classification method is the Decision Trees with Random Forests method, when using a Threshold crossing segmentation or a 1-window segmentation. Methods using the 5-step window segmentation method have a smaller reliability than methods using the 1-step window segmentation: the segments obtained by 5-step window segmentation can incorporate periods of time when the chick exhibit several different behaviours. It should also be noted that chicks behavioural traces often include shorts stops of the chicks when they change behaviour. These stops can have a duration inferior to 5 time steps, and may impact negatively the performance of the 5-step window segmentation. The K-Means clustering algorithm give promising results, but is outperformed by the tested classification algorithms. It is not surprising, as this is a clustering algorithm: it is not trained beforehand, and cannot use any a-priori information (except the number of labels).

Figure [\ref=Fig8] shows an automated ethogram of an individual chick using the best-performing segmentation and classification methods: "Threshold crossing" and Decision Trees with Random Forest.

Figure [\ref=Fig9] shows the distribution of durations of each behaviour for all imprinted chicks (113 individuals), all indifferent chicks (74 individuals) and all avoider chicks (18 individuals), over three series of experiments. Statistical analysis (Kruskal-Wallis one-way analysis of variance [\cite=kruskal1952use]) shows that the three datasets are significantly different (p=[formula]).

Figure [\ref=Fig10] presents an example of a trajectory of an imprinted chick. This trajectory is segmented and coloured according to the observed behaviour of the chick. The chick tends to stop when it is changing direction, or when it is changing it's behaviour.

Automated ethograms generated by our methodology can take two forms. Individual ethograms, in the form of behavioural sequences (Fig. [\ref=Fig8]), describe the evolution of the behaviour of a single chick (in one given experiment) with respect to time. The global dynamics of chicks behaviour for all imprinted chicks can be described using the transition frequencies between the seven behavioural patterns considered (Table [\ref=table2]). Transition frequencies can be used to build global ethograms, in the form of Finite State Machines, or state transition diagrams, as shown in Fig. [\ref=Fig11] (self-transitions are not taken into account). According to these figures, chicks tend to stop when they are changing their behaviour.

Quantification of individual variability

In this section, we show that is it possible to quantify the imprinting quality of the chicks toward the robot, by using the individual ethograms described in Sec. [\ref=sec:automatedEthograms]. Only data from imprinted and indifferent chicks are considered, as avoiders chicks avoid any imprinting stimuli toward the robot: the imprinting process fails and the imprinting quality is null.

The global distribution of behaviours for every chick can be found in Fig. [\ref=Fig12]. Our objective is to define an imprinting index, corresponding to the measure of individual attachment of a chick toward the robot. We use information from the distribution of behaviour of each chicks to compute this index. As we want to define a one-dimensional index, this information needs to be compressed.

We introduce a new representation of the behaviour of each chicks, similar to the one used in [\ref=Fig12] and previous sections, but with a reduced dimensionality (3 instead of 7): for each chick, a vector of three values (bs,bj,bc) represents respectively the portion of time the chick (1) rests, (2) runs toward the robot and (3) stays close to the robot. These values are presented in Fig. [\ref=Fig12]. In this representation, the "Bumped" behaviour is ignored because it only occurs rarely. The "Other" behaviour is ignored because it does not correspond to a clearly identified behaviour.

To obtain a representation of chick behaviour with a further reduced dimensionality, we performed principal component analysis (PCA) on the dataset composed of (bs,bj,bc) vectors for all chicks: 97.26% of the variance in this dataset is explained by the first principal component. This shows that the first principal component is sufficient to quantify the behaviour of a chick. The first principal component is computed as follow: bsps + bjpj + bcpc, where ps = 0.7510,pj =  - 0.0975 and pc =  - 0.6531. We define an imprinting index, corresponding to the measure of individual attachment of a chick toward the robot, by a linear transformation of the first principal component:

[formula]

where ii0 is chosen to separate imprinted and non-imprinted (indifferent and avoiders) sets.

This imprinting index can be used to sort all chicks by the "imprinting force" of a chick toward the robot.

A quantitative analysis of the imprinting level of imprinted and indifferent chicks (187 individuals) was performed (as described in Sec. [\ref=sec:classificationRes]), with results shown in Fig. [\ref=Fig13]. It shows that the majority of indifferent chicks have an imprinting index close to - 20, with small imprinting variability: it can be explained by the fact that indifferent chicks are immobile during most of the experiments. Imprinted chicks have a larger imprinting variability than indifferent chicks. Most imprinted chicks have an imprinting index between 0 and 65.

Time evolution of social bonding

We investigate the influence of social bonding on the imprinting quality of chicks toward the robot. After the imprinting process, 72 randomly selected chicks are put in 12 groups of 6 individuals for 20 days. Each of these group contains a random number of imprinted, indifferent and avoiders chicks. Then, we assess if the chicks have changed their individual behaviour toward the robot by performing another set of experiments, with the same approach described in previous sections. These experiments were only performed on 42 individuals in 7 groups. We produce imprinting indexes using the method described in [\ref=sec:indivVar]. To study the change in imprinting quality of chicks put in groups compared to chicks alone, we introduce the measure:

[formula]

where iit1 and iit2 are the imprinting index of a chick respectively before and after being put into groups. The distribution of the δii measure is shown in Fig. [\ref=Fig14]. The mean value of all considered δii is - 7.5018: we observe a general decline of individual attachment toward the robot. It can possibly be explained by the aging of the animals.

To take into account the composition of the groups in our analysis, we introduce the group imprinting index as an average of imprinting indices of group members in the first individual test: [formula] where iikt1 is the imprinting index of the k-th chick in a group before being put into a group. We compute δgii as a difference between the group average and the individual imprinting index: δgii  =  iig - ii. Chicks for which this value is positive shows an imprinting quality below the average in their group, and chicks for which this value is negative show more attachment toward the robot compared to the average of their group. The link between the δgii and δii is shown in Fig. [\ref=Fig15]. The represented distributions are significantly positively correlated (Student's T test for a transformation of the Pearson's correlation p = 0.000012, with a correlation coefficient of 0.5907). We observe that, after being put in groups, chicks have an imprinting quality toward the robot that is closer to the average of their group. A chick that originally was not very interested in the robot develops a stronger attachment after being placed in the group of individuals strongly imprinted toward the robot. On the other hand, a chick that originally was very attached to the robot become less interested in the robot after being placed in the group of individuals that have a low interest toward the robot.

Materials and Methods

Ethics statement Animal experiments were performed in accordance with the recommendations and guidelines of the local competent authority and ethic committee.

The PoulBot robot

The robot does not look like a chicken, however chicks developed a strong social attachment to it thanks to the filial imprinting mechanism [\cite=Rogers1996]. Chicks prefer imprinting object with spotted pattern, dots or strikes [\cite=Klopfer1964a]. Moving objects are more attractive [\cite=Bateson1966], as visual imprinting would occur on the association between object form and movement [\cite=Broom1969]. Chicks are attracted by colours that are easy to discriminate from the colours of the ground. Red-orange or blue revealed to be the most attractive colours [\cite=Ham2007]. Not only the nature but the characteristics of the colours have an influence on recognition and imprinting [\cite=Davis1976]. Chick can learn or be imprinted on static coloured two-dimensional stimuli [\cite=Salzena1971]. Contrasted patterns attract more the chick attention and are more effective for accurate memory [\cite=Osorio1999].

Auditory communication is of importance in poultry [\cite=Mench2001] and imprinting also depends on auditory stimuli [\cite=VanKampen1991] [\cite=Mench2001]. Early exposure to auditory stimulus induces preferences in experiments. Several vocalizations and their roles still need to be investigated in imprinting process but it is known that early exposure to a sound influence the later preferences. It seems that both auditory and visual learning are enhanced during the critical period, which is consistent with the interpretation that imprinting is a within-event learning occurring when elements and their representations are linked [\cite=Bolhuis1999].

The main features of the robot namely movement, colour pattern and sound emission have been designed taking into account these results. Moreover, each of them can be switched on and off and programmed independently of each other allowing the study of the multi-modality of factors favoring filial imprinting. The fact that the robot is fully autonomous and can move in the same environment as the chicks allows studies where the animals can move freely and in groups, thus allowing to study the link between individual and collective behaviour.

The mobile robot used in this study is a track-type mobile robot presented in Fig. [\ref=Fig1] [\cite=Gribovskiy2010]. We named it the PoulBot. The robot is a configuration of the marXbot robot - a modular research robot developed at EPFL [\cite=Bonani2010]. The PoulBot consists of the following modules: a base module providing energy, means for locomotion, a gyroscope, an accelerometer, 24 short range infrared proximity sensors around the robot and a speaker, a colour pattern module allowing a robot to carry a specific pattern, an extra ring of proximity sensors placed above the colour pattern module and a main computer board with a 533MHz Freescale i.MX31 and an omnidirectional camera, the main board also provides Wi-Fi and Bluetooth wireless connectivity. On the top of the robot we fixed three colour markers used to track the robot position and orientation with a camera fixed above the experimental setup (see below). Every module of the robot consists of one or several Microchip dsPIC33 microcontrollers that drive the sensors and/or actuators of the module. The microcontrollers are connected with each other and with the main computer of the robot through a controller-area network (CAN) bus. The robot can be extended with the sound acquisition module and with the pecking module.

The control system of our robot is a hierarchical behaviour based controller [\cite=Mataric2008]. The robot is equipped with a set of primitive behaviours tightly bonded with the sensors and actuators of the robot. Each primitive behaviour serves to achieve a particular goal or to perform a specific activity (e.g., wall-following or obstacle-avoidance behaviours). The primitive behaviours are combined together to form higher level composite behaviours for specific experiments. Behaviour-based systems work well in dynamic environments, in cases when fast reaction and high adaptability are important. These characteristics make the behaviour based approach a natural choice when designing a control system for a robot that interacts with animals.

Animal hatching housing and handling

We performed experiments with chicks, Gallus gallus domesticus, from hatching up to 3 week-old. As breed, we chose the egg layer White Leghorn that is common in scientific studies. The incubators were disposed together in a 10m2 isolated rearing room that was maintained in the dark and at a constant temperature of [formula] during incubation. Eggs were incubated at the classical temperature of [formula] with a relative humidity of 70%. After hatching, chicks were identified with numbered plastic rings their hatching time was recorded. They were left to rest and dry in the incubators. When dry, they were kept in the dark in individual boxes until the imprinting process. The light was left off to reduce imprinting of first hatched chicks on siblings. The presence of humans was reduced to the minimum necessary for handling. During hatching, the frequency of visit by experimentalists was of 1 hour.

During incubation and up to the imprinting process, two speakers and a MP3 device played a calibrated sound sound that the robots also played during imprinting and tests. The sound was played from egg state to the end of the imprinting sessions. This calibrated sound had a frequency of 6kHz and with a beep duration of 150ms and interval between two beeps of 350ms. These features have been chosen in correspondence to the range of chick audition [\cite=Collias1953] [\cite=Collias1987]. We chose the upper threshold of the range and a sound designed to be neutral since it is totally artificial, which means that it is not related to a natural chick or hen calls, such as alarm calls or clucking, and have thus no biological sense. This was made for auditory imprinting not oriented towards a special message signal.

After the imprinting process, chicks are kept in groups of 6 in breeding nurseries and given food and water ad libitum. The temperature of the breeding room was reduced during the three weeks from 32 to [formula] according to breeding standards.

Experimental setup and protocol

We ran open-field tests, where animals and robots were released on a flat arena surrounded by walls and their behaviour was studied. The experimental arena is a flat square of 3 m by 3 m, surrounded by a wooden wall of 60 cm in height. A common daylight lamp is a source of a strong infrared (IR) emission that affects the IR sensors of the robot. To resolve this issue, we used lamps with reduced infrared emission FQ49W/965 by OSRAM. Twelve lamps were uniformly fixed on the ceiling to provide lighting conditions as homogeneous as possible. A Scout scA1000-30gc colour camera by Basler Vision Technologies with a CS-mount T3Z2910CS varifocal lens by Computar was fixed above the setup for tracking and recording tasks. The camera has a resolution of [formula] pixels and a maximum frame rate of 30 frames per second. It uses a Gigabit Ethernet connection to transfer video to the PC. The experimental PC has an eight-core Intel CoreTM2 Quad processor and 2 GB of RAM. It runs the monitoring and recording software presented in the next Section and the GUI module of the robot control system. It also serves as a temporary storage of the experimental data recorded during the day, before the data is transferred to external hard drives. The temperature in the experimental room during the whole experimentation period was kept constant. The experimental facilities are described in Fig. [\ref=Fig16]. The imprinting set-up is shown in Fig. [\ref=Fig17].

The imprinting procedure precedes every series of experiments. Depending on birth rates, we tried to compose imprinting batches with chicks born within at most two hour intervals. This was made to have a sufficient number of chicks per imprinting session. To perform the imprinting we build an arena composed of two rows of boxes on the sides. Four boxes were built in MDF wood with a Plexiglas side facing the wall to let chicks see the robot that traveled back and forth in front of them. Wooden boxes were 1500x150x300 mm. Each box had ten compartments of 150x150 mm to house one chick at a time. By putting one chick per box the setup allowed the simultaneous imprinting of 40 chicks. Four robots moved along the walls in front of each box at a close distance of about 100 mm , forward and backward, at a speed of 60 mm/s, one in front of each box. The robots emitted a calibrate sounds that was the same as during incubation and hatching (see above) and displayed a specific colour pattern. This individual and in-line imprinting process was designed to reduce imprinting among siblings. We performed the imprinting sessions according to the optimal period for chicken filial imprinting the The first exposure to the robots was 9 hours after hatching [\cite=Ramsay1954] [\cite=Hess1973]. The first exposure was programmed 9 hours after the birth of the chicks. Three sessions of one hour in the presence of the robot were done interrupted in-between by one hour resting time in the breeding room. Rotation were done to imprint all chicks of a hatching batch (100 individuals at most).

Shortly after an end of the imprinting procedure we tested all chicks: every chick was left for a half an hour with a robot wandering on the experimental arena and chick behaviour was observed. The robot emits a calibrated beeping sound and moves straight at a constant speed of 70 mm/s. When the robot reaches an edge of the set-up it bounces back with a random angle. The speed of the robot was selected according to observation of the mean chick speed during previous calibration experiments. Each test lasted for 30 minutes and for data analysis the first 2 minutes are skipped and the next 25 minutes are kept. This avoids artifacts due to animal introduction and extraction from the experimental setup. All tests were recorded and stored as digital videos for further processing. The chicks were tested, one after the other, in the sequence corresponding to their age, older first, younger last.

Classification of filial imprinting

For classifying chicks imprinting success, as described in Sec. [\ref=sec:classificationRes], we used a linear support vector machine (SVM) classifier, a supervised learning method that is often used to solve problems in classification, regression, and novelty detection [\cite=Vapnik1995] [\cite=Meyer2003] [\cite=Bishop2006].

Classification using linear SVM is performed by solving the problem of finding a hyperplane partitioning the training dataset. During training, the examples of separate classes are separated by a gap that is as wide as possible. We make the hypothesis that our exploration space can be linearly separated, so using linear SVM (instead of the non-linear SVM using kernel function [\cite=Shawe-Taylor2004]) is sufficient. SVM is fundamentally a two-class classifier, but a number of methods exist to handle a higher number of classes [\cite=Bishop2006].

The LIBSVM (Version 3.0) [\cite=Chang2001] was used to perform the classification.

We used the following statistics on chicks and robot movements as relevant features (explanatory variables) for the classification process: mean distance between a robot and a chick, mean speed of a chick, and its standard deviation. We reduced the dimensionality of the related feature vector from three to two by using principal components analysis (PCA) [\cite=Bishop2006]. The resulting dataset was used to train a three-class SVM classifier.

The training takes about 6 milliseconds (with 64 individuals) and the classification takes about 7 milliseconds (for 205 individuals) with Matlab R2011b running on an ordinary laptop PC (Lenovo Thinkpad T60p, Linux Ubuntu 12.04). Moreover, for individual tests the extraction of the chick and robot positions is done automatically in real time during the recording of the test. Thus the classifier allows to categorize, in real time, rapidly, large batches of experiments saving a huge amount of experimental time.

Segmentation of trajectories

The recorded experimental videos were analyzed during the experimental run using a SwisTrack that is an open source multi-platform tracking software [\cite=Lochmatter2008]. The robot position and orientation are defined by three colour markers on top of it. Thus the detection of robots and chicks is colour based. The coordinates of the robots and the animals extracted from the video were mapped to the real-world coordinates (in mm) by using the calibration routine based on the well known Tsai's calibration technique [\cite=Tsai1987]. In order to remove high frequency noise introduced into trajectories by the detection errors, every trajectory is filtered by using the Savitzky-Golay smoothing filter [\cite=Savitzky1964].

This trajectories are then segmented. The segmentation process identify segments of the trajectories (i.e.: group of continuous time-steps in the chicks behavioural traces) when the chick exhibit a particular behaviour. This is a first step toward labelling the trajectories with the observed behaviour of the chicks toward the robot. In an optimal segmentation, segments should end when a chick changes into behaviour. A typical segmentation method used in the literature is the N-steps window segmentation: trajectories containing M time-steps are split into M / N segments each with a size of N time-steps. An extreme case is the 1-step window segmentation, where every time-step is a new segment. Note that the choice of N can influence the reliability of a segmentation: if N is too big, segments can include period of times where the chicks exhibit several different behaviours. On the other hand, N-step window segmentation with a low N can be more sensitive to noise. We introduce a more robust segmentation method, the 'Threshold crossing' method. We make two hypothesises, supported by human observations: first, that chicks reduce their speed below a given threshold when they change behaviour; second, that chicks accelerate when they begin to exhibit a given behaviour, and decelerate when they change behaviour. This allow us to introduce an original segmentation method, that we call 'Threshold crossing'. This segmentation method is based on the speed and acceleration of a chick (Fig. [\ref=Fig7]): time-steps when the speed or acceleration of a chicks are below predefined thresholds are considered as stops.

Classification and Clustering of trajectories

To find the quantitative representation of these behaviours in the parameter space we use either classification algorithms or clustering algorithms. To prepare the training set we manually labeled a number of segments of trajectories, obtained using the segmentation method described in [\ref=sec:behaviouralMeasurments]. While classification algorithms are trained on human-labelled data, clustering algorithms identify behaviours without any training. Either techniques will label observation data into 7 classes of behaviours: "stops", "joins", "follows", "in front", "loops","bumped" and "other", which reflect the activity of the chick, and its relation to the movements of the robot. The Python library scikit-learn was used to perform all classification and clustering operations.

(1) Decision Trees ([\cite=Breiman1984], DT in Table [\ref=table1]). Decision Trees correspond to a recursive partitioning of the training set into several homogeneous subsets. It has a flowchart structure where nodes and branches represent conditions (expressing how to partition the training set), and leafs nodes represent class labels. Decision Trees are non-parameter and nonlinear, and so can be used in cases when little is known a-priori about the relationship between the variables. They are also simple to interpret and verify by a human. The classification could incur a loss due to overfitting, a pruning mechanism [\cite=Helmbold1995] was used to solve this issue.

(2) Random Forests (DT/Forest in Table [\ref=table1]). It is a variation of the Decision Tree method: one can use an ensemble of trees, that is known as a random forest [\cite=Breiman2001], instead of a single tree, to increase the accuracy of classification.

(3) A k-Nearest Neighbours classifier, with an euclidean distance metric [\cite=kantardzic2011data]. This algorithm makes use of a measure of similarity between all the training records and the features of the object to be classified, then identify the most similar k neighbours of all objects, and determine each object class by an object by a majority vote of its neighbours (i.e. assign the class which is the most frequent among the k training records nearest to that object). Note that kNN classifiers are known to be sensitives to noisy, irrelevant features, or by the difference of scaling of the features [\cite=kantardzic2011data]. That may explain the classification results (Table [\ref=table1]), where kNN was out-performed by other algorithms.

(4) Linear multi-class SVM classifier, as described in Section [\ref=sec:classificationMethod].

(5) K-Means [\cite=kantardzic2011data]. This clustering algorithm partitions the observations into K = 7 clusters, in which each observation belongs to the cluster with the nearest mean. The results are akin to partitioning the data space into Voronoi cells. Convergence speed can be greatly affected by the choice of initial values. We use the popular k-means++ [\cite=arthur2007k] algorithm for choosing initial values.

Discussion

This study validates the use of imprinting to ensure a social bond between robots and animals in order to perform controlled experiments with calibrated stimuli and sustained social interactions. When the robots are accepted by the animals, they can be programmed to keep sustained social interactions with them in long duration trials (our experiments lasted 30 minutes). As the robots are autonomous and work in close loop of interactions with the animals,they allow to avoid any human interference during the trials. The whole set-up presented here works in absence of humans in the experimental room and without supervision. The robots can be programmed to produce calibrated and repetitive multi-modal stimuli including visual (colour patterns), sound (prerecorded natural cues or totally artificial) and motion patterns.

Moreover, we build a framework that allows automation of high throughput data analysis. From the positions of animals and their dynamics in time we construct quantitative automated ethograms.

We test state-of-the-art algorithms to automate data analysis and show that supervised method based on Decision Tree with forest gives the best results. We also show that simple unsupervised methods such as K-means already gives interesting results. Here, the algorithms allow to combine the knowledge of human experts with fast computational methods. It is then possible to analyze the experimental data of 205 animals in a few minutes on modern computers.

This paper has two contributions. First, we introduce a methodology that allows the automated generation of quantified ethograms both on the individual level (represented by sequences of labelled behaviours) and on the group level (represented by Finite State Machines). Second, we investigate the individual variability of chicks in term of imprinting, using a classification algorithm. Results also confirm that social bonding have an influence on the imprinting quality. We observe that, after being put in groups, chicks have an imprinting quality toward the robot that is closer to the average of their group. A chick that originally was not very interested in the robot develops a stronger attachment after being placed in the group of individuals strongly imprinted toward the robot. On the other hand, a chick that originally was very attached to the robot become less interested in the robot after being placed in the group of individuals that have a low interest toward the robot.

This methodology is a first step towards mathematical modelling based on quantified ethograms, and this study is a first step toward making the link between inter-individual variability and collective behaviour. In our methodology, we first study and quantify individually each chick. Then, the chicks are put in different grouping configuration, according to their inter-individual variability. An interesting and on-going perspective is to make a group behaviour analysis taking in account the chicks individual behavioural traits, and the group composition.

Acknowledgment

This work is supported by the Swiss National Science Foundation grant no. 112150 "Mixed society of robots and vertebrates", EU-ICT project "ASSISI-bf", no. 601074.