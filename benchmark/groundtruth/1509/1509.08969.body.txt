>p >m

Light Field ReconstructionUsing Shearlet Transform

Introduction

of intermediate views from a given set of captured views of a 3D visual scene is usually referred to as image-based rendering (IBR) [\cite=shum2008image]. The scene is typically captured by a limited number of cameras which form a rather coarse set of multiview images. However, denser set of images (i.e. intermediate views) is required in immersive visual applications such as free viewpoint television (FVT) and virtual reality (VR) aimed at creating the perception of continuous parallax.

Modern view synthesis methods are based on two, fundamentally different, approaches. The first approach is based on the estimation of the scene depth and synthesis of novel views based on the estimated depth and the given images, where the depth information works as correspondence map for view reprojection. A number of depth estimation methods have been developed specifically for stereo images [\cite=scharstein2002taxonomy], and for multiview images as well  [\cite=kim2013scene],  [\cite=pearson2013plenoptic],  [\cite=wanner2014variational]. In all cases, the quality of depth estimation is very much content (scene) dependent. This is a substantial problem since small deviations in the estimated depth map might introduce visually annoying artifacts in the rendered (synthesized) views. The second approach is based on the concept of plenoptic function and its light field (LF) approximation  [\cite=adelson1991plenoptic],  [\cite=levoy1996light]. The scene capture and intermediate view synthesis problem can be formulated as sampling and consecutive reconstruction (interpolation) of the underlying plenoptic function. LF based methods do not use the depth information as an auxiliary mapping. Instead, they consider each pixel of the given views as a sample of a multidimensional LF function, thus the unknown views are function values that can be determined after its reconstruction from samples. In  [\cite=gortler1996lumigraph], different interpolation kernels utilizing available geometrical information are discussed. As shown there, established interpolation algorithms such as linear interpolation require a substantial number of samples (images) in order to obtain synthesized views with good quality.

The required bounds for sampling the LF of a scene have been defined in  [\cite=lin2004geometric]. In order to generate novel views without ghosting effects by using linear interpolation, one needs to sample the LF such that the disparity between neighboring views is less than one pixel  [\cite=lin2004geometric]. Hereafter, we will refer to such sampling as dense sampling and to the correspondingly sampled LF as densely sampled LF. In order to capture a densely sampled LF, the required distance between neighboring camera positions can be estimated based on the minimal scene depth (zmin) and the camera resolution. Furthermore, camera resolution should provide enough samples to properly capture highest spatial texture frequency in the scene  [\cite=chai2000plenoptic].

Densely sampled LF is an attractive representation of scene visual content, particularly for applications, such as refocused image generation [\cite=ng2005fourier], dense depth estimation [\cite=tosic2014light], novel view generation for FVT [\cite=tanimoto2006overview], and holographic stereography [\cite=jurik2012geometry]. However, in many practical cases one is not able to sample a real-world scene with sufficient number of cameras to directly obtain a densely sampled LF. Therefore, the required number of views has to be generated from the given sparse set of images by using IBR. The work [\cite=chai2000plenoptic] has discussed the effective use of the depth limits (zmin,zmax) in order to reconstruct desired views from a limited number of given views using appropriate interpolation filters. Use has been made of the so-called epipolar-plane image (EPI) and its Fourier domain properties [\cite=bolles1987epipolar]. Further benefits in terms of improved rendering quality has been achieved by using depth layering  [\cite=pearson2013plenoptic],  [\cite=chai2000plenoptic]. More recently, another approach to LF reconstruction has been proposed [\cite=shi2014light]. It considers the LF sampled by a small number of 1D viewpoint trajectories and employs sparsity in continuous Fourier domain in order to reconstruct the remaining full-parallax views.

In this article, we advance the concepts of LF sparsification and depth layering with the aim to develop an effective reconstruction of the LF represented by EPIs. The reconstruction utilizes the fact that EPIs have sparse representation in an appropriate transform domain. Furthermore, we also assume that a good sparse transform should incorporate scene representation with depth layers, which are expected to be sparse. We favor the shearlet transform as the sought sparsifying transform and develop an inpainting technique working on EPI, in a fashion similar to how shearlets have been applied for seismic data reconstruction  [\cite=hauser2012seismic].

Preliminary results of novel view synthesis by using shearlet transform have been presented in [\cite=vagh2015imag]. In this paper, we extend the ideas presented in [\cite=vagh2015imag] by including the underlying analysis, describing in detail the construction of the used shearlet transform and the corresponding view synthesis algorithm and evaluating the efficiency of the proposed algorithm on various datasets.

The outline of this paper is as follows. The LF and EPI concepts are presented in Section [\ref=sec:lf]. Section [\ref=sec:epitd] focuses on the identification of suitable transform domain and particularly discusses the shearlet transform, its properties and construction for the given case. The reconstruction algorithm is presented in Section [\ref=sec:recalg]. The algorithm evaluation for different datasets and a comparison with the state of the art is presented in Section [\ref=sec:eval]. Finally, the work is concluded in Section [\ref=sec:conc].

Light field formalization

Light field representation

The propagation of light in space in terms of rays is fully described by the 7D continuous plenoptic function R(θ,φ,λ,τ,Vx,Vy,Vz), where (Vx,Vy,Vz) is a location in the 3D space, (θ,φ) are propagation angles, λ is wavelength, and τ is time  [\cite=adelson1991plenoptic]. In more practical considerations, the plenoptic function is simplified to its 4D version, termed as 4D LF or simply LF. It quantifies the intensity of static and monochromatic light rays propagating in half space. In this representation, the LF ray positions are indexed either by their Cartesian coordinates on two parallel planes, the so-called two-plane parameterization L(u,v,s,t), or by their one plane and direction coordinates L(u,v,φ,θ)  [\cite=liang2011light].

Consider camera with image plane (u,v) and focal distance f moving along the (s,t) plane. This is an important practical consideration, which associates the parameterizing planes with LF acquisition and multiview imagery and relates LF sampling with discrete camera positions and a discrete camera sensor. The case is illustrated in  [\ref=fig:epi] (a) where the z axis represents the scene depth and the plane axes s and u are considered perpendicular to the figure and omitted for simplicity. Constraining the vertical camera motion by fixing s = s0 and moving the camera along the t-axis, leads to so-called horizontal parallax only (HPO) multiview acquisition. Images captured by successive camera positions [formula] can be stacked together which is equivalent to placing the t-axis perpendicular to the (u,v) plane. The corresponding LF L(u,v,s0,t) is illustrated in  [\ref=fig:epi] (b).

EPI Representation and Sampling Requirements

The LF data organization as in  [\ref=fig:epi] (b) leads to the concept of EPIs pioneered by Bolles et al. in [\cite=bolles1987epipolar]. Assume an ideal horizontal camera motion (or, equivalently, perfectly rectified perspective images). Gathering image rows for fixed u = u0 along all image positions forms an LF slice E(v,t) = L(u0,v,s0,t). Such LF slice is referred to as EPI and is given in  [\ref=fig:epi] (c). In the EPI, relative motion between the camera and object points manifests as lines with depth depending slopes. Thus, EPIs can be regarded as an implicit representation of the scene geometry. In comparison with regular photo images, an EPI has a very well defined structure. Any visible scene point appears in one of the EPIs as a line whose slope depends on the distance of the point from the capture position and the measured intensity over the line reflects the intensity of emanated light from that scene point. The Lambertian reflectance model (any point in the scene emanates light in different direction with same intensity) leads to an EPI with even more definitive structure - each line in the EPI has a constant intensity proportional to the intensity of the point. For a scene point at depth z0 measured from the capture plane (s0,t), the disparity in the image plane (u0,v) between two cameras positioned at t1 and t2 is [\cite=chai2000plenoptic]

[formula]

where f is the camera focal distance. This is illustrated by the red lines in  [\ref=fig:epi] (a), which show a point projected on cameras at t1 and t2. The same point appears as the red line in  [\ref=fig:epi] (c).

By assuming a horizontal sampling rate Δv satisfying the Nyquist sampling criterion for scene's highest texture frequency, one can relate the required camera motion step (sampling) with the scene depth. For given zmin the sampling rate Δt should be such that

[formula]

in order to ensure maximum 1 pixel disparity between nearby views  [\cite=lin2004geometric], [\cite=chai2000plenoptic].  [\ref=fig:epi] (d) shows the frequency domain support of a densely sampled EPI, which is of bow-tie shape. The baseband (in green) is limited by the minimum and maximum depth and its replicas are caused by the sampling rates Δv and Δt. In Fourier domain depths are transformed to lines, i.e. the frequency support of all scene points at a certain depth z0, which in EPI appear as lines with same slope, is confined to a line (the yellow line in  [\ref=fig:epi] (d)). By selecting equality for Δt in Eq. ([\ref=eqn:deltt]), we effectively place the zmin line at 45 degrees in the frequency domain plane. This maximizes the baseband support, which helps in designing reconstruction filters. In particular, simple separable filters (e.g. linear interpolators) can be used.

Motivation

Our problem in hand is to reconstruct densely sampled EPIs (and thus the whole LF) from their decimated and aliased versions produced by a higher camera step Δt. The problem is illustrated in  [\ref=fig:epi] (e). The figure shows a case, where a densely sampled EPI has been decimated by a factor of 4, which means that every 4th row has been retained while the others have been zeroed (see also  [\ref=fig:epirows] (b) for illustration of subsampling in EPI domain). As seen in the figure, aliased replicas (gray) and baseband (green) overlap, hence a band-limited reconstruction is infeasible with a classical filtering method. The work [\cite=chai2000plenoptic] has specified requirements for the LF sampling density for given zmin and zmax in order to allow a global band-limited reconstruction. Reconstruction of more complex scenes (e.g. piecewise-planar or tilted-plane) would require additional information about scene depth and depth layering [\cite=pearson2013plenoptic], [\cite=chai2000plenoptic]. For real scenes it is natural to assume that objects are distributed at a finite, rather small number of depths. In our approach, we aim at implicitly determining those sparse depth layers by analyzing the given aliased EPIs in frequency domain using depth guided filters. This is equivalent to applying a proper frequency plane tiling. The case in  [\ref=fig:epi] (e) is further analyzed in  [\ref=fig:epi] (f), which highlights a frequency plane tiling by 4 depth layers, with 1 px disparity range in each layer. If those depth layers are given, they are sufficient to support interpolating the EPIs without aliasing artifacts. Our aim is thus to implicitly obtain those depth layers by transform-domain analysis implying the scene's depth sparse distribution. Furthermore, by an additional dyadic separation of the frequency plane, i.e. a multiresolution analysis, one can process each region differently and utilize a more efficient analysis tool.  [\ref=fig:epi] (g) illustrates a wavelet based separation of the frequency plane for the same aliased EPI. It is easy to notice, that the L1 region does not contain any aliasing. Therefore by applying a low-pass filter corresponding to the L1 region on the aliased EPI will reconstruct the desirable densely sampled EPIs frequencies in that region. In other words, the procedure of low-pass filtering followed by decimation can be interpreted as increasing the pixel size, which directly decreases the disparity between the given rows. In this manner, fewer required depth layering directions will have to be distinguished from each other in order to efficiently reconstruct the full EPI. Based on the above discussion, the desirable frequency plane tiling with elemental filters for the case of densely sampled EPI reconstruction from its 4th row subsampled version is given in  [\ref=fig:epi] (h). The construction of such set of filters is closely related to the definition and constructive reconstruction of shearlet frames as presented in the next section.

Epipolar-plane image in transform domain

Directional sensitive transforms

Consider a class of piecewise-smooth functions [formula] (also referred to as cartoon-like images), as discussed in [\cite=candes1999curvelets], [\cite=candes2004new],[\cite=kutyniok2012book]. A function [formula] consists of two components and has a form f = f0  +  f1χB, where f0,f1 are C2-smooth with support in 2 and χB is characteristic function of a set B  ⊂  [0,1]2 with bound δB being a closed C2-curve with bounded curvature. The problem of reconstructing a function from [formula] space using its given incomplete measurements can be addressed through sparse approximation using some appropriately constructed transform. The quality of the representation performance of the [formula] in given frame is described by the asymptotic decay speed of the L2 error of the approximation obtained using only N largest coefficients of the frame decomposition. Wavelet-domain decomposition has significant drawback in representing the considered [formula] function space. For wavelets, the approximation error rate is O(N- 1), where N is the number of best elements of a wavelet in a decomposition used for function representation [\cite=kutyniok2012shearlets]. In comparison, adaptive triangle based approximation of the cartoon-like images provides O(N- 2) approximation rate  [\cite=donoho2001sparse], where N is the number of triangles used for image representation. This result provides the desirable sparse approximation rate to be achieved using frame based representation for piecewise-smooth functions. In order to provide better approximation than the wavelet transform, the desirable transform should provide a good directional sensitivity due to approximation of singularities distributed over the C2-smooth curve δB which is the border between smooth image pieces. Several frames and corresponding transforms have been constructed for sparse representations, among them, tight curvelet frames by Candes and Donoho [\cite=candes2004new] and countourlets by Do and Vetterli [\cite=do2005contourlet]. Going back to the case of study, namely the EPI, one can observe that the anisotropic property of the EPI is caused by a shear transform. This naturally leads to the idea of using a transform constructed with the same property, namely the shearlet transform.

The optimal sparse approximation property of the tight shearlet frame has been studied in [\cite=guo2007optimally]. Similar results for compactly supported shearlet frame have been reported in [\cite=kutyniok2011compactly]. Both types of shearlet frame construction provide an optimal sparse approximation of [formula], in the sense that N-term approximation fN constructed by keeping N largest coefficients of the frame decomposition satisfies

[formula]

Compactly supported shearlets

The general definitions of a shearlet system and shearlet group can be found in [\cite=kutyniok2012book], which contains also all necessary conditions about discretization of the parameters to construct the shearlet frame of functions. We will describe in more detail the so-called cone-adapted shearlet system, which is appropriate to construct desirable separation of frequency domain. Let us consider a scaling function [formula] and shearlets [formula]. For [formula] the density of the (regular) cone-adapted discrete shearlet system SH(φ,ψ,ψ̃) is the set of functions for parameters [formula]

[formula]

where and [formula], [formula] are parabolic scaling matrices, [formula] is a shearing matrix, and [formula], [formula] are sampling densities of translation grid. The transform maps [formula] to the sequence of coefficients

[formula]

The function Φ(φ) handles the region close to the origin Cφ and Ψ(ψ),Ψ̃(ψ̃) handle the Cψ,Cψ̃ cones as illustrated in  [\ref=fig:shear] (b). This is accomplished by appropriately selecting the generator functions φ,ψ,ψ̃. More details about the construction and sufficient conditions for forming frame of functions from the cone-adapted shearlet system can be found in [\cite=kutyniok2012book]. In addition, it is also desirable to have compact support of the shearlet frame elements that is important for the algorithm considered in this paper. In order to construct a compactly supported shearlet system, different approaches have been considered [\cite=kutyniok2011compactly], [\cite=lim2013nonseparable]. In  [\cite=kutyniok2011compactly], a compactly supported shearlet has been constructed in spatial domain by selecting 2D separable functions as generators where φ1(x1), ψ1(x1) are 1D scaling and wavelet functions. Henceforth, we will denote (ξ) as the Fourier transform of f(x). Under certain conditions on ψ1,φ1 the corresponding expansion SH(c;φ,ψ,ψ̃) form a frame and the constructed elements of the frame are compactly supported in spatial domain. Choosing separable shearlet generator ψ(x1,x2) is not efficient. Significant overlap between [formula] and [formula] makes shearlet frame over redundant and with bad directional selectivity [\cite=lim2013nonseparable].

A construction of compactly supported shearlets by selecting non-separable ψ 2D directional filter has been presented in [\cite=kutyniok2011compactly]. Using such shearlet generator provides better covering of frequency plane by transform elements and has better directional selectivity. In order to present the construction and implementation of the proposed shearlet transform we follow the implementation of the digital non-separable 2D shearlet transform, associated with compactly supported shearlets as presented in [\cite=kutyniok2014shearlab].

Consider a multiresolution analysis with wavelet and scaling function ψ1,φ1∈L2(R) given as The nonseparable shearlet generator is defined as

[formula]

where the trigonometric polynomial P is a 2D directional fan filter [\cite=do2005contourlet] which is used to approximate the 2D non-separable filter with essential support in frequency domain bounded within the region shown in  [\ref=fig:shear] (a).

In order to present discrete shearlet transform of the continuous function [formula] we assume that for some sufficiently large [formula], the function can be represented using its discrete samples [formula]

[formula]

where φ(x) is defined as in Eq. ([\ref=eq:sep]). The particular choice of J depends on the given input data and will be discussed in Section [\ref=sec:recalg].

Modified shearlet transform for EPI

The choice of A2j as a parabolic scaling matrix, has been motivated by the aim to construct best approximation of function with singularities over parabolic curves. For the EPI one can observe singularities distributed over straight lines. Therefore, a better choice for the scaling transform is given by

[formula]

This choice supports the desirable number of shears in each scale and provides scaling only by one axis. It can be considered as a special case of a more general shearlet transform called universal shearlet [\cite=kutyniok2012book], [\cite=kutyniok2014shearlab]. Furthermore the shearlet system for Ψ(ψ) consists of the functions

[formula]

where

[formula]

and cj = (cj1,cj2) are sampling constants for translation. Easy to notice

[formula]

Following the same methodology as in [\cite=kutyniok2014shearlab], it can be shown that the digital filter corresponding to ψj,0,m has the form

[formula]

where [formula] denote tensor product such that [formula], [formula] are the Fourier coefficients of the trigonometric polynomial P(2J - j - 1ξ1,2J + 1ξ2), [formula] and [formula] are the Fourier coefficients of the respective trigonometric polynomials and [formula].  [\ref=fig:shear] (d) illustrates the frequency responses of the digital filters hj,gj for [formula].

The shear transform [formula] does not preserve the regular grid [formula], therefore its digitalization is not trivial. The solution to the problem presented in [\cite=lim2013nonseparable], is to refine the [formula] grid along x-axis by a factor 2j. In that case, the grid [formula] is invariant under the Sk2- j transform. Thus, for an arbitrary [formula], the shear transform Sk2- j can be implemented as a digital filter

[formula]

where τj represents a digital low-pass filter with normalized cutoff frequency at 2- j.

Based on previous results from Eq. ([\ref=eq:psijkm1]), ([\ref=eq:psijkm2]), ([\ref=eq:psij0d]), ([\ref=eq:pfull]) and proper choice of cj it can be shown that digital filter corresponding to ψj,k,m has a form

[formula]

A digital filter ψd corresponding to separable elements of the transform φm, has a form [formula].

Based on the above, a direct shearlet transform associated with set of elements Ψ(c;ψ) and corresponding to frequency plane region Cψ is defined as follows

[formula]

where [formula].

In order to calculate the inverse transform we need to construct the dual frame. This can be done based on the shift invariance property of the shearlet frame. First we set

[formula]

Then, the dual shearlet filters are defined as follows

[formula]

The constructed frame guarantees stable reconstruction using the dual frame, if A  ≤  Ψ̂d  ≤  B conditions are satisfied for some finite bounds 0 < A,B <   ∞    [\cite=mallat2008wavelet]. An illustration of the obtained Ψ̂d for J  =  2, is presented in  [\ref=fig:shear] (e). In this case, the upper and lower bounds are numerically found to be 0.03 < Ψ̂d < 1.03. The reconstruction formula is given by

We are interested only in transform elements where the shearing has positive sign, i.e. 0  ≤  k  ≤  2j + 1, such that the corresponding transform elements are covering the frequency domain region highlighted by gray in  [\ref=fig:shear] (c). Therefore, we use the direct transform S for discrete values fJ and [formula] defined as

[formula]

Respectively, the inverse transform S* is defined as

[formula]

The frequency-domain support of the elements selected from the frame in  [\ref=fig:shear] (e) is shown in  [\ref=fig:shear] (f).

Reconstruction algorithm

In this section we present an LF reconstruction algorithm utilizing an EPI sparse representation in shearlet domain. Usually, a setup of uniformly distributed, parallel positioned and rectified cameras is used for capturing a 3D scene. The horizontal parallax between views limits the motion associated with the depth of the objects in horizontal axis only. This allows us to perform intermediate view generation over EPI independently. In order to formulate the reconstruction algorithm in discrete domain we assume that the starting coarse set of views is downsampled version of the unknown densely sampled LF we try to reconstruct. The uniformly distributed cameras imply the possibility of estimating a common upper bound dmax for disparities between nearby views. Thus, the given coarse set of views are regarded as taken at each dmax  =  ⌈dmax⌉-th view of a densely sampled LF.

Thus, in every densely sampled EPI, all unknown rows should be reconstructed assuming given every dmax-th row. An example is presented in [\ref=fig:epirows] (a), where EPI representation of four views with 16 px disparity is given. Therefore, the targeted densely sampled EPI is to be constructed in such a way that the available data will appear in rows with 16 px distance ([\ref=fig:epirows] (b)). [\ref=fig:epirows] (c) shows the same rows with respect to the fully reconstructed EPI, where successive rows appear at disparity less or equal to 1 px. EPI lines are not distinguishable in  [\ref=fig:epirows] (a). The lines start to form when the views are properly arranged, as in [\ref=fig:epirows] (b), and they get fully reconstructed in the densely sampled EPI.

Without loss of generality we assume that the densely sampled EPI is a square image denoted by [formula] where N = mdmax and m is a number of available views. Given the samples [formula] of the y* obtained by

[formula]

where [formula] is a measuring matrix, such that [formula] and 0 elsewhere. The measurements y form an incomplete EPI where only rows from the available images are presented, while everywhere else EPI values are 0. Eq. ([\ref=eq:yHy]) can be rewritten in the form y = Hy* by lexicographically reordering the variables [formula]. The shearlet analysis and synthesis transforms are defined as [formula] where η is the number of all translation invariant transform elements.

The reconstruction of y* given the sampling matrix H and the measurements y can be cast as an inpainting problem, with constraint to have solution which is sparse in the shearlet transform domain, i.e.

[formula]

We make use of the iterative procedure within the morphological component analysis approach, which has been originally proposed for decomposing images into piecewise-smooth and texture parts [\cite=starck2005morphological], [\cite=fadili2009mcalab]. In particular, we aim at reconstructing the EPI y* by performing regularization in shearlet transform domain. Solution is sought in the form of the following iterative thresholding algorithm

[formula]

where [formula] is a hard thresholding operator applied on transform domain coefficients and αn is an acceleration parameter. The thresholding level λn decreases with the iteration number linearly in the range

[formula]

Evaluation

In this section we evaluate the performance of the proposed method. First, we demonstrate the performance of the reconstruction algorithm with respect to different transforms presented in [\cite=kutyniok2014shearlab], [\cite=hauser2012fast]. Ground truth densely sampled EPI ( [\ref=fig:diccomp](d)) is obtained using properly generated views of a synthetic scene. Every 16th row has been used as input data for the reconstruction method as in  [\ref=fig:diccomp] (a), and interpreted in similar fashion as presented in  [\ref=fig:epirows]. The obtained reconstruction results are presented in  [\ref=fig:diccomp] (b), (c), (e), (f). The reconstruction using Haar wavelet transform is not properly revealing straight lines and the performance is poor. Directional sensitive transforms are showing better reconstruction performance, while the proposed shearlet transform outperform the others. The proposed transform combines two properties, compact support in horizontal direction in spatial domain and tight distribution of transform elements near low-frequency region in frequency plane which affect the reconstruction performance.

Next, we characterize the reconstruction performance for different test sets using leave N out tests. The experimental setup considers downsampled versions of a number of given test multiview sets, where every N-th view is kept and the others are dropped. The downsampled versions are used as input to the algorithm, which is supposed to reconstruct all views for the given sets, which have been dropped during the downsampling step. The reconstruction quality is assessed by calculating the PSNR between the original and the reconstructed views. DERS+VSRS [\cite=tanimoto2009depth], [\cite=tanimoto2009view], is used as a reference algorithm to compare with. DERS (depth estimation reference software) is applied for every three consecutive images in order to estimate disparity map corresponding to the middle view. Using a stack of given images with corresponding estimated disparity maps, the desired intermediate views are generated using VSRS (view synthesis reference software).

We have used a number of publicly available datasets, as presented in Table [\ref=table:mvd]. The table summarizes also some specifications of the sequences such as spatial resolution and number of views. In all test cases, our algorithm is applied over all EPIs for reconstructing the missing intermediate views. The adaptive selection of the acceleration parameter, as described in Section [\ref=sec:recalg], has been applied. Typically, 100 iterations were used per dataset in order to obtain the presented results.

[\ref=fig:comp] presents the comparative results of reconstruction based on our and the DERS+VSRS algorithms. For efficient implementation of the algorithm, circular convolution was implemented through Fourier transform as presented in the diagram in  [\ref=fig:diag]. While this makes the procedure fast, in some cases it introduces border effects (e.g. in  [\ref=fig:compimg] see specifically the Bunny difference map). Our method performs better in all cases but one, notably for the Coach dataset. However, for the Couch dataset instead of DERS, we have used all disparity maps, as already obtained by the algorithm presented in [\cite=kim2013scene]. In the referred algorithm, the disparity maps are estimated using the full set of images, not only the downsampled one. Thus, the depth maps are of higher quality than the one that can be achieved if only the downsampled views are given. The comparison in this case is made in order to quantify the performance of our algorithm against an ideal case of DIBR. A direct comparison of reconstructed views obtained by ours method and the one from [\cite=kim2013scene] shows that even in the case of 'unfair' comparison our algorithm reconstructs views with competitive quality. Another observation is that the datasets Pantomime show high variations in reconstruction quality for different views. This property can be observed for both reconstruction algorithms. The cause is in the lack of perfect rectification between views in that dataset.

We compare our method also against the method presented in [\cite=pearson2013plenoptic] which is another IBR method utilizing depth layering. Both methods show equal performance measured for the Teddy dataset. The PSNRs are averaged over four reconstructed views. The result reported in [\cite=pearson2013plenoptic] shows 33.25 dB, while our method gives 33.33 dB.

Our next tests deal with full parallax imagery. In [\cite=shi2014light], a method is proposed for LF reconstruction that utilizes sparsity of full parallax LF in continuous Fourier domain. The method can be used for reconstruction for non-Lambertian scenes and it requires a set of views obtained from a set of 1D viewpoint trajectories [\cite=shi2014light]. We compared reconstruction results for dataset Bunny and Truck [\cite=vaish2008new] consisting of 17  ×  17 views, which are representing Lambertian scenes, thus suitable for the proposed and the method in [\cite=shi2014light]. In the proposed method the reconstruction is applied for every horizontal and then for every vertical EPI consecutively. Two experiments, one with 25 views and one with 81 views out of 289 has been applied. The method in [\cite=shi2014light] uses 93 views as input. The views used as inputs for both algorithms are illustrated in  [\ref=fig:pattern] and the average error, in terms of PSNR, over reconstructed views is presented in Table [\ref=table:lfpsnr]. Illustration of obtained views with corresponding difference maps is shown in  [\ref=fig:complf]. As seen from the figure, in the case of the Bunny dataset, the proposed method uses fewer views as input and still performs similar to the one in [\cite=shi2014light]. In the case of the Truck dataset, the proposed method performs significantly better in terms of average PSNR.

One of the applications of full parallax LF is to construct digitally refocused images in post-processing.  [\ref=fig:truckref] shows digitally refocused images corresponding to the central view for differently sampled LFs. As expected, the lack of available views results in strong artifacts in the synthesized refocused image  [\ref=fig:truckref] (a) where only 5  ×  5 subset of views is used, while for the up-sampled (reconstructed) LF consisting of 49  ×  49 views, very small disparity between the reconstructed views causes smooth blurring in the refocused image areas.  [\ref=fig:truckref] (c), presents the result of similar refocusing for the original dataset  [\ref=fig:truckref] (b).

Conclusions

In the paper, we have presented a method for reconstructing densely sampled LF from a small number of rectified multiview images taken with a wide baseline. The reconstructed LF bears the property that the disparity between adjacent views is 1 pixel at most while the input views can be with quite high disparity. The method utilizes a sparse representation of the underlying EPIs in shearlet domain and employs an iterative regularized reconstruction. We have constructed a shearlet frame specifically for the case of EPIs and proposed an adaptive tuning for the parameter controlling the convergence in the iterative procedure. Experiments with various datasets compare our method favorably against the reference DIBR software and the state of the art in IBR. A feature of the method is that it reconstructs all views and therefore can be used in applications which require densely sampled views such as refocusing, wide field of view LF displays and digital holographic printing.

Although, the implementation of the algorithm reported in this paper is limited to scenes with Lambertian properties, it is possible to extend the algorithm such that it will be able to reconstruct non-Lambertian scenes. This will, primary, require modification of the bases used in reconstruction since different parts of the frequency domain has to be covered, in comparison to the Lambertian case. This extension is a topic of future research.