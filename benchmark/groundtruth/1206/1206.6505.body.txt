New Local Duals in Eternal Inflation

Introduction

Global-local duality is one of the most fascinating properties of eternal inflation. It lies at the heart of a profound debate: should we expect to understand cosmology by adopting a global, "bird's eye" viewpoint that surveys many causally disconnected regions, as if we stood outside the universe as a kind of meta-observer? Or should fundamental theory describe only experiments that can be carried out locally, in accordance with the laws of physics and respectful of the limitations imposed by causality?

Global-local duality appears to reconcile these radically different perspectives. It was discovered as a byproduct of attempts to solve the measure problem of eternal inflation: the exponential expansion of space leads to infinite self-reproduction, and all events that can happen in principle will happen infinitely many times. (Short reviews include Refs. [\cite=Fre11] [\cite=Sal11].) To compute relative probabilities, a regulator, or measure, is required.

Most measure proposals are based on geometric cutoffs: one constructs a finite subset of the eternally inflating spacetime according to some rule. Relative probabilities can then be defined as ratios of the expected number of times the corresponding outcomes that occur in these subsets. Geometric cutoffs can be divided into two classes. Very roughly speaking, global cutoffs act on time, across the whole universe; this is natural from the bird's eye viewpoint. Local cutoffs act on space; this is more natural from the viewpoint of an observer within the spacetime.

Global cutoffs define a parameter T that can roughly be thought of as a time variable. Spacetime points with T smaller than the cutoff form a finite set in which expected numbers of outcomes can be computed; then the limit T  →    ∞   is taken to define probabilities:

[formula]

Examples include the proper time cutoff [\cite=Lin86a] [\cite=LinLin94] [\cite=GarLin94] [\cite=GarLin94a] [\cite=GarLin95], where T is the proper time along geodesics in a congruence; the scale factor time cutoff [\cite=LinMez93] [\cite=LinLin94] [\cite=Lin06] [\cite=DesGut08a] [\cite=DesGut08b] [\cite=BouFre08b] [\cite=Bou12b], where T measures the local expansion of geodesics; and the light-cone time cutoff [\cite=Bou09] [\cite=BouYan09] [\cite=BouFre10b], where T is determined by the size of the future light-cone of an event.

Local cutoffs restrict to the neighborhood of a single timelike geodesic. The simplest local cutoff is the causal patch [\cite=Bou06] [\cite=BouFre06a]: the causal past of the geodesic, which depends only on the endpoint of the geodesic. Another example is the fat geodesic [\cite=BouFre08b], which restricts to an infinitesimal proper volume near the geodesic. Relative probabilities are defined by computing an ensemble average over different possible histories of the cutoff region:

[formula]

Global-local duality is the statement that there exist pairs of cutoffs--one global, one local--that yield precisely the same predictions. Our goal will be to exhibit the generality of this property and the basic structure underlying it. This will allow us to identify new local duals to some global measures of particular interest.

Discussion

Global-local duality implies that the distinction between two seemingly disparate perspectives on cosmology is, at best, subtle. However, it is too early to conclude that the global and local viewpoints are as interchangeable as the position and momentum basis in quantum mechanics. Some important distinctions remain; and for now, each side, global and local, exhibits attractive features that the other lacks.

Advantages of the global viewpoint: A key difference between global and local cutoffs is that local measures are sensitive to initial conditions, whereas global measures exhibit an attractor regime that completely determines all probabilities. The attractor regime can only be affected by infinite fine-tuning, or by choosing initial conditions entirely in terminal vacua so that eternal inflation cannot proceed. Thus, global measures are relatively insensitive to initial conditions.

Therefore, a local cutoff can reproduce the predictions of its global dual only with a particular choice of initial conditions on the local side, given by the attractor solution of the global cutoff. (The distribution over initial conditions is set by the field distribution on a slice of constant global cutoff parameter.) Ultimately, there appears to be no reason why initial conditions might not be dictated by aspects of a fundamental theory unrelated to the measure. In this case, global and local measures could be inequivalent. But for now, the global cutoff is more restrictive, and thus more predictive, than its local dual, some of whose predictions could be changed by a different choice of initial conditions.

Advantages of the local viewpoint: Through the study of black holes and the information paradox, we have learned that the global viewpoint must break down at the full quantum level. Otherwise, the black hole would xerox arbitrary quantum states into its Hawking radiation, in contradiction with the linearity of quantum mechanics [\cite=SusTho93]. By contrast, a description of any one causally connected region, or causal patch, will only contain one copy of the information. For example, an observer remaining outside the black hole will be able to access the Hawking radiation but not the original copy, which is accessible to an observer inside the black hole. Indeed, this was the key motivation for introducing the causal patch as a measure: if required in the context of black holes, surely the same restriction would apply to cosmology as well.

The global spacetime is obtained by pretending that the state of the universe is measured, roughly once per Hubble time in every horizon volume. It is not clear what the underlying process of decoherence is, since no natural environment is available (by definition, since we are considering the entire universe). By contrast, the local description (at least, the causal patch) exhibits decoherence at the semiclassical level, since matter can cross the event horizon [\cite=BouSus11]. This suggests that the global picture may be merely a convenient way of combining the different semiclassical histories of the causal patch into a single spacetime.

Aside from the fundamental questions raised by global-local duality, we expect that our results will aid future studies of measure phenomenology. Computations are significantly simpler in the local dual, because it strips away an infinite redundancy. The local cutoff region can be considered an elementary unit of spacetime, which (from the global viewpoint) is merely reproduced over and over by the exponential expansion of the eternally inflating universe.

Outline

In Sec. [\ref=sec-cp], we set the stage by showing that the light-cone time cutoff is equivalent to the causal patch, with initial conditions in the longest-lived de Sitter vacuum. This is a known result [\cite=Bou09] [\cite=BouYan09]. The measures on both sides of the duality are particularly simple; as a consequence, the duality proof is especially transparent.

In Sec. [\ref=sec-fg], we define the Short Fat Geodesic measure, and we show that it is the local dual to the recently proposed New Scale Factor Cutoff [\cite=Bou12b]. This generalizes to arbitrary eternally inflating spacetimes the known duality between the fat geodesic and the scale factor time cutoff [\cite=BouFre08b], which originally applied only to everywhere-expanding multiverse regions. We also discuss important formal differences between the causal patch/light-cone time pair and all other global-local pairs we consider. Unlike other local measures, which require the specification of spatial boundary conditions, the causal patch is entirely self-contained and can be evaluated without referring to a global viewpoint.

In Sec. [\ref=sec-x], we generalize the proof of the previous section to relate a large class of global-local pairs. On the local side, one can consider modulations of the fatness of the geodesic; on the global side, this corresponds to particular modifications of the definition of the cutoff parameter T, which we identify explicitly. We illustrate this general result by deriving local duals to two global proposals, the CAH cutoff [\cite=Vil11] and the proper time cutoff. The local dual, the Hubbletube, naturally extends the range of applicability of the CAH cutoff to include decelerating regions; but unfortunately, an additional prescription (such as CAH+ [\cite=Vil11]) is still required to deal with nonexpanding regions. The local dual to the proper time cutoff, the Incredible Shrinking Geodesic, makes the phenomenological problems of this simplest of global cutoffs readily apparent.

Causal Patch/Light-Cone Time Duality

In this section we show that the causal patch measure (with particular initial conditions) is equivalent to the light-cone time measure, i.e., that both define the same relative probabilities. We follow Ref. [\cite=BouYan09], where more details can be found. The proof is rather simple if one is willing to use the (intuitively natural) results for the attractor behavior of eternal inflation as a function of the global time coordinate. For this reason we will first present a proof of duality, while assuming the attractor behavior, in Sec. [\ref=sec-cpdef]. Then we will derive the attractor behavior, in Sec. [\ref=sec-lcattract].

Causal Patch Measure

The causal patch is defined as the causal past of the endpoint of a geodesic. Consider two outcomes I and J of a particular observation; for example, different values of the cosmological constant, or of the CMB temperature. The relative probabilities for these two outcomes, according to the causal patch measure, is given by

[formula]

Here, 〈NI〉 is the expected number of times the outcome I occurs in the causal patch.

Computing 〈NI〉CP involves two types of averaging: over initial conditions, p(0)i, and over different decoherent histories of the patch. We can represent the corresponding ensemble of causal patches as subsets of a single spacetime. Namely, we consider a large initial hypersurface (a moment of time), Σ0, containing Z  →    ∞   different event horizon regions, with a fraction p(0)i of them in the vacuum i. Event horizons are globally defined, but we will be interested in cases where the initial conditions have support mainly in long-lived metastable de Sitter vacua. Then we make a negligible error by assuming that the event horizon on the slice Σ0 contains a single de Sitter horizon volume, of radius H- 1α = (3 / Λα)1 / 2, where Λα is the cosmological constant of vacuum α, and we may take the spatial geometry to be approximately flat on Σ0. More general initial conditions can be considered [\cite=BouYan09].

At the center of each initial horizon patch, consider the geodesic orthogonal to Σ0, and construct the associated causal patch. We may define 〈NI〉CP as the average over all Z causal patches thus constructed, in the limit Z  →    ∞  . So far, each causal patch is causally disconnected from every other patch. It is convenient to further enlarge the ensemble by increasing the density of geodesics to z geodesics per event horizon volume, and to take z  →    ∞  :

[formula]

where the sum runs over the zZ causal patches, and Nν,CPI is the number of times I occurs in the causal patch ν. The causal patches will overlap, but this will not change the ensemble average.

At finite large z, a sufficiently early event Q in the future of Σ0 will thus be contained in a number of causal patches. The later Q occurs, the fewer patches will contain it (Fig. [\ref=fig-magic]). In the limit z  →    ∞  , every event will be contained in an infinite number of patches, but there is still a sense in which later events are overcounted less. This can be captured by defining the quantity π(Q), as z- 1 times the number of causal patches containing a given event Q.

By causality, the causal patch of a geodesic contains Q if and only if that geodesic enters the future of Q. Therefore, π(Q) is the volume, measured in units of horizon volume, on Σ0, of the starting points of those geodesics that eventually enter the future light-cone of Q. This allows us to reorganize the sum in Eq. ([\ref=eq-cpsum]). Instead of summing over causal patches, we may sum over all events Q where outcome I occurs, taking into account that each such instance will be "overcounted" by the ensemble of causal patches, by a factor proportional to π(Q):

[formula]

Light-cone time is defined precisely so that it is constant on hypersurfaces of constant π(Q). The exact definition is not essential but it is convenient to choose

[formula]

This defines a time variable at every event Q in the future of the initial hypersurface Σ0. We may reorganize the sum once more, as an integral over light-cone time:

[formula]

where dNI is the number of events of type I that occur in the time interval (tLC,tLC + dtLC), and the integral ranges over the future of Σ0.

Proof of Equivalence to the Light-Cone Time Measure

So far, we have been dealing with a local measure, the causal patch. We have merely represented the causal patch ensemble in terms of a single global spacetime. Moreover, we have rewritten the ensemble average, as an integral over a time variable tLC, adapted to the factor π(Q) by which events in the global spacetime are weighted in the ensemble.

We will now show that with a particular, simple choice of initial conditions, the causal patch probabilities P̂I (i.e., the ensemble averages 〈NI〉CP) agree with the probabilities computed from a global measure, the light-cone time cutoff. These probabilities are defined by

[formula]

where NI(tLC) is the number of events of type I prior to the light-cone time tLC.

As we shall review below, the cosmological dynamics, as a function of light-cone time, leads to an attractor regime:

[formula]

where φ  <  γ < 3. Therefore, the light-cone time probabilities are given by

[formula]

The causal patch probabilities can also be evaluated using Eq. ([\ref=eq-lcattract]), if we choose initial conditions in the attractor regime, i.e., if we take Σ0 to be a slice of constant, very late light-cone time. Substituting into Eq. ([\ref=eq-tsum]), one finds

[formula]

Since γ < 3, the integral converges to an I-independent constant, so relative probabilities in the causal patch measure are given by

[formula]

This agrees with the light-cone time probabilities, Eq. ([\ref=eq-lcfinal]). Therefore, the two measures are equivalent.

Light-Cone Time Rate Equation and Attractor Solution

We will now complete the proof by deriving the attractor regime, Eq. ([\ref=eq-lcattract]). (We will follow [\cite=BouYan09] and will make use of certain general properties of rate equations in eternal inflation [\cite=GarSch05].) It is convenient to do this in two steps. Treating each long-lived metastable de Sitter vacuum as pure, empty de Sitter space, one derives the number nα(tLC) of horizon patches of vacuum α. Because of the slow decays, most regions are indeed empty, and slices of constant light-cone time are spatially flat on the horizon scale. Thus, a horizon patch at constant time tLC can be defined as a physical volume

[formula]

where

[formula]

is the time and distance scale associated with the cosmological constant in vacuum α. The number nα of horizon patches at the time tLC is related to the physical volume Vα occupied by vacuum α, as

[formula]

In the second step, one focusses on the decay events in this distribution, i.e., the production of new bubbles. These bubbles can then be considered in detail. In general they will be not be empty, and they need not have positive cosmological constant.

The rate equation for the number of horizon patches of metastable de Sitter vacua is

[formula]

where κiβ = viτΛ,βΓiβ is the dimensionless decay rate from β to i. That is, Γiβ is the rate at which i-bubbles are produced inside the β-vacuum, per unit four-volume; and κiβ is the decay rate per unit horizon volume and unit de Sitter time scale. Also, [formula] is the total dimensionless decay rate of vacuum α. We will now explain the origin of each term on the right-hand side.

The first term, 3nα, arises from the exponential volume growth of de Sitter space. In regions occupied by vacuum α, the metric behaves locally as [formula], where t is proper time. The relation between proper time and light-cone time is

[formula]

in pure de Sitter space. In metastable de Sitter space this relation is modified, on average, by a relative correction not exceeding κα, which can be neglected for the purposes of the rate equation.

The second term, -  καnα is an effective term that takes into account the decay of vacuum α into other vacua. Decays of this type proceed by the formation of a bubble of the new vacuum [\cite=CDL]. Typically, the spherical domain wall separating the vacua will be small initially, compared to the size of the event horizon of the parent vacuum. The domain wall will then expand at a fixed acceleration, asymptotically approaching the future light-cone of the nucleation event. A detailed treatment of this dynamics would enormously complicate the rate equation, but fortunately an exquisite approximation is available. Even at late times, because of de Sitter event horizons, only a portion the of parent vacuum is destroyed by the bubble. This portion is the causal future of the nucleation point, and at late times it agrees with the comoving future of a single horizon volume centered on the nucleation point, at the nucleation time. Because the bubble reaches its asymptotic comoving size very quickly (exponentially in light-cone time), only a very small error, of order κα, is introduced if we remove this comoving future, rather than the causal future, from the parent vacuum. That is, for every decay event in vacuum α, the number of horizon patches of type α is reduced by 1 in the rate equation. This is called the square bubble approximation. The expected number of such events is -  καnαdtLC.

The third term, [formula], captures the production of bubbles of vacuum α by the decay of other vacua. The prefactor of this term is fixed by the continuity of light-cone time. This is the requirement that the future light-cone of an event Q-  ε just prior to the nucleation event has the same asymptotic size π(Q-  ε) as the future light-cone of an event Q+  ε just after nucleation, π(Q+  ε), as ε  →  0. In the square bubble approximation, this implies that each nucleation event effectively contributes a comoving volume of new vacuum equivalent to one horizon patch at the time of nucleation. For the reasons described in the previous paragraph, one patch has the correct comoving size to eventually fill the future light-cone of Q+  ε. Thus, for every decay event in which a bubble of vacuum α is produced, the number of horizon patches of type α is increased by 1 in the rate equation. The expected number of such events is [formula].

The rate equation ([\ref=eq-nrate]) has the solution [\cite=GarSch05]

[formula]

where φ  <  γ  <  3. (The case γ  =  3 arises if and only if the landscape contains no terminal vacua, i.e., vacua with nonpositive cosmological constant, and will not be considered in this paper.) Here, [formula] is the largest eigenvalue of the matrix Mαβ defined by rewriting Eq. ([\ref=eq-nrate]) as [formula]; and [formula] is the corresponding eigenvector. The terms of order eφt are subleading and become negligible in the limit as tLC  →    ∞  . To a very good approximation (better than q  ≪  1), the eigenvector is dominated by the longest-lived metastable de Sitter vacuum in the theory, which will be denoted by *  :

[formula]

and

[formula]

is its total dimensionless decay rate.

Next, we compute number of events of type I prior to the time tLC. We assume that the events unfolding in a new bubble of vacuum i depend only on i, but on the time of nucleation. This is true as long as the parent vacuum is long-lived, so that most decays occur in empty de Sitter space. For notational convenience, we will also assume that evolution inside a new bubble is independent of the parent vacuum; however, this could easily be included in the analysis. Then the number of events of type I inside a bubble of type i, dNI / dNi will depend only on the light-cone time since bubble nucleation, [formula]. Therefore, we can write

[formula]

Because the dominant vacuum *   plays a role analogous to an equilibrium configuration, it is convenient to separate it out from the sum, and to define κI * as the dimensionless rate at which events of type I are produced in *   regions. The rate at which vacua of type i are produced is

[formula]

By changing the integration variable to uLC in Eq. ([\ref=eq-nilct1]), and using Eq. ([\ref=eq-nsolution]), one finds that

[formula]

where

[formula]

depends only on I and i. The above integral runs over the interior of one i-bubble, excluding regions where i has decayed into some other vacuum. Naively, the integral should range from 0 to tLC. But the global measure requires us to take the limit tLC  →    ∞   in any case, and it can be done at this step separately without introducing divergences. Since *   does not appear in the sum in Eq. ([\ref=eq-NIsolution]), and all other vacua decay faster than *  , the interior of the i-bubble in Eq. ([\ref=eq-nii]) grows more slowly than eγtLC. Therefore, the integral converges, and we may write

[formula]

where

[formula]

Short Fat Geodesic/New Scale Factor Cutoff Duality

In this section we introduce the Short Fat Geodesic measure. We show that, with particular initial conditions, it is equivalent to the New Scale Factor Cutoff [\cite=Bou12b]. This generalizes to arbitrary eternally inflating spacetimes the duality between the (long) fat geodesic and (old) scale factor time cutoff discovered in Ref. [\cite=BouFre08b], which applied only to everywhere-expanding multiverse regions.

Short Fat Geodesic Measure

A fat geodesic is defined as an infinitesimal neighborhood of a geodesic. At each point on the geodesic, one can define an orthogonal cross-sectional volume dV, which we imagine to be spherical. It is important to note that an orthogonal cross-section can be defined only infinitesimally--there is no covariant way of extending the cross-section to a finite volume. For example, the spacelike geodesics orthogonal to a point on the geodesic in question need not form a well-defined hypersurface.

Consider a family of geodesics orthogonal to an initial hypersurface Σ0. Along each geodesic, we may define the scale factor parameter

[formula]

where

[formula]

is the expansion of the congruence. In Eq. ([\ref=eq-exp]), dV is the volume element at the proper time τ along a geodesic spanned by infinitesimally neighboring geodesics in the congruence; dV0 is the volume element spanned by the same neighbors at τ = 0. In terms of the unit tangent vector field (the four-velocity) of the geodesic congruence, ξ  =  ∂τ, the expansion can be computed as [\cite=Wald]

[formula]

If geodesics are terminated at the first conjugate point, this procedure assigns a unique scale factor parameter to every event in the future of Σ0 [\cite=Bou12b]

A Short Fat Geodesic is a fat geodesic restricted to values of the scale factor parameter larger than that at Σ0, which we may choose to be zero. Thus, it consists of the portions of the fat geodesic along which neighboring geodesics are farther away than they are on Σ0. Typically, the congruence will expand locally for some time. Eventually, all but a set of measure zero of geodesics will enter a collapsing region, such as a structure forming region such as ours, or a crunching Λ < 0 vacuum. In such regions, focal points will be approached or reached, where η  →    -    ∞  . The Short Fat Geodesic is terminated earlier, when η = 0.

If the congruence is everywhere expanding, the Short Fat Geodesic reduces to the (long) fat geodesic defined in Ref. [\cite=BouFre08b], as a special case. This is precisely the case in which the old scale factor time is well-defined and a duality between (long) fat geodesic and old scale factor time cutoff was derived. The duality derived below is more general and applies to arbitrary eternally inflating universes. If the expanding phase is sufficiently long, the terminal point where η = 0 can be less than one Planck time from the caustic [\cite=Bou12b]. This is expected to be generic if the initial conditions are dominated by a long-lived metastable de Sitter vacuum. In this approximation, the short fat geodesic could be defined equivalently as being terminated at the first caustic.

Let us pause to point out some important differences between the causal patch cutoff discussed in the previous section, and the Short Fat Geodesic.

The causal patch depends only on the endpoint of the geodesic. It has (and needs) no preferred time foliation. That is, there is no preferred way to associate to every point along the generating geodesic a particular time slice of the causal patch containing that point. By contrast, a specific infinitesimal neighborhood is associated to every point on the Short Fat Geodesic, so the contents of the cutoff region depend on the entire geodesic. (The same will be true for the X-fat Geodesic considered in the following section.)

As a consequence, the geodesic congruence could be eliminated entirely in the construction of the causal patch ensemble, in favor of a suitable ensemble of points on the future conformal boundary of the spacetime [\cite=BouFre10b]. By contrast, the congruence is an inevitable element in the construction of all other measures considered in this paper.

The causal patch can be considered on its own, whereas the Short Fat Geodesic is naturally part of a larger spacetime. In the construction of an ensemble of causal patches in Sec. [\ref=sec-cpdef], the global viewpoint was optional. This is because the causal patch is self-contained: if the initial state is a long-lived de Sitter vacuum, no further boundary conditions are required in order to construct the decoherent histories of the patch. We chose a global representation (a large initial surface with many horizon patches) only with a view to proving global-local duality. By contrast, the Short Fat Geodesic is greater than the domain of dependence of its initial cross-section. It has timelike boundaries where boundary conditions must be specified. The simplest way to obtain suitable boundary conditions is from a global representation in terms of geodesics orthogonal to some surface Σ0.

We will consider a dense family (a congruence) from the start, because of the infinitesimal size of the fat geodesic. We index each geodesic by the point x0∈Σ0 from which it originates. For the same reason, it will be convenient to work with a (formally continuous) distribution DI(x) of events of type I. The distribution is defined so that the number of events of type I in a spacetime four-volume V4 is

[formula]

where g = | det gab|. (The special case of pointlike events can be recovered by writing DI as a sum of δ-functions.)

The infinitesimal number of events of type I in the Short Fat Geodesic emitted from the point x0∈Σ0 is

[formula]

where τ is the proper time along the geodesic, and the integral is restricted to portions of the geodesic with positive scale factor parameter. dV is a fixed infinitesimal volume, which we may choose to define on Σ0:

[formula]

The total number of events in the ensemble of fat geodesics is obtained by integrating over all geodesics emanating from Σ0:

[formula]

where h0 is the root of the determinant of the three-metric on Σ0. We may take Eq. ([\ref=eq-nfg]) as the definition of the fat geodesic measure, with relative probabilities given by

[formula]

Note that Eq. ([\ref=eq-nfg]) is not a standard integral over a four volume; it is an integral over geodesics. We may rewrite it as an integral over a four-volume because the definition of the Short Fat Geodesic ensures that the geodesics do not intersect. Then the coordinates t,x0 define a coordinate system in the four-volume traced out by the congruence. However, the four-volume element is not [formula]. Because the geodesics in the volume element [formula] expand along with the congruence, the correct four-volume element is

[formula]

This follows from the definition of expansion and scale factor parameter, Eqs. ([\ref=eq-sft]) and ([\ref=eq-exp]).

Returning to the event count, we can now write Eq. ([\ref=eq-nfg]) as an integral over the spacetime region V4(η > 0) traced out by the congruence of Short Fat Geodesics:

[formula]

The weighting factor e- 3η can be understood intuitively as the number of fat geodesics that overlap at each spacetime point; see Fig. [\ref=fig-fg].

In particular, we may choose the scale factor parameter η as a coordinate. However, the coordinate is one-to-one only if we restrict to the expanding or the collapsing portion of each geodesic. Thus, we may write

[formula]

where

[formula]

Here, Σ±η' are hypersurfaces of constant scale factor parameter η' in the expanding (+  ) or contracting (-  ) portion of the congruence.

Proof of Equivalence to the New Scale Factor Cutoff

We now turn to the global side of the duality. Again, we consider the congruence of geodesics orthogonal to an initial surface Σ0. The New Scale Factor Cutoff measure is defined as

[formula]

where NI(η) is the number of events of type I that have taken place in the spacetime regions with scale factor parameter less than η [\cite=Bou12b]. Using Eq. ([\ref=eq-density]), we may write this as

[formula]

The integral runs over the spacetime four-volume M(η), defined as the set of points that lie in the future Σ0 (on which we set η = 0) and whose scale factor time, Eq. ([\ref=eq-sft]), is less than η. In order to make the assignment of a scale factor parameter to every spacetime point unique, each geodesic is terminated immediately prior to caustic points, when neighboring geodesics intersect.

To compute the probabilities defined by the scale factor time cutoff, we note that the cosmological dynamics of eternal inflation leads to an attractor regime [\cite=Bou12b]:

[formula]

where φ  <  γ < 3. This will be reviewed in the next subsection; for now, we will simply use this result. With Eq. ([\ref=eq-sfprob]), it implies that the scale factor time probabilities are given by

[formula]

The Short Fat Geodesic measure can also be evaluated using Eq. ([\ref=eq-sfattract]), if initial conditions on Σ0 are chosen to lie in the attractor regime. A suitable Σ0 can be constructed as as a late-time hypersurface orthogonal to the congruence constructed from a much earlier, arbitrary initial hypersurface, and resetting η  →  0 there. The proof will exploit the fact that the Short Fat Geodesic probabilities, Eqs. ([\ref=eq-fgd]) and ([\ref=eq-nifgpm]), involve an integral over a spacetime set closely related to M(η), reweighted relative to Eq. ([\ref=eq-neta]) by a factor that depends only on η and thus does not change relative probabilities in the attractor regime.

The set M(η) will contain one connected expanding region, M+(η), bounded from below by Σ0, in which scale factor time is growing towards the future. In any model with collapsing regions (structure forming regions or crunches), M(η) will also contain infinitely many mutually disconnected collapsing regions inside bubbles near the future conformal boundary of the spacetime. (The total contribution to the measure from such regions to the New Scale Factor Cutoff measure is finite at any finite value of η [\cite=Bou12b].) We denote the union of all collapsing regions by M-(η).

Let us split the integral in Eq. ([\ref=eq-neta]) into expanding and contracting portions:

[formula]

where

[formula]

Since this division depends only on local properties, each portion has its own attractor solution:

[formula]

with N̄+I  +  N̄-I  =  N̄I. This will be shown explicitly in the following subsection. In each portion, the scale factor parameter is monotonic along the geodesics in the congruence, and we may use it as an integration variable:

[formula]

where the hypersurface Σ±η' consists of the points with fixed η' in the expanding (+  ) or contracting (-  ) region. Therefore

[formula]

so we may rewrite Eq. ([\ref=eq-nifgpm]) as

[formula]

We can now use the attractor solutions for the New Scale Factor Cutoff, Eq. ([\ref=eq-sfattract-pm-dual]), to evaluate the Short Fat Geodesic cutoff:

[formula]

The prefactor is I-independent, so relative probabilities in the Short Fat Geodesic measure are given by

[formula]

This agrees with the New Scale Factor Cutoff probabilities, Eq. ([\ref=eq-sfprob2]). Therefore, the two measures are equivalent.

This result is somewhat counterintuitive. If the Short Fat Geodesic is defined for regions where η > 0, its global dual should be the New Scale Factor Cutoff not as defined above, but restricted to η > 0 both in the expanding and collapsing regions. In fact, it is. Both versions of the New Scale Factor Cutoff, with and without this additional restriction in the collapsing regions, are dual to the Short Fat Geodesic, because both have the same attractor regime. It is important to distintuish between η < 0 regions and decreasing-η regions in the global cutoff. The former quickly become unimportant in the attractor regime; the latter are always important. For the cumulative quantity NI(η) to be exactly in the attractor regime, it would be necessary to restrict to η > 0 on both the expanding and collapsing side, and thus to exclude a few collapsing regions; otherwise, there may be a small transient of order eφη from those initial collapsing regions that have η < 0. However, the duality relies on evaluating the local measure by integrating up the global "derivative" dNI / dη with weighting e- 3η. Since the calculation makes reference only to the derivative in the region η > 0, the regions with η < 0 do not enter into the duality.

New Scale Factor Cutoff Rate Equation and Attractor Solution

In this subsection we derive the attractor solution, Eq. ([\ref=eq-sfattract]), starting from the rate equation for the New Scale Factor Cutoff. We will follow [\cite=Bou12b] and use the seminal results of [\cite=GarSch05]. As for the case of light-cone time, we will proceed in two steps. We first consider the rate equation for de Sitter vacua; then we include the detailed consequences of decays within this distribution, and explain how to treat collapsing regions.

Naively, the rate equation should follow from the result for light-cone time, Eq. ([\ref=eq-lcattract]), by an appropriate substitution. In empty de Sitter space, θ / 3 = τ- 1Λ,α, so Eqs. ([\ref=eq-sft]) and ([\ref=eq-dtlcdt]) imply that dtLC = dη in this regime. Setting dtc  →  dη in Eq. ([\ref=eq-lcattract]), however, yields an incorrect equation:

[formula]

The last term on the right hand side is incorrect. In the light-cone time rate equation, this term arose from the square bubble approximation. It is an effective term that anticipates the asymptotic size of bubbles of new vacua instead of treating their growth in detail. It subsumes, in particular, the cumulative effects of the early era within a new bubble (less than τΛ,α after nucleation). During this era the relation dtLC  =  dη does not hold, so the substitution that led to Eq. ([\ref=eq-nratewrong]) is unjustified. Another way of saying this is that the square bubble approximation is a different procedure for different time variables.

The correct rate equation for the New Scale Factor Cutoff contains an extra factor of vα / vβ in the final sum, where vα is the proper volume of a horizon patch of type α. It thus takes a particularly simple form,

[formula]

when expressed in terms of the proper volumes Vα occupied by metastable de Sitter vacua α at scale factor time η, instead of the number of horizon patches nα = Vα / vα. More generally, one finds that the rate equation takes the above form, with V  →  X, η  →  T, if T measures the growth of the overall volume of space in units of X. For example, scale factor parameter measures the growth of proper volume (T = η, X = 1) and light-cone time measures the growth of volume in units of horizon volume (T = tLC, X = vα).

To derive Eq. ([\ref=eq-vrate]), we note that the first two terms on the right hand side follow from the arguments given for the analogous terms in Sec. [\ref=sec-sfattract]. They would also follow from Eq. ([\ref=eq-nrate]) by substituting dtLC  →  dη and using Vα = nαvα; but the third term, as explained above, cannot be so obtained. It must be derived from a first principle argument identical to that given in Sec. [\ref=sec-sfattract]; except that it is now the continuity of New Scale Factor parameter, not light-cone time, that must be ensured when a new bubble is formed. This means that instead of requiring that the number of horizon patches of β-vacuum lost must equal the number of horizon patches of α-vacuum gained in β  →  α transitions, we now require that the proper volume of β-vacuum lost must equal the proper volume of β-vacuum gained. The amount lost in β, per nucleation of α, is always one horizon volume of β; this follows from causality. In the rate equation in terms of scale factor parameter, this must be converted into proper volume, and the same proper volume must be assigned to the new vacuum, α. This leads to the final term in Eq. ([\ref=eq-vrate]). It also explains why the New Scale Factor rate equation looks simplest in terms of proper volume.

The solution of the rate equation for New Scale Factor time can be obtained from Eq. ([\ref=eq-nsolution]) by substituting tLC  →  η and n  →  V:

[formula]

That is, we must set α (and not, as for light-cone time, [formula]), equal to the dominant eigenvector of the transition matrix Mαβ. As before γ = 3 - q is the largest eigenvalue. Note that this eigenvector and the dominant vacuum *   are exactly the same as in the case of light-cone time. On a slice of constant light-cone time, the *   vacuum dominates the number of horizon patches; on a slice of constant New Scale Factor Cutoff, it dominates the volume.

It is convenient to define

[formula]

The number of horizon patches of type α at New Scale Factor parameter η obeys

[formula]

We now derive NI(η). The procedure will be slightly different from the one in Ref. [\cite=Bou12b] in that we will keep expanding and collapsing regions explicitly separated in all expressions. NI(η) receives a contribution from the expanding (+) regions, and one from the contracting (-) regions, NI(η) = N+I(η) + N-I(η). Analogous to Eq. ([\ref=eq-nilct1]) for the Lightcone Time Cutoff, one finds for the New Scale Factor Cutoff:

[formula]

and

[formula]

As in the previous section, we can now change the integration variable to ζ  =  η  -  ηnuc in Eqs. ([\ref=eq-nisft1-+new]) and ([\ref=eq-nisft1--new]), and use ([\ref=eq-nibarni]) to get

[formula]

where

[formula]

and

[formula]

with

[formula]

and

[formula]

Again, ([\ref=eq-nii2+new]) and ([\ref=eq-nii2-new]) converge because all vacua decay faster than the dominant vacuum. This yields Eq. ([\ref=eq-sfattract]), with N̄I  =  N̄+I  +  N̄-I.

General Global-Local Dualities

It is easy to generalize the duality studied in the previous section, between the Short Fat Geodesic cutoff and the New Scale Factor Cutoff. On the local side, the fatness of the geodesic can be allowed to vary along the geodesic. On the global side, this corresponds to a different choice of time variable. In this section, we mostly consider a generalization that preserves the key feature that the fatness of the geodesic does not depend explicitly on the time along the geodesic, but only on local features. This restriction defines a family of measures that include the scale factor cutoff, the light-cone time cutoff, and the CAH cutoff as special cases. In the final subsection, we consider a further generalization that we exemplify by deriving a local dual to the proper time cutoff.

X-fat Geodesic Measure

Consider a family of geodesics orthogonal to an initial hypersurface Σ0. We assign each of these geodesics a cross sectional volume, X. Intuitively, we may picture X as modulating the infinitesimal fatness of the geodesic. Equivalently, X can be thought of as a weighting factor that allows events of type I to contribute differently to the probability for I, depending on where they are encountered. We require that X be everywhere nonnegative to ensure that probabilities are nonnegative. We will assume, for now, that X depends only on local properties of the congruence, such as the expansion, the shear, and their derivatives:

[formula]

A simple example, which we will consider explicitly in Sec. [\ref=sec-hubbletube], is the Hubbletube. It is obtained by setting X to the local Hubble volume. With [formula], the X-fat geodesic reduces to the ordinary fat geodesic. In Sec. [\ref=sec-propertime], we will consider further generalizations, in which X is not restricted to a local function of congruence parameters.

Along each geodesic, we may define the T parameter:

[formula]

Geometrically, e3T is the factor by which a volume element has expanded along the congruence, in units of the volume X. Every X-Fat Geodesic will be restricted to values of the T parameter larger than that at Σ0, which we may choose to be zero.

We would like to compute probabilities using our new local cut-off, the X-fat geodesic, by modifying the definition of the fat geodesic, Eq. ([\ref=eq-nfg]):

[formula]

Relative probabilities given by

[formula]

We now follow the steps leading to Eq. ([\ref=eq-fgd0]) in Sec. [\ref=sec-fgdef]. Assuming that the geodesics do not intersect, Eq. ([\ref=eq-nxg]) can be rewritten as an standard integral over the four-volume encountered by the congruence:

[formula]

In particular, we can pick T as a coordinate. Like the scale factor time, T in Eq. ([\ref=eq-tx]) is defined for every point on the nonintersecting congruence. Multiple points along the same geodesic may have the same T; this will not be a problem. However, the coordinate is one-to-one only if we restrict to the "expanding" or the "contracting" portion of each geodesic. Thus, in terms of T, Eq. ([\ref=eq-xgd0]) becomes

[formula]

where

[formula]

Here, Σ±T' are hypersurfaces of constant T parameter T' in the expanding (+  ) or contracting (-  ) portion of the congruence.

Proof of Equivalence to the T-cutoff Measure

Let us consider the time variable T defined in Eq. ([\ref=eq-tx]) as a global cutoff. Probabilities are defined by

[formula]

where NI(T) is the number of events of type I that take place in spacetime regions with time less than T. Because T need not be monotonic along every geodesic, such regions may not be connected. As shown in Sec. [\ref=sec-sfattract], this does not affect the proof of equivalence, which proceeds as in Sec. [\ref=sec-fg]. Again, NI(T) receives a contribution from expanding (+) and contracting (-) regions, NI(T) = N+I(T) + N-I(T).

In terms of the distribution D,

[formula]

and therefore

[formula]

We make use of the attractor solution

[formula]

where φ  <  γ < 3 (see the following subsection). With Eq. ([\ref=eq-Tprob]), it implies that the T-cutoff probabilities are given by

[formula]

The X-fat geodesic probabilities are also determined by Eq. ([\ref=eq-Tattract]), if initial conditions on Σ0 are chosen to lie in the attractor regime. Plugging Eq.  ([\ref=eq-dndT]) into Eq.  ([\ref=eq-xgd]), and then using Eq. ([\ref=eq-xgd-sum]), we get

[formula]

In the attractor regime, by Eq. ([\ref=eq-Tattract]), one has

[formula]

Substituting into Eq. ([\ref=eq-xgd2]) and using γ < 3, the integral converges to an I-independent constant. Thus, relative probabilities in the X-fat geodesic measure are given by

[formula]

This agrees with the T-cutoff probabilities, Eq. ([\ref=eq-Tprob2]). Therefore, the two measures are equivalent.

T-cutoff Rate Equation and Attractor Solution

In this subsection, we derive the rate equation for the number of horizon patches of de Sitter vacua α as a function of T, and the attractor solution, Eq. ([\ref=eq-Tattract]). For the rate equation, we treat all de Sitter vacua as empty at all times. We use the square bubble approximation which treats each bubble as comoving in the congruence at its asymptotic size.

Let xα be the asymptotic value of X in the vacuum α. X will converge rapidly to xα in empty de Sitter regions because, by assumption, X depends only on local properties of the congruence. By Eq. ([\ref=eq-tx]) this implies that dT = dη in such regions. Thus, the rate equation is

[formula]

The term 3nα captures the exponential growth of the number of horizon patches, which goes as e3η. The term -  καnα captures the decay of vacuum α, per unit horizon patch and unit scale factor time in empty de Sitter space.

The last term captures the creation of new regions of vacuum α by the decay of other vacua. In the square bubble approximation, one horizon patch of β is lost when an α-bubble forms in β (see Sec. [\ref=sec-lcattract]). Thus, vβ / xβ X-patches of β-vacuum are lost, where vβ is the volume of one horizon patch of β. Continuity of the time variable T requires that the number of patches of size X be continuous, so vβ / xβ X-patches of α vacuum must be added. One X-patch of α vacuum equals xα / vα horizon patches of α vacuum. Thus, the total number of horizon patches of α-vacuum that are created per β-decay in the square bubble approximation is [formula]. The number of such decays in the time interval dT is καβnβdT. This completes our derivation of the last term.

When expressed in terms of the number of X-patches,

[formula]

the rate equation takes a very simple form:

[formula]

This form is identical to that of Eqs. ([\ref=eq-nrate]) and ([\ref=eq-vrate]), and the general results of Ref. [\cite=GarSch05] apply. The late-time solution is again determined by the dominant eigenvalue, γ = 3 - q, of the transition matrix Mαβ, and by the associated eigenvector, which we now label ñXα:

[formula]

Next, we compute number of events of type I prior to the time T. With

[formula]

the number of horizon patches of type α at time T obeys

[formula]

The remainder of the analysis is completely analogous to Sec. [\ref=sec-sfattract]. When we include collapsing (i.e. decreasing T) regions at the future of Σ0, we still obtain an attractor regime. Like in the New Scale Factor case [\cite=Bou12b], the corresponding [formula] and [formula] will only depend on local physics in each bubble universe but not on [formula]. This holds because we are assuming that X only depends on local properties of the congruence. Therefore, ΔT- and ΔT+ will increase by the same finite amounts during expansion and collapse phases in a particular pocket universe, no matter when the bubble universe is nucleated. There will be infinitely many collapsing regions at the future of Σ0, but a finite number of bubbles contribute, namely the ones that formed before the time [formula], where [formula]

[formula]

Again, we conclude

[formula]

where

[formula]

and

[formula]

As in [\cite=Bou12b], this integral converges because all vacua decay faster than the dominant vacuum, and one obtains the same attractor behavior.

The Hubbletube and the CAH measure

An example of particular interest is the Hubbletube: the X-fat geodesic whose fatness is proportional to the local Hubble volume vH, as measured by the expansion of the congruence:

[formula]

Since constant numerical factors drop out of all relative probabilities, we simply set

[formula]

This measure is dual to a global cutoff at constant T, where

[formula]

Equivalently, the global cutoff surfaces can be specified in terms of any monotonic function of T, e.g. exp (T). Note that

[formula]

where [formula] is the scale factor and τ is proper time along the congruence. We thus recognize the global dual of the Hubbletube as Vilenkin's CAH-cutoff [\cite=Vil11].

Naively, the CAH-cutoff is well-defined only in regions with accelerating expansion: [formula], where the time variable T increases monotonically along the geodesics. In this regime, the duality with the Hubbletube is obvious. But this regime is also extremely restrictive: it excludes not only gravitationally bound regions such as our galaxy, but also all regions in which the expansion is locally decelerating, including the homogeneous radiation and matter-dominated eras after the end of inflation in our vacuum.

However, if geodesics are terminated before caustics, the CAH cutoff can instead be defined as a restriction to a set of spacetime points with T less than the cutoff value. This is similar to the transition from the old to the new scale factor measure: in the spirit of Ref. [\cite=Bou12b], one abandons the notion of T as a time variable. In the case of the CAH parameter T, an infinite number of decelerating regions will be included under the cutoff for any finite T.

This possibility of increasing the regime of applicability of the CAH cutoff is particularly obvious from the local viewpoint. The local measure requires only θ > 0 for positive fatness; this is strictly weaker than [formula]. It still excludes collapsing regions, but not regions undergoing decelerating expansion.

On either side of the duality, geodesics must be terminated at some arbitrarily small but finite proper time before they reach turnaround (θ = 0), where T  →    -    ∞  . Otherwise, events at the turnaround time receive infinite weight. This is needed only for finiteness; it eliminates an arbitrarily small region near the turnaround from consideration but does not affect other relative probabilities. However, this marks an important difference to the Short Fat Geodesic and the New Scale Factor measure, where no additional cutoff near η  →    -    ∞   was needed.

In any case, the restriction to regions with θ > 0 is necessary to make the Hubbletube well-defined. Unfortunately, this restriction is too strong to yield a useful measure since it excludes gravitationally bound regions like our own. Unlike in the case of the New Scale Factor Cutoff or the Causal Patch, there are thus large classes of regions to which the CAH cutoff cannot be applied. Additional rules must be specified, such as the CAH+ measure of Ref. [\cite=Vil11].

The Incredible Shrinking Geodesic and the Proper Time Cutoff

The global proper time cutoff is defined as a set of points that lie on a geodesic from Σ0 with proper length (time duration) less than τ along the geodesic [\cite=Lin86a] [\cite=LinLin94] [\cite=GarLin94] [\cite=GarLin94a] [\cite=GarLin95]. (To make this well-defined, we terminate geodesics at the first caustic as usual, so that every point lies on only one geodesic.) Relative probabilities are then defined as usual, in the limit as the cutoff is taken to infinity.

The rate equation for the number of de Sitter horizon patches, in terms of proper time, is

[formula]

where the transition matrix is given by

[formula]

This differs from the transition matrix in all previous examples by the appearence of the Hubble constants of the de Sitter vacua, and so it will not have the same eigenvector and eigenvalues; it will have a completely different attractor regime. Instead of Planck units, it will be convenient to work in units of the largest Hubble constant in the landscape, Hα  →  Hα / H max and τ  →  H maxτ. We note that H- 1 max is necessarily a microscopic timescale in any model where our vacuum contains a parent vacuum whose decay is sufficient for a reheat temperature consistent with nucleosynthesis. In the string landscape, one expects H max to be of order the Planck scale.

Due to the smallness of decay rates and the large differences in the Hubble rate between Planck-scale vacua (H  ~  1) and anthropic vacua (H  ≪  1), we expect that again the largest eigenvalue is very close to the largest diagonal entry in the transition matrix, and that the associated eigenvector is dominated by the corresponding vacuum. In all previous examples, the dominant vacuum, *  , was the longest-lived de Sitter vacuum. The associated eigenvalue was [formula], where κ* is the decay rate of the *   vacuum. Now, however, the Hubble constant of each de Sitter vacuum, Hα, is the more important factor. The dominant vacuum, *  , will be the fastest-expanding vacuum, i.e., the vacuum with the largest Hubble constant, which in our unit conventions is H max = 1. In the same units, the associated eigenvalue is again γ = 3 - κ*.

By decay chains, the dominant expansion rate γ drives both the growth rate of all other vacuum bubbles and all types of events, I, at late times:

[formula]

where φ  <  γ < 3. Relative probabilities are given as usual by

[formula]

The proper time measure famously suffers from the youngness problem [\cite=LinLin96] [\cite=Gut00a] [\cite=Gut00b] [\cite=Gut04] [\cite=Teg05] [\cite=Lin07] [\cite=Gut07], or "Boltzmann babies" [\cite=BouFre07]. Typical observers are predicted to be thermal fluctuations in the early universe, and our own observations have probability of order exp ( - 1060). This holds in any underlying landscape model as long as it contains our vacuum. Thus the proper time measure is ruled out by observation at very high confidence level.

Explaining the origin of the youngness problem is somewhat convoluted in the global picture. Consider an event that occurs at 13.7 Gyr after the formation of the bubble universe it is contained in and that is included under the cutoff. For every such event, there will be a double-exponentially large number exp (3H maxΔτ) of events in the same kind of bubble universe that occur at 13.7 Gyr    -  Δτ after the formation of the bubble. This is because new bubbles of this type are produced at an exponential growth rate with characteristic time scale H max. We will now show that the proper time cutoff has a local dual, the Incredible Shrinking Geodesic, in which the youngness problem is immediately apparent.

We now seek a local dual, i.e., a geodesic with fatness (or local weight) X(τ), which will reproduce the same relative probabilities if initial conditions are chosen in the dominant (i.e., fastest-expanding) vacuum. To find the correct fatness, we invert Eq. ([\ref=eq-tx]):

[formula]

Note that this result does not satisfy the constraint we imposed in all previous subsections, that the geodesic has constant fatness in asymptotic de Sitter regions.

Obtaining a local dual in this manner is somewhat brute-force. Recall that the duality relies on fact that the overcounting of events by overlapping fat geodesics depends only on the global time. Here this is accomplished in two steps. The factor e3η undoes the dilution of geodesics: it fattens the geodesics by their inverse density, thus making the overcounting factor everywhere equal to one. The factor e- 3τ is a regulator that depends only on the global time and renders the integral in Eq. ([\ref=eq-nxg]) finite.

However, the result for X(τ) immediately makes the youngness problem apparent: note that X is constant as long as the geodesic remains in the fastest expanding de Sitter vacuum, where θ = 3H max = 3 (see Fig. [\ref=fig-shrink]). However, in all other regions, H < 1, so θ - 3 < 0 and the weight of events is suppressed exponentially as a function of the time after the decay of the dominant vacuum. In particular, in anthropically allowed regions, such as ours, the Hubble rate is very small compared to the microscopic rate H max = 1. Thus, events are approximately suppressed as e- 3τ, that is, exponentially with a microscopic characteristic timescale. For example, with H max of order the Planck scale, we thus find that events today are less likely than events yesterday by a factor of exp ( - 1048), and less likely than a billion years ago by a factor of exp ( - 1060). As a consequence, this measure assigns higher probability to (conventionally unlikely) observers arising from large quantum fluctuations in the early universe (and their bizarre observations) than to our observations [\cite=LinLin96] [\cite=Gut00a] [\cite=Gut00b] [\cite=Gut04] [\cite=Teg05] [\cite=Lin07] [\cite=Gut07] [\cite=BouFre07].