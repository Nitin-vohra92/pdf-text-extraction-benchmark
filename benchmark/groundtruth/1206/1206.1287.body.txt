Weak randomness completely trounces the security of QKD

Introduction -- The emergence of quantum theory in the early twentieth century led to a revolution in many areas of physics. One of its main features was the introduction of intrinsic randomness, originating from the very nature of the theory. This probabilistic nature led to questioning of concepts of (macro)realism and locality [\cite=EinsteinPodolskyRosen-CanQuantum-MechanicalDescription-1935] which was considered as an unwanted consequence of quantum theory. True randomness, much unwanted from the point of view of classical physics, serves as a valuable resource in many cryptographic protocols. It is for this reason that quantum random number generators (QRNG) were one of the first commercially available devices utilizing basic principles of quantum physics in its elementary nature.

Towards the latter part of the twentieth century it was recognized that quantum mechanics could lead another revolution and dramatically extend the premise of information processing. Classical notions of security underpinned by computational conditions were seriously threatened by the edicts of quantum mechanics and by the emergence of Shor's algorithm [\cite=Shor-Polynomial-TimeAlgorithmsPrime-1997]. However, quantum mechanics offered a new security paradigm whereby the use of quantum states imparted unconditional secure communication through quantum key distribution (QKD) [\cite=BB84]. Quantum key distribution protocols enable two communicating parties to produce a shared random secret key in such a way that also reveals the presence of any third party. The secret key can be used later to implement an unconditionally secure encryption protocol [\cite=Vernam-CipherPrintingTelegraph-1926].

The security of QKD has been established not only for an ideal noiseless experimental setting, but it has also been proven robust within more realistic settings to the extent that QKD systems are now commercially available [\cite=QNRG]. Interestingly, the robustness of QKD protocols has only been proven with respect to possible attacks on quantum data exchanged by the communicating parties with the assumption that a third party possesses knowledge of all exchanged classical data.

Sources of classical random bits, repeatedly used during different phases of quantum protocols, were silently considered being perfect. An unstated assumption in the standard proofs of security [\cite=Lo1999] [\cite=Mayers2001] [\cite=Shor2000] is that the source of random bits used in the protocol is unbiased and completely unaccessible to the adversary. Unfortunately, however, perfect or unbiased randomness is very difficult to obtain in practice. All classical sources of random bits provide in fact only pseudorandom bit strings, which might be fully accessible to the adversary together with knowledge of its preparation procedure and input bits. Specialized QRNG devices only produce biased randomness and require classical post processing [\cite=Solcgravea-TestingofQuantum-2010], something one has to consider as accessible to the adversary. Real world random number generators inevitably leak information via side channels and, thus, may be vulnerable to outside conditions (e. g., temperature, input power, EM radiation etc.) which are potentially controlled by the adversary.

Although the problem of weak (biased) randomness has been broadly studied and is relatively well understood in classical information processing [\cite=DodisPrabhakaran-(im)possibilityofcryptography-2004] [\cite=MaurerWolf-PrivacyAmplificationSecure-1997] [\cite=McInnes] [\cite=RennerWolf-UnconditionalAuthenticityand-2003], there has not been a similar analysis of its quantum counterpart. This may be due to the fact that there theoretically exists a perfect source of randomness in quantum world and any weaknesses are only attributed to imperfect implementation. Recent investigations however show that quantum information processing can help to increase security of communication using weak randomness even for regions of parameters where purely classical processing would inevitably reveal all information to the adversary [\cite=enc2qbit] [\cite=BoudaPivoluskaPlesch-EncryptiontoMultiple-2012].

In this Letter we will examine the security setting of QKD in which the adversary, aside from having a full control of the quantum and classical channel, has also some limited control over the sources of randomness the communicating parties employ during the protocol (Fig. 1). We will show that with an increasing key length, only a negligible control of the randomness is necessary to render the QKD insecure. In particular, we will demonstrate that the secret key individually held by communicating parties will differ significantly. Moreover, knowledge pertaining to the secret key held by the adversary will be comparable to the knowledge held by the receiving party.

Weak sources -- Random processes are usually described by their probability distributions. However, it is insufficient to model a weak random source by a single probability distribution because the bias of the source is typically unknown. The only information usually known about the source is that it is random to a certain extent; thus, we allow the output of the weak random source to be distributed according to any probability distribution containing sufficient randomness. We will quantify the amount of randomness of a distribution by the [formula] of its source. The min-entropy of the random variable [formula] is defined by

[formula]

A non-uniform source of randomness is an (N,b)-source if it emits N-bit strings drawn according to a probability distribution with a min-entropy of at least b bits. Thus, every specific N-bit sequence is drawn with probability smaller or equal to 2- b. For b = N, one obtains a perfect source where all sequences are drawn with the same probability. The bias of the source can be easily quantified by the min-entropy loss denoted c = N - b. A distribution is (N,b)-flat if it is an (N,b)-source and it is uniform on a subset of 2b sample points, i. e., each string is outputted with a probability of either zero or 2- b.

The quantity [formula] is called the min-entropy rate for perfect random sources that deliver one bit of entropy per bit produced. We will be particularly interested in the min-entropy loss rate which will be denoted by quantity [formula]. This quantity is (almost) zero for (almost) perfect random sources and approaches unity as the quality of the source decreases.

The QKD protocol -- Here we demonstrate the attack using a variation of the well-known BB84 protocol [\cite=BB84] as a representative for the prepare-measure family of protocols.

Distribution phase:

Sifting phase:

Parameter estimation:

Random sampling provides a way to estimate the number of errors between XA and XB. According to the output from a random variable T, Alice chooses a set of bit positions of XA and assigns these as the test positions. Alice and Bob reveal the bit value in each test position. The number of errors t provides a reasonable estimate r on the actual number of errors in the remaining bits of XRA and XRB [\cite=Mayers2001]. If the number of errors in the test positions is excessive then there is a high probability that the adversary is present and the protocol is aborted.

In any practical application one wants the test set to be relatively small in order to achieve a maximal possible key length. In existing QKD protocols, the size of the test set is typically in order of [formula] or log (n) [\cite=christandl-2004] [\cite=HorodeckiHorodeckiHorodeckiEtAl-QuantumKeyDistribution-2008] [\cite=LoChauArdehali-EfficientQuantumKey-2005]. In the following asymptotic analysis, we assume the most general case and post only a condition that the size of the test set is sublinear in n. In particular, we assume it is equal to Θ(n1 - α) with 0 < α < 1.

Information reconciliation and privacy amplification: Following parameter estimation, the bit strings XRA and XRB contain with a high probability up to r errors. The goal of the information reconciliation is to remove these errors even at the cost of revealing some information about XRA and XRB. This task is usually realized by one-way communication [\cite=LoChauArdehali-EfficientQuantumKey-2005] [\cite=Mayers2001] [\cite=Shor2000]. Such one way information reconciliation can be implemented as long as Bob has more information than the adversary about Alice's string XRA [\cite=CsiszarKorner-Broadcastchannelswith-1978].

The goal of the privacy amplification is to remove any knowledge possessed by Eve about the shared string XRA. A widely used method [\cite=BennettBrassardCrepeauEtAl-Generalizedprivacyamplification-1995] [\cite=Renner2005] is based on the random choice of a hashing function. In this case, Alice randomly chooses a hashing function f and sends it to Bob. The final shared key is f(XRA)  =  f(XRB). Importantly, this method also uses one-way communication.

The Adversary's attack -- is biased. Similar to the case of faulty quantum channels we will consider the worst case scenario and attribute all randomness imperfections to the adversary. This can be modelled by a scenario whereby the adversary can influence the distribution of the random variable T to such an extent that the adversary is allowed to set any (n,n - c)-distribution to the random variable T with c denoting the strength of the adversary's attack. We assume that c is large enough to guarantee the adversary that at least half of the qubits will not be tested. Later we calculate the required value of c.

Without the loss of generality, let us suppose that the first half of Bob's measurement outcomes will not be tested. The adversary can measure the first half of the 2n-qubits in the {|0〉,|1〉} basis. If Eve's measurement outcome is |0〉, she sends a state |1〉 to Bob and if her measurement outcome is |1〉, she sends a state |0〉. Following this procedure and the sifting phase, the adversary has on average [formula] measurement outcomes. The adversary adds another [formula] bits chosen randomly and uniformly to obtain her estimate XE of Alice's string XA. Since Alice and Bob have not tested those bits measured by the adversary, the protocol will continue on to remaining phases.

We now quantify the amount of information that Bob and the adversary possess about Alice's n-bit string XA. To obtain the result, we calculate the Hamming distance H(A,B) between strings A and B. There are three cases to consider. Firstly, the adversary may have measured a transmitted qubit in the correct basis. In such a case, the adversary obtains a bit value that coincides with the corresponding bit value in XA with Bob then obtaining the bit complement. This happens on average in n  /  4 measurement cases. Secondly, it may happen that the adversary measures a transmitted qubit in incorrect basis. Here both Bob and the adversary obtain the correct value with probability 1  /  2. This happens on average in n  /  4 bits. The final situation to consider is the case in which the adversary does not perform a particular qubit measurement. The adversary then chooses random values for these bit positions and correctly guesses the value with probability 1  /  2. In this situation, Bob's measurement value is due to measuring in the correct basis and, thus, he determines the value of Alice's bit with certainty. This last situation occurs in n  /  2 of the bits.

The amount of information that Bob and the adversary possess about Alice's string XA is given by H(XB,XA) and H(XE,XA) respectively. Both of these quantities are on average equal to 5n  /  8. Consequently, the adversary and Bob possess on average the same level of knowledge about Alice's string. As the subsequent steps of the protocol demand that only Alice communicates information, it follows that with the conclusion of the protocol, the adversary and Bob continue to share the same level of information about Alice's bit sting. This illustrates that ultimately there can be no privacy between Alice and Bob.

The strength of the Adversary -- Alice needs [formula] bits to specify n1 - α positions out of n. On the other hand, the adversary wants Alice to choose the n1 - α test bits only from [formula] of the positions. Apparently, the best option for the adversary - in terms of the smallest entropy loss - is to set any [formula]-flat distribution to Alice's random number generator. Such a distribution would uniformly select test bits only within the pre-selected half of all positions.

Of particular importance here will be an analysis of the relative behavior of two quantities; the first quantity is the length of the test bit string

[formula]

and the second quantity is the min-entropy loss

[formula]

Both of these quantities diverge since Alice demands an increased level of randomness to choose the test bits from an ever increasing set size. Now, the min-entropy loss rate c / N expresses the amount of total randomness required to restrict all possible test bit positions within a prescribed subset of the total bit set. We will show that the rate c / N, which is given as

[formula]

remains finite.

We will consider this expression in the limit of large n as all current security proofs for various QKD protocols have only been proven in the asymptotic regime of infinite key length. In evaluating the min-entropy loss rate c / N in the limit of large n, we will make use of the Stirling approximation of the factorial function [formula]. Furthermore, we can approximate the quantity c as [formula] while the quantity N can the approximated to [formula]. The min-entropy loss rate c / N in the limit of large n can be evaluated to

[formula]

Under the assumption of perfect randomness, all QKD protocols have been proven to be perfectly secure in the limit of an infinitely large key size. However, implementing perfect randomness is difficult. By relaxing the assumption of perfect randomness to reflect real life conditions, Eq. ([\ref=c/N]) illustrates that QKD no longer remains robust. In particular, a negligible control on the source of randomness renders QKD insecure.

Entanglement based protocols -- In these protocols [\cite=Lo1999] [\cite=Ekert1991], parties share entangled pairs of photons and employ monogamy of entanglement to build up security. A portion of these states are used to check the monogamy - and, thus, exclude the presence of an adversary - while the remaining states are used to perform the protocol itself. The test pairs are selected by a random source exactly in the same way as in the prepare-measure based protocols. Having access to the random source of the selecting party, Eve might easily perform an attack where she could entangle herself to pairs not being tested in the future and, thereby, obtain information about the secret key.

Conclusion -- In this Letter we demonstrated that if one allows an adversary a limited access to the random sources used by the communicating parties then the security of QKD protocols is be completely compromised. This is the case for almost all known QKD protocols that use part of the data set to test for an adversary. In such instances, the adversary is able to restrict the test sample efficiently. The obvious defence against such an attack is to increase the number of test states to a significant linear portion of the raw key. This would, however, profoundly decrease the length of the secret key.

Acknowledgements -- We acknowledge the support of the Czech Science Foundation GAR projects P202/12/1142 and P202/12/G061, as well as projects CE SAS QUTE and VEGA 2/0072/12. MPl acknowledges the support of SoMoPro project funded under FP7 (People) Grant Agreement no 229603 and by South Moravian Region. CW acknowledges support from the Marie Curie Actions programme.