Performance of FORTRAN and C GPU Extensions for a Benchmark Suite of Fourier Pseudospectral Algorithms

Introduction

Graphics processing units (GPUs) can have better performance for mathematical operations on large arrays when compared to traditional central processing units (CPUs). The fast Fourier transform (FFT) is one application for which GPUs have a significant performance advantage over CPUs. The performance advantage can be significant for simulations which fit within the memory constraints of a single GPU.

GPU acceleration has largely been accomplished in variants of C with variants of FORTRAN being a recent addition. A comparison of performance of the lesser known OpenACC and CUDA FORTRAN on GPUs is of interest because a large number of legacy codes use FORTRAN, [\cite=HenEtAl11] [\cite=ZafGhoSebZho11] and because [\cite=LevWag11] indicates that on CPUs, FORTRAN compilers typically generate more efficient scientific computing codes than C compilers. Previous works which have examined speedup offered by single GPUs in solving differential equations using Fourier transforms are [\cite=BauKei11], [\cite=Che12] and [\cite=ZhaWanYao09].

In this paper, extensions of FORTRAN for GPUs when solving nonlinear PDEs with pseudospectral methods are compared.The user friendliness of these different GPU programming models is described. A benchmark suite of algorithms for three different nonlinear PDEs with Fourier pseudospectral methods is also provided.

Programming Models

At present it is unclear what programming model will be widely adopted for accelerators. Some current options include OpenCL, OpenACC, OpenHMPP, F2C-ACC, CUDA, and CUDA FORTRAN. This note will compare CUDA C, CUDA FORTRAN, and OpenACC GPU programs to serial and OpenMP[\cite=OMPSpec12] FORTRAN CPU programs.

FORTRAN and OpenACC

OpenACC is a standard currently under development to allow for parallel programming of CPUs and GPUs[\cite=OACCspec12]. It primarily uses directives to move data between a host CPU and a GPU and parallelize operations on the GPU. FORTRAN, C, and C++ are supported and there is a hope that it will be merged with OpenMP in the future to allow for a unified interface to GPUs and other accelerators.

CUDA C

CUDA C is a set of extensions to C that allow special functions, called kernels, to be executed on supported NVIDIA GPUs[\cite=NvCGuide12]. CUDA C provides a lower level interface than many of the other application interfaces discussed here.

CUDA FORTRAN

CUDA FORTRAN, is a set of extensions to FORTRAN that allows kernels to execute on NVIDIA GPUs[\cite=PgiFGuide12]. The main constructs are similar to CUDA C; however, CUDA FORTRAN has several directives that can automatically generate kernels for common cases. CUDA FORTRAN provides both a high level interface similar to OpenACC and a low level interface like CUDA C.

An Overview of The Equations

The three choosen equations, which are of mathematical and physical interest, can be solved entirely using Fourier pseudospectral methods and simple representative timestepping schemes. The resulting programs are short, can be understood in their entirety by a single person and only require an FFT routine.

The Cubic Nonlinear Schrödinger Equation

The focusing two dimensional cubic nonlinear Schrödinger equation is

[formula]

where ψ(x,y,t) is a complex valued function of time, t, and two spatial variables, x and y. This equation arises in a variety of contexts including quantum mechanics, in simplified models for lasers, and water waves. When ψ has periodic boundary conditions, the cubic Schrödinger equation has two conserved quantities,

[formula]

known as the mass and energy respectively; they can be used to assess the accuracy of a numerical solution. For more background on this equation, see [\cite=SheTanWan11] and [\cite=Yan10].

The Sine-Gordon Equation

The 2D sine-Gordon equation,

[formula]

arises in many different applications, including propagation of magnetic flux on Josephson junctions, sound propagation in a crystal lattice, and several others discussed in [\cite=ScChMc73]. It has a conserved Hamiltonian

[formula]

which is useful in evaluating the accuracy of numerical solutions.

The 2D Navier-Stokes Equation

The 2D incompressible Navier-Stokes equations in stream function (ψ)-vorticity (ω) form are

[formula]

These equations model fluid flow, and further background on them can be found in [\cite=Tri88] among other references. The Taylor-Green vortex solution of these equations is

[formula]

Fourier Pseudospectral Methods

Fourier pseudospectral methods are a class of numerical methods to solve partial differential equations that utilize the Fourier transform. These methods became popular after the publication of [\cite=GotOrs77]; other expositions are in [\cite=Boy01], [\cite=CanEtAl06], [\cite=CheEtAl12], [\cite=HesGotGot07], [\cite=SheTanWan11], [\cite=Tre00] and [\cite=Yan10]. These methods utilize the fact that differentiation of a function is a simple and fast multiplication by the wave number in Fourier space. The nonlinear terms in are computed in real space. This section gives a brief description of the second order in time algorithms used. The programs are available at .

A Numerical Method for the Nonlinear Schrödinger Equation

The nonlinear Schrödinger equation is approximated by splitting it into two equations which can be solved exactly, [\cite=SheTanWan11] and [\cite=Yan10]. The Fourier transform of ψ will be denoted by ψ̂. In Fourier space one first solves

[formula]

for half a time step, 0.5δt. Letting kx and ky denote the wave numbers in the x and y directions, eq. [\eqref=eq:linSch] is solved by ψ̂(t = 0.5δt) =  exp [ -  i(k2x  +  k2y)δt]ψ̂(t = 0). The solution of

[formula]

for a full time step is [formula], since [formula] is conserved. Finally eq. [\eqref=eq:linSch] is solved for another half time step to get the solution a full time step later.

A Numerical Method for the Sine-Gordon Equation

Following [\cite=DoSc10], the second derivative in time is approximated by a central difference. The resulting numerical method is

[formula]

A Numerical Method for the 2D Navier-Stokes Equation

Time is discretized using the Crank-Nicolson method, where the nonlinear terms are solved for using fixed point iteration

[formula]

The superscript n denotes the time step and the superscript k denotes the iterate. The fixed point iterations stop when

[formula]

Results

All three equations are solved using different numerical methods so actual computation time comparisons between methods are of less interest than common scaling trends. For this comparison all of the codes were compiled with the compilers and flags shown in Table [\ref=Table:info].

The CPU simulations were run on AMD Opteron Magny-Cours 6136 2.4 GHz dual-socket eight-core processors with 48GB of memory and the GPU simulations on Nvidia Fermi M2070 with 6GB of memory per GPU. Double precision floating point arithmetic was used. Computation times are only measured for advancing the numerical solution forward in time, they do not include setup time for creating FFT plans, allocations, calculating exact solutions, etc. because in production simulations where many time steps are taken, these will be negligible. Performance differences between FORTRAN compilers on CPUs do not change the conclusions.

The Cubic Nonlinear Schrödinger Equation

The programs used 4 double complex arrays, 2 arrays for the actual computation and 2 further arrays, to calculate the mass and energy. In all tests, the mass was conserved up to machine precision and the energy was constant to within 6 significant figures.

Table [\ref=Table:NLS] shows that the GPU gives a speed up of up to a factor of 40 compared to a multicore OpenMP CPU implementation. An initial naive CUDA FORTRAN implementation for which kernel parallelization options are left to the compiler was typically a factor of 2 slower than the CUDA C implementation for which block sizes were specified. GPUs had speed ups of order 100 times compared to a single CPU core. Figure [\ref=Fig:Chart] shows that for this code, CUDA Fortran had the best performance.

The Sine-Gordon Equation

The programs used real-to-complex Fourier transforms. They required 2 double precision arrays of size Nx  ×  Ny and 3 double complex arrays of size Nx  ×  (Ny / 2 + 1). In all tests, the final Hamiltonian was within 6 significant figures.

Table [\ref=Table:SG] shows that CUDA C performs the best, followed closely by CUDA FORTRAN and OpenACC. The differences between the GPU implementations were relatively small compared to the difference between GPU and CPU implementations. The GPU implementations performed on the order of 50 times better than a single core CPU. Figure [\ref=Fig:Chart] shows that for this code, CUDA C had the best performance.

The 2D Navier-Stokes Equation

The programs use the same real-to-complex Fourier transforms as the sine-Gordon equation, where the real-valued input array has a size of Nx  ×  Ny and the complex-valued output array is of size Nx  ×  (Ny / 2 + 1). 10 arrays are used for the GPU codes and 11 arrays are used for CPU codes, where the extra array is required because FFTW does not preserve its input. Five complex-real transforms and 1 real-complex transform are used in the timestepping loop.

Table [\ref=Table:NS] shows that the GPU gives a speed up of up to a factor of 30 compared to a single CPU core. Figure [\ref=Fig:Chart] shows that for this code, OpenACC does better than CUDA C, and CUDA FORTRAN has the best performance.

User Comparison of the different GPU programming environments

Porting existing FORTRAN codes to CUDA FORTRAN was simple and intuitive; the combination of FORTRAN and Open ACC was a little less intuitive, but still relatively straightforward. The differences between CPU and GPU versions with CUDA FORTRAN or OpenACC are small, so it is feasible to maintain CPU and GPU versions of the same code. In contrast, porting a FORTRAN code to CUDA C is error prone, requires significant reprogramming and a good understanding of the GPU architecture.

Finally, [\cite=HenEtAl11] observed that the F2C-ACC directive based FORTRAN to CUDA compiler results in a runtime code with better performance than regular CUDA FORTRAN. The performance of CUDA FORTRAN codes may experience very different speedups with minor changes to the parallelization or compiler options. Choosing these options optimally requires some knowledge of the underlying architecture - autotuning compilers would be useful for doing this.

Acknowledgment

This work used the computers Forge and Kollman within the Extreme Science and Engineering Discovery Environment, which is supported by National Science Foundation grant number OCI-1053575. B. Cloutier and P. Rigge were supported by the University of Michigan Undergraduate Research Opportunity Program and Blue Waters Undergraduate Petascale Education Program respectively. The authors acknowledge support from a faculty grant for innovations in teaching with technology from the University of Michigan and a Blue Waters Undergraduate Petascale Module Development grant from the Shodor Foundation. They thank Bennet Fauber, Robert Krasny, Carl Ponder, Sarah Tariq, Divakar Viswanath, Jared Whitehead and Brian Wylie for help and suggestions, and the reviewers for a careful reading.