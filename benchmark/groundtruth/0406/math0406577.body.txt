Theorem Lemma Corollary Remark Example Conjecture Problem Note

Leonard pairs from 24 points of view

There exists a basis for V with respect to which the matrix representing A is diagonal and the matrix representing A* is irreducible tridiagonal.

There exists a basis for V with respect to which the matrix representing A* is diagonal and the matrix representing A is irreducible tridiagonal.

Leonard pairs

Throughout this paper, [formula] will denote an arbitrary field, and [formula] will denote the algebraic closure of [formula].

We begin by recalling the notion of a Leonard pair.

[\cite=LS99] Let V denote a vector space over [formula] with finite positive dimension. By a Leonard pair on V, we mean an ordered pair A,A*, where A:V  →  V and A*:V  →  V are linear transformations that satisfy both (i), (ii) below.

There exists a basis for V with respect to which the matrix representing A is diagonal and the matrix representing A* is irreducible tridiagonal.

There exists a basis for V with respect to which the matrix representing A* is diagonal and the matrix representing A is irreducible tridiagonal.

(A tridiagonal matrix is said to be irreducible whenever all entries immediately above and below the main diagonal are nonzero).

According to a common notational convention, for a linear transformation A the conjugate-transpose of A is denoted A*. We emphasize we are not using this convention. In a Leonard pair A,A*, the linear transformations A and A* are arbitrary subject to (i), (ii) above.

Here is an example of a Leonard pair. Set [formula] (column vectors), set

[formula]

and view A and A* as linear transformations from V to V. We assume the characteristic of [formula] is not 2 or 3, to ensure A is irreducible. Then A,A* is a Leonard pair on V. Indeed, condition (ii) in Definition [\ref=def:lprecall] is satisfied by the basis for V consisting of the columns of the 4 by 4 identity matrix. To verify condition (i), we display an invertible matrix P such that P- 1AP is diagonal and P- 1A*P is irreducible tridiagonal. Set

[formula]

By matrix multiplication P2 = 8I, where I denotes the identity, so P- 1 exists. Also by matrix multiplication,

[formula]

Apparently P- 1AP equals A* and is therefore diagonal. By ([\ref=eq:apeq]), and since P- 1 is a scalar multiple of P, we find P- 1A*P equals A and is therefore irreducible tridiagonal. Now condition (i) of Definition [\ref=def:lprecall] is satisfied by the basis for V consisting of the columns of P.

The above example is a member of the following infinite family of Leonard pairs. For any nonnegative integer d, the pair

[formula]

is a Leonard pair on the vector space [formula], provided the characteristic of [formula] is zero or an odd prime greater than d. This can be proved by modifying the proof for d = 3 given above. One shows P2 = 2dI and AP = PA*, where P denotes the matrix with ij entry

[formula]

We follow the standard notation for hypergeometric series [\cite=gasperrahmanbk]. The details of the above calculations are given in Section 16 below.

To motivate our results we mention some background on Leonard pairs. There is a connection between Leonard pairs and certain orthogonal polynomials contained in the Askey scheme [\cite=KoeSwa]. Observe the [formula] that appears in ([\ref=eq:ex1]) is a Krawtchouk polynomial [\cite=KoeSwa]. There exist families of Leonard pairs similar to the one above in which the Krawtchouk polynomial is replaced by one of the following.

The above polynomials are defined in Koekoek and Swarttouw [\cite=KoeSwa], and the connection to Leonard pairs is given in [\cite=LS99] and [\cite=BanIto]. This connection is also discussed in Section 16 below.

Leonard pairs play a role in representation theory. For instance, Leonard pairs arise naturally in the representation theory of the Lie algebra sl2 [\cite=TD00], the quantum algebra Uq(sl2) [\cite=Koelink3], [\cite=Koelink1], [\cite=Koelink2], [\cite=Koelink4], [\cite=koo3], [\cite=Hjal], [\cite=Terint], [\cite=qSerre], the Askey-Wilson algebra [\cite=GYZnature], [\cite=GYLZmut], [\cite=GYZTwisted], [\cite=GYZlinear], [\cite=GYZspherical], [\cite=Zhidd], [\cite=ZheCart], [\cite=Zhidden], and the Tridiagonal algebra [\cite=TD00], [\cite=qSerre], [\cite=LS99].

Leonard pairs play a role in combinatorics. For instance, there is a combinatorial object called a P-and Q-polynomial association scheme [\cite=BanIto], [\cite=bcn], [\cite=Leopandq], [\cite=Tercharpq], [\cite=Ternew]. Leonard pairs have been used to describe certain irreducible modules for the subconstitutent algebra of these schemes [\cite=TersubI], [\cite=TersubII], [\cite=TersubIII]. See [\cite=Cau], [\cite=CurNom], [\cite=Curspin], [\cite=go], [\cite=HobIto], [\cite=TD00], [\cite=Tan] for more information on Leonard pairs and association schemes.

Leonard pairs are closely related to the work of Grunbaum and Haine on the "bispectral problem" [\cite=GH7], [\cite=GH6]. See [\cite=GH4], [\cite=GH5], [\cite=GH1], [\cite=GH3], [\cite=GH2] for related work.

We now give an overview of the present paper. Let V denote a vector space over [formula] with finite positive dimension, and let A,A* denote a Leonard pair on V. Using this pair, we define 24 bases for V which we find attractive. In our study of these 24 bases, we will be concerned with (i) how these bases are related to each other, and (ii) for each basis, the matrices that represent A and A*. We will elaborate on these two points below, but first we sharpen our notation. By a basis for V, we mean a sequence of vectors in V that are linearly independent and span V. We emphasize the ordering is important. Let [formula] denote a basis for V. Then the sequence [formula] is a basis for V, which we call the inversion of [formula].

When we define our 24 bases, we will find they are related to each other according to the diagram in Figure 1. In that diagram, each vertex represents one of the 24 bases. For each pair of bases in the diagram that are connected by an arc, consider the transition matrix from one of these bases to the other. The shading on the arc indicates the nature of this transition matrix. If the arc is solid, the transition matrix is diagonal. If the arc is dashed, the transition matrix is lower triangular. If the arc is dotted, the two bases are the inversion of one another.

.sty

The reader might observe the above diagram is a Cayley graph for the symmetric group S4. Apparently, there is a connection between our 24 bases and S4. We now make this connection explicit.

Let Ω denote the set consisting of four symbols 0,d,0*,d*. We identify the symmetric group S4 with the set of all linear orderings of Ω. For i = 1,2,3 we define a symmetric binary relation on S4 which we call i-adjacency. Each element wxyz of S4 is by definition 1-adjacent (resp. 2-adjacent) (resp. 3-adjacent) to xwyz (resp. wyxz) (resp. wxzy) and no other elements of S4. Two elements in S4 will be called adjacent whenever they are i-adjacent for some i (1  ≤  i  ≤  3). If we draw a diagram in which we represent the elements of S4 by vertices, and for i = 1,2,3 we represent i-adjacency by solid, dashed, and dotted arcs, respectively, we get the diagram in Figure 1.

For each element g of S4, we will define a certain basis for V, which we denote by [g]. We will find that for all pairs g,h of adjacent elements in S4,

if g,h are 1-adjacent the transition matrix from [g] to [h] is diagonal,

if g,h are 2-adjacent the transition matrix from [g] to [h] is lower triangular,

if g,h are 3-adjacent then [g] is the inversion of [h].

When we define our 24 bases, we will find that A and A* act on them as follows. For all g∈S4, let Ag (resp. A* g) denote the matrix representing A (resp. A*) with respect to [g]. To describe Ag and A* g, we refer to 0*,d* as the starred elements of Ω. Writing g = wxyz, we will find

if neither of y,z are starred then Ag is diagonal and A* g is irreducible tridiagonal.

if y is starred but z is not, then Ag is lower bidiagonal and A* g is upper bidiagonal.

if z is starred but y is not, then Ag is upper bidiagonal and A* g is lower bidiagonal.

if both of y,z are starred, then Ag is irreducible tridiagonal and A* g is diagonal.

(A square matrix is said to be lower bidiagonal whenever all nonzero entries lie either on or immediately below the main diagonal. A matrix is said to be upper bidiagonal whenever the transpose is lower bidiagonal).

For all ordered pairs g,h of adjacent elements in S4, we find the entries of the transition matrix from the basis [g] to the basis [h]. We express these entries in terms of the eigenvalues of A, the eigenvalues of A*, and two sequences of scalars called the first split sequence and the second split sequence. For all g∈S4, we compute the entries of Ag and A* g in terms of the eigenvalues of A, the eigenvalues of A*, the first split sequence and the second split sequence.

Leonard systems

When working with a Leonard pair, it is often convenient to consider a closely related and somewhat more abstract object, which we call a Leonard system. In order to define this, we first make an observation about Leonard pairs.

[\cite=LS99] Let V denote a vector space over [formula] with finite positive dimension, and let A,A* denote a Leonard pair on V. Then the eigenvalues of A are distinct and contained in [formula]. Moreover, the eigenvalues of A* are distinct and contained in [formula].

To prepare for our definition of a Leonard system, we recall a few concepts from elementary linear algebra. Let d denote a nonnegative integer, and let [formula] denote the [formula]-algebra consisting of all d + 1 by d + 1 matrices with entries in [formula]. We index the rows and columns by [formula]. Let A denote a [formula]-algebra isomorphic to [formula]. Let A denote an element of A. By an eigenvalue of A, we mean a root of the minimal polynomial of A. The eigenvalues of A are contained in the algebraic closure of [formula]. The element A will be called multiplicity-free whenever it has d + 1 distinct eigenvalues, all of which are in [formula]. Let A denote a multiplicity-free element of A. Let [formula] denote an ordering of the eigenvalues of A, and for 0  ≤  i  ≤  d put

[formula]

where I denotes the identity of A. By elementary linear algebra,

[formula]

From this, one finds [formula] is a basis for the subalgebra of A generated by A. We refer to Ei as the primitive idempotent of A associated with θi. It is helpful to think of these primitive idempotents as follows. Let V denote the irreducible left A-module. Then

[formula]

For 0  ≤  i  ≤  d, EiV is the (one dimensional) eigenspace of A in V associated with the eigenvalue θi, and Ei acts on V as the projection onto this eigenspace.

[\cite=LS99] Let d denote a nonnegative integer, let [formula] denote a field, and let A denote a [formula]-algebra isomorphic to [formula]. By a Leonard system in   A, we mean a sequence

[formula]

that satisfies (i)-(v) below.

A,   A*   are both multiplicity-free elements in   A.

[formula] is an ordering of the primitive idempotents of   A.

[formula] is an ordering of the primitive idempotents of   A*.

[formula].

[formula]

We refer to d as the diameter of Φ, and say Φ is over [formula]. We sometimes write A  =  A(Φ), [formula]. For notational convenience, we set E- 1 = 0, Ed + 1 = 0, E*- 1 = 0, E*d + 1 = 0.

In the two lemmas below, we explain the relationship between the notions of Leonard pair and Leonard system. We will use the following notation. Let V denote a vector space over [formula] with finite positive dimension. We let [formula] denote the [formula]-algebra consisting of all linear transformations from V to V. We recall [formula] is [formula]-algebra isomorphic to [formula], where [formula].

Let V denote a vector space over [formula] with finite positive dimension. Let A,A* denote a Leonard pair on V, and observe each of A,A* is multiplicity-free by Lemma [\ref=lem:preeverythingtalkS99]. Let [formula] denote a basis for V that satisfies Definition [\ref=def:lprecall](i). For 0  ≤  i  ≤  d, observe vi is an eigenvector for A; let θi denote the corresponding eigenvalue, and let Ei denote the primitive idempotent of A associated with θi. Similarly, let [formula] denote a basis for V that satisfies Definition [\ref=def:lprecall](ii). For 0  ≤  i  ≤  d, observe v*i is an eigenvector for A*; let θ*i denote the corresponding eigenvalue, and let E*i denote the primitive idempotent of A* associated with θ*i. Then the sequence

[formula]

is a Leonard system in End(V).

We verify the conditions (i)-(v) of Definition [\ref=def:defls]. Condition (i) is immediate from Lemma [\ref=lem:preeverythingtalkS99] and the definition of multiplicity-free. Conditions (ii), (iii) are immediate from the construction. Condition (iv) holds, since by Definition [\ref=def:lprecall](i) the matrix representing A* with respect to the basis [formula] is irreducible tridiagonal. Condition (v) holds, since by Definition [\ref=def:lprecall](ii) the matrix representing A with respect to the basis [formula] is irreducible tridiagonal.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. For 0  ≤  i  ≤  d, let vi denote a nonzero vector in EiV. Then [formula] is a basis for V with respect to which the matrix representing A is diagonal and the matrix representing A* is irreducible tridiagonal. For 0  ≤  i  ≤  d, let v*i denote a nonzero vector in E*iV. Then [formula] is a basis for V with respect to which the matrix representing A* is diagonal and the matrix representing A is irreducible tridiagonal. Moreover the pair A,A* is a Leonard pair on V.

Routine.

We mention a few basics concerning Leonard systems.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let σ:A  →  A' denote an isomorphism of [formula]-algebras. We write

[formula]

and observe Φσ is a Leonard system in A'.

[\cite=LS99] Let Φ and Φ' denote Leonard systems over [formula]. By an isomorphism of Leonard systems from Φ to Φ', we mean an isomorphism of [formula]-algebras σ:A(Φ)  →  A(Φ') such that Φσ  =  Φ'. The Leonard systems Φ, Φ' are said to be isomorphic whenever there exists an isomorphism of Leonard systems from Φ to Φ'.

We finish this section with a remark. Let d denote a nonnegative integer, and let A denote a [formula]-algebra isomorphic to [formula]. Let σ:A  →  A denote any map. Then by the Skolem-Noether theorem [\cite=CR], σ is an isomorphism of [formula]-algebras if and only if there exists an invertible S∈A such that Xσ  =  SXS- 1 for all X∈A.

The structure of a Leonard system

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]). In this section, we show there does not exist an isomorphism of Leonard systems from Φ to itself, other than the identity map. We begin with a lemma.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]). Then the elements

[formula]

form a basis for A.

The number of elements in ([\ref=eq:lpbasis]) equals (d + 1)2, and this number is the dimension of A. Therefore it suffices to show the elements in ([\ref=eq:lpbasis]) are linearly independent. To do this, we represent the elements in ([\ref=eq:lpbasis]) by matrices. Let V denote the irreducible left A-module. For 0  ≤  i  ≤  d, let vi denote a nonzero vector in E*iV, and observe [formula] is a basis for V. For the purposes of this proof, let us identify each element of A with the matrix in [formula] that represents it with respect to the basis [formula]. Adopting this point of view A is irreducible tridiagonal and A* is diagonal. For 0  ≤  r,s  ≤  d we show the entries of ArE*0As satisfy

[formula]

Observe that for 0  ≤  i,j  ≤  d, the [formula] entry of E*0 is one if both i = 0,j = 0, and zero otherwise. From this we find

[formula]

Since A is irreducible tridiagonal, we find that for 0  ≤  i  ≤  d, the [formula] entry of Ar is zero if i > r, and nonzero if i = r. Similarly for 0  ≤  j  ≤  d, the [formula] entry of As is zero if j > s, and nonzero if j = s. Combining these facts with ([\ref=eq:redent]) we routinely obtain ([\ref=eq:lowert]) and it follows the elements ([\ref=eq:lpbasis]) are linearly independent. Apparently the elements ([\ref=eq:lpbasis]) form a basis for A, as desired.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]). Then the elements A,E*0 together generate A. Moreover, the elements A,A* together generate A.

The first assertion is immediate from Lemma [\ref=eq:lsmatbasis]. The second assertion follows from the first and the observation that E*0 is a polynomial in A*.

We mention a useful consequence of Corollary [\ref=cor:genset].

Let Φ denote the Leonard system ([\ref=eq:ourstartingpt]), and let X denote an element in A that commutes with both A and A*. Then X is a scalar multiple of the identity. Put another way, there does not exist an isomorphism of Leonard systems from Φ to itself, other than the identity map.

Since A,A* together generate A, we find X commutes with everything in A. Now X is a scalar multiple of the identity by elementary linear algebra. The last assertion follows in view of our remark at the end of Section 2.

We mention an implication of Lemma [\ref=eq:lsmatbasis] that will be useful later in the paper.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]). Let D denote the subalgebra of A generated by A, and observe D has dimension d + 1 since A is multiplicity-free. Let [formula] denote a basis for D. Then the elements

[formula]

form a basis for A.

The number of elements in ([\ref=altbase]) is (d + 1)2, and this number is the dimension of A. Therefore it suffices to show the elements ([\ref=altbase]) span A. But this is immediate from Lemma [\ref=eq:lsmatbasis], and since each element in ([\ref=eq:lpbasis]) is contained in the span of the elements ([\ref=altbase]).

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]). Then the elements

[formula]

form a basis for A.

Immediate from Lemma [\ref=lem:altbase], with Xi  =  Ei for 0  ≤  i  ≤  d.

The relatives of a Leonard system

A given Leonard system can be modified in several ways to get a new Leonard system. For instance, let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]). Then each of the following three sequences is a Leonard system in A.

[formula]

We refer to Φ* (resp. [formula]) (resp. [formula]) as the dual (resp. first inversion) (resp. second inversion) of Φ. Viewing [formula] as permutations on the set of all Leonard systems,

[formula]

The group generated by symbols [formula] subject to the relations ([\ref=eq:deightrelationsAS99]), ([\ref=eq:deightrelationsBS99]) is the dihedral group D4. We recall D4 is the group of symmetries of a square, and has 8 elements. Apparently [formula] induce an action of D4 on the set of all Leonard systems. Two Leonard systems will be called relatives whenever they are in the same orbit of this D4 action. The relatives of Φ are as follows:

We remark there may be some isomorphisms among the above Leonard systems.

We finish this section by recalling some parameters that will help us describe a given Leonard system.

[\cite=LS99] Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]). For 0  ≤  i  ≤  d, we let θi (resp. θ*i) denote the eigenvalue of A (resp. A*) associated with Ei (resp. E*i). We refer to [formula] as the eigenvalue sequence of Φ. We refer to [formula] as the dual eigenvalue sequence of Φ. We observe [formula] are mutually distinct and contained in [formula]. Similarly [formula] are mutually distinct and contained in [formula].

The standard basis and the split basis

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. As we mentioned earlier, we will obtain 24 bases for V. One way to view our construction is as follows. Using Φ we define three bases for V, called the Φ-standard basis, the Φ-split basis, and the Φ-inverted split basis. In each of the three cases, the basis is defined up to multiplication of each element by the same nonzero scalar in [formula]. Our set of 24 bases will consist of a Ψ-standard basis, a Ψ-split basis, and a Ψ-inverted split basis for each relative Ψ of Φ.

We now define the notion of a standard basis.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. Let u denote a nonzero element of E*0V. Then for 0  ≤  i  ≤  d, the element Eiu is nonzero and hence a basis for EiV. Moreover the sequence

[formula]

is a basis for V.

Let the integer i be given. Recall E*0V has dimension 1, and u is a nonzero vector in E*0V, so u spans E*0V. Apparently Eiu spans EiE*0V. Observe EiE*0 is nonzero by Corollary [\ref=cor:eibasis] so EiE*0V is nonzero. Apparently Eiu is nonzero, and is therefore a basis for EiV, as desired. The sequence ([\ref=eq:stbasisint]) is a basis for V in view of ([\ref=eq:VdecompS99]).

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. By a Φ-standard basis for V, we mean a sequence ([\ref=eq:stbasisint]), where u is a nonzero vector in E*0V. When the identity of Φ is clear, we will occasionaly speak of a standard basis instead of a Φ-standard basis.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. With respect to any Φ-standard basis for V, the matrix representing A is

[formula]

where the θi are from Definition [\ref=def:evseq]. Moreover, by Lemma [\ref=lem:lsgiveslp], the matrix representing A* is irreducible tridiagonal. We will work out the entries of this tridiagonal matrix in due course, but it is convenient to wait until after we have introduced some more bases. For those who wish to skip ahead, the entries of this tridiagonal matrix can be found in the second table of Theorem [\ref=thm:repa], row 1.

We now define the notion of a split basis. In the process, we will recall two sequences of scalars which we will find useful. These sequences are called the first split sequence of Φ and the second split sequence of Φ.

In order to define a split basis, we review some results of [\cite=TD00], [\cite=LS99]. Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]) and let V denote the irreducible left A-module. For 0  ≤  i  ≤  d we define

[formula]

We showed in [\cite=TD00] that each of [formula] has dimension 1, and that

[formula]

Moreover,

[formula]

for 0  ≤  i  ≤  d. The elements A and A* act on the Ui as follows. We showed in [\cite=LS99] that

[formula]

where the θi,θ*i are from Definition [\ref=def:evseq]. Pick an integer i (1  ≤  i  ≤  d). By ([\ref=eq:lower]) we find (A*  -  θ*iI)Ui  =  Ui - 1 and by ([\ref=eq:raise]) we find (A - θi - 1I)Ui - 1  =  Ui. Apparently Ui is an eigenspace for (A - θi - 1I)(A*  -  θ*iI), and the corresponding eigenvalue is a nonzero element of [formula]. We denote this eigenvalue by φi. We refer to the sequence [formula] as the first split sequence of Φ. We let [formula] denote the first split sequence for [formula], and call this the second split sequence of Φ. For notational convenience, we define φ0 = 0, φd + 1  =  0, φ0 = 0, φd + 1  =  0.

We obtain our split basis as follows. Setting i = 0 in ([\ref=eq:split1]), we find U0 = E*0V. Combining this with ([\ref=eq:raise]), we find

[formula]

Let u denote a nonzero vector in E*0V. From ([\ref=eq:uialt]) we find that for 0  ≤  i  ≤  d, the vector [formula] is a basis for Ui. From this and ([\ref=eq:splitdec]) we find the sequence

[formula]

is a basis for V.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. By a Φ-split basis for V, we mean a sequence ([\ref=eq:basis1]), where u is a nonzero vector in E*0V. When the identity of Φ is clear, we will occasionaly speak of a split basis instead of a Φ-split basis.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. From ([\ref=eq:basis1]) and the lines below ([\ref=eq:lower]), we find that with respect to any Φ-split basis for V, the matrices representing A and A* are

[formula]

respectively.

We now define the notion of an inverted split basis. As its name implies, an inverted split basis is nothing but the inversion of a split basis. To be concrete, we make the following definition.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. By a Φ-inverted split basis for V, we mean a sequence

[formula]

where u is a nonzero vector in E*0V. When the identity of Φ is clear, we will occasionaly speak of an inverted split basis instead of a Φ-inverted split basis.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. Combining ([\ref=eq:matrepaastar]) with Definition [\ref=def:invsplit], we find that with respect to any Φ-inverted split basis for V, the matrices representing A and A* are

[formula]

respectively.

A classification of Leonard systems

In the preceeding section, we defined the first and second split sequence of a Leonard system. The scalars involved in these sequences are related by many equations. To describe these relationships, we recall our classification of Leonard systems.

[\cite=LS99] Let d denote a nonnegative integer, and let

[formula]

denote scalars in [formula]. Then there exists a Leonard system Φ over [formula] with eigenvalue sequence [formula], dual eigenvalue sequence [formula], first split sequence [formula], and second split sequence [formula] if and only if (i)-(v) hold below.

[formula],

[formula] if [formula],

[formula],

[formula],

The expressions

[formula]

are equal and independent of i for   2  ≤  i  ≤  d - 1.

Moreover, if (i)-(v) hold above then Φ is unique up to isomorphism of Leonard systems.

We view Theorem [\ref=thm:classls] as a linear algebraic version of a theorem of Leonard [\cite=Leodual], [\cite=BanIto]. This is discussed in [\cite=LS99].

One nice feature of the parameter sequences ([\ref=eq:paramlist1S99]), ([\ref=eq:paramlist2S99]) is that they are modified in a simple way as one passes from a given Leonard system to a relative. Our result is the following.

[\cite=LS99] Let Φ denote a Leonard system, with eigenvalue sequence [formula], dual eigenvalue sequence [formula], first split sequence [formula] and second split sequence [formula]. Then (i)-(iii) hold below.

The eigenvalue and dual eigenvalue sequences of Φ* are given by [formula] and [formula], respectively. The first and second split sequences of Φ* are given by [formula] and [formula], respectively.

The eigenvalue and dual eigenvalue sequences of [formula] are given by [formula] and [formula], respectively. The first and second split sequences of [formula] are given by [formula] and [formula], respectively.

The eigenvalue and dual eigenvalue sequences of [formula] are given by [formula] and [formula], respectively. The first and second split sequences of [formula] are given by [formula] and [formula], respectively.

Four flags for V

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. We mentioned earlier we will obtain 24 bases for V. In Section 5 we described these bases to some extent, but we stopped short of displaying them. The reason is we wish to first introduce our labelling scheme. As we indicated in Section 1, it is appropriate to label our bases with elements of S4. We begin with a definition.

Let Ω denote the set consisting of four symbols 0,d,0*,d*. We identify the symmetric group S4 with the set of all linear orderings of Ω. For i = 1,2,3 we define a symmetric binary relation on S4 which we call i-adjacency. An element wxyz of S4 is by definition 1-adjacent (resp. 2-adjacent) (resp. 3-adjacent) to xwyz (resp. wyxz) (resp. wxzy) and no other elements of S4. Two elements in S4 will be called adjacent whenever they are i-adjacent for some i (1  ≤  i  ≤  3).

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. We recall the notion of a flag on V. By a flag on V, we mean a sequence [formula] consisting of subspaces of V such that Fi - 1  ⊆  Fi for 1  ≤  i  ≤  d and such that Fi has dimension i + 1 for 0  ≤  i  ≤  d. We refer to Fi as the [formula] component of the flag.

The following construction yields a flag on V. To explain the construction, we make a definition. By a decomposition of V, we mean a sequence [formula] consisting of 1-dimensional subspaces of V such that

[formula]

Let [formula] denote a decomposition of V, and set

[formula]

for 0  ≤  i  ≤  d. Then the sequence [formula] is a flag on V.

We will be concerned with the following four flags on V.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. Let the set Ω be as in Definition [\ref=def:S4interp]. For each element z∈Ω, we define a flag on V, which we denote by [z]. To define this flag, we display its [formula] component for 0  ≤  i  ≤  d.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. We recall what it means for two flags on V to be opposite. Suppose we are given two flags on V, denoted [formula] and [formula]. These flags are said to be opposite whenever

[formula]

Given a decomposition of V, the following construction yields an ordered pair of opposite flags on V. Let [formula] denote a decomposition of V, and set

[formula]

for 0  ≤  i  ≤  d. Then the sequences [formula] and [formula] are opposite flags on V.

We now turn things around. Given an ordered pair of opposite flags on V, the following construction yields a decomposition of V. Suppose we are given an ordered pair of opposite flags on V, denoted [formula] and [formula]. Set

[formula]

Then the sequence [formula] is a decomposition of V.

Let D denote the set consisting of all decompositions of V, and let F denote the set consisting of all ordered pairs of opposite flags on V. In the previous two paragraphs, we defined a map from D to F and a map from F to D. It is routine to show these maps are inverses of one another [\cite=Ronan]. In particular, each of these maps is a bijection.

We now return to the Leonard system Φ.

The four flags in Definition [\ref=def:fourflags] are mutually opposite.

It is immediate from the construction that flags [0],[d] are opposite, and that flags [0*],[d*] are opposite. We now show the flags [0*],[d] are opposite. For 0  ≤  i  ≤  d, let Ui denote the subspace of V from ([\ref=eq:defui]). By the two lines following ([\ref=eq:defui]), we find the sequence [formula] is a decomposition of V. By ([\ref=eq:split1]), ([\ref=eq:split2]) and the line following ([\ref=eq:getg]), we find the flags [0*],[d] are opposite. Applying this fact to the relatives of Φ, we see that the remaining pairs of flags in Definition [\ref=def:fourflags] are opposite.

Twelve decompositions of V

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), let V denote the irreducible left A-module, and let the set Ω be as in Definition [\ref=def:S4interp]. In this section, we obtain for each ordered pair yz of distinct elements in Ω, a decomposition of V which we denote by [yz].

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), let V denote the irreducible left A-module, and let the set Ω be as in Definition [\ref=def:S4interp]. Let yz denote an ordered pair of distinct elements in Ω. Set

[formula]

where Fj (resp. Gj) denotes the [formula] component of the flag [y] (resp. [z]) for 0  ≤  j  ≤  d. Recall [y] and [z] are opposite, so the sequence [formula] is a decomposition of V. We denote this decomposition by [yz].

With reference to Definition [\ref=def:byzb], we remark on the difference between [yz] and [zy]. To do this, we use the following notation. Let [formula] denote a decomposition of V. Then the sequence [formula] is a decomposition of V, which we call the inversion of [formula].

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), let V denote the irreducible left A-module, and let the set Ω be as in Definition [\ref=def:S4interp]. Let y,z denote distinct elements in Ω. Then each of the decompositions [yz], [zy] is the inversion of the other.

Immediate from Definition [\ref=def:byzb] and the definition of inversion.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), let V denote the irreducible left A-module, and let the set Ω be as in Definition [\ref=def:S4interp]. In Definition [\ref=def:byzb], we obtained for each ordered pair yz of distinct elements in Ω, a decomposition of V denoted [yz]. This gives 12 decompositions of V. By Lemma [\ref=lem:yzinvzy], these consist of 6 pairs of inverse decompositions. To be concrete, we now display these decompositions.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), let V denote the irreducible left A-module, and let the set Ω be as in Definition [\ref=def:S4interp]. Let yz denote an ordered pair of distinct elements in Ω, and consider the corresponding decomposition [yz] of V from Definition [\ref=def:byzb]. For 0  ≤  i  ≤  d, the [formula] subspace of [yz] is given in the following table.

Describing our 12 decompositions from another point of view, we have the following.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), let V denote the irreducible left A-module, and let the set Ω be as in Definition [\ref=def:S4interp]. Let yz denote an ordered pair of distinct elements in Ω, and consider the corresponding decomposition [yz] from Definition [\ref=def:byzb]. Let us denote this decomposition by [formula]. Then for 0  ≤  i  ≤  d, the sums [formula] and [formula] are given as follows.

24 bases for V

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. For each element g∈S4, we display a basis for V, denoted [g]. To describe our procedure, we use the following notation.

Let [formula] denote a basis for V, and set [formula] for 0  ≤  i  ≤  d. Observe the sequence [formula] is a decomposition of V. We say this decomposition is induced by [formula].

Let the set Ω be as in Definition [\ref=def:S4interp], and let yz denote an ordered pair of distinct elements of Ω. Consider the corresponding decomposition of V, denoted [yz]. We define two bases for V, both of which induce [yz]. We denote these bases by [wxyz] and [xwyz], where w and x denote the elements in Ω other than y,z. Apparently this procedure yields, for each g∈S4, a basis [g] for V. These 24 bases are displayed below.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. Let η0, ηd, η*0, η*d denote nonzero vectors in V such that

[formula]

With reference to Definition [\ref=def:S4interp], let g denote an element of S4 and consider row g of the table below. For 0  ≤  i  ≤  d, the vector vi given in that row is a basis for the subspace given to its right. Moreover, the sequence [formula] is a basis for V. We denote this basis by [g].

Concerning the first row of the above table, our assertions follow from the lines preceeding ([\ref=eq:basis1]). Concerning the third row of the above table, our assertions follow upon replacing i by d - i in the first row. We have now proved our assertions for the first and third rows of the table. Applying these assertions to the relatives of Φ, we obtain the first 16 rows of the table. Consider the next remaining row, where g equals d*0*0d. For this row, our assertions are immediate from Lemma [\ref=lem:stbasis]. Applying this result to the relatives of Φ, we obtain the remaining rows of the table.

We record a few observations.

Referring to Theorem [\ref=thm:bases], for all elements wxyz in S4, the basis [wxyz] from Theorem [\ref=thm:bases] induces the decomposition [yz] of V from Definition [\ref=def:byzb].

Compare the data in Theorem [\ref=thm:bases] with the data in Theorem [\ref=thm:sixdecp].

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. In the table below, each basis for V contained the first column (resp. second column) (resp. third column) is a Ψ-standard basis (resp. Ψ-split basis) (resp. Ψ-inverted split basis), where Ψ is the relative of Φ given to the left of this basis.

Immediate from inspecting the table in Theorem [\ref=thm:bases].

Later in the paper, we will compute, for each ordered pair g,h of adjacent elements in S4, the entries in the transition matrix from the basis [g] to the basis [h]. Before going that far, we say something about the general nature of these transition matrices. First we recall our terms.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. Suppose we are given two bases for V, written [formula] and [formula]. By the transition matrix from [formula] to [formula], we mean the matrix T in [formula] satisfying

[formula]

We recall a few properties of transition matrices. Let T denote the transition matrix from [formula] to [formula]. Then T- 1 exists, and equals the transition matrix from [formula] to [formula]. Let [formula] denote a basis for V, and let S denote the transition matrix from [formula] to [formula]. Then TS is the transition matrix from [formula] to [formula].

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. With reference to Definition [\ref=def:S4interp], let g,h denote adjacent elements in S4, and consider the corresponding bases [g], [h] for V given in Theorem [\ref=thm:bases]. Then (i)-(iii) hold below.

Suppose g,h are 1-adjacent. Then the transition matrix from [g] to [h] is diagonal.

Suppose g,h are 2-adjacent. Then the transition matrix from [g] to [h] is lower triangular.

Suppose g,h are 3-adjacent. Then [g] is the inversion of [h].

For notational convenience we write g = wxyz. (i) In this case h = xwyz. Observe [g] and [h] both induce the decomposition [yz] by Lemma [\ref=lem:invers], so the transition matrix from [g] to [h] is diagonal.

(ii) In this case h = wyxz. By Lemma [\ref=lem:invers], the bases [g] and [h] induce the decompositions [yz] and [xz], respectively. When we consider how the decompositions [yz] and [xz] are related, we find the transition matrix from [g] to [h] is lower triangular.

(iii) In this case h = wxzy. In the table of Theorem [\ref=thm:bases], for each block we compare rows 1,3 and rows 2,4. We find in all cases [g] is the inversion of [h].

Some scalars

Our next goal is to compute the matrices representing A and A* with respect to each of the bases in Theorem [\ref=thm:bases]. To describe the entries of these matrices, we will use the following parameters.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]). We define

[formula]

where tr means trace.

The scalars ai,a*i have the following interpretation.

With reference to Definition [\ref=def:aidef],

[formula]

Concerning ([\ref=eq:aimeaning]), let i be given. Since E*i is a rank 1 idempotent, there exists a scalar [formula] such that

[formula]

Taking the trace of both sides of ([\ref=eq:findalph]), and recalling XY, YX have the same trace, we routinely find αi  =  ai. We have now proved ([\ref=eq:aimeaning]). Applying this to Φ*, we obtain ([\ref=eq:aismeaning]).

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]). Then for 0  ≤  i  ≤  d the scalar ai equals both

[formula]

where θ*- 1, θ*d + 1 denote indeterminants. Moreover, the scalar a*i equals both

[formula]

where θ- 1, θd + 1 denote indeterminants.

Let the integer i be given. The scalar ai equals the expression on the left in ([\ref=eq:aivarphi]) by [\cite=LS99]. Applying this fact to [formula], and using Theorem [\ref=thm:phimod](iii), we find ai equals the expression on the right in ([\ref=eq:aivarphi]). We have now shown ai equals the two expressions in ([\ref=eq:aivarphi]). Applying this to Φ*, and using Theorem [\ref=thm:phimod](i), we find a*i equals the two expressions in ([\ref=eq:aisvarphi]).

The 24 bases; matrices representing A and A*

In this section, we return to the 24 bases in Theorem [\ref=thm:bases]. For each g∈S4, we compute the matrices representing A and A* with respect to the basis [g].

We use the following notation.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. With reference to Definition [\ref=def:S4interp], let g denote an element in S4. For all X∈A, we let Xg denote the matrix in [formula] that represents X with respect to the basis [g], where [g] is from Theorem [\ref=thm:bases]. Denoting this basis by [formula] we have

[formula]

We observe the map X  →  Xg is a [formula]-algebra isomorphism from A to [formula].

Let g denote an element of S4. With reference to Definition [\ref=def:matrixrep], the entries of Ag and A* g are given in the tables below. Any entry not displayed is zero.

Consider the first row of the first table, where g equals d*00*d. As indicated in the table of Lemma [\ref=lem:reconcile], row 1, column 2, the basis [g] is a Φ-split basis. From the line above ([\ref=eq:matrepaastar]), we find Ag (resp. A* g) is given on the left (resp. right) in ([\ref=eq:matrepaastar]). From this we obtain our results for the first row of the first table. Now consider the third row of the first table, where g equals d*0d0*. From the table of Lemma [\ref=lem:reconcile], row 1, column 3, the basis [d*0d0*] is a Φ-inverted split basis. From the line above ([\ref=eq:invmat]) we find Ag (resp. A* g) is given on the left (resp. right) in ([\ref=eq:invmat]). From this we obtain our results for the third row of the first table. We have now proved our assertions for rows 1 and 3 of the first table. Applying this result to the relatives of Φ, and using Theorem [\ref=thm:phimod], we obtain the remaining rows of the first table. Consider the first row of the second table, where g equals d*0*0d. From the table of Theorem [\ref=thm:bases], row 17, we find the corresponding basis [g] is

[formula]

For 0  ≤  i  ≤  d, the vector Eiη*0 is an eigenvector for A, with eigenvalue θi. Therefore

[formula]

We now find A* g. From the construction, and since A,A* is a Leonard pair, the matrix A* g is irreducible tridiagonal. From ([\ref=eq:aismeaning]) we find the diagonal entries A* gii  =  a*i for 0  ≤  i  ≤  d. We show

[formula]

for 1  ≤  i  ≤  d. To see ([\ref=eq:biform]), we momentarily return to the basis [d*00*d]. From the table of Theorem [\ref=thm:bases], row 1, we find that for 0  ≤  j  ≤  d, the [formula] vector in the basis [d*00*d] is given by

[formula]

We write ([\ref=eq:ith]) in terms of ([\ref=eq:stbasis]). Recall the sum [formula] equals the identity I. Applying this sum to the vector ([\ref=eq:ith]) and simplifying the result using ([\ref=eq:primid1S99]), we find the vector ([\ref=eq:ith]) equals

[formula]

Let L denote the matrix in [formula] with [formula] entry [formula], for 0  ≤  i,j  ≤  d. Apparently L is the transition matrix from the basis [d*0*0d] to the basis [d*00*d]. By linear algebra, we obtain

[formula]

where we recall g = d*0*0d and we abbreviate h = d*00*d. For 1  ≤  i  ≤  d, we compute the i - 1,i entry in ([\ref=eq:atta]). Since A* g is tridiagonal, and since L is lower triangular, we find the i - 1,i entry of A* gL equals A* gi - 1,iLii or in other words

[formula]

We mentioned above the matrix A* h is given on the right in ([\ref=eq:matrepaastar]). Since A* h is upper bidiagonal, and since L is lower triangular, we find the i - 1,i entry of LA* h equals Li - 1,i - 1A* hi - 1,i or in other words

[formula]

Equating ([\ref=eq:bside1]), ([\ref=eq:bside2]), we obtain ([\ref=eq:biform]). Applying ([\ref=eq:biform]) to [formula] and using Theorem [\ref=thm:phimod], we routinely find

[formula]

for 1  ≤  i  ≤  d. We have now proved our assertions for the first row of the second table. Applying these facts to the relatives of Φ, and using Theorem [\ref=thm:phimod], we obtain the remaining rows of the second table and all rows of the third table.

Summarizing the data from Theorem [\ref=thm:repa], we have the following.

Referring to Theorem [\ref=thm:repa], pick any g∈S4, and consider the form of Ag and A* g. Writing g = wxyz, this form is given as follows.

We remark the number of elements in S4 satisfying each of the above four cases is 4,8,8,4, respectively.

Follows from the data in Theorem [\ref=thm:repa].

The eigenvalues and dual eigenvalues

Our next goal is to compute, for each ordered pair g,h of adjacent elements in S4, the entries in the transition matrix from the basis [g] to the basis [h]. In order to describe these entries, we make some comments about eigenvalues, and define some expressions. In this section, we focus on eigenvalues.

Let β denote a scalar in [formula]. Let d denote a nonnegative integer, and let [formula] denote a sequence of scalars taken from [formula]. We say this sequence is β-recurrent whenever σi - 1  -  βσi  +  σi + 1 is independent of i for 1  ≤  i  ≤  d - 1. Let Φ denote the Leonard system in Theorem [\ref=thm:classls]. Then by condition (v) of that theorem, the eigenvalue sequence and the dual eigenvalue sequence of Φ are β-recurrent, where β + 1 is the common value of ([\ref=eq:betaplusone]). These two sequences are the ones we wish to discuss in this section, but since what we have to say about them applies to all β-recurrent sequences, we keep things general.

We begin by mentioning some well known formula concerning β-recurrent sequences. Recall [formula] denotes the algebraic closure of the field [formula].

Let d denote a nonnegative integer, and let [formula] denote a sequence of scalars taken from [formula]. Let β denote a scalar in [formula], and assume [formula] is β-recurrent. Let q denote a nonzero scalar in [formula] such that q + q- 1  =  β.

Suppose [formula]. Then there exists scalars a,b,c in [formula] such that

[formula]

Suppose q = 1. Then there exists scalars a,b,c in [formula] such that

[formula]

Suppose q =  - 1, and that the characteristic of [formula] is not 2. Then there exists scalars a,b,c in [formula] such that

[formula]

Referring to case (ii) above, if [formula] has characteristic 2, we interpret the expression i(i - 1) / 2 as 0 if i = 0 or i = 1 (mod 4), and as 1 if i = 2 or i = 3 (mod 4).

Let q denote a nonzero scalar in [formula], and let n denote an integer. We let [n]q denote the following scalar in [formula].

First assume n is odd. In this case we define

[formula]

We observe

[formula]

and that [ - n]q  =    -  [n]q. For example,

[formula]

Next assume n is even. In this case we define

[formula]

We observe

[formula]

and that [ - n]q  =    -  [n]q. For example,

[formula]

Referring to the cases q = 1,q =  - 1 of ([\ref=eq:evenndef]), if [formula] has characteristic 2, we interpret n / 2 as 1 if n = 2 (mod 4), and as 0 if n = 0 (mod 4).

We mention a handy recursion.

Let q denote a nonzero scalar in [formula]. Then for all integers n,

[formula]

Routine calculation using ([\ref=eq:odddef]) and ([\ref=eq:evenndef]).

Let q denote a nonzero element of [formula] such that [formula]. Then [formula] for all integers n.

The scalars [0]q and [2]q are contained in [formula], since these equal 0 and 1, respectively. By this and a routine induction using Lemma [\ref=lem:recnq], we find [n]q is contained in [formula] for all even integers n. The scalars [ - 1]q and [1]q are contained in [formula], since these equal - 1 and 1, respectively. By this and a routine induction using Lemma [\ref=lem:recnq], we find [n]q is contained in [formula] for all odd integers n.

Let d denote a nonnegative integer, and let [formula] denote a sequence of scalars taken from [formula]. Let β denote a scalar in [formula], and assume [formula] is β-recurrent. Let q denote a nonzero scalar in [formula] such that q + q- 1  =  β. Then for 0  ≤  i,j,r,s  ≤  d we have

[formula]

provided i + j = r + s.

Let the integers i,j,r,s be given, and assume i + j = r + s. First suppose [formula], [formula]. Let n denote the common value of i + j, r + s, and for convenience set e  =  q1 / 2 - q- 1 / 2 (if n is odd) and e = q - q- 1 (if n is even). Observe r - s and r + s = n have the same parity, so by Definition [\ref=def:nbracknv],

[formula]

Similarly

[formula]

By Lemma [\ref=lem:closedf](i), there exists scalars a,b,c in [formula] such that [formula] are given by ([\ref=eq:maincase]). Observe

[formula]

Similarly

[formula]

Combining ([\ref=eq:iminj])-([\ref=eq:rmins2]) we obtain ([\ref=eq:handyf]). We have now proved the lemma for the case [formula], [formula]. The proof for the cases q = 1, q =  - 1 is similar, and omitted.

Let q denote a nonzero scalar in [formula], and let r,s,t denote nonnegative integers. A bit later in the paper, we will define some expressions [r,s,t]q that make sense under the assumption [formula] for 1  ≤  i  ≤  r + s + t. We comment on this assumption. First observe [1]q and [2]q are nonzero, since these scalars both equal 1. For i  ≥  3, it could happen that [i]q = 0; we explain how in the rext result.

Let q denote a nonzero scalar in [formula], and let i denote a positive integer. Then (i)-(vi) hold below.

Assume [formula], [formula]. Then [i]q  =  0 if and only if qi = 1.

Assume q = 1 and that [formula] has characteristic 0. Then [formula].

Assume q = 1 and that [formula] has characteristic p, p  ≥  3. Then [i]q = 0 if and only if p divides i.

Assume q =  - 1 and that [formula] has characteristic 0. Then [formula].

Assume q =  - 1 and that [formula] has characteristic p, p  ≥  3. Then [i]q = 0 if and only if 2p divides i.

Assume q = 1 and that [formula] has characteristic 2. Then [i]q = 0 if and only if 4 divides i.

First assume [formula], [formula]. Then [i]q is a nonzero scalar multiple of qi - 1 by Definition [\ref=def:nbracknv], and assertion (i) follows. Next assume q = 1 and that the characteristic of [formula] is not 2. Then the sequence [formula] is given by [formula] and assertions (ii), (iii) follow. Next assume q =  - 1 and that the characteristic of [formula] is not 2. Then the sequence [formula] is given by [formula] and assertions (iv), (v) follow. Now assume q = 1 and that [formula] has characteristic 2. Then the sequence [formula] is given by [formula] and assertion (vi) follows.

Let d denote an integer at least 3. Let [formula] denote a sequence of distinct scalars taken from [formula], and assume

[formula]

is independent of i for 2  ≤  i  ≤  d - 1. Let q denote a nonzero scalar in [formula] such that q + q- 1 + 1 equals the common value of ([\ref=eq:sigfrac]). Then [formula] for 1  ≤  i  ≤  d.

Abbreviate β = q + q- 1, and observe [formula] is β-recurrent. First suppose [formula] and [formula]. Then for 1  ≤  i  ≤  d we have [formula]; otherwise σi  =  σ0 by Lemma [\ref=lem:closedf](i). The result now follows by Lemma [\ref=lem:branotz](i). Next suppose q = 1 and that [formula] has characteristic 0. Then the result holds by Lemma [\ref=lem:branotz](ii). Next suppose q = 1 and that [formula] has characteristic p, p  ≥  3. Then d < p; otherwise σp  =  σ0 in view of Lemma [\ref=lem:closedf](ii). The result now follows by Lemma [\ref=lem:branotz](iii). Next suppose q =  - 1 and that [formula] has characteristic 0. Then the result holds by Lemma [\ref=lem:branotz](iv). Next suppose q =  - 1 and that [formula] has characteristic p, p  ≥  3. Then d < 2p; otherwise σ2p  =  σ0 in view of Lemma [\ref=lem:closedf](iii). The result now follows by Lemma [\ref=lem:branotz](v). Now suppose q = 1 and that [formula] has characteristic 2. Then d  ≤  3; otherwise σ4  =  σ0 by Lemma [\ref=lem:closedf](iii) and the comment at the end of that lemma. The result now follows by Lemma [\ref=lem:branotz](vi).

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and assume d  ≥  3. Let q denote a nonzero scalar in [formula] such that q + q- 1  +  1 equals the common value of ([\ref=eq:betaplusone]). Then [formula] for 1  ≤  i  ≤  d.

Apply Lemma [\ref=lem:restnv] to the eigenvalue sequence of Φ.

We finish this section with a definition.

Let q denote a nonzero scalar in [formula]. For each nonnegative integer n we define

[formula]

We interpret [0]!q = 1.

The scalars [r,s,t]q

A bit later in the paper we will compute, for each ordered pair g,h of adjacent elements in S4, the entries in the transition matrix from the basis [g] to the basis [h]. Among the entries in these transition matrices, we will encounter an expression that occurs so often we will give it a name. The details are in the following definition.

Let q denote a nonzero scalar in [formula] and let r,s,t denote nonnegative integers. We define the expressions (r,s,t)q and [r,s,t]q as follows. We set

[formula]

Next assume [formula] for 1  ≤  i  ≤  r + s + t. Then we set

[formula]

We remark [formula] provided [formula]. Moreover, [r,s,t]q = 1 if at least one of r,s,t equals 0.

Referring to the above definition, to get a better appreciation for [r,s,t]q we now evaluate the expression on the right in ([\ref=eq:triplemain]) using Definition [\ref=def:nbracknv]. To express our results, we use the following notation. For all [formula] we define

[formula]

and interpret (a;q)0 = 1.

Let q denote a nonzero scalar in [formula], let r,s,t denote nonnegative integers, and assume [formula] for 1  ≤  i  ≤  r + s + t.

Suppose [formula], [formula]. Then

[formula]

Suppose q = 1 and that the characteristic of [formula] is not 2. Then

[formula]

Suppose q =  - 1 and that the characteristic of [formula] is not 2. If each of r,s,t is odd, then [r,s,t]q = 0. If at least one of r,s,t is even, then

[formula]

The expression ⌊n⌋ denotes the greatest integer less than or equal to n.

Suppose q = 1 and that [formula] has characteristic 2. Recall in this case r + s + t  ≤  3 by Lemma [\ref=lem:branotz](vi). If each of r,s,t equals 1, then [r,s,t]q = 0. If at least one of r,s,t equals 0 then [r,s,t]q = 1.

Concerning the expressions on the right in ([\ref=eq:nextlevel]), ([\ref=eq:nextlevelone]), ([\ref=eq:nextlevelminone]), the denominator is nonzero by Lemma [\ref=lem:branotz].

Evaluate ([\ref=eq:triplemain]) using Definition [\ref=def:nbracknv], ([\ref=eq:nqfact]), and ([\ref=eq:curvedef]).

We will need the following identity.

Let q denote a nonzero scalar in [formula], and let r,s,t denote positive integers. Assume [formula] for 1  ≤  i < r + s + t. Then with reference to Definition [\ref=def:bra] we have

[formula]

First assume [formula] and [formula]. By Definition [\ref=def:nbracknv], and since the integers r + t,r - t have the same parity, we find

[formula]

Using ([\ref=eq:nextlevel]), we obtain

[formula]

where

[formula]

One readily verifies

[formula]

Multiplying both sides of ([\ref=eq:fif]) by x, and evaluating the result using ([\ref=eq:rptrmt])-([\ref=eq:tmone]), we routinely obtain ([\ref=eq:ident]). We have now proved the result for the case [formula], [formula]. The proof for the cases q = 1, q =  - 1 are similar, and omitted.

The scalars ε0,εd,ε*0,ε*d

In the next section we will compute, for each ordered pair g,h of adjacent elements in S4, the entries in the transition matrix from the basis [g] to the basis [h]. Recall our 24 bases are constructed using four vectors η0,ηd,η*0,η*d, and each of these vectors is determined only up to multiplication by a nonzero scalar. To account for this, we introduce four scalars ε0,εd,ε*0,ε*d.

For convenience, we make the following definition.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]). We define

[formula]

where the θi,θ*i are from Definition [\ref=def:evseq].

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]). Then with reference to Definition [\ref=def:etilde],

[formula]

[formula]

[formula]

[formula]

To get (i), set i = 0 in ([\ref=eq:primiddef]) and compare the result with ([\ref=eq:tildeedef]). Assertions (ii)-(iv) are similarily proved.

Let Φ denote a Leonard system in ([\ref=eq:ourstartingpt]). Let g denote the element d*00*d of S4 and recall by Lemma [\ref=lem:reconcile] that [g] is a Φ-split basis. For 0  ≤  i,j  ≤  d, the [formula] entry of the matrices Ẽg0, Ẽgd, Ẽ* g0, Ẽ* gd are given as follows.

The [formula] entry of Ẽg0 is

[formula]

if j = 0, and 0 if [formula].

The [formula] entry of Ẽgd is

[formula]

if i = d, and 0 if [formula].

The [formula] entry of Ẽ* g0 is

[formula]

if i = 0, and 0 if [formula].

The [formula] entry of Ẽ* gd is

[formula]

if j = d, and 0 if [formula].

The entries of Eg0, Egd, E* g0, E* gd are given in [\cite=LS99]. Using these entries and Lemma [\ref=lem:etildee], we routinely obtain the assertions of the present lemma.

For notational convenience, we introduce the following notation.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]). We set

[formula]

where [formula] denotes the first split sequence of Φ and where [formula] denotes the second split sequence of Φ. We observe by Theorem [\ref=thm:classls](i) that [formula], [formula].

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]). Then with reference to Definition [\ref=def:etilde], the trace of each of ẼdẼ*0, Ẽ0Ẽ*d equals φ. Moreover, the trace of each of Ẽ0Ẽ*0, ẼdẼ*d equals φ.

Using the data in Lemma [\ref=lem:tildeaction], we routinely find the trace of ẼdẼ*0 equals φ. To obtain the remaining assertions, apply this result to the relatives of Φ, and use Theorem [\ref=thm:phimod].

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]). Then with reference to Definition [\ref=def:etilde],

[formula]

We first prove the equation on the left in ([\ref=eq:bkf1]). Since E*0 is a rank one idempotent, and since Ẽ*0 is a nonzero scalar multiple of E*0, there exists a scalar [formula] such that Ẽ*0ẼdẼ*0  =  αẼ*0. We show α  =  φ. We mentioned Ẽ*0 is a nonzero scalar multiple of E*0, so

[formula]

We take the trace of each side of ([\ref=eq:middle]). Observe the trace of E*0 equals 1, so the trace of the right side of ([\ref=eq:middle]) equals α. Since XY and YX have the same trace, and using Ẽ*0E*0  =  Ẽ*0, we find in view of Lemma [\ref=lem:tractildee] that the trace of the left side of ([\ref=eq:middle]) equals φ. Apparently α  =  φ, and this implies the equation on the left in in ([\ref=eq:bkf1]). Applying this result to the relatives of Φ, we obtain the remaining assertions.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]). Then with reference to Definition [\ref=def:etilde], we have the following.

[formula]

The equation on the left in ([\ref=eq:tripleprod]) is readily obtained using the matrix representations given in Lemma [\ref=lem:tildeaction]. Applying this equation to the relatives of Φ, we obtain the remaining equations in ([\ref=eq:tripleprod]), ([\ref=eq:tripleprod2]).

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. Let η0,ηd,η*0,η*d denote nonzero vectors in V that satisfy ([\ref=eq:videf]). Then there exists nonzero scalars ε0,εd,ε*0,ε*d in [formula] such that

[formula]

Let ε*0 denote an arbitrary nonzero scalar in [formula]. To obtain ε0, consider the basis [d*d00*] from the table of Theorem [\ref=thm:bases], row 10. Using ([\ref=eq:tildeedef]), we recognize the vector Ẽ0η*0 is the [formula] vector in this basis. By Theorem [\ref=thm:bases], we find Ẽ0η*0 is a basis for E0V. By the construction η0 is a basis for E0V, so Ẽ0η*0 is a nonzero scalar multiple of η0. Apparently, there exists a nonzero scalar [formula] that satisfies the equation on the left in ([\ref=eq:e0]). Similarly, there exists nonzero scalars εd,ε*d in [formula] that satisfy the equations on the left in ([\ref=eq:ed]), ([\ref=eq:eds]), respectively. To obtain the equation on the right in ([\ref=eq:eds]), apply the equation on the left in ([\ref=eq:tripleprod]) to η*0  /  ε*0, and evaluate the result using E*0η*0  =  η*0, Lemma [\ref=lem:etildee](iii), and the equations on the left in ([\ref=eq:ed]), ([\ref=eq:eds]), ([\ref=eq:e0]). To obtain the equation on the left in ([\ref=eq:e0s]), apply the equation on the right in ([\ref=eq:bkf3]) to η*0  /  ε*0, and evaluate the result using E*0η*0  =  η*0, Lemma [\ref=lem:etildee](iii), and the equation on the left in ([\ref=eq:e0]). The equations on the right in ([\ref=eq:ed]), ([\ref=eq:e0s]), ([\ref=eq:e0]) are similarly obtained.

The scalars ε0,εd,ε*0,ε*d from Lemma [\ref=lem:newvi] are "free" in the following sense. Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. Let ε0,εd,ε*0,ε*d denote arbitrary nonzero scalars in [formula]. Then there exists nonzero vectors η0,ηd,η*0,η*d in V that satisfy ([\ref=eq:videf]) and ([\ref=eq:ed])-([\ref=eq:e0]).

The reader may notice a certain lack of symmetry in the definition of ε0,εd,ε*0, ε*d. We accept this asymmetry to avoid introducing the square roots of φ and φ. We remark these square roots may not be in [formula]. To display the underlying symmetry in ([\ref=eq:ed])-([\ref=eq:e0]), make the following change of variables:

[formula]

The following equations will be useful.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. Let η0,ηd,η*0,η*d denote nonzero vectors in V that satisfy ([\ref=eq:videf]). Let the scalars ε0,εd,ε*0,ε*d be as in Lemma [\ref=lem:newvi]. Then

[formula]

First consider the equation on the left in ([\ref=eq:dds]). Comparing the two equations in ([\ref=eq:ed]), we find Ẽdη*d  /  ε*d  =  Ẽdη*0  /  ε*0. Recall Ed is a scalar multiple of Ẽd, so Edη*d  /  ε*d  =  Edη*0  /  ε*0. We now have the equation on the left in ([\ref=eq:dds]). The remaining equations in ([\ref=eq:dds]), ([\ref=eq:dds2]) are similarly proved.

The 24 bases; transition matrices

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let V denote the irreducible left A-module. For each element g∈S4, we displayed in Theorem [\ref=thm:bases] a basis for V, denoted [g]. In this section we compute, for each ordered pair g,h of adjacent elements of S4, the entries in the transition matrix from the basis [g] to the basis [h].

We mention a few points from linear algebra. In line ([\ref=eq:transdefpre]) we recalled the notion of a transition matrix. We now recall the closely related concept of an intertwining matrix. Let g,h denote elements of S4, and consider the corresponding bases [g], [h] of V. By an intertwining matrix from [g] to [h], we mean a nonzero matrix [formula] satisfying

[formula]

We observe a matrix in [formula] is an intertwining matrix from [g] to [h] if and only if it is a nonzero scalar multiple of the transition matrix from [g] to [h].

The following matrix will play a role in our discussion. We let Z denote the matrix in [formula] with entries

[formula]

We observe Z2 = I.

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let g,h denote elements in S4. Then for all [formula], the following are equivalent.

S is an intertwining matrix from [g] to [h].

S is nonzero and both

[formula]

The implication (i)  →  (ii) is clear, so consider the implication (ii)  →  (i). Let T denote the transition matrix from [g] to [h]. We show S is a nonzero scalar multiple of T. Since T is the transition matrix from [g] to [h], it is an intertwining matrix from [g] to [h]. Therefore

[formula]

Combining ([\ref=eq:twocond]), ([\ref=eq:twoconds]), we find ST- 1 commutes with both Ag and A* g. We mentioned the map X  →  Xg from A to [formula] is an isomorphism of [formula]-algebras. Combining this with our previous comment and using Corollary [\ref=cor:rig], we see ST- 1 is a scalar multiple of the identity. Denoting this scalar by α we have S = αT. We observe [formula] since [formula]. Apparently S is a nonzero scalar multiple of T, so S is an intertwining matrix from [g] to [h].

Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]). With reference to Definition [\ref=def:S4interp], let wxyz denote an element of S4, and consider the transition matrices from the basis [wxyz] to the bases

[formula]

The first and second transition matrices are diagonal and lower triangular, respectively, and their entries are given in the following tables. The third transition matrix is the matrix Z from ([\ref=eq:zmat]). In the tables below, [formula] (resp. [formula]) denotes the eigenvalue sequence (resp. dual eigenvalue sequence) for Φ. Moreover [formula] (resp. [formula]) denotes the first split sequence (resp. second split sequence) for Φ. The scalars φ,φ are from ([\ref=eq:phiabb]), and the scalars ε0,εd,ε*0,ε*d are from Lemma [\ref=lem:newvi].

In the above table, q denotes a scalar in the algebraic closure of [formula] such that q + q- 1 + 1 is the common value of ([\ref=eq:betaplusone]).

The basis [wxzy], which is on the right in ([\ref=eq:threetargets]), is the inversion of [wxyz] by Lemma [\ref=lem:transshape](iii). Apparently Z is the transition matrix from [wxyz] to [wxzy]. We now consider the other two bases in ([\ref=eq:threetargets]). For these we prove our assertions case by case. We begin with the first row of the first table, where wxyz equals d*00*d. We consider the transition matrix from [d*00*d] to [0d*0*d]. We denote this matrix by T and let D denote the diagonal matrix in [formula] with [formula] entry

[formula]

We show D = T. Recall [formula] by Lemma [\ref=lem:newvi], and [formula] by Definition [\ref=def:phinot], so [formula]. Using the data in the first table in Theorem [\ref=thm:repa], rows 1 and 2, we routinely find AgD  =  DAh and A* gD  =  DA* h, where we abbreviate g for d*00*d and h for 0d*0*d. Applying Lemma [\ref=lem:whentrans], we find D is an intertwining matrix from [d*00*d] to [0d*0*d]. Therefore D is a scalar multiple of T. We show this scalar is 1. To do this, we compare the [formula] entry of D and T. Setting i = d in ([\ref=eq:ddef]), and recalling [formula], we find the [formula] entry of D equals εd  /  ε*0. We now find the [formula] entry of T. From the table in Theorem [\ref=thm:bases], row 1, we find the [formula] vector in the basis [d*00*d] is Ẽdη*0. From the same table, row 2, we find the [formula] vector in the basis [0d*0*d] is ηd. From the equation on the left in ([\ref=eq:ed]), we find ηd  =  εd  /  ε*0Ẽdη*0, and it follows the [formula] entry of T is εd  /  ε*0. We now see D and T have the same [formula] entry, so D = T. In particular, D is the transition matrix from [d*00*d] to [0d*0*d].

We now consider the transition matrix from [d*00*d] to [d*0*0d]. We found the transition matrix from [d*0*0d] to [d*00*d] in the proof of Theorem [\ref=thm:repa]. To summarize, let L denote the matrix in [formula] with [formula] entry

[formula]

Then L is the transition matrix from [d*0*0d] to [d*00*d]. To get the transition matrix from [d*00*d] to [d*0*0d], we find the inverse of L. Observe L is lower triangular. Let K denote the lower triangular matrix in [formula] with [formula] entry

[formula]

for 0  ≤  j  ≤  i  ≤  d. We recall [formula] are mutually distinct, so the denominator in ([\ref=eq:kent]) is nonzero. We claim K is the inverse of L. To prove this, we show LK  =  I. The matrices L and K are both lower triangular, so LK is lower triangular. By ([\ref=eq:ldefrem]), ([\ref=eq:kent]) we find that for 0  ≤  i  ≤  d,

[formula]

so (LK)ii  =  1. We now show (LK)ij = 0 for 0  ≤  j < i  ≤  d. Let i,j be given. It suffices to show (θi  -  θj)(LK)ij  =  0, since [formula] are mutually distinct. Observe

[formula]

since the two sums in ([\ref=eq:twosum]) are one and the same. We have now shown (LK)ij  =  0 for 0  ≤  j < i  ≤  d. Combining our above arguments, we find LK = I so K is the inverse of L. Now apparently K is the transition matrix from [d*00*d] to [d*0*0d].

We have now proved our assertions concerning the first row of the first table. Applying these assertions to the relatives of Φ, and using both Theorem [\ref=thm:phimod] and Note [\ref=note:nosym], we obtain our assertions concerning the first and fourth rows of each block of the first table.

We now consider the second row of the first table, where wxyz equals 0d*0*d. We find the transition matrix from [0d*0*d] to [d*00*d]. Referring to the diagonal matrix D from ([\ref=eq:ddef]) we showed D is the transition matrix from [d*00*d] to [0d*0*d]. Therefore D- 1 is the transition matrix from [0d*0*d] to [d*00*d].

We now consider the transition matrix from [0d*0*d] to [00*d*d]. Let q denote a nonzero scalar in [formula] such that q + q- 1 + 1 is the common value of ([\ref=eq:betaplusone]). Let H denote the lower triangular matrix in [formula] with [formula] entry

[formula]

for 0  ≤  j  ≤  i  ≤  d. The expression [j,i - j,d - i]q is given in ([\ref=eq:triplemain]). We remark each of [formula] is nonzero by Corollary [\ref=lem:dennonz], so the denominator in [j,i - j,d - i]q is nonzero. We show H is the transition matrix from [0d*0*d] to [00*d*d]. Observe Hii  =  1 for 0  ≤  i  ≤  d, so H is invertible. We show A* gH = HA* h, where we abbreviate g for 0d*0*d and h for 00*d*d. The entries of A* g and A* h are given in the first table of Theorem [\ref=thm:repa], rows 2 and 15. Using this information, we find that for 0  ≤  i,j  ≤  d, the ijth entry of A* gH is given by

[formula]

where we interpret Hi + 1,j = 0 if i = d. Similarily, the ijth entry of HA* h is given by

[formula]

where we interpret Hi,j - 1 = 0 if j = 0. We show ([\ref=eq:ent1]) equals ([\ref=eq:ent2]) or in other words

[formula]

To prove ([\ref=eq:needed]), first suppose j - i > 1. Then each of Hij, Hi,j - 1, Hi + 1,j is zero since H is lower triangular, so both sides of ([\ref=eq:needed]) are zero. Next suppose j - i = 1. Then Hij = 0 since H is lower triangular. Moreover Hi,j - 1 = Hii = 1 and Hi + 1,j = Hjj  =  1, so both sides of ([\ref=eq:needed]) are zero. Next suppose i = d and j = 0. Then both sides of ([\ref=eq:needed]) are zero. Next suppose i = d and 1  ≤  j  ≤  d. Then using ([\ref=eq:tentry]) we find both sides of ([\ref=eq:needed]) equal [formula]. Next suppose 0  ≤  i < d and j = 0. Then using ([\ref=eq:tentry]) we find both sides of ([\ref=eq:needed]) equal the opposite of [formula]. Finally suppose 1  ≤  j  ≤  i  ≤  d - 1. To verify ([\ref=eq:needed]) in this case, we use Lemma [\ref=lem:ident]. Set r = j, s = i - j + 1, t = d - i, and observe each of r,s,t is positive. Since r + s + t = d + 1, and since each of [formula] is nonzero, we find [formula] for 1  ≤  h < r + s + t. Apparently our choice of r,s,t satisfy the conditions of Lemma [\ref=lem:ident]. Applying that lemma we find

[formula]

Applying Lemma [\ref=lem:eigformnv] to the sequence [formula], and recalling each of [formula] is nonzero, we find

[formula]

Combining ([\ref=eq:neededz]), ([\ref=eq:neededt2]) we obtain

[formula]

Multiplying both sides of ([\ref=eq:neededt]) by [formula], and evaluating the result using ([\ref=eq:tentry]), we routinely obtain ([\ref=eq:needed]). We have now shown ([\ref=eq:needed]) holds for 0  ≤  i,j  ≤  d, and it follows A* gH  =  HA* h. Recall we are trying to show H is the transition matrix from [0d*0*d] to [00*d*d]. Let N denote this transition matrix. To show H = N, we proceed in two steps. We first show H is a scalar multiple of N. We then show this scalar equals 1. Proceeding with the first step, we define S: = NH- 1 and show S is a scalar multiple of the identity. By Lemma [\ref=lem:transshape](ii), we find N is lower triangular. Recall H is lower triangular, so S is lower triangular. Since N is the transition matrix from [0d*0*d] to [00*d*d] we find N is an intertwining matrix from [0d*0*d] to [00*d*d]. Therefore A* gN  =  NA* h. Combining this with A* gH  =  HA* h, we find SA* g = A* gS. We claim S is diagonal. Suppose not. Then there exists a pair of integers i,j (0  ≤  j < i  ≤  d) such that [formula]. Of all such pairs i,j pick one with i - j maximal. We compute the [formula] entry in SA* g = A* gS. Observe the [formula] entry of SA* g is Sijθ*j and that of A* gS is θ*iSij, so (θ*i  -  θ*j)Sij = 0. Observe [formula], so Sij = 0, a contradiction. We have now shown S is diagonal. Computing entries just above the main diagonal in SA* g = A* gS, we find S is a scalar multiple of the identity. Apparently H is a scalar multiple of N. We now show this scalar equals 1. To do this, we compare the [formula] entry of H and N. We saw above that the [formula] entry of H equals 1. We find the [formula] entry of N. From the table in Theorem [\ref=thm:bases], row 2, we find the [formula] vector in the basis [0d*0*d] is ηd. From the same table, row 15, we find the [formula] vector in the basis [00*d*d] is ηd. Apparently the [formula] entry of N equals 1. We now see H and N have the same [formula] entry, so H = N. In particular H is the transition matrix from [0d*0*d] to [00*d*d].

We have now proved our assertions concerning the second row of the first table. Applying these assertions to the relatives of Φ, and using both Theorem [\ref=thm:phimod] and Note [\ref=note:nosym], we obtain our assertions concerning the second and third rows of each block of the first table. We have now verified all our assertions concerning the first table.

Consider the first row of the second table, where wxyz equals d*0*0d. We find the transition matrix from [d*0*0d] to [0*d*0d]. Let P denote this matrix and let F denote the diagonal matrix in [formula] with diagonal entries

[formula]

We show F = P. To do this, we first show F is an intertwining matrix from [d*0*0d] to [0*d*0d]. Clearly [formula]. We show AgF  =  FAh, A* gF  =  FA* h, where we abbreviate g for d*0*0d and h for 0*d*0d. The matrices representing A and A* with respect to [d*0*0d] and [0*d*0d] are given in the second table of Theorem [\ref=thm:repa], rows 1 and 2. Using the data in these rows, we routinely find AgF  =  FAh, A* gF  =  FA* h. Applying Lemma [\ref=lem:whentrans], we find F is an intertwining matrix from [d*0*0d] to [0*d*0d]. Now apparently F is a scalar multiple of P. We show this scalar equals 1. To do this, we compare the [formula] entry of F and P. Setting i = d in ([\ref=eq:fdef]), and recalling [formula], [formula], we find the [formula] entry of F equals ε*d  /  ε*0. We now find the [formula] entry of P. From the table in Theorem [\ref=thm:bases], row 17, we find the [formula] vector in the basis [d*0*0d] is Edη*0. From the same table, row 18, we find the [formula] vector in the basis [0*d*0d] is Edη*d. From the equation on the left in ([\ref=eq:dds]), we find Edη*d  =  ε*d  /  ε*0Edη*0. Apparently the [formula] entry of P equals ε*d  /  ε*0. We now see F and P have the same [formula] entry, so F = P. In particular, F is the transition matrix from [d*0*0d] to [0*d*0d].

We already found the transition matrix from [d*0*0d] to [d*00*d]. This is the matrix L from ([\ref=eq:ldefrem]).

We have now obtained our assertions concerning the first row of the second table. Applying these assertions to the relatives of Φ, and using both Theorem [\ref=thm:phimod] and Note [\ref=note:nosym], we obtain all our assertions concerning the second table. This completes the proof.

We finish this section with some comments on transition matrices. Let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), and let g,h denote elements in S4. Consider the transition matrix from the basis [g] to the basis [h]. If g and h are adjacent in the sense of Definition [\ref=def:S4interp], then this transition matrix is given in Theorem [\ref=thm:trans]. If the above restriction on g,h is removed, then this transition matrix can be computed as follows. To explain the idea, we use the following notation. By an edge in S4, we mean an ordered pair consisting of adjacent elements of S4. Let r denote a nonnegative integer. By a walk of length r in S4, we mean a sequence [formula] of elements of S4 such that gi - 1,gi is an edge for 1  ≤  i  ≤  r. The above walk is said to be from g0 to gr. let gh denote an edge in S4. By the weight of that edge, we mean the transition matrix from [g] to [h]. Let [formula] denote a walk in S4. By the weight of this walk, we mean the product [formula], where Wi is the weight of the edge gi - 1,gi for 1  ≤  i  ≤  r. Let g,h denote elements in S4. Then the transition matrix from [g] to [h] is given by the weight of any walk from g to h.

Remarks

In the introduction to this paper, we mentioned that Leonard pairs are related to certain orthogonal polynomials contained in the Askey scheme. One significance of the polynomials is that they give the entries in the transition matrices relating certain pairs of bases among our set of 24. In this section, we illustrate what is going on with some examples. For related work, see [\cite=GYZnature], [\cite=GYLZmut], [\cite=GYZlinear], [\cite=Zhidd] and [\cite=Koelink3], [\cite=Koelink1], [\cite=Koelink2], [\cite=Koelink4], [\cite=koo3], [\cite=Hjal].

Throughout this section, we let Φ denote the Leonard system in ([\ref=eq:ourstartingpt]), with eigenvalue sequence [formula], dual eigenvalue sequence [formula], first split sequence [formula] and second split sequence [formula]. For 0  ≤  i,j  ≤  d we define

[formula]

We observe Pij is a polynomial of degree j in θi and a polynomial of degree i in θ*j. These are the polynomials of interest.

The Pij arise in the following context. Let V denote the irreducible left A-module. In Theorem [\ref=thm:bases], we presented 24 bases for V. Of these, we focus on the following two:

[formula]

We recall the basis ([\ref=eq:stbasiscom]) is a Φ-standard basis. With respect to this basis, the matrix representing A is diagonal, and the matrix representing A* is irreducible tridiagonal. We denote these matrices by H and B*, respectively. Their entries are given in the second table of Theorem [\ref=thm:repa], row 1. The basis ([\ref=eq:dstbasiscom]) is a Φ*-standard basis. With respect to this basis, the matrix representing A* is diagonal and the matrix representing A is irreducible tridiagonal. We denote these matrices by H* and B, respectively. Their entries are given in the third table of Theorem [\ref=thm:repa], row 1. Let P denote the transition matrix from ([\ref=eq:stbasiscom]) to ([\ref=eq:dstbasiscom]), with the vectors η0,η*0 chosen so that

[formula]

The effect of ([\ref=eq:goodchoice]) is that Pi0 = 1 for 0  ≤  i  ≤  d. We let P* denote the transition matrix from ([\ref=eq:dstbasiscom]) to ([\ref=eq:stbasiscom]), this time with the η0,η*0 chosen so that

[formula]

As expected P*i0 = 1 for 0  ≤  i  ≤  d. From the construction of P and P* we find there exists a nonzero scalar [formula] such that

[formula]

Moreover by Lemma [\ref=lem:whentrans] we have

[formula]

We compute the entries of P. For this we use the method outlined in the last paragraph of the previous section. The following is a walk in S4 from d*0*0d to d00*d*.

[formula]

Apparently P equals the weight of the walk ([\ref=eq:walk1]). Computing this weight using the data in Theorem [\ref=thm:trans], we find

[formula]

where Pij is from ([\ref=eq:sumpart]), and where kj equals

[formula]

times

[formula]

for 0  ≤  j  ≤  d. We now compute P*. Replacing Φ by Φ* in the above discussion, and using Theorem [\ref=thm:phimod], we routinely find

[formula]

where Pji is from ([\ref=eq:sumpart]), and where k*j equals

[formula]

times

[formula]

for 0  ≤  j  ≤  d. We now compute the scalar ν from ([\ref=eq:ppn]). From the construction of P and P* we routinely find νE0E*0E0 = E0. Taking the trace in this equation we find

[formula]

Evaluating the left side in ([\ref=eq:tracen]) using Lemma [\ref=lem:etildee] and Lemma [\ref=lem:tractildee], we routinely find

[formula]

From ([\ref=eq:ppn]) we obtain the following orthogonality relations for the Pij. Expanding the left side of PP*  =  νI using matrix multiplication, and evaluating the result using ([\ref=eq:pcalp]), ([\ref=eq:pcalps]) we find

[formula]

Doing something similar with the equation P*P = νI we find

[formula]

We remark the equations ([\ref=eq:prel]) express several three-term recurrences satisfied by the Pij.

We now indicate how the Pij fit into the Askey scheme. Instead of giving a complete treatment, we content ourselves with two examples.

Our first example is associated with the Leonard pair from ([\ref=eq:fam1]). For this example the Pij will turn out to be Krawtchouk polynomials. Let d denote a nonnegative integer, and consider the following elements of [formula].

[formula]

To avoid degenerate situations, we assume the characteristic of [formula] is zero or an odd prime greater than d. It is routine to show ([\ref=eq:thsol]), ([\ref=eq:vpsol]) satisfy the conditions (i)-(v) of Theorem [\ref=thm:classls]. Let us assume Φ is the corresponding Leonard system from that theorem. For this Φ, we routinely find B and B* both equal the matrix on the left in ([\ref=eq:fam1]). Moreover H and H* both equal the matrix on the right in ([\ref=eq:fam1]). Pick any integers i,j (0  ≤  i,j  ≤  d). Evaluating the right side of ([\ref=eq:sumpart]) using ([\ref=eq:thsol]), ([\ref=eq:vpsol]), we find Pij equals

[formula]

where

[formula]

Hypergeometric series are defined in [\cite=gasperrahmanbk]. From this definition we find ([\ref=eq:2F1expand]) is the hypergeometric series

[formula]

A definition of the Krawtchouk polynomials can be found in [\cite=AAR] or [\cite=KoeSwa]. Comparing this definition with ([\ref=eq:2F1not]), we find Pij is a Krawtchouk polynomial of degree j in θi and a Krawtchouk polynomial of degree i in θ*j. Pick an integer j (0  ≤  j  ≤  d). Evaluating ([\ref=eq:kjpart1]), ([\ref=eq:kjpart2]) and ([\ref=eq:kjspart1]), ([\ref=eq:kjspart2]) using ([\ref=eq:thsol]), ([\ref=eq:vpsol]), we find kj and k*j both equal the binomial coefficient

[formula]

Evaluating ([\ref=eq:nclform]) using ([\ref=eq:thsol]), ([\ref=eq:vpsol]) we find ν = 2d. We comment that for this example P = P*, so P2 = 2dI.

We now give our second example. For this example the Pij will turn out to be q-Racah polynomials. To begin, let d denote a nonnegative integer, and consider the following elements in [formula].

[formula]

for 0  ≤  i  ≤  d, and

[formula]

for 1  ≤  i  ≤  d. We assume q,h,h*,s,s*,r1,r2 are nonzero scalars in the algebraic closure [formula], and that r1r2  =  ss*qd + 1. It is routine to show ([\ref=eq:thdefend])-([\ref=eq:phidefend]) give a parametric solution to Theorem [\ref=thm:classls](iii)-(v). Let us assume conditions (i),(ii) of Theorem [\ref=thm:classls] are satisfied as well, so that ([\ref=eq:thdefend])-([\ref=eq:phidefend]) correspond to a Leonard system. We assume Φ is the corresponding Leonard system from Theorem [\ref=thm:classls]. For this Φ we find B, B*, Pij, kj, k*j, ν. Recall the entries of B are given in the third table of Theorem [\ref=thm:repa], row 1. Evaluating these entries using ([\ref=eq:thdefend])-([\ref=eq:phidefend]), we find

[formula]

where we define B0, - 1: = 0, Bd,d + 1: = 0. The entries of B* are similarly obtained. To get the entries of B*, in the above formulae exhange (θ0,h,s) and (θ*0,h*,s*), and preserve (r1,r2,q). Pick integers i,j (0  ≤  i,j  ≤  d). Evaluating the right side of ([\ref=eq:sumpart]) using ([\ref=eq:thdefend])-([\ref=eq:phidefend]), we find Pij equals

[formula]

where

[formula]

Basic hypergeometric series are defined in [\cite=gasperrahmanbk]. From that definition we find ([\ref=eq:uihyper]) is the basic hypergeometric series

[formula]

A definition of the q-Racah polynomials can be found in [\cite=Ask], [\cite=AskAW], or [\cite=KoeSwa]. Comparing this definition with ([\ref=eq:qrac]), and recalling r1r2 = ss*qd + 1, we find Pij is a q-Racah polynomial of degree j in θi and a q-Racah polynomial of degree i in θ*j. Pick an integer j (0  ≤  j  ≤  d). Evaluating ([\ref=eq:kjpart1]), ([\ref=eq:kjpart2]) using ([\ref=eq:thdefend])-([\ref=eq:phidefend]), we find

[formula]

The scalar k*j is similarly found. To get k*j, in ([\ref=eq:qrack]) exchange s and s*, and preserve (r1,r2,q). Evaluating ([\ref=eq:nclform]) using ([\ref=eq:thdefend])-([\ref=eq:phidefend]), we find

[formula]

Paul Terwilliger, Department of Mathematics, University of Wisconsin, 480 Lincoln Drive, Madison, Wisconsin, 53706, USA email: terwilli@math.wisc.edu