= cmr10 at 10 true pt

0 pt 12 pt

Theorem Conjecture Problem Assumption Heuristic Proposition Fact Lemma Corollary Claim Question

Remark Remarks

Definition

Random symmetric matrices are almost surely non-singular

Introduction

Let An denote a random n by n matrix, whose entries are i.i.d. Bernoulli random variables, which take values 0 and 1 with probability 1 / 2. A basic question is the following

Is it true that An is almost surely non-singular ?

Here and later we say that an event holds almost surely if it holds with probability tending to one as n tends to infinity.

The above question was answered affirmatively by Komlós in 1967 [\cite=Kom1]. Later, Komlós generalized the result (to more general models of random matrices) [\cite=Kom2] and also simplified the proof [\cite=Bol1]. In a recent paper [\cite=TV1], Tao and Vu found a different proof which leads to a sharp estimate on the absolute value of the determinant of An.

Another popular model of random matrices is that of random symmetric matrices; this is one of the simplest models that has non-trivial correlations between matrix entries. Let Qn denote a random symmetric n by n matrix, whose upper diagonal entries (qij,1  ≤  i  ≤  j  ≤  n) are i.i.d. Bernoulli random variables. It is natural to ask

Is it true that Qn is almost surely non-singular ?

As far as we can trace, this question was first posed by Weiss in the early nineties. Despite its obvious similarity to Question [\ref=komlos1], we do not know of any partial results concerning this question, prior to this paper. A significant new difficulty is that the symmetry ensures that the determinant det (Qn) is a quadratic function of each row, as opposed to det (An) which is a linear function of each row.

The goal of the current paper is to give an affirmative answer to Question [\ref=weiss].

Qn is almost surely non-singular. More precisely

[formula]

for any positive constant δ (the implicit constant in the O() notation of course is allowed to depend on δ).

The exponent - 1 / 8 + δ can be improved somewhat by tightening the calculation and applying more technical arguments. However, to improve the bound to an exponential bound (in the spirit of [\cite=KKS]) seems to require new ideas; see Section [\ref=section:open].

The rest of the paper is organized as follows. In the next section, we present our approach and the key lemmas. The lemmas will be discussed in Sections 3-5. Section 6 is devoted to the generalization of the result to other models of random matrices. We conclude by Section [\ref=section:open] which contains several open questions.

Notation. In the whole paper, we assume that n is large, whenever needed. The asymptotic notations are used under the assumption that n  →    ∞  . [formula] and [formula] denote expectation and variance, respectively; log  denotes the logarithm with natural base.

The approach and main lemmas

As mentioned above, there are now three different proofs of Komlós 1967 result on the non-singularity of An. The simpler ones are [\cite=Bol1] and [\cite=TV1]. But the original (and longest) proof from [\cite=Kom1] is what really inspires us. The key difference between these proofs lies in the ways one generates An. In the proofs from [\cite=Bol1] and [\cite=TV1] one builds up An by exposing the row vectors one by one and making use of the independence of these vectors. This approach, unfortunately, is no longer effective for Qn, as the last few rows are almost deterministic once one has exposed all rows above them. In [\cite=Kom1], one builds up An by taking An - 1 and adding a (random) row and a (random) column. This idea turns out to be useful for the consideration of Qn. However, for Qn the additional row and column are not independent. They are transposes of each other and this has become the main obstacle. We have managed to overcome this obstacle by developing a quadratic variant of Littlewood-Offord type results concerning the concentration of random variables (see Section 4).

The basic strategy is to relate the rank of Qn with the rank of Qn + 1. Assume that we get Qn + 1 by adding a new column and its transpose as a new row to Qn. Our starting point is the following simple observation

[formula]

We shall refine this by showing that if Qn is singular (so [formula]), then [formula] will equal [formula] with high probability; similarly, if Qn is non-singular (so [formula]), then [formula] will equal [formula] with high probability. These two results together will then be easily combined with an inductive argument to show that [formula] with high probability.

We now turn to the details. Let us fix a small positive constant ε  >  0. We allow the implicit constants to depend on ε, and we will assume that n is sufficiently large depending on ε. Set

[formula]

Given m vectors {v1,v2,...,vm}, a linear combination of the vi is a vector [formula], where the ci are real numbers. We say that a linear combination vanishes if v is the zero vector. A vanishing linear combination has degree k if exactly k among the ci are non-zero. We call a singular n by n matrix normal if its row vectors do not admit a non-trivial vanishing linear combination with degree less than N. Otherwise we call the matrix abnormal.

We use the terms normal and abnormal only when the matrix in question is singular. These terms are not defined (and we don't need them) for non-singular matrices.

In Section [\ref=abim-sec] we shall prove that most singular matrices are normal:

The probability that Qn is singular and abnormal is O((2 / 3)n).

In Section [\ref=rank-sec] we shall prove

Let A be a (deterministic) n by n singular normal matrix, and let A' be the n + 1 by n + 1 matrix formed by augmenting A by a random vector of length n + 1 and its transpose. Then

[formula]

and thus

[formula]

Intuitively, these two lemmas state that in most cases, augmenting a singular matrix by a random vector and its transpose will increase the rank by exactly 2. Note that by Bayes' identity, Lemma [\ref=lemma:rankincrease1] automatically generalizes to matrices A which are random instead of deterministic, as long as the random vector which is augmenting A is independent of A.

We now develop analogues of the above two lemmas for non-singular matrices.

A row of an n by n non-singular matrix is called good if its exclusion leads to an (n - 1)  ×  n matrix whose column vectors admit a nontrivial vanishing linear combination with degree at least N. (In fact, there is exactly one such combination-up to scaling-as the rank of this (n - 1)  ×  n matrix is n - 1.) A row is bad otherwise. We say that an n  ×  n non-singular matrix A is perfect if every row in A is a good row. If a non-singular matrix is not perfect, we call it imperfect.

We use the terms perfect and imperfect only when the matrix in question is non-singular. These terms are not defined for singular matrices.

In Section [\ref=abim-sec] we shall prove that most non-singular matrices are perfect:

The probability that Qn is both non-singular and imperfect is O((2 / 3)n).

In Section [\ref=rank-sec] we shall prove the following analogue of Lemma [\ref=lemma:rankincrease1]:

Let A be a (deterministic) non-singular perfect symmetric matrix of size n, and let A' be the (n + 1)  ×  (n + 1) matrix formed by augmenting A by a random (n+1)-vector of 0s and 1s, and its transpose. Then

[formula]

for any positive constant δ, where the implicit constant can of course depend on δ. In particular, since

[formula]

we see that

[formula]

The last two lemmas are the non-singular counterparts of the first two. Together, they state that if a matrix already has full rank, augmenting it will typically produce another matrix of full rank. Again, we can automatically generalize Lemma [\ref=lemma:rankincrease2] to the case when A is random and independent of the augmenting row.

Let us assume these lemmas for the moment and conclude the proof of Theorem [\ref=theo:main].

Consider a random matrix Qn. We embed it into a sequence {Q1,Q2,...} of random matrices, where Qn + 1 is formed from Qn by adding a random vector of 0s and 1s (independent of Qn) of length n + 1 as the last column, and its transpose as the last row.

Define the (somewhat artificial) random variable Xn by setting Xn  =  0 if Qn is non-singular (thus [formula]), and [formula] otherwise. Thus Xn ranges between 0 and (1.1)n. We have the following decay estimate for the expectation [formula] of Xn.

[formula].

For any 0  ≤  j  ≤  n, let Aj be the event that Qn has rank n - j, and that An is neither abnormal (if j > 0) nor imperfect (if j = 0). By Bayes' identity and Lemmas [\ref=lemma:abnormal], [\ref=lemma:imperfect], we have

[formula]

and

[formula]

Now let us condition on the event A0, thus Qn is non-singular. From Lemma [\ref=lemma:imperfect] we see that Qn + 1 has rank n with probability O(N- 1 / 8), and rank n + 1 otherwise. Thus

[formula]

Now let 1  ≤  j  ≤  n and condition on the event Aj, thus Qn is singular with rank n - j. From Lemma [\ref=lemma:abnormal] and Lemma [\ref=lemma:rankincrease1] we see that Qn + 1 has rank n - j + 2 with probability 1  -  O(N- 1 / 2), and has rank n - j or n - j + 1 otherwise. Thus

[formula]

if N = n1 - ε is large enough. Putting all these estimates together, and noting that

[formula]

we obtain the claim.

From the above lemma and an easy induction, we see that

[formula]

for all large n. From Markov's inequality we then see that

[formula]

Theorem [\ref=theo:main] then follows from the definition of N.

It remains to prove Lemmas [\ref=lemma:abnormal]-[\ref=lemma:rankincrease2]. This will be done in the next few sections. Among these lemmas, the first three are variants of lemmas from [\cite=Kom1] and are relatively simple. The proof of Lemma [\ref=lemma:rankincrease2] is a somewhat more complicated and requires a new machinery, discussed in Section [\ref=section:LO].

Proof of Lemmas [\ref=lemma:abnormal] and [\ref=lemma:imperfect]

The two proofs are similar and rely on the following simple observation from [\cite=Kom1] (which has also been used in [\cite=KKS], [\cite=TV1], [\cite=TV2]):

Let H be a linear subspace in [formula] of dimension at most d  ≤  n. Then it contains at most 2d vectors from {0,1}n.

The space H is spanned by the row vectors of a d'  ×  n full-ranked matrix, where [formula]. This matrix has at least one non-singular d'  ×  d' minor, thus there exists a set of d' co-ordinates of [formula] which can be used to parameterize H. But in {0,1}n, these co-ordinates take only 2d'  ≤  2d values, and the claim follows.

For any 1  ≤  d  ≤  n. Let g(n,d) be the probability that the row vectors of Qn admit a nontrivial vanishing linear combination of degree d. For d = 1 we have the easy bound g(n,1)  ≤  n2- n, since g(n,d) is simply the probability that one of the rows of Qn is entirely zero. Now take d  ≥  2. To bound g(n,d) from above, notice that by symmetry and the union bound we have the crude estimate

[formula]

where h(n,d) is the probability that the first d rows admit such combination. This means that if we fix the first d - 1 row vectors, then the dth row vector lies in the subspace spanned by these vectors. The same claim is true if we delete the first d - 1 columns from Qn (we need to do this as Qn is symmetric). The remaining entries in the dth row vector are now distributed independently in {0,1}n - d - 1, and so by Lemma [\ref=lemma:subspace] the probability of lying in the span of the first d - 1 row vectors is at most is at most 2d - 1  /  2n - d - 1. Thus the probability that Qn is singular and abnormal is at most

[formula]

by the definition [\eqref=N-def] of N.

Let b(n) be the probability that the last row of Qn is bad. By symmetry and the union bound, the probability that Qn is non-singular and imperfect is at most nb(n). We can bound b(n) using the same argument as in the previous proof, with a slight modification; the column vectors have length n - 1 so we need to replace n by n - 1, but this does not affect the bound. We omit the details.

A quadratic Littlewood-Offord inequality

Let us start by the following classical result, proved by Erdös, which strengthens an earlier result of Littlewood and Offord.

[\cite=erdos] Let [formula] be i.i.d. random variables which take values 0 and 1 with probability 1 / 2. Let [formula] be real deterministic coefficients, with |ai|  ≥  1 for at least k  ≥  1 values of i. Then for any interval [formula] of length 1, we have

[formula]

where the implied constant is absolute.

Roughly speaking, the theorem says that linear random sums cannot concentrate on small intervals if the coefficients of the underlying linear form are large.

There are a number of far reaching generalizations and interesting refinements of Theorem [\ref=theo:LO] (see e.g. [\cite=Hal] and the references therein). We mention some rather trivial ones here (which we will need later). Firstly we can replace the unit interval I by any other interval of length O(1) (at the cost of changing the implied constant in O((1 + k)- 1 / 2), of course), by covering such an interval by unit intervals. Similarly, we may scale the constraint |ai|  ≥  1 and replace it by |ai|  ≥  c for some other c  >  0, again at the cost of letting the implied constant depend on c. Finally, one can replace the distribution of the zi with the distribution [formula], where α,β,γ are non negative constants summing up to one and α < 1. The implied constant will then of course depend on α,β,γ.

To conclude the proof of Theorem [\ref=theo:main], we need to generalize Theorem [\ref=theo:LO] in a direction different from what has been done before. Instead of considering a linear form, we are going to consider a quadratic form of the zi. (In fact, our method works for polynomials of any fixed degree, by iterating the argument below.) Consider random variables zi as in Theorem [\ref=theo:LO] and define the quadratic random variable

[formula]

The main result of this section is the following quadratic generalization of Theorem [\ref=theo:LO].

Let the quadratic random variable Q be as in [\eqref=QDEF], let [formula] be any non-trivial partition, and let S be any non-empty subset of U1. For each i∈S, let di be the number of indices j∈U2 such that |cij|  ≥  1. Suppose that di  ≥  1 for each i∈S. Then for any interval I of length 1, we have

[formula]

The implied constant is absolute.

It is unlikely that the bound on the right-hand side is best possible, but for us, any bound which decays to zero when the number of large coefficients cij goes to infinity will suffice.

The proof of Theorem [\ref=theo:quadLO] is lengthy and will be given later. Assuming it for the moment, we have the following corollary:

Let Q be as in [\eqref=QDEF], and suppose that there is a set [formula] of cardinality |U|  ≥  m  ≥  2 such that for each i∈U, there are m indices [formula] where |cij|  ≥  1. Then for any interval I of length 1

[formula]

The implied constant is absolute.

Without loss of generality we may take m to be even. Let U1 be an arbitrary subset of U of cardinality m / 2 and write [formula], then for any i∈U1 there exists at least m / 2 indices j∈U2 for which |cij|  ≥  1. Applying Theorem [\ref=theo:quadLO] with S: = U1, we conclude

[formula]

as desired.

By rescaling the above corollary, we obtain the following discrete version.

Let Q be as in [\eqref=QDEF], and suppose that there are at least m indices i such that for each i there are m indices j where |cij|  ≠  0. Then

[formula]

where the implied constant is absolute.

This Corollary will be the one we use to establish Lemma [\ref=lemma:rankincrease2].

Proof of Theorem [\ref=theo:quadLO]

We now prove Theorem [\ref=theo:quadLO]. As a first attempt to prove this theorem, one might try to view the quadratic form Q as a linear form

[formula]

where the coefficients Qi are themselves linear form random variables [formula]. Thus one might hope to obtain Theorem [\ref=theo:quadLO] from two applications of Theorem [\ref=theo:LO]. Unfortunately, there is a serious obstruction to this strategy, because the coefficients [formula] are not independent of the variables [formula]. However, we can get around this obstacle by the following decoupling lemma, which relies on the Cauchy-Schwarz inequality.

Let X and Y be random variables and E = E(X,Y) be an event depending on X and Y. Then

[formula]

where X' and Y' are independent copies of X and Y, respectively. Here we use [formula] to denote the event that A and B both hold.

This lemma is a probabilistic analogue of the well-known result in extremal graph theory, that if a bipartite graph connecting n and m vertices contains at least cnm edges for some 0  ≤  c  ≤  1, then it also contains at least c4n2m2 copies of the four-cycle C4, where we include degenerate four-cycles. Indeed, the two results are easily shown to be equivalent. This decoupling lemma also plays the role of the van der Corput lemma used in Weyl's estimation of exponential sums with quadratic (or more generally polynomial) phases; indeed it is quite likely that one could obtain an estimate very similar to Theorem [\ref=theo:quadLO] by means of these techniques (combined with Esséen's concentration inequality), however we have chosen a more elementary combinatorial approach here.

Let us first consider the case when X takes a finite number of values [formula] and Y takes a finite number of values [formula]. From Bayes' identity we have

[formula]

and

[formula]

and hence by the Cauchy-Schwarz inequality

[formula]

Similarly, we have

[formula]

and

[formula]

so by Cauchy-Schwarz again

[formula]

Combining these two applications of Cauchy-Schwarz, we obtain the claim. The general case when X and Y could be take a countable or uncountable number of values then follows, either by a discretization argument, or by replacing the sums with integrals and using Fubini's theorem; we omit the details, since for our application we only need the case when X,Y take finitely many values.

We return to the task of proving Theorem [\ref=theo:quadLO]. Let Z∈{0,1}n be the random variable [formula]. Consider the quadratic form [formula] defined by [\eqref=QDEF], and fix a non-trivial partition [formula] and a non-empty subset S of U1. Let I be an interval of length 1. We need to prove that

[formula]

Define X: = (zi)i∈U1 and Y: = (zi)i∈U2. We can write Q(Z) = Q(X,Y). Let zi' be an independent copy of zi and set X': = (z'i)i∈U1 and Y': = (z'i)i∈U2). Applying Lemma [\ref=lemma:decoupling], we see that it suffices to show that

[formula]

A simple calculation shows that the random variable

[formula]

can be written as

[formula]

where for i∈U1, wi is the random variable wi: = zi  -  z'i, and Ri is the random variable

[formula]

We have eliminated the coupling problem in the factorization [\eqref=Q-factor], because the random variables (Ri)i∈U1 are independent of the random variables (wi)i∈U1.

Consider the four events Q(X,Y)∈I,Q(X',Y)∈I,Q(X,Y')∈I and Q(X',Y')∈I. If all of these hold, then R lies in the interval J: = 2I - 2I of length 4. Thus, it suffices to show that

[formula]

Recall that for each i∈U1, di be the number of coefficients j∈U1 for which |cij|  ≥  1. For each i∈S  ⊆  U1, we may apply Theorem [\ref=theo:LO] (and Remark [\ref=remark:LO]) to the random variable Ri to obtain

[formula]

By the union bound we thus have the crude estimate

[formula]

This use of the union is somewhat wasteful and we can do better by invoking the second moment method. For each i∈S, let Ii be the indicator variable of the event |Ri|  ≥  1, thus Ii = 1 when |Ri|  ≥  1 and Ii  =  0 otherwise. Thus [\eqref=rgi] can be rewritten as

[formula]

and hence by linearity of expectation

[formula]

Also, since di  ≥  1, we have at least one j∈U2 for which |cij|  ≥  1, which easily implies that [formula]. Thus we also have

[formula]

Next we compute the variance of [formula]:

[formula]

By Chebyshev's inequality, we conclude

[formula]

Thus with probability [formula], we have |Ri|  ≥  1 for at least |S| / 4 values of i∈S.

Let us now temporarily condition the Ri to be fixed for all i∈U1, and assume that |Ri|  ≥  1 for at least |S| / 4 values of i∈S. Applying Theorem [\ref=theo:LO] (and Remark [\ref=remark:LO]) to [formula] (treating the Ri as fixed coefficients), we have the conditional probability estimate

[formula]

By the preceding discussion and Bayes identity, we thus have

[formula]

as desired.

Proof of Lemmas [\ref=lemma:rankincrease1] and [\ref=lemma:rankincrease2]

Proof of Lemma [\ref=lemma:rankincrease1]. Let A be a normal symmetric singular n  ×  n matrix of rank d. Let vi be the ith row vector of A. Without loss of generality, we can assume that [formula] are linearly independent. Thus, the last row vector vn can be written as a linear combination of these vectors in a unique way

[formula]

As A is normal, by definition at least N among the coefficients ci are non-zero.

Consider the addition of a random (0,1) column of length n to A. Each of the row vectors vi receives a new (random) coordinate and becomes a new vector vi'. Clearly, [formula] are still independent. If the new matrix A' fails to have a larger rank than A, then the last row vn' must remain within the span of [formula]. By considering the first n coordinates, the only way this can happen is if

[formula]

This implies that the last coordinate xn + 1 of v'n satisfies

[formula]

where yin + 1 is the last coordinate of vi'. Since xn + 1 and yin + 1 are i.i.d (0,1) random variables and at least N of the ci are non-zero, Theorem [\ref=theo:LO] (see also Remark [\ref=remark:LO]) implies that the probability that [\eqref=equa:linearbound] holds is O(N- 1 / 2). Thus, we can conclude that with probability 1 - O(N- 1 / 2), the new column increases the rank by one. If adding the new column increases the rank by one, then by the fact that A is symmetric, adding the column and its transpose as a new row increases the rank of A by 2 (regardless the value of the last diagonal entry), concluding the proof. [formula]

Proof of Lemma [\ref=lemma:rankincrease2]. Let A be a perfect non-singular symmetric matrix of order n. Let A' be the n + 1 be n + 1 symmetric matrix obtained from A by adding a new random (0,1) column u of length n + 1 as the n + 1st column and its transpose as the n + 1st row.

Let [formula] be the coordinates of u; xn + 1 is the low-right diagonal entry of A'. The determinant for A' can be expressed as

[formula]

where cij is the ij cofactor of A. We can rewrite det A' as

[formula]

thanks to the fact that x2n + 1  =  xn + 1. We are going to bound the probability that Q = 0.

In order to apply Corollary [\ref=cor:quadLO2], we next show that for each 1  ≤  i  ≤  n, many among the cij are not zero.

Since A is non-singular, dropping the ith row (for any 1  ≤  i  ≤  n) results in an n - 1  ×  n matrix whose columns admit a unique (up to scaling) vanishing linear combination [formula]. As A is perfect, at least N among the coefficients aj are non-zero. For each j where aj  ≠  0, dropping both the ith row and the jth column must result in a full rank matrix of order n - 1. Thus cij  ≠  0. Thus, we can conclude that for each 1  ≤  i  ≤  n, there are at least N indices j where cij  ≠  0. The claim of the lemma follows by applying Corollary [\ref=cor:quadLO2] with m = N. [formula]

More general results

In this section we briefly discuss (without detailed proofs) several easy extensions of the method to yield some variants and generalizations of our results.

Generalizations of Theorem [\ref=theo:quadLO]

Theorem [\ref=theo:quadLO] and Corollary [\ref=cor:quadLO1] can be extended to polynomials with arbitrary degree. One such extension reads as follows:

Let [formula]be i.i.d. random variables which take values 0 and 1 with probability 1 / 2. Let k be a fixed positive integer. Let

where at least nk - 1m of the coefficients [formula] are at least 1 in absolute value. Then for any interval I of length 1

where ak  =  2- (k2 + k) / 2 and the implicit constant in O depends on k.

The proof proceeds via induction on k, with the base case being the classical Littlewood-Offord lemma and the inductive step closely following that of Theorem [\ref=theo:quadLO], including the use of the following generalization of the decoupling lemma (also proven by induction on k):

Let [formula] be random variables and [formula] be an event depending on the Xi. Then

[formula]

where XSi: = Xi if i∈S and XSi: = Xi', an independent copy of Xi if i∉S.

Theorem [\ref=theo:quadLO] can also be extended to more general classes of variables than the Bernoulli random variable (taking values 0 and 1 with equal probability) by a nearly identical proof, with the main difference being that the base case, Theorem [\ref=theo:LO], must be replaced by [\cite=Hal].

Generalizations of Theorem [\ref=theo:main]

We say that a random variable ξ has the ρ-property if

[formula]

Let ξij, 1  ≤  i,j  ≤  n be independent random variables. Assume that there is a constant ρ < 1 (not depending on n) such that for all 1  ≤  i  <  j  ≤  n, ξij has the ρ-property. Observe that we do not require ξij be identical, and that furthermore we do not place any requirements on the diagonal elements of the matrix.

Let ξij, 1  ≤  i  ≤  j  ≤  n be as above. Let Qn be the random symmetric matrix with upper diagonal entries ξij. Then Qn is non-singular with probability 1 - O(n- 1 / 8  +  δ), where the implicit constant depends only on ρ and δ.

To prove this result, it suffices to show that analogues of Lemmas [\ref=lemma:abnormal]-[\ref=lemma:rankincrease2] still hold for this more generalized model. Lemmas [\ref=lemma:abnormal] and [\ref=lemma:imperfect] (with 2/3 replaced by any δ with ρ  <  δ < 1) follow from the same argument as in the original theorem, except that Lemma [\ref=lemma:subspace] must be replaced by

Let H be a linear subspace in [formula] of dimension at most d  ≤  n. Let v be a vector whose entries are independent random variables all but one of which have the ρ property. Then

[formula]

As before, H can be parameterized by some set of d'  ≤  d coordinates. Once those coordinates of v are known, the remaining coordinates can each take on at most one value for all (v∈H), giving a necessary set of (n - d') independent events, (n - d' - 1) of which have probability at most ρ.

The proof of Lemma [\ref=lemma:rankincrease1] also goes through, except that Theorem [\ref=theo:LO] must be replaced by the following rescaled version of the d = 1 case of [\cite=Hal]:

Let [formula] be independent random variables with the ρ property. Let [formula] be real deterministic coefficients, with ai  ≠  0 for at least k values of i. Then for any interval [formula], we have

[formula]

where the implied constant depends only on ρ.

A nearly identical decoupling argument now proves an analogue of Theorem [\ref=theo:quadLO], with di now taken for each i to be the number of j for which cij is nonzero. Corollary [\ref=cor:quadLO2] (with the implied constant now depending only on ρ) and Lemma [\ref=lemma:rankincrease2] now follow as before.

Open questions

Let us conclude this section with a few open questions. From a quantitative point of view, there are two natural ways to strengthen both Questions [\ref=komlos1] and [\ref=weiss].

Give an estimate for the determinant.

Give an estimate for the probability that the matrix is singular.

In fact, Question [\ref=tv1] seems to be the motivation of Komlós for his original paper [\cite=Kom1] (see the title of that paper) which started this line of research. There are several partial results concerning the model An. In the rest of this section, it is more convenient to assume that the entries of An (and Qn) take value 1 and - 1 (rather than 1 and 0). Under this condition, Tao and Vu [\cite=TV1] showed that almost surely det An has absolute value n(1 / 2 - o(1))n. We conjecture that a similar bound holds for Qn.

Almost surely, | det Qn|  =  n(1 / 2 - o(1))n.

Regarding Question [\ref=tv2], Kahn, Komlós and Szemerédi [\cite=KKS] proved that the singular probability of An is O(.999n). This bound has recently been improved [\cite=TV2] to (3 / 4 + o(1))n. The conjectured bound is (1 / 2 + o(1))n. We conjecture that the same bound holds for Qn.

The probability that Qn is singular is (1 / 2 + o(1))n.

By considering the probability that the first two rows are equal, it is easy to see that (1 / 2 + o(1))n is a lower bound (one can actually makes a more precise conjecture similar to the case with An). The proof in this paper showed a upper bound O(n- c) for some positive constant c.

The main obstacle in these questions is the fact that the row vectors of Qn, unlike those of An, are not independent. In fact, if one exposes these vectors one by one, then the last few vectors are almost deterministic. The independence among the row vectors are critical in all previous papers [\cite=KKS] [\cite=TV1] [\cite=TV2]. It so seems to require a new idea to attack these conjectures.

Acknowledgement. We would like to thank G. Kalai for communicating the problem.