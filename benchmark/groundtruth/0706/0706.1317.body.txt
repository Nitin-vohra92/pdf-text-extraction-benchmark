A model for learning to segment temporal sequences, utilizing a mixture of RNN experts together with adaptive variance

Acknowledgment Requests for reprints should be sent to Jun Namikawa, Brain Science Institute, RIKEN. 2-1 Hirosawa, Wako-shi, Saitama, 351-0198 Japan Tel +81-48-467-6467, FAX +81-48-467-7248

Key Words recurrent neural network, mixture of experts, maximum likelihood estimation, self-organization, segmentation of temporal sequences

Introduction

How to learn complex temporal sequence patterns by means of neural network models has been a challenging problem. Recurrent neural networks (RNNs) [\cite=Jordan86] [\cite=Elman90] [\cite=Pollack91] [\cite=Zipser89] have been one of the most popular models applied to temporal sequence learning. RNNs can learn sensory-motor sequence patterns [\cite=Jordan86] [\cite=Jordan88a], symbolic sequences with grammar [\cite=Elman90] [\cite=Pollack91] and continuous spatio-temporal patterns [\cite=Zipser89].

In spite of the considerable amount of RNN research carried out since the mid 1980s, it has been thought that RNNs cannot be scaled to be capable of learning complex sequence patterns, especially when the sequence patterns to be learnt contain long-term dependency [\cite=Bengio94]. This is due to the fact that the error signal cannot be propagated effectively in long-time windows of sequences using the back-propagation through time (BPTT) algorithm [\cite=Rumelhart86], because of the potential nonlinearity of the RNN dynamics [\cite=Bengio94].

There have been some breakthroughs in approaches to this problem. Hochreiter and Schmidhuber [\cite=Hochreiter97] [\cite=Schmidhuber2002] proposed a method called "Long Short-Term Memory" (LSTM). LSTM learns to bridge minimal time lags in long time steps by enforcing constant error flow through "constant error carousels" within special units. These units learn to open and close access to the constant error flow. Echo state networks [\cite=Jaeger2001] [\cite=Jaeger2004] and a very similar approach, liquid state machines [\cite=Maass2002], have recently attracted significant attention. Echo state networks possesses a large pool of hidden neurons with fixed random weights, and the pool is capable of rich dynamics. Jaeger [\cite=Jaeger2004] demonstrated that an echo state network can successfully learn the Mackey-Glass chaotic time series which is a well-known benchmark system for time series prediction.

Tani and Nolfi [\cite=Tani99] investigated the same problems, but from a different angle, focusing on the idea of compositionality for sensory-motor learning. The term compositionality was adopted from the "Principle of Compositionality" [\cite=Evans81] in linguistics, which claims that the meaning of a complex expression is determined by the meanings of its constituent expressions and the rules used to combine them. This principle, when translated to the sensory-motor learning context, leads to the assertion that diverse and complex patterns can be learned to be generated by adaptively combining a set of re-usable behavior primitives. Here, acquiring behavior primitives requires a mechanism for autonomously segmenting a continuously experienced sensory-motor flow into reusable chunks. Tani and Nolfi (1998) proposed a scheme for hierarchical segmentation of the sensory-motor flow, applying the idea of a mixture of experts [\cite=Jacobs91] [\cite=Jordan94] [\cite=Wolpert98] to hierarchically organized RNNs. Consider a network consisting of multiple local RNNs, organized in levels. At the base level, each RNN competitively learns to be an expert at predicting/generating a specific sensory-motor profile. As the winner among the expert modules changes, corresponding to structural changes in the sensory-motor flow, it is considered that the sensory-motor flow is segmented, by switching between winners. Meanwhile, the RNN experts at the higher level learn the winner switching sequence patterns with much slower time constants compared to those at the sensory-motor level. The higher level learns not for details of sensory-motor patterns but for abstraction of primitive sequences with long-term dependency.

Although the scheme of the mixture of RNN experts seems to be tractable, in reality there are potential problems arising from scaling [\cite=TaniSMC2007]. It is known that if the number of modules increases, segmenting the sequence becomes unstable and learning by a gating mechanism tends to fail. This is due to near-miss problems in matching the current sensory-motor pattern to the best local RNN among others, which have acquired similar pattern profiles. Since the number of modules determines the scalability of the system, it is desirable that learning proceeds stably with larger numbers of modules.

In the present study, a novel learning method is presented for a mixture of RNN experts model. The proposed learning method allows a sequence to be segmented into reusable blocks without loss of stability with increasing number of learning modules. A maximum likelihood estimation based on the gradient descent algorithm is employed, similar to the conventional learning method for mixture of RNN experts [\cite=Tani99] [\cite=IgariNC2006], although the present likelihood function differs from those presented previously. In the proposed method, the weighting factor for the allocation of blocks to modules is changed adaptively via a variance parameter for each module. The superior performance of the proposed method is demonstrated through application to a problem that involves learning to extract a set of reusable primitives from data constructed by stochastically combining multiple Lissajous curve patterns. The proposed learning method is compared with the conventional method on the basis of generalization capability as a measure of the extent to which compositionality can be achieved in modular networks. Finally, the proposed method is applied in combination with a gating network to learn the sensory-motor flows for a small humanoid robot as a realistic problem.

Model

In this section, we define a model known as a mixture of recurrent neural network (RNN) experts model. A mixture of RNN experts is simply a mixture of experts model for which the learning modules are RNNs. The model equations are defined as follows:

[formula]

[formula]

[formula]

[formula]

where N is the number of expert modules, ε is a time constant satisfying 0  ≤  ε  ≤  1, [formula] and [formula] are the input and output vectors of the model at time n, respectively. For each i, [formula], [formula] and [formula] denote internal potential of context neurons, states of context neurons and states of output neurons of the module i, respectively. The matrices W(i)1,W(i)2,W(i)3 and vectors [formula] are parameters of the module i. A gate opening value for the module i is denoted by g(i)n, and it is assumed that g(i)n  ≥  0 and [formula]. The gate opening vector [formula] represents the winner-take-all competition among modules to determine the output [formula]. The determination of the gate opening vector [formula] is explained in section [\ref=subsection:learning_rule].

Learning method

The proposed learning method is defined on the basis of the probability distribution of the mixture of RNN experts. Here the parameters of learning module i are denoted by [formula], and a gate opening vector [formula] is described by a variable [formula] such as

[formula]

Let [formula] be an input sequence, [formula] and [formula] be parameters, where [formula] is a set of parameters given by γi  =  (ϑi,σi). Given X, [formula], and [formula], the probability density function (p.d.f.) of output [formula] is defined by

[formula]

where [formula] is given by

[formula]

d is the output dimension, and [formula] is an output of the module i computed by the equations ([\ref=equation:mixture_of_rnn_experts1]), ([\ref=equation:mixture_of_rnn_experts2]) and ([\ref=equation:mixture_of_rnn_experts3]) with parameter ϑi. Thus, the output of the model is governed by a mixture of normal distributions. This equation results from the assumption that an observable sequence data is embedded in additive Gaussian noise. It is well known that minimizing the mean square error is equivalent to maximizing the likelihood determined by a normal distribution for learning in a single neural network. Therefore, equation ([\ref=equation:mixture_of_normal_distribution]) is a natural extension of a neural network for learning. The details of the derivation of equation ([\ref=equation:mixture_of_normal_distribution]) is given in [\cite=Jacobs91].

Given a parameter set [formula] and an input sequence X, the probability of an output sequence [formula] is given by

[formula]

The likelihood function L of the data set D  =  (X,Y), parametrized by [formula], is denoted by

[formula]

where [formula] is the p.d.f. of the prior distribution given by

[formula]

This equation means that the vector [formula] is governed by N-dimensional Brownian motion. The prior distribution has the effect of suppressing the change of gate opening values.

The learning method proposed here is to choose the best parameter [formula] by maximizing (or integrating over) the likelihood [formula] with training data D. Concretely, we use the gradient descent method with a momentum term as the training procedure. The update rule for the model parameter is

[formula]

[formula]

where θ(t) is the parameter at learning step t, α is the learning rate, and η is the momentum term parameter. For each parameter, the partial differential equation [formula] are given by

[formula]

[formula]

[formula]

[formula]

Notice that [formula] can be solved by the back propagation through time (BPTT) method [\cite=Rumelhart86]. In this paper, we assume that the infimum [formula] of the parameter σi is greater than 0, because if σi converges to 0, then Δθ(t) diverges.

The explanation above refers to a training data set D consisting of a single sequence. However, the method can be readily extended to the learning of several sequences by calculating the sum of gradients for each sequence. When several sequences are used as training data, the initial states [formula] and the parameters [formula] of the gate opening vector must be provided for each sequence.

An important difference between the proposed method and the conventional method used in [\cite=Tani99] [\cite=IgariNC2006] is the use of an optimized variance [formula] of the normal distribution. Indeed, if [formula] is a constant, e.g., [formula], then the proposed method is equivalent to the conventional one. Adapting the variance [formula] results in different learning speeds for different learning modules, because the learning speed of a module i depends on σi, from equation ([\ref=equation:gradient_vartheta]). Moreover, from equation ([\ref=equation:gradient_sigma]), σi decreases if the mean square error of the module i is less than dσ2i. This fact implies that there exists positive feedback in the learning speed of modules. When the same sequence blocks are allocated to a set of modules, the learning speed of the best matching module becomes faster than for the other modules in the set due to this feedback mechanism, reinforcing the matching between the module and the allocated blocks. Hence, this feedback leads to a decision on the winner of the competition among modules. It is shown later that the adaptive optimization of [formula] plays an important role in segmenting the sequence D into blocks via the gate opening vector [formula].

Feedback loop with time delay

Let us consider the case in which there exists a feedback loop from output to input with a time delay τ, that is to say, the model is an autonomous system. In this case, a training data set D  =  (X,Y) has to satisfy [formula]. At the end of learning, if every output of the model is completely equal to the training data, the model can generate the sequence Y using a feedback loop instead of using the training data X as external input. In this paper, open-loop dynamics refers to the case in which external inputs are given by training data, and closed-loop dynamics refers to the case involving self-feedback. In section [\ref=section:simulation], we consider the case in which the model is an autonomous system.

Numerical simulation

Learning

The learning ability of the proposed learning method with optimizing [formula] is compared here that of the conventional method (constant [formula]) and a standard RNN model with BPTT [\cite=Rumelhart86] as a benchmark. The architecture of the RNN with BPTT method is the same as that for a module of the mixture of RNN experts model. The training data is a two-dimensional sequence generated by Markov chain switching of 9 Lissajous curves, each of period 32 (see Figure [\ref=figure:teaching_data]). Assume that the transition probabilities of the Markov chain are such that transitions among curves are consonant with orbit continuity. Since we consider the model which has a feedback loop with time delay τ, the training data set D  =  (X,Y) satisfies [formula]. We provides details of the training data in Appendix [\ref=section:appendix_A].

We describe the experimental conditions in this section. The training data was of length T  =  10,000, and learning was conducted for 300,000 steps in each model. The parameter settings were set to N  =  24 learning modules, dim   =  10 context neurons in each learning module, a time constant of ε  =  0.1, a time delay of τ  =  5 for the feedback loop, an infimum of   =  0.05 for the variance of the normal distribution, a standard deviation of ς  =  1 for the prior distribution, a momentum of η  =  0.9, and a learning rate of α  =  0.01  /  Td, where T is length and d is the dimension of the training data. The learnable parameters of the mixture of RNN experts were initialized as [formula] and [formula], every element of the matrices W(i)1,W(i)2,W(i)3 and the vectors [formula] were initialized randomly from the uniform distribution on the interval ( - 0.1,0.1), and an initial state [formula] for each i was initialized randomly from the interval

[formula]

Generalization

Here we examine the generalization capability of the proposed method as compared with that of the conventional method. In order to evaluate this generalization capability, we prepared test data separate from the training data, and we regarded the mean square error for regenerating the test data as the generalization error. However, the gate opening values determined by the parameter [formula] correspond only to the training data. Thus, in computing the generalization error, we reconstruct [formula] that maximizes the likelihood for the test data by using the same learning scheme. Note that the parameter ϑi of each learning module and the variance [formula] do not change in the reconstruction. The aim of this analysis is to evaluate the general feasibility of the segmentation and data allocation scheme based on a gating mechanism. If the gating mechanism successfully segments the training data into blocks as reusable primitives, and each module acquires a rule for allocating blocks in the training phase, not only the training error but also the generalization error will be small. The value of |Q| can also be regarded as a measure of generalization, representing the number of primitives extracted from the observed data.

To explain practical meaning of the generalization error and |Q| more clearly, let us consider the case in which a gating network, which predicts or generates gate opening values, is added to the proposed model. Although the definition of the model in section [\ref=section:model] does not include the gating network because of focusing on the segmentation of temporal sequences, the gating network is usually used together with experts when applying to realistic problems. In this case, if the generalization error of experts is sufficiently reduced, the generalization error of the whole system can be reduced by decreasing that of the gating network. It is therefore sufficient to discuss the generalization ability of a single network when evaluating the generalization performance of the whole system, and the generalization ability of the single network can be evaluated by the stochastic approach [\cite=Hammer2003]. Hence, the model can be considered to have good generalization performance if it minimizes the generalization error. Furthermore, training of the gating network tends to be easier when |Q| is small. Accordingly, the model can be understood to have good generalization performance if the scheme minimizes both the generalization error and |Q|.

This experiment serves to compare the case of adaptive [formula] with the constant case in which [formula] and [formula] (=  0.05). Moreover, we can also compare them with the learning of RNN using BPTT, where the architecture of RNN is that of a mixture of RNN experts. As training data and test data, we used a 2-dimensional sequence generated by Markov chain switching of 2 Lissajous curves of period 32, with time delay of the feedback loop τ  =  1. The lengths of the training and test data were 1000 and 2000, respectively. In the optimizing [formula] case, we initialized [formula] to 5. Other parameter settings were the same as for Experiment 1.

The generalization error and |Q| after 100,000 learning steps are displayed in Figure [\ref=figure:error_and_classnum_for_each_N]. The results are shown for 10 samples with different initial conditions for each N, the number of learning modules. The generalization error for closed-loop dynamics is lower for the case of optimizing [formula] than for the other cases, and |Q| for the optimizing [formula] is as low as that achieved by any of the other cases. In the case of [formula], even though the generalization error decreases with increasing N to match that of the adaptive [formula] case, |Q| increases markedly with N. In the case of [formula], neither the generalization error nor |Q| are dependent on the number of modules, but the generalization error is greater than that in the adaptive [formula] case. These results suggest that only the generalization error or |Q|, not both, can be reduced if [formula] is constant. Thus, the model with constant [formula] is unable to continue performing effectively as the number of modules increases. On the other hand, the adaptive optimization of [formula] satisfies the positive characteristics of both the [formula] and [formula] cases by reducing both generalization error and |Q| even at large N. For the reason which was explained in section [\ref=subsection:learning_example], by optimizing [formula] in the learning phase, |Q| is low over the range in which the error margins are sufficiently reduced. These results thus suggest that the proposed learning method for the mixture of RNN experts model is scalable with respect to the number of learning modules, maintaining good performance in terms of generalization error with increasing N.

Figure [\ref=figure:error_and_classnum_for_each_varsigma] shows the effects of the parameter ς on generalization in learning. The simulation computed up to 100,000 learning steps for each parameter value ς of the prior distribution, where the number of modules N was set at 16. The computation was repeated 10 times for each ς. By equation ([\ref=equation:gradient_beta]), the effect of suppressing gate opening change is inversely proportional to ς2. If the change of gate opening is suppressed to an extreme degree, the model cannot learn the training data, and the generalization error is increased. On the other hand, if the change of gate opening values is not suppressed, then |Q| is not reduced. From Figure [\ref=figure:error_and_classnum_for_each_varsigma] (b), if [formula] is constant, dependence of |Q| on the parameter ς is stronger than in the case of adaptive [formula]. As a result, in the case of optimizing [formula], the parameter range of ς for which both the generalization error and |Q| are minimized, is larger than for the case of constant [formula]. Therefore, it can be said that the proposed method can achieve better generalization in learning more stably than the conventional one.

Practical application

The practical learning performance of the proposed method is evaluated by applying the scheme to the learning of sensory-motor flows for a small humanoid robot. The situation comprises a robot set before a workbench on which a cubic object was placed. The task for the robot is to autonomously generate desired behaviours consisting of several primitive motions (see Figure [\ref=figure:robot_motion]): (1) reaching for the object, (2) moving the object up and down, (3) moving the object left and right, (4) moving the object forward and backward, (5) touching the object with the left and right hand alternately, and (6) touching the object with both hands. For each behaviour, the robot begins from a home position and ends with the home position. Each behaviour is described by a 10 dimensional sensory-motor flow, which consists of an 8 dimensional motor vector representing the arm joint angle, and 2 dimensional vision sense representing the object position. The task is to predict and generate sensory-motor sequences.

In this section, a gating network to predict or generate gate opening values is added to the mixture of RNN experts model in order to realize a practically applicable scheme. In the analyses above, gate opening values were determined by the parameter [formula], because the main focus of this paper is the learning process to segment sequence data into primitives with respect to spatio-temporal patterns. Since segmenting sequences is one of the most difficult processes in the learning of the mixture of experts model, our approach focusing on the data segmentation is efficient to investigate the learning processe. However, such a model is unable to predict or generate unknown time series. To apply the model to an actual problem, the model must be extended to a fully autonomous sequence generator by adding a gating network for module switching. Thus, we consider the gating network learning in this section. Learning for the gating network can be performed by adopting the gate opening vector given by [formula] as a target. The definitions of the gating network and the corresponding learning method are described in appendix [\ref=section:appendix_B], and further details can be found in a study [\cite=Namikawa2008b].

The training data consists of 3 kinds of behaviors as depicted in Figure [\ref=figure:robot_motion], and 3 initial locations of the object for each behavior, yielding a total of 9 training sequences. The model is constructed with N  =  16 experts, 20 context neurons for each expert, and 30 context neurons for the gating network. The time constant and time delay of the feedback loop are set to ε  =  εg  =  0.05 and τ  =  3, respectively. Other parameters are the same as in section [\ref=subsection:learning_example], and the parameters of the gating network are initialized in the same way as for a module of the mixture of RNN experts.

Figure [\ref=figure:robot_error] shows the mean square error for the closed-loop dynamics after training the mixture of RNN experts model up to 100,000 steps and the gating network up to 50,000 steps. Figure [\ref=figure:robot_teach_and_output] describes the training data, output, and gate opening values of the model trained with the gating network. It can be seen that the model can autonomously generate sequences similar to the training data if [formula] is optimized by using our method, whereas the trained model is unable to generate similar sequences if [formula] is constant. These results demonstrate that the proposed learning method is effective in application to realistic problems of time series prediction and generation, even when employing a gating network.

Discussion

Segmentation of temporal time series caused by indeterminacy

One of the most important problems in the learning of a mixture of RNN experts model concerns the segmentation of sequence data into blocks as reusable primitives. By the definition of the likelihood function, the module with smallest error margin is usually selected by the gating mechanism. Moreover, as the prior distribution given by equation ([\ref=equation:prior_distribution]) has the effect of suppressing the change in gate opening values, the gating mechanism retains the selected module until the module is no longer able to correctly predict sequence data. Thus, locally represented knowledge of a reusable primitive is brought by the indeterminacy of the sequence data, and is embedded into each module. Indeed, it was shown above that a mixture of RNN experts model is able to learn to generate data constructed by stochastically combining 9 Lissajous curves. Figure [\ref=figure:output] (b) indicates that the adaptive optimization of [formula] allows a set of reusable chunks corresponding to the Lissajous curve patterns to be successfully extracted, and self-organized chunks to be allocated in each corresponding module.

The segmentation mechanism caused by the indeterminacy has also been discussed in a study by Tani and Nolfi [\cite=Tani99]. In their study, involving a robot actively exploring two rooms connected by a door, the sensory-motor flow was segmented by means of the uncertainty of the door opening. Similarly, for stochastic switching between Lissajous curves or the arbitrary composition of robot motions in the present study, both of which involve indeterminacy in the observable data, the proposed learning method allows the mixture of RNN experts model to successfully segment the data using the information of nondeterministic switching. The present scenarios thus reproduce the essential characteristics of the scenario considered by Tani and Nolfi in terms of the segmentation mechanism.

Dynamic change of functions

As training data in section [\ref=section:simulation], we have considered Markov chain switching of Lissajous curves. Switching patterns by Markov chain belongs to a simple class of systems in which a function dynamically changes. In addition to such Markov chain models, there are other systems utilizing dynamic functions. For instance, a switching map system is a dynamical system containing several maps, in which maps to govern temporal evolution of the system are dynamically switched with other maps in the system [\cite=Sato2000] [\cite=Namikawa2004]. As other examples, we can consider chaotic itinerancy and function dynamics. Chaotic itinerancy is a class of phenomena such as chaotic itinerant motion among varieties of ordered states [\cite=Ikeda89] [\cite=Kaneko2003], and a function dynamics [\cite=Kataoka2000] [\cite=Kataoka2001] [\cite=Kataoka2003] is a dynamical system on a 1-dimensional function space. It is still unclear whether these systems can be learned by the model using the proposed method, either because the primitive sequences are governed by a chaotic dynamics, or the rule governing the change of primitives has a long-term dependency, more complex than that of a Markov chain. Further analysis to explain learnability of the model is a future research topic.

Conclusion

In this study, we have presented a novel method of adaptive variance applied to learning for a mixture of RNN experts. In order to show the capability of the proposed method, we have shown an example of a learning experiment in which the model using the proposed method can learn training data with respect to correctly segmenting a continuous flow into primitives, whereas the model using the conventional method cannot learn it. The generalization capability has also been examined in order to compare the proposed method with the conventional method. From these results, we claim that our method has improved learning performance of the model. Furthermore, we have shown a humanoid robot experiment to make sure of a potential of our method. This experiment has inferred that the model utilizing our method can be applied to realistic problems of time series prediction and generation.

Training data: Markov chain switching among nine Lissajous curves

The training data in section [\ref=subsection:learning_example] comprise a 2-dimensional sequence generated by Markov chain switching of 9 Lissajous curves (see Figure [\ref=figure:teaching_data]). The equation for Lissajous curve i is given by

[formula]

[formula]

and the parameters ai,bi,ci,Ai,Bi,Ci,Di are determined such that the period of each Lissajous curve is 32. The transition probability R governing the change between Lissajous curves is defined by

[formula]

and it is assumed that the transition among curves is consonant with continuity of the orbit.

Learning process of the gating network

We present the definition of a gating network together with the training procedure. The dynamics of the gating network are defined by

[formula]

[formula]

[formula]

[formula]

where [formula], [formula] and [formula] denote input states, context states and output states, respectively. In addition, [formula] and [formula] are the internal potentials of neurons, and τ represents the time delay of feedback. The output [formula] of the gating network represents the gate opening vector at time n. To discriminate between the gate opening vector determined by parameter [formula] and the output of the gating network, in this appendix the gate opening vector determined by [formula] is denoted as n, and is used as an estimate of the gate opening vector.

Let [formula] be a set of learnable parameters of a gating network. Assume that Dg  =  (X,(n)Tn = 1) is given. We define a likelihood [formula] by the Dirichlet distribution

[formula]

[formula]

where Z(n) is the normalization constant, and [formula] is given by X and [formula]. Notice that [formula] in equation ([\ref=equation:likelihood_of_gating_net]) is calculated by the teacher forcing technique [\cite=Zipser89], namely, using n - τ instead of [formula] in equation ([\ref=equation:mixture_of_rnn_experts5]). In addition, because of the term [formula] on the right-hand side of equation ([\ref=equation:mixture_of_rnn_experts5]), [formula] cannot be computed if n  ≤  τ. It is therefore assumed that [formula] if n  ≤  τ. If g(i)n is considered to be the probability of choosing an expert i at time n, maximizing [formula] is equivalent to minimizing the Kullback-Leibler divergence

[formula]

The learning process for the gating network involves to choose the best parameter [formula] by using the gradient descent method for the likelihood [formula], in the same way as the equations ([\ref=equation:gradient_descent_method_with_momentum1]) and ([\ref=equation:gradient_descent_method_with_momentum2]). The partial differential equation [formula] is given by

[formula]

Note that [formula] can be solved by the BPTT method. The procedure for training the model consisting of the mixture of RNN experts and gating network is organized into two phases as follows: The training procedure progresses with phase (2) after convergence of phase (1).