Comment on: "Analytical approximations for the collapse of an empty spherical bubble"

In a recent paper Obreschkow et al[\cite=OBF12] derived simple and accurate analytical approximations to the solution of the Rayleigh equation[\cite=LR17] for the collapse of an empty spherical bubble. Their approximants are based on the expansion of the solution about the origin of time and can be improved systematically. They showed that those simple analytical expressions are suitable for the analysis of experimental cavitation data obtained in microgravity.

Each approximant is the partial sum of the power series times a function that takes into account the algebraic singularity at the other boundary point. The authors also derived an approximate limit of the sequence of partial sums in terms of the polylogarithm or Jonquière's function. To this end, they resorted to a linear fit of the logarithm of the expansion coefficients.

The results obtained by Obreschkow et al[\cite=OBF12] are partly analytical and partly numerical. In this comment we analyze them in a somewhat more rigorous way with the purpose of providing a sound analytical foundation and explanation of the main expressions.

It is sufficient for our purposes to restrict ourselves to the dimensionless Rayleigh equation of motion for a collapsing bubble[\cite=OBF12]

[formula]

Taking into account the initial conditions and the fact that r( - t) is also a solution we conclude that r( - t) = r(t). The equation ([\ref=eq:Rayleigh_dimensionless] has been written in such a way that the bubble collapses at t = 1; that is to say: r(1) = 0[\cite=OBF12].

If we multiply equation ([\ref=eq:Rayleigh_dimensionless]) by [formula] and integrate with respect to the dimensionless time t we obtain

[formula]

Note that [formula] is a solution to Eq. ([\ref=eq:First_int]) that satisfies the boundary conditions at t = 0. Since this solution does not satisfy Eq. ([\ref=eq:Rayleigh_dimensionless]) then both equations are not identical. If we solve Eq. ([\ref=eq:First_int]) for dt / dr and integrate between r = 0 and r = 1 we obtain the value of ξ:[\cite=LR17]

[formula]

If, on the other hand, we solve equation ([\ref=eq:First_int]) for [formula] and differentiate the result with respect to t we obtain another useful equation[\cite=OBF12]

[formula]

The solution to the Rayleigh equation ([\ref=eq:Rayleigh_dimensionless]) can be expanded in a Taylor series about the origin as follows:

[formula]

Although equations ([\ref=eq:Rayleigh_dimensionless]), ([\ref=eq:First_int]) and ([\ref=eq:Ray_2]) are not identical this series can be obtained from any of them and it converges for all 0  ≤  t  ≤  1 as discussed below.

Taking into account the initial conditions, the behavior of r(t) about t = 1 and the symmetry of the solution Obreschkow et al[\cite=OBF12] obtained the first and simplest approximant [formula]. This expression is considerably accurate in a neighborhood of t = 0 because [formula] is quite close to c1  ≈   - 0.418. In addition to it, the authors found that the error of this expression is smaller than 1% for all t. For this reason they proposed the modified power-series approximants

[formula]

where the functions Sn(t) are the partial sums for the Taylor expansion of S(t) = r(t) / r0(t) about t = 0. Numerical calculation suggests that aj < 0 and |aj + 1| < |aj| for all j. Based on these results Obreschkow et al[\cite=OBF12] concluded that the approximants rn(t) converge monotonically towards r∞  (t) as n  →    ∞  . The accuracy of these approximants increases with n, but according to Obreschkow et al[\cite=OBF12] r∞  (t) is not identical to r(t) because [formula] in Eq. ([\ref=eq:Ray_2]) and [formula] derived from Eq. ([\ref=eq:r_n(t)]) do not obey the same asymptotic behavior as t  →  1.

Obreschkov et al[\cite=OBF12] realized that ln (aj) vs ln (j) is an almost straight line from which they estimated that aj  ≈  a1j- 2.21. Based on this approximate relationship they derived the following quite accurate analytical approximation to r(t):

[formula]

where [formula] is the polylogarithm or Jonquière's function.

In what follows we will discuss the following points: first, why r0(t) and the approximants of greater order rn(t) are so accurate, second, if r∞  (t) is equivalent to r(t) for all t, and third, why r∞  (t) is approximately given by Eq. ([\ref=eq:r*(t)]). In order to answer these questions we need the actual behavior of r(t) as t  →  1.

We can obtain the asymptotic behavior of r(t) as t  →  1 most easily from Eq. ([\ref=eq:First_int]); the result is

[formula]

It is worth noting that the leading term

[formula]

is an exact solution to Eq. ([\ref=eq:Ray_2]) that does not satisfy the initial conditions. The function ([\ref=eq:r_a(t)]) does not satisfy the other two alternative equations ([\ref=eq:Rayleigh_dimensionless]) and ([\ref=eq:First_int]

If we substitute r(t) = r0(t)S(t) into either of the equations ([\ref=eq:Rayleigh_dimensionless] ([\ref=eq:First_int]) or ([\ref=eq:Ray_2]) and take the limit t  →  1- then we obtain

[formula]

that is consistent with the analytical asymptotic expression ([\ref=eq:r_asympt] as follows from

[formula]

Obreschkow et al[\cite=OBF12] already proved that r0(t) is a reasonably good approximation to r(t) in the neighborhood of t = 0. Eq. ([\ref=eq:r(t)/r0(t)] tells us that r0(t) is also quite close to r(t) in the neighborhood of t = 1. For this reason r0(t) is so accurate for all t and the approach of Obreschkow et al[\cite=OBF12] is remarkably successful even when the sequence of partial sums Sn(t) converges slowly.

Let us now go into the question whether rn(t) actually gives r(t) when n  →    ∞  . To begin with, note that the sequence of partial sums converges for all t < 1 because the singular point closest to the origin is located at t = 1. Therefore it is clear that if Sn(1) converges towards S(1) as n  →    ∞   then Sn(t) converges towards S(t) for all t and rn(t) converges towards the actual solution r(t) of the dimensionless Rayleigh equation. Our numerical analysis suggests that Sn(1)  →   S(1) as n  →    ∞  ; compare, for example, S200(1)  ≈  0.972892 with Eq. ([\ref=eq:S(1)]). If we accept that S∞  (1) = S(1) then we can easily prove that r∞  (t) satisfies any of the equations ([\ref=eq:Rayleigh_dimensionless] ([\ref=eq:First_int]) or ([\ref=eq:Ray_2]) as t  →  1. Consider, for example, Eq. ([\ref=eq:Ray_2]). If we substitute r(t) = r0(t)S(t) then [formula]. On the other hand [formula] which proves the point. Therefore, if r∞  (t) satisfies Eq. ([\ref=eq:Ray_2]) for the most unfavorable case t = 1 then it satisfies that equation for all t.

The approximant ([\ref=eq:r*(t)]) is quite accurate in the neighborhood of t = 1 because

[formula]

is very close to the exact asymptotic behavior given by Eq. ([\ref=eq:r_a(t)]). In what follows we show how the form of r*(t) emerges from the asymptotic behavior of the coefficients aj.

To begin with, note that if f(x) exhibits a branch point at x = x0 with exponent α (1 - x / x0)α then the coefficients cj of the Taylor expansion about x = 0 for f(x) behave asymptotically as |cj|  ~  c|x0|- jj-  α - 1, where c is a constant. Obviously, we are assuming that there is no other singularity closer to the origin or in the vicinity of x0. For this reason, the coefficients of the original series ([\ref=eq:t_series]) behave approximately as cj  ≈  cj- 7 / 5 reflecting the branch-point singularity at t = 1 with exponent α = 2 / 5. Note that the Taylor series about x = 0 for f(x) converges for all 0  ≤  x  ≤  x0 if α > 0 and that the rate of convergence increases with α. The function S(t) exhibits a branch-point singularity at t = 1 with exponent α = 6 / 5 as shown by the asymptotic expansion

[formula]

Therefore, the coefficients aj behave asymptotically as |aj|  ~  aj- 6 / 5 - 1 = aj- 2.2, where a is a constant. This theoretical result clearly explains the outcome of the linear fitting by which Obreschkow et al[\cite=OBF12] obtained the approximant r*(t). The slight discrepancy between the theoretical and numerical exponents is due to the fact that those authors fitted all the coefficients aj and the asymptotic behavior is determined by those of sufficiently large j. If, for example, we fit the coefficients aj for 100  ≤  j  ≤  150 then we obtain a much better agreement between theory and numerical approximation: |aj|  ≈  0.017j- 2.20. Obviously, the reason for fitting all the coefficients is the practical purpose of obtaining a suitable approximation for all t[\cite=OBF12]. In the present case we are mainly interested in explaining the form of the approximant ([\ref=eq:r*(t)]) and for that reason we resort to fitting the coefficients with the largest available orders that reflect the asymptotic behavior of r(t) close to t = 1. We also appreciate that the sequence of partial sums Sn(t) converges for all 0  ≤  t  ≤  1 because 1 + α = 11 / 5 > 1 and that the rate of convergence of the series ([\ref=eq:r_n(t)]) is greater than the one of ([\ref=eq:t_series]).

Finally, we want to discuss an alternative power series with much better convergence properties. It is well known that in some cases the inverted series exhibits better convergence properties than the original one[\cite=AF08]. The series inversion is the basis for the parametric perturbation theory[\cite=A07]. In the present case we define the new variable ρ

[formula]

where z = t2, and invert the series to obtain z(ρ):

[formula]

It follows from the asymptotic expansion

[formula]

that z(ρ) exhibits a singularity of the form [formula], where ρ0  =   2 / ξ2  ≈  2.3905. Therefore, the coefficients bj behave asymptotically as |bj|  ~  b|ρ0|- jj- 7 / 2, where b is a positive constant. It follows from fitting ln (|bj|) for 80  ≤  j  ≤  100 that |bj|  ~  1.78  ×  2.39- j  ×  j- 3.6, where 3.6  ≈   7 / 2 and 2.39  ≈  2 / ξ2 which confirm the theoretical result.

Clearly, the coefficients of the inverted series decrease more rapidly than the coefficients of either ([\ref=eq:t_series]) or ([\ref=eq:r_n(t)]). Therefore, from a numerical point of view it is convenient to build approximants based on the inverted series. The price we have to pay is that the inverted series does not yield r(t) directly, which may not be a serious drawback for some purposes. We can improve the convergence of the inverted series by means of an appropriate summation method like the Padé approximants and thus obtain [formula] which together with [formula] yields the parametric representation for r(t).

Summarizing: the most important results of this comment are

The particular form and remarkable accuracy of the approximation r*(t) of Obreschkow et al is now explained by the fact that the coefficients aj behave asymptotically as j- 11 / 5 for large j.

Present analysis strongly suggests that r∞  (t) is identical to r(t) for all 0  ≤  t  ≤  1 in disagreement with the statement of breschkow et al.

Alternative approximations to r(t) in terms of the inverted power series exhibit faster convergence than the approach of Obreschkow et al, although the inverted power series does not yield r(t) directly.