scaled = scaled = scaled = scaled =

scaled 1 =

scaled

scaled

SLAC-PUB-7915 OUNP-99-06 Saclay/SPhT-T99/047 PITHA 99/12 May 1999

MEASUREMENT OF THE RUNNING b-QUARK MASS USING e+e- →   bg [formula] EVENTS

A. Brandenburg1, P.N. Burrows2, D. Muller3, N. Oishi4, P. Uwer5

ABSTRACT

We have studied the determination of the running b-quark mass, m(M) , using Z0 decays into 3 or more hadronic jets. We calculated the ratio of [formula]-jet fractions in e+e- b b vs. e+e- [formula] (ql = u or d or s) events at next-to-leading order in perturbative QCD using six different infra-red- and collinear-safe jet-finding algorithms. We compared with corresponding measurements from the SLD Collaboration and found a significant algorithm-dependence of the fitted m(M) value. Our best estimate, taking correlations into account, is mb(MZ) = 2.56  ±  0.27 (stat.) + 0.28- 0.38 (syst.) + 0.49- 1.48 (theor.) GeV/c2.

1 Institut für Theoretische Physik, RWTH Aachen, D-52056 Aachen, Germany and DESY Theory Group, D-22603 Hamburg, Germany.

2 Oxford University, Particle and Nuclear Physics, Oxford, OX1 3RH, UK.

3 Stanford Linear Accelerator Center, 2575 Sand Hill Road, Menlo Park, CA 94025, USA.

4 Nagoya University, Nagoya 464, Japan.

5 Service de Physique Théorique, Centre d'Etudes de Saclay, F-91191 Gif-sur-Yvette cedex, France.

Introduction

Three-jet events of the type e+e- [formula] provide an ideal laboratory for making precise tests of Quantum Chromodynamics (QCD) [\cite=qcd]. Since the initial state is free of strongly-interacting particles the experimental environment is intrinsically 'clean', and the process is more amenable to calculation using perturbation theory than, for example, multijet final states in hadron-hadron or lepton-hadron collisions. A number of perturbative QCD (pQCD) predictions for 3-jet dominated hadronic event-shape observables, for massless quarks, complete at next-to-leading order (NLO) are available [\cite=ert] [\cite=nlo] [\cite=GiGl92] [\cite=CaSe96b] [\cite=CaSe97] [\cite=FrKuSi96] [\cite=NaTr97].

One would expect the emission of gluon radiation in events containing massive quarks, e+e- [formula]    (Q = b or c), to be modified relative to that in e+e- [formula] (ql = u or d or s) events due to the restriction in phase space imposed by the non-zero quark mass. One would also expect such a modification to depend on the choice of the event-shape observable, and to be potentially relatively large for those observables in which the quark-jet mass enters kinematically into the definition. Recently NLO calculations of e+e- [formula] have been performed in which quark mass effects have been taken into account explicitly [\cite=arnd] [\cite=rodrigo] [\cite=nason]. >From these calculations one expects the size of the c-mass effects in [formula] events at [formula] to be rather small, at the level of 1%. However, for bg [formula] events the relative size of the b-mass effects on event-shape observables can be much larger, up to around 5%. Such a large effect needs to be taken into account in precise studies of bg [formula] events where the experimental errors can be comparable with, or smaller than, this size.

For example, tests of the flavour-independence of strong interactions involve measurements of the ratios rQ(X) = XQ / Xuds of a 3-jet observable X in [formula] versus [formula] events. Currently the experimental errors on rb(X) are of the order of 1-2%, and b-mass effects are clearly visible in the data [\cite=phil] [\cite=delphi]. By contrast, the errors on rc(X) are much larger than 1% and any c-mass effects are not discernible. Hence, in recent measurements the NLO massive calculations have been employed to correct rb(X) for the b-mass effects, so as to determine the ratio of strong couplings, [formula]α[formula]α[formula] [\cite=delphi] [\cite=sld] [\cite=opal], and test the ansatz of flavour-independence of strong interactions.

An alternative, and a priori equally valid, approach is to assume that strong interactions are flavour independent, and use the sensitivity of event-shape observables to mass effects to determine the b-mass itself. In the theoretical prediction one has the freedom to choose the renormalization scheme which defines the quark mass. For example, one can write the NLO result in terms of either the perturbative pole mass Mb or the 'running' mass mb(μ). The latter is defined by the modified minimal subtraction ([formula]) scheme [\cite=msbar] employed to renormalize the mass at a scale μ. At the Z0 scale, MZ, the running mass is preferable because large logarithms of the form ln (M2b / M2Z) are absorbed in mb(MZ), and the perturbative expansion is thus improved. The DELPHI Collaboration has recently studied the 3-jet-rate R3(yc), where R3 was determined using the Durham (D) jet-finding algorithm [\cite=durham], and yc is the scaled-invariant-mass criterion which determines the jet multiplicity. From their measurement of rb(R3) at yc = 0.02 DELPHI obtained [\cite=delphi]:

[formula]

Such 3-jet-event observables have been used for many years to determine αs(MZ) from inclusive-flavour e+e- annihilation events [\cite=alphas]. Though the α αs value obtained by fitting a NLO pQCD calculation to any one measured observable can have quite a small experimental error, [formula] for some observables, there is a strong dependence of the fitted α(M) αs(MZ) value on the choice of observable [\cite=sldalp] [\cite=lepalp]. This spread of values leads to a large and dominant uncertainty on α(M) αs(MZ) determined with this technique [\cite=alphas]. Since non-perturbative effects are supposedly taken into account in these measurements, usually by applying corrections based on well-tested hadronisation models [\cite=models], a consistent description within the framework of pQCD is viable only if one postulates large (and uncalculated) next-to-next-to-leading-order (NNLO) contributions to the observables. Hence, in this picture, the spread in α(M) αs(MZ) values determined at NLO results from the omission of the uncalculated higher-order terms. Furthermore, it can be argued that a strong dependence of a NLO calculation on the renormalisation scale is generally a sign of large NNLO contributions. Such a dependence is indeed observed for most of the observables [\cite=sldalp] [\cite=lepalp] [\cite=optscale], and supports the previous interpretation, though there is little consensus on a procedure for quantifying the scale-dependence of measurements of α(M) αs(MZ) .

The DELPHI determination of m(M)  (Eq. [\ref=eq:delphi]) is based on a ratio of 3-jet-event observables calculated at NLO. Given this apparently very precise result derived from one observable, it is interesting to consider the possible effect of NNLO contributions. Naively one might expect any potentially sizeable effects in the numerator and denominator largely to cancel. However, a residual uncertainty at only the 2% level on rb corresponds (Section 3) to a 0.5 GeV/c2 error on m(M) , which is comparable with the quoted total error on the DELPHI measurement. For the purpose of investigation we have studied the extraction of m(M) from the ratios rb(R3), where R3 was determined using six different infra-red- and collinear-safe jet-finding algorithms. As in the case of α(M) αs(MZ) measurements using such observables, the study of an ensemble of results from different observables, all calculated at NLO, may uncover systematic effects relating to the uncalculated NNLO contributions. We used the Durham and Geneva (G) [\cite=bkss] schemes, and the E, E0, P and P0 variations of the JADE algorithm [\cite=jade] to evaluate the b-mass-dependent NLO pQCD predictions, and compared them with the corresponding experimental measurements published by the SLD Collaboration [\cite=sld].

In Section 2 we outline the theoretical framework and briefly describe the NLO calculations used here. In Section 3 we compare the calculations with the data and extract values of m(M) using each jet algorithm in turn. We compare the results obtained using the different jet algorithms, and discuss the systematic uncertainties. In Section 4 we combine these results to obtain our best estimate of the central m(M) value and error by taking correlations into account. These results supercede the preliminary results presented in [\cite=phil].

Theoretical Framework

In this section we describe the computation of the double ratio:

[formula]

where we define Rq3(yc) to be the fraction of events classified as containing 3 or more jets with a particular jet-finding algorithm at a particular yc value. The event flavour is defined by the flavour of the primary quarks that couple to the Z0 . This definition means that events of the type Z0  →  qlg  →  qlb are classified as light-quark events Rb3(yc) and Ruds3(yc) can be written to NLO accuracy:

[formula]

where the coefficients A (B) represent the LO (NLO) contribution to 3-jet production, and the coefficients C represent the LO contribution to 4-jet production. Thus we have (we suppress here the argument yc):

[formula]

Some comments are in order about the generalization of observables originally defined for massless quarks to account for quark masses. Because of the fact that, for massless quarks, energy and the modulus of the three-momentum can be interchanged, the generalization to massive quarks contains a certain degree of freedom. For massive quarks one should use a definition which is infrared safe and does not distinguish between a hard parton and the hard parton substituted by two collinear ones, or a hard parton and soft parton. (See for example [\cite=Gottschalk] where this is discussed for the example of the thrust.) While this is not a problem for the Durham, Geneva, and E algorithms one should be careful when using algorithms which use a recombination procedure that keeps the recombined four-momentum massless, in particular the E0, P, and P0 algorithms. Replacing a massive quark by a hard parton and a soft one, or two collinear partons, would yield a massless four-momentum vector after the recombination, instead of getting the original four-momentum back. These algorithms hence 'feel' soft and collinear partons if they are naively applied for massive quarks. (Fortunately this problem does not occur if further splitting is considered.)

One possibility would be to modify these algorithms in some fashion so as to keep the hadronisation corrections small; this was in fact the original motivation for developing the Durham and Geneva algorithms. Here we preserve the definition of the algorithms so as to be able to compare with the published results of the SLD analysis. The SLD measurements are corrected to the parton-level, where the naive jet definition is applied even if one of the four-momenta is massive. We are hence able to extract consistently the b mass from these measurements obtained with the E0,P, and P0 jet algorithms by treating the b quark as massive in our theoretical prediction.

3-jet Contributions

For 3-jet production the LO massless (Auds) and massive (Ab) [\cite=Io78] as well as the NLO massless (Buds) [\cite=nlo] coefficients are well known. In order to calculate the massive NLO coefficients Bb we need the matrix elements for

[formula]

to order α2s, as well as the matrix elements for the parton processes

[formula]

In the calculation of the virtual corrections to Eq. [\ref=eq:3-partons] both ultra-violet (UV) and infra-red (IR) singularities are encountered. The UV singularities are removed by the usual renormalization procedure of the mass parameter and the QCD coupling αs.

The IR singularities are cancelled by the real contributions from the processes listed in Eq. ([\ref=eq:4-partons]). It is worthwhile adding some remarks about this cancellation. Today it is more or less standard to regulate the IR divergences in the framework of dimensional regularization. To cancel the divergences in the virtual corrections one must then integrate the real contributions over some regions of phase-space in d dimensions. More precisely one must integrate over the regions where a gluon is soft or two massless partons are collinear. In general this would be a formidable task. Therefore several techniques have been developed in the past (see for example [\cite=GiGl92] [\cite=CaSe96b] [\cite=CaSe97] [\cite=GiGlKo93]) to simplify this problem using the general factorization properties of QCD amplitudes. In the calculation reported in [\cite=arnd] on which the current paper is based the so called phase-space-slicing method [\cite=GiGl92] was used. The same is true for the results presented in [\cite=rodrigo] on which the DELPHI analysis [\cite=delphi] is based. In the calculation given in [\cite=nason] an alternative, the so-called subtraction method, was used.

In the simplest version of the phase-space slicing method one separates the 'soft' and 'collinear' regions (often called 'unresolved regions') from the rest of the phase-space ('resolved regions') by demanding a minimal invariant mass-squared s min for all pairs of partons. In the soft and collinear regions the squared matrix elements can be approximated by the use of the soft and collinear factorization which is valid in the appropriate limits. After this simplification the relevant part of the squared matrix elements can be integrated analytically in d dimensions. The phase-space integration over the resolved regions can be done numerically in four dimensions. In the case of massive quarks the phase-space slicing method must be modified, although the basic features are the same. In particular, the 'slicing' between the soft/collinear regions and the regions where all partons are hard can still be parametrized in terms of one variable s min.

The approximation used in the unresolved region is only valid for small values of s min. On the other hand for small s min large cancellations between the numerically integrated and the analytically integrated parts will arise leading to possible errors in the sum of the two. Note that the artificial cut parametrized by s min is not related to any physical cut. Thus the theoretical prediction must be independent of s min. In practice, for the NLO coefficient Bb this will be true up to corrections of the order of s min / s. With the value [formula], which we have used in our calculation, the systematic error in Bb due to the phase-space slicing method is negligible compared with the numerical error due to the numerical integration, which is itself negligibly small.

Note that although free of collinear singularities in the case of massive quarks, one must also include the contribution of the reaction [formula] to the 3-jet rate. The collinear singularity appearing for massless quarks shows up as ln (mb) for massive quarks. Only if this contribution is included is the 3-jet contribution free of collinear singularities in the limit of vanishing b-quark mass. The logarithm cancels against the logarithm coming from the virtual corrections to the gluon propagator due to a b-quark loop. Needless to say, this reaction contributes also to the 4-jet rate.

Note also that in the reaction [formula] collinear singularities (due to collinear configurations of a (anti-)quark gluon pair) that appear for massless quarks give rise only to logarithms of the mass. This explains why it is difficult to calculate Rb3 numerically for small values of mb without further analytical work. In the virtual correction these logarithms are explicit. In the real contribution they must be obtained numerically from the phase space integration, which becomes more difficult for smaller masses due to numerical instabilities.

For technical reasons it is easier to perform the calculation of rb first in the pole mass scheme, and switch to the running mass afterwards. The relation between the pole mass Mb and the [formula]  mass mb(μ) reads

[formula]

where, to order αs,

[formula]

This implies the following relation between rb in both mass renormalization schemes [\cite=spira]:

[formula]

The mass dependence of Ab can be written as Ab(mb) = Auds  +  δAb(mb)m2b / s, which defines the function δAb(mb). For m2b  ≪  s, δAb depends only weakly on mb. Ignoring this residual mass dependence we have

[formula]

and we use the r.h.s. of ([\ref=eq:approx]) to convert the results for rb from the pole mass to the [formula] mass renormalization scheme. This excellent approximation avoids the calculation of the derivative dAb / dmb for each algorithm.

4-jet Contributions

Both the massless [\cite=nlo] and massive [\cite=BMM92] LO 4-jet fraction contributions (C) are well known. Recently, the massless 4-jet fraction has been computed to NLO [\cite=DiSi97]. These corrections, which are of order α3s and therefore not included in our prediction for rb, can change, depending on the jet algorithm, the values of the massless C coefficients by up to 100%. Note that part of these large NNLO corrections to rb will cancel between the massless and (yet unknown) massive [formula] C coefficients entering ([\ref=eq:rbexpand]).

Calculation of rb

The calculation of rb was performed, for each of the six jet algorithms at the optimal yc values (discussed below), for m(M) values in the range [formula] GeV/c2. These predictions are shown as points in Fig. [\ref=sixfigs]. For the P and P0 algorithms we also calculated a point at mb(MZ) = 1 GeV/c2 so as to constrain better the extrapolation rb →   1 as mb(MZ) →   0. The renormalization scale μ was set to [formula] and we used αs(MZ) = 0.118. The dependence of rb on the renormalization scale μ is trivial if rb is expressed in terms of the pole mass Mb; it enters only through the running of αs. An additional μ dependence is introduced if one switches to the running mass mb(μ) by using Eq. ([\ref=eq:polrun]). The theoretical uncertainty on mb(MZ) due to the choice of the renormalization scale will be discussed in section 3.

The function

[formula]

where α, β and γ are free parameters, was fitted to these points. The ansatz ([\ref=eq:fit]) can be jusified as follows: 1) As m  →  0, the massive fraction Rb3 approaches the massless one Ruds3; 2) since m2  ≪  s, it is a very good approximation to keep only the leading terms in m2 / s. The fitted parameter values are listed in Table [\ref=tfitpar]; the functions are shown in Fig. [\ref=sixfigs] and provide a good description of the mass dependence of the calculations.

It can be seen that the m(M) -dependence varies according to the jet algorithm. For m(M) ≥   2.0 GeV/c2, rb > 1 and the slope is positive for the E, E0, P and P0 cases, whereas rb < 1 and the slope is negative for the D and G cases. This can be understood qualitatively in terms of two competing physical origins. First, the non-zero b-mass tends to cause a phase-space suppression of gluon emission relative to the massless quark case, implying rb <   1. Second, for a given kinematic configuration, the large b-mass tends to enhance the invariant mass of a local quark-gluon pair relative to the massless quark case. Since the JADE family of jet algorithms is based on a clustering metric that is closely related to invariant mass, for fixed yc the two partons are more likely to be resolved as separate jets when the quark is massive, implying rb  ≥  1. By contrast, the clustering metric used in the Durham and Geneva algorithms is less sensitive to this kinematic effect, the phase-space suppression dominates, and rb  ≤  1. For increasing values of yc one expects both effects to diminish in importance and rb →   1. For the D algorithm this has been observed in the DELPHI study [\cite=delphi].

Extraction of the b-Quark Mass

We used measurements of rb published [\cite=sld] by the SLD Collaboration. These measurements are based on a sample of 150,000 hadronic Z0 decays recorded between 1993 and 1995, for which the original 120-million pixel CCD vertex detector was used for event flavour separation. SLD has subsequently recorded a further 400,000 Z0 decays with a new 307-million-pixel vertex detector, and it would be straightforward to repeat the present analysis when the new data are made available. Though not as statistically powerful as the DELPHI result for the D jet algorithm, the SLD published data include results for the six different jet algorithms D, G, E, E0, P and P0, and are hence suitable for this study of possible observable-dependent systematic effects.

Full details of the experimental procedure are given in [\cite=sld]. Briefly, e+e- →   hadrons events were selected, and a flavour-tagging algorithm was applied to select samples of events of primary b, c, and uds quark flavour. The algorithm was based on the mass and momentum of secondary decay vertices reconstructed using the vertex detector. Light-quark (uds) events rarely contain reconstructed secondary decay vertices, and these typically result from strange particle decays and are of low mass. Conversely, b b events typically contain high-mass vertices from B-hadron decays. The purity of the b-tagged (uds-tagged) event sample was 90% (91%) respectively.

Each jet-finding algorithm was applied in turn to the uds- and b-tagged samples and, for each algorithm, the ratios (Eq. [\ref=eq:observable]) were formed. The ratio is an attractive quantity as many of the experimental and theoretical systematic uncertainties effectively cancel. Each ratio was then corrected for the effects of detector acceptance and resolution, the bias of the flavour tag to select preferentially 2-jet rather than 3-jet events, the flavour compositions, and hadronisation effects. For each algorithm an 'optimal' yc value was selected so as to minimise the combined statistical and experimental systematic error.

The measured rb values and the associated errors are listed in Table [\ref=tab:sldr] [\cite=sld]. The central values and statistical errors are also shown in Fig. [\ref=sixfigs]. The set of rb values is not consistent with unity, which indicates that the b-mass effects are significant. Furthermore, a systematic algorithmic dependence is apparent, with rb  ≥  1 for the JADE family of algorithms and rb  ≤  1 for the D and G algorithms, in agreement with the expectations discussed in Section 2.

For each jet algorithm, by comparing the theoretical curve in Fig. [\ref=sixfigs] with the SLD data, one can read off the preferred m(M) value. The central values are listed in Table [\ref=tbmass]. In each case upper and lower statistical errors were evaluated from the crossing points of the error band with the theoretical prediction, except in the case of the G algorithm, for which the upper statistical bound is consistent with mb = 0; in this case an error equal to the central value was assigned. Each experimental systematic error on rb [\cite=sld] was similarly transformed into a systematic error on m(M) and the sum in quadrature is listed in Table [\ref=tbmass]. Hadronisation uncertainties [\cite=sld] were evaluated in a similar fashion and are listed in Table [\ref=tbmass].

Additional theoretical uncertainties were investigated by varying the value of αs(MZ) within the range 0.115  ≤   α(M) αs(MZ) [formula]. The corresponding changes in m(M) were at the level of ±  (10 - 20) MeV/c2. The renormalisation scale was also varied within the range MZ / 2  ≤  μ  ≤  2MZ. The corresponding changes in m(M) were at the level of [formula]MeV/c2 or less. For each algorithm these uncertainties were added in quadrature to define a theoretical uncertainty, which is listed in Table [\ref=tbmass].

The six measured b-quark masses range from 2.3 to 4.1 GeV/c2, with an r.m.s. deviation of 0.7 GeV/c2; this scatter is larger than one might expect from these data given the strong correlations between measurements using different jet algorithms, suggesting some additional source of uncertainty. In order to quantify this issue we evaluated the statistical correlations among the rb values determined using different jet algorithms. We repeated the analysis on subsets of both the data and the simulated data and calculated the correlation coefficients empirically. The data and simulation gave consistent results, and the average correlation coefficients are listed in Table [\ref=tcorrels]. Each has a statistical uncertainty of ±  0.03. The four JADE-like algorithms show strong correlations with each other, in the range 0.65-0.84, as might be expected. Correlations between other pairs of algorithms are weaker, in the range 0.41-0.65.

We evaluated

[formula]

where rbi (fi) are the measured (calculated) double ratios, i,j =  E, E0, P, P0, D, G, the error matrix is defined by Vij  =  cijσiσj, cij is the correlation coefficient given in Table [\ref=tcorrels], and σi is the quadratic sum of the data and Monte Carlo statistical errors on rbi. For values of m(M) around 2.9 GeV/c2, which is the average of the results shown in Table [\ref=tbmass], we obtained χ2 ≃ 38/6, which indicates an inconsistency among the results from the different algorithms. We minimised χ2 with respect to variation of m(M) and obtained χ2 = 26/5 for m(M) = [formula] (stat.) GeV/c2, which is still unacceptably high. The best-fit χ2 value is insensitive to variations of the cij within their uncertainties, and to (simultaneous) systematic shifts of the measured ri within the experimental systematic errors and hadronisation and theoretical uncertainties. The experimental systematic errors, which are dominated by uncertainties in the flavour composition of the samples, and the hadronisation uncertainties were assumed to be 100% correlated among all algorithms and were omitted from the χ2 calculation; theoretical uncertainties were also omitted.

We repeated this minimisation procedure and omitted in turn the measurement based on each of the six algorithms. In no case did we obtain a χ2 value better than 12, which corresponds to a confidence level of 1.7%. We then omitted pairs of measurements in turn. Fits with χ2 <   9, i.e. >  6% confidence level, were obtained only for two of these 15 cases in which both the E and E0, or both the P and P0, algorithms were omitted; the corresponding mass values were 2.5 and 3.5 GeV/c2, respectively. To the extent that the hadronisation and theoretical uncertainties have been properly estimated, we do not have a priori justification for omitting any particular algorithm(s). We do note, however, that algorithms in the JADE family have a significantly worse soft gluon behaviour than the D and G algorithms [\cite=bkss]. The former algorithms tend to combine soft gluons to form an 'artificial' jet at values of yc that are not small, which may cause large higher-order perturbative corrections even for moderate values of yc.

The χ2 value is, however, quite sensitive to small changes in the measured rbi or predicted fi. As an exercise, we have postulated an additional uncertainty of size ε which is uncorrelated between different jet algorithms. Under the hypothesis mb = 2.94 GeV/c2, which is the average of the values listed in Table [\ref=tbmass], for ε = 0.015 the χ2 value is 10.5; for ε = 0.02 the χ2 value is 7.1, which is acceptable. For ε  ≥  0.02 a fit for m(M) yields a stable value of roughly 2.6 GeV/c2, indicating that a consistent m(M) value can be obtained provided that there exist additional uncertainties, uncorrelated between jet algorithms, at the level of 2% on rb. A 2% error on the predicted rb corresponds to an error of ~  0.5 GeV/c2 on the extracted value of m(M) from a given algorithm, and would roughly account for the 0.7 GeV/c2 r.m.s. deviation among the values in Table [\ref=tbmass].

We suspect that the most likely source of the inconsistency among results for the different jet algorithms is the missing higher-order perturbative contributions to rb. As we have shown, these would have to be only at the level of 2% in order to resolve the inconsistency. Possible NNLO contributions to rb of this small magnitude are not a priori unexpected; 5-10% level NNLO contributions are implied by the scatter among α(M) αs(MZ) values determined using these and closely-related event-shape observables [\cite=alphas] which form the numerator and denominator of rb.

Summary and Conclusions

We have studied the determination of the running b-quark mass by comparing NLO perturbative QCD calculations of the [formula]-jet ratio rb = Rb3 / Ruds3 with data from the SLD Collaboration. We used six different infra-red- and collinear-safe jet-finding algorithms in order to study systematic effects. We find algorithm-dependent values of m(M) in the range [formula] GeV/c2. The value determined using the Durham algorithm is consistent with that reported in [\cite=delphi].

We quantified the statistical, experimental systematic, hadronisation and additional theoretical uncertainties, and attempted to obtain a best-fit m(M) value by minimising χ2, taking statistical correlations between the results from the different algorithms into account. We could not obtain an acceptable best-fit χ2 value unless, in two cases, we omitted two algorithms from consideration. In the absence of an a priori reason to do this we retained all six algorithms in order to investigate possible additional systematic effects. We were able to obtain an acceptable value of χ2, and a stable value m(M) ≃ 2.6 GeV/c2, provided that we postulated (an) additional source(s) of uncertainty of relative size [formula]% on rb, which is uncorrelated between algorithms. We are unable to account for the origin of such an uncertainty, but speculate that it may be due to uncalculated higher-order pQCD contributions.

We now discuss the assignment of a single value of m(M) . Taking an unweighted average of the mb values in Table [\ref=tbmass], yields mb(MZ) = 2.94+ 0.80- 0.95 (stat.) + 1.22- 1.36 (syst.) + 0.26- 1.20 (had.) + 0.11- 0.12 (theor.) [formula] (r.m.s.) GeV/c2, where we include the r.m.s. deviation as an additional error. Though well defined, this procedure does not make full use of the information contained in the six measurements. The χ2 minimisation procedure does take into account the full statistical covariance matrix, as well as correlations in the systematic error and hadronisation uncertainties. Since the resulting χ2 is acceptable, and the fitted m(M) value is stable for any additional uncorrelated uncertainties of size ε ≥   0.02, we choose ε = 0.02, and obtain χ2 = 6.5/5 with

[formula]

We consider that this represents our best estimate of the running b-quark mass using the SLD data.

The statistical error on m(M) is substantially reduced by the correlations among the six individual rb results. The experimental systematic error is also reduced by the fact that a given shift of rb causes the m(M) values for the E, E0, P and P0 algorithms to shift in opposite directions to those for the D and G algorithms. The theoretical uncertainty comprises the sum in quadrature of the hadronisation uncertainty (+ 0.25- 1.42 GeV/c2), and the propagation of the uncorrelated error of [formula] on each rb (±  0.42 GeV/c2). Variations of α αs and μ contribute an uncertainty of + 0.14- 0.12 GeV/c2; under the assumption that the 'ε error' results from uncalculated higher-order pQCD contributions the effects represented by these variations are already 'counted', and we have not added them in quadrature with the other theoretical uncertainties. Their inclusion does not change the central m(M) value and increases the total theoretical uncertainty to + 0.51- 1.49 GeV/c2.

Our result is in agreement with that from [\cite=delphi]. The latter measurement has a significantly smaller theoretical uncertainty. For the Durham algorithm alone we would obtain an uncertainty of similar size, but our study of six different jet algorithms has revealed additional systematic effects which warrant further investigation.

Acknowledgements

P.N.B., D.M. and N.O. thank colleagues in the SLD Collaboration for their support for this work. We thank Werner Bernreuther, Otmar Biebel, and Mike Seymour for helpful discussions.