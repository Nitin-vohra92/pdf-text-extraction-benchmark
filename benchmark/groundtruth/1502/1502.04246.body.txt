Stable Leader Election in Population Protocols Requires Linear Time

Introduction

Background.

Population protocols (PPs) were introduced by Angluin, Aspnes, Diamadi, Fischer, and Peralta[\cite=angluin2006passivelymobile] as a model of distributed computing in which the agents have very little computational power and no control over their schedule of interaction with other agents. They also can be thought of as a special case of Petri nets/vector addition systems[\cite=petri1966communication] [\cite=karp1969parallel], which were introduced in the 1960s as a model of concurrent processing. In addition to being an appropriate model for electronic computing scenarios such as mobile sensor networks, they are a useful abstraction of "fast-mixing" physical systems such as animal populations[\cite=Volterra26], chemical reaction networks, and gene regulatory networks[\cite=bower2004computational].

A PP is defined by a finite set Λ of states that each agent may have, together with a transition function δ:Λ  ×  Λ  →  Λ  ×  Λ. Given states r1,r2,p1,p2∈Λ, if δ(r1,r2) = (p1,p2) (denoted r1,r2  →  p1,p2) and a pair of agents in respective states r1 and r2 interact, then their states become p1 and p2. A configuration of a PP is a vector [formula] describing, for each state s∈Λ, the count [formula] of how many agents are in state s. Executing a transition r1,r2  →  p1,p2 alters the configuration by decrementing the counts of r1 and r2 by 1 each and incrementing p1 and p2 by 1 each.

Associated with a PP is a set of valid initial configurations that we expect the PP to be able to handle. Agents interact in a pairwise manner and change state based on the transition function. The next pair of agents to interact is chosen uniformly at random among the n agents. (An interaction may be a "null transition" r1,r2  →  r1,r2.) We count the expected number of interactions until some event occurs, and then define the "parallel time" until this event as the expected number of interactions divided by the number of agents n. This measure of time is based on the natural parallel model where each agent participates in a constant number of interactions in one unit of time, hence Θ(n) total interactions are expected per unit time [\cite=angluin2006fast]. In this paper all references to "time" refer to parallel time.

In order to define error-free computation in PPs, we rely on to the notion of stable computation [\cite=angluin2007computational]. The PP must get to a configuration that is correct and "stable" in the sense that no subsequent sequence of transitions can take the PP to an incorrect configuration. Error-free computation must be correct in an "adversarial" schedule of transitions: we require that from every configuration reachable by any sequence of transitions from the initial configuration, it is possible to reach to a correct stable configuration. Since the configuration space is finite, this is equivalent to requiring, under the randomized model, that a correct stable configuration is reached with probability 1.

A PP works "with a leader" if there is a special "leader" state [formula], and every valid initial configuration [formula] satisfies [formula]. This is in contrast to a uniform initial configuration ([formula] for some state x and [formula] for all states y  ≠  x) or an initial configuration only encoding the input ([formula] for [formula] to represent any input [formula]). It is known that the predicates [formula] stably computable by PPs are exactly the semilinear predicates, whether an initial leader is allowed or not [\cite=angluin2007computational]. Although the initial leader does not alter the class of computable predicates, it may allow faster computation. Specifically, the fastest known PPs to stably compute semilinear predicates without a leader take as long as Θ(n) to converge. In contrast, with a leader, it is known that any semilinear predicate can be stably computed with expected convergence time O( log 5n) [\cite=angluin2006fast]. Thus, in certain circumstances, the presence of a initial leader seems to give PPs more computational power (e.g., to converge quickly). Angluin, Aspnes, and Eisenstat [\cite=angluin2006fast] asked whether polylogarithmic time stable computation of semilinear predicates is possible without a leader; absent a positive answer, the presence of a leader appears to add power to the model.

Statement of main result.

Motivated in part by the apparent speedup possible with an initial leader, we ask how quickly a leader may be elected from a configuration lacking one. We pose the problem as follows: design a PP [formula] with two special states x (the initial state) and [formula] (the leader state, which may or may not be identical to x) such that, for every [formula], from the initial configuration [formula] defined as [formula] and [formula] for all other states y, has the following property. For every configuration [formula] reachable from [formula], there is a configuration [formula] reachable from [formula] that has a stable leader, meaning that in all configurations [formula] reachable from [formula] (including [formula] itself), [formula].

There is a simple O(n) expected time PP for stable leader election, with (assuming [formula]) the single transition [formula]. Our main theorem shows that every PP that stably elects a leader requires time Ω(n) to reach a state with a stable leader; thus the previous PP is asymptotically optimal.

Multiple leader states, multiple leaders, and other initial configurations.

A more general notion of leader election is to identify a subset Ψ  ⊂  Λ of states that are all considered leader states, and to require the PP to eventually reach a configuration [formula] in which [formula], and this sum is 1 in every configuration reachable from [formula]. This corresponds more appropriately to how leader states actually coordinate computation in PPs: a leader agent must remember some state information in between transitions (hence it changes state while remaining the unique leader). Our techniques actually show this stronger result as well (as explained in Section [\ref=sec:result-statement:locking]). Further, our result implies that a PP cannot elect any fixed quantity of leaders (e.g. exactly 256) or variable quantity of leaders under a fixed bound (e.g. at most 256) in sublinear expected time.

In the simplest formulation of the task of leader election, we always start with n agents in state x (as described above). Can we capture more generally leader election from a configuration "without a pre-existing leader"? Intuitively, we want to exclude initial configurations with states present in small but non-zero count. We can exclude such initial configurations, but allow otherwise deliberately prepared starting conditions, using the notion of α-dense configurations: any state present in the initial configuration has count ≥  αn. Our general negative result (Theorem [\ref=thm:main-q-locking]) implies that even starting with best-case initial configurations, as long as, for some constant α  >  0, they are all α-dense, sublinear time leader election is impossible. An open question relates to weakening the notion of α-dense (see below).

Chemical reaction networks.

Open questions.

An important open question concerns the contrast between convergence and stabilization. We say a PP electing a leader converges when it stops changing the count of the leader (if it is correct, this count should be 1), and we say it stabilizes when it first enters a configuration from which the count of the leader cannot change. In many PPs these two events coincide, but it is possible to converge strictly before stabilizing. Our proof shows only that stabilization must take expected Ω(n) time. We leave as an open question whether there is a PP that stably elects a leader and converges in expected o(n) time. Recall that there are PPs that work with a leader to stably compute semilinear predicates with convergence time O( log 5n) [\cite=angluin2006fast]. Thus if stable leader election can converge in expected sublinear time, by coupling the two PPs it might be possible to achieve stable computation of arbitrary semilinear predicates with sublinear convergence time.

It is similarly open to determine the optimal stabilization time for computing semilinear predicates. The stably computing PPs converging in O( log 5n) time [\cite=angluin2006fast] provably require expected time Ω(n) to stabilize, and it is unknown whether faster stabilization is possible even with an initial leader.

The open question of Angluin, Aspnes, and Eisenstat [\cite=angluin2006fast] asks whether their efficient high-probability simulation of a space-bounded Turing machine by a PP could remove the assumption of an initial leader. That simulation has some small probability ε  >  0 of failure, so if one could elect a leader with a small probability ε'  >  0 of error and subsequently use it to drive the simulation,by the union bound the total probability of error would be at most ε  +  ε' (i.e., still close to 0). However, it remains an open question whether the necessary PP exists. Alistairh and Gelashvili [\cite=polylogleaderICALP] showed that relaxing the requirement of O(1) states to O( log 3n) states allows for a leader to be elected with high probability in expected time O( log 3n).

Our general negative result applies to α-dense initial configurations. However, is sublinear time stable leader election possible from other kinds of initial configurations that satisfy our intuition of not having preexisting leaders? It is known, for example, that for each 0  <  ε  <  1, an initial configuration with Θ(n) agents in one state and Θ(nε) in another state can elect a leader in expected time O( log 2n) with high probability[\cite=angluin2006fast], although this protocol has a positive probability of failure. In general we want to better characterize the initial configurations for which sublinear time leader election is possible.

Preliminaries

If Λ is a finite set (in this paper, of states), we write [formula] to denote the set of functions [formula]. Equivalently, we view an element [formula] as a vector of |Λ| nonnegative integers, with each coordinate "labeled" by an element of Λ. Given s∈Λ and [formula], we refer to [formula] as the count of s in [formula]. Let [formula] denote the total number of agents. We write [formula] to denote that [formula] for all s∈Λ. Since we view vectors [formula] equivalently as multisets of elements from Λ, if [formula] we say [formula] is a subset of [formula]. It is sometimes convenient to use multiset notation to denote vectors, e.g., {x,x,y} and {2x,y} both denote the vector [formula] defined by [formula], [formula], and [formula] for all [formula]. Given [formula], we define the vector component-wise operations of addition [formula], subtraction [formula], and scalar multiplication [formula] for [formula]. For a set Δ  ⊂  Λ, we view a vector [formula] equivalently as a vector [formula] by assuming [formula] for all [formula]

A population protocol (PP) is a pair [formula], where Λ is a finite set of states, and δ:Λ  ×  Λ  →  Λ  ×  Λ is the (symmetric) transition function. A configuration of a PP is a vector [formula], with the interpretation that [formula] agents are in state s. By convention, the value [formula] represents the total number of agents [formula]. A transition is a 4-tuple α  =  (r1,r2,p1,p2)∈Λ4, written α:r1,r2  →  p1,p2, such that δ(r1,r2) = (p1,p2). This paper typically defines a PP by a list of transitions, with δ implicit (there is a null transition δ(r1,r2) = (r1,r2) if a different transition is not specified). If an agent in state r1 interacts with an agent in state r2, then they change states to p1 and p2.

More formally, given a configuration [formula] and transition α:r1,r2  →  p1,p2, we say that α is applicable to [formula] if [formula], i.e., [formula] contains 2 agents, one in state r1 and one in state r2. If α is applicable to [formula], then write [formula] to denote the configuration [formula] (i.e., the configuration that results from applying α to [formula]); otherwise [formula] is undefined. A finite or infinite sequence of transitions (αi) is a transition sequence. Given an initial configuration [formula] and a transition sequence (αi), the induced execution sequence (or path) is a finite or infinite sequence of configurations [formula] such that, for all [formula] (i  ≥  1), [formula]. If a finite execution sequence, with associated transition sequence q, starts with [formula] and ends with [formula], we write [formula]. We write [formula] if such a transition sequence exists (i.e., it is possible for the system to reach from [formula] to [formula]) and we say that [formula] is reachable from [formula]. If it is understood from context what is the initial configuration [formula], then say [formula] is simply reachable if [formula]. Note that this notation omits mention of [formula]; we always deal with a single PP at a time, so it is clear from context which PP is defining the transitions. If a transition α:r1,r2  →  p1,p2 has the property that for i∈{1,2}, [formula], or if (r1 = r2 and (ri  ≠  p1 or ri  ≠  p2)), then we say that α consumes ri. In other words, applying α reduces the count of ri. We similarly say that α produces pi if it increases the count of pi.

We will find ourselves frequently dealing with infinite sequences of configurations. The following lemma, used frequently in reasoning about population protocols, shows that we can always take a nondecreasing subsequence.

Any infinite sequence [formula] has an infinite nondecreasing subsequence [formula], where

In any configuration the next interaction is chosen by selecting a pair of agents uniformly at random and applying transition function δ. To measure time we count the expected total number of interactions (including null), and divide by the number of agents n. (In the population protocols literature, this is often called "parallel time"; i.e. n interactions among a population of n agents corresponds to one unit of time). Let [formula] and [formula]. Denote the probability that the PP reaches from [formula] to some configuration [formula] by [formula]. If [formula], define the expected time to reach from [formula] to C, denoted [formula], to be the expected number of interactions to reach from [formula] to some [formula], divided by the number of agents n.

Main Results

Impossibility of Sublinear Time Stable Leader Election

We consider the following stable leader election problem. Suppose that each PP [formula] we consider has a specially designated state [formula], which we call the leader state. Informally, the goal of stable leader election is to be guaranteed to reach a configuration with count 1 of [formula] (a leader has been "elected"), from which no transition sequence can change the count of [formula] (the leader is "stable"). We also assume there is a special initial state x (it could be that [formula] but it is not required), such that the only valid initial configurations [formula] are of the form [formula] and [formula] for all states [formula]. We write [formula] to denote such an initial configuration with [formula]

A configuration [formula] is stable if, for all [formula] such that [formula], [formula] (in other words, after reaching [formula], the count of [formula] cannot change); [formula] is said to have a stable leader if it is stable and [formula].

The following definition captures our notion of stable leader election. It requires the PP to be "guaranteed" eventually to reach a configuration with a stable leader.

We say a PP elects a leader stably if, for all [formula], for all [formula] such that [formula], there exists [formula] with a stable leader such that [formula].

In other words, every reachable configuration can reach to a configuration with a stable leader. It is well-known [\cite=angluin2007computational] that the above definition is equivalent to requiring that the PP reaches a configuration with a stable leader with probability 1.

Let [formula], and let Y be the set of all configurations with a stable leader. We say a PP elects a leader stably in time t(n) if, for all [formula], [formula]

Our main theorem says that stable leader election requires at least linear time to stabilize:

If a PP stably elects a leader in time t(n), then t(n)  =  Ω(n).

Thus a PP that elects a leader in sublinear time cannot do so stably, i.e., it must have a positive probability of failure.

The high-level strategy to prove Theorem [\ref=thm:main] is as follows. With high probability the PP initially goes from configuration [formula] to configuration [formula], such that in the sequence [formula] for increasing population size n, every state count grows without bound as n  →    ∞   (indeed Ω(n)); this follows from Theorem [\ref=thm:timer]. We then show that any such configuration must have an "O(1)-bottleneck transition" before reaching a configuration with a stable leader (informally this means that every transition sequence from [formula] to a configuration [formula] with a stable leader must have a transition in which both input states have count O(1), depending on the PP but not on n). Since it takes expected time Ω(n) to execute a transition when both states have constant count, from any such configuration it requires linear time to stably elect a leader. Since one of these configurations is reached from the initial configuration with high probability, those configurations' contribution to the overall expected time dominates, showing that the expected time to stably elect a leader is linear.

More General Impossibility Result in Terms of Inapplicable Transitions and Dense Configurations

Rather than proving Theorem [\ref=thm:main] using the notion of leader stability directly, we prove a more general result concerning the notion of a set of inapplicable transitions. The two generalizations are as follows. (1) A configuration [formula] is stable by Definition [\ref=defn:stable] if no transition altering the count of [formula] is applicable in any configuration reachable from [formula]; Definition [\ref=defn:q-stable] generalizes this to an arbitrary subset Q of transitions. (2) The valid initial configurations of Section [\ref=subsec:stable-leader-election-defn] are those with [formula] and [formula] for all [formula]; Theorem [\ref=thm:main-q-locking] generalizes this to any set I of configurations that are all "α-dense" (defined below) for a fixed α > 0 independent of n, with a weak sort of "closure under addition" property: namely, that for infinitely many [formula], we have [formula].

Let Q be a set of transitions. A configuration [formula] is said to be Q-stable if no transition in Q is applicable in any configuration reachable from [formula].

If we let Q be the set of transitions that alter the count of the leader state [formula], then a Q-stable configuration [formula] with [formula] exactly corresponds to the property of having a stable leader.

Let [formula] and Q be a set of transitions. Let Y be the set of Q-stable configurations reachable from some configuration in I. We say that a PP [formula] Q-stabilizes from I if, for any [formula], [formula]. If I and Q are understood from context, we say that [formula] stabilizes. For a time bound t(n), we say that [formula] stabilizes in expected time t(n) if, for all [formula] such that [formula], [formula].

To prove our time lower bound, we show that a "slow" transition necessarily occurs, which means that the counts of the two states in the transition are "small" when it occurs. We will pick a particular nondecreasing infinite sequence C of configurations and define "small" relative to it: the "small count" states are those whose counts are bounded in C (denoted [formula] below).

For an (infinite) set/sequence of configurations C, let [formula] be the set of states [formula]. Let [formula].

Note that if [formula] is a nondecreasing sequence, then for all [formula], there is [formula] such that for all [formula], [formula]. (Note that if C is not nondecreasing, the conclusion can fail; e.g., [formula] for m even and [formula] for m odd.)

Let 0  <  α  ≤  1. We say that a configuration [formula] is α-dense if for all s∈Λ, [formula] implies that [formula], i.e., all states present in [formula] occupy at least an α fraction of the total count of agents.

Theorem [\ref=thm:main] is implied by the next theorem, which the rest of the paper is devoted to proving.

Let [formula], let Q be any subset of transitions of [formula], let α  >  0, and let [formula] be a set of α-dense initial configurations such that, for infinitely many [formula], [formula]. Let Y be the set of Q-stable configurations reachable from I, and let [formula]. Suppose [formula] Q-stabilizes from I in expected time o(n). Then there are infinitely many [formula] such that [formula], [formula].

In other words, if some states have "small" count in all reachable stable configurations, then there is a reachable stable configuration in which those states have count 0. A PP [formula] that stably elects a leader is a PP in which Q is the set of transitions that alter the count of [formula], [formula] (note all [formula] are 1-dense), Y is the set of configurations reachable from I with a stable leader, and [formula] Q-stabilizes from I. Hence by Theorem [\ref=thm:main-q-locking], if [formula] stabilizes in expected time o(n), there is a stable reachable [formula] where [formula], a contradiction. Thus Theorem [\ref=thm:main] follows from Theorem [\ref=thm:main-q-locking].

We can also use Theorem [\ref=thm:main-q-locking] to prove that stable leader election requires linear time under the more relaxed requirement that there is a set Ψ  ⊂  Λ of "leader states," and the goal of the PP is to reach a configuration [formula] in which [formula] and stays 1 in any configuration reachable from [formula]. Choosing Q as the set of transitions that alter that sum, Theorem [\ref=thm:main-q-locking] implies this form of stable leader election also requires Ω(n) expected time.

Throughout the rest of this paper, fix [formula], α, I, and Q as in the statement of Theorem [\ref=thm:main-q-locking].

Technical Tools

Bottleneck Transitions Require Linear Time

This section proves a straightforward observation used in the proof of our main theorem. It states that, if to get from a configuration [formula] to some configuration in a set [formula], it is necessary to execute a transition r1,r2  →  p1,p2 in which the counts of r1 and r2 are both at most some number b, then the expected time to reach from [formula] to some configuration in Y is Ω(n / b2).

Let [formula]. We say that transition α:r1,r2  →  p1,p2 is a b-bottleneck for configuration [formula] if [formula] and [formula].

Let γ  >  0, [formula], [formula], and [formula] such that [formula], [formula], and every transition sequence from every [formula] to some [formula] has a b-bottleneck. Then [formula]

Sublinear Time from Dense Configurations Implies Bottleneck Free Path from Configurations with Every State "Populous"

The following theorem, along with Corollary [\ref=cor:bottlebeck-linear-time], fully captures the probability theory necessary to prove our main theorem. Given it and Corollary [\ref=cor:bottlebeck-linear-time], Theorem [\ref=thm:main-q-locking] is provable (through Lemma [\ref=lem:pos-prob-states-expected-time]) using only combinatorial arguments about reachability between configurations.

For ease of notation, we assume throughout this paper that all states in Λ are producible, meaning they have positive count in some reachable configuration. Otherwise the following theorem applies only to states that are actually producible. Recall that for α  >  0, a configuration [formula] is α-dense if for all s∈Λ, [formula] implies that [formula]. Say that [formula] is full if [formula], i.e., every state is present. The following theorem states that with high probability, a PP will reach from an α-dense configuration to a configuration in which all states are present (full) in "high" count (β-dense, for some 0  <  β  <  α).

Let [formula] be a PP and α  >  0. Then there are constants ε,β  >  0 such that, letting for all α-dense configurations [formula], [formula] [formula]

In [\cite=DotyTCRN2014], the theorem is stated for "sufficiently large" [formula], but of course one can always choose ε to be small enough to make it true for all [formula].

The following lemma reduces the problem of proving Theorem [\ref=thm:main-q-locking] to a combinatorial statement involving only reachability among configurations (and the lack of bottleneck transitions between them). In Section [\ref=sec:main-proof] we will prove Theorem [\ref=thm:main-q-locking] by showing that the existence of the configurations [formula] and [formula] and the transition sequence pm in the following lemma implies that we can reach a Q-stable configuration [formula], where [formula] and Y is the set of Q-stable configurations reachable from I.

Let α  >  0. Let [formula] be a PP such that, for some set of transitions Q and infinite set of α-dense initial configurations I, [formula] reaches a set of Q-stable configurations Y in expected time o(n). Then for all [formula], there is a configuration [formula] reachable from some [formula] and transition sequence pm such that (1) [formula] for all s∈Λ, (2) [formula], where [formula], and (3) pm has no m-bottleneck transition.

Transition Ordering Lemma

The following lemma was first proven (in the more general model of Chemical Reaction Networks) in [\cite=SpeedFaultsDISC]. Intuitively, the lemma states that a "fast" transition sequence (meaning one without a bottleneck transition) that decreases certain states from large counts to small counts must contain transitions of a certain restricted form. In particular the form is as follows: if Δ is the set of states whose counts decrease from large to small, then we can write the states in Δ in some order [formula], such that for each 1  ≤  i  ≤  k, there is a transition αi that consumes di, and every other state involved in αi is either not in Δ, or comes later in the ordering. These transitions will later be used to do controlled "surgery" on fast transition sequences, because they give a way to alter the count of di, by inserting or removing the transitions αi, knowing that this will not affect the counts of [formula].

Let [formula] such that b2  >  |Λ|  ·  b1. Let [formula] such that [formula] via transition sequence q that does not contain a b2-bottleneck. Define Then there is an order on Δ, so that we may write [formula], such that, for all [formula], there is a transition αi of the form di,si  →  oi,o'i, such that [formula], and αi occurs at least (b2  -  |Λ|  ·  b1) / |Λ|2 times in q.

Proof of Theorem [\ref=thm:main-q-locking]

By Lemma [\ref=lem:pos-prob-states-expected-time], there are sequences [formula] and [formula] of configurations, and a sequence (pm) of transition sequences, such that, for all m, (1) [formula] for all s∈Λ, and for some [formula], [formula], (2) [formula] is Q-stable, and (3) [formula] and pm does not contain an m-bottleneck.

By Dickson's Lemma there is an infinite subsequence of [formula] for which both [formula] and [formula] are nondecreasing. Without loss of generality, we take [formula] and [formula] to be these subsequences. Let [formula] and [formula].

To prove Theorem [\ref=thm:main-q-locking] we need to show that there are configurations in Y (the set of Q-stable configurations reachable from I) that contain states only in Γ. Note that stability is closed downward: subsets of a Q-stable configuration are Q-stable. For any fixed [formula], [formula] for sufficiently large m, by the definition of Γ (the states that grow unboundedly in [formula] as m  →    ∞  ). Thus any configuration [formula] is automatically Q-stable. This is why Claims [\ref=claim:firstfixing], [\ref=claim:secondfixing], and [\ref=claim:interleaving] of this proof center around reaching configurations that have count 0 of every state in Δ.

Recall the path [formula] from Lemma [\ref=lem:pos-prob-states-expected-time]. Intuitively, Claim [\ref=claim:firstfixing] below says that because this path is m-bottleneck free, Lemma [\ref=lem:ordering] applies, and its transitions can appended to the path to consume all states in Δ from [formula], resulting in a configuration [formula] that contains only states in Γ. The "cost" of this manipulation is that, to ensure the appended transitions are applicable, we add extra agents in specific states corresponding to [formula]. Claim [\ref=claim:firstfixing] is not sufficient to prove Theorem [\ref=thm:main-q-locking] because of this additional [formula]; the subsequent Claims [\ref=claim:secondfixing] and [\ref=claim:interleaving] will give us the machinery to handle it.

Example.

We illustrate Claim [\ref=claim:firstfixing] through an example. Define a PP by the transitions For convenience, for state s∈Λ, let s also denote the count of that state in the configuration considered. Let configuration [formula] be where f = 100, a = 100, b = 100, c = 100. Suppose a transition sequence pm without an m-bottleneck (m = 100) takes the PP from [formula] to [formula], in which a  =  3, b = 2, c = 1, and f = 394. Then in the language of Lemma [\ref=lem:ordering], Δ  =  {a,b,c}; these states go from "large" count in [formula] to "small" count in [formula].

Our strategy is to add interactions to pm in order to reach a configuration [formula] with a = b = c = 0. There are two issues we must deal with. First, to get rid of a we may try to add 3 instances of [\eqref=rxn:claims-example-1] at the end of pm. However, there is only enough b for 2 instances. To eliminate such dependency, in Claim [\ref=claim:firstfixing], whenever we add a transition b,a  →  f,c, we add an extra agent in state b to [formula]. (In general if we consume r2 by adding transition r1,r2  →  p1,p2, we add an extra agent in state r1 to [formula].) Second, we need to prevent circularity in consuming and producing states. Imagine trying to add more executions of [\eqref=rxn:claims-example-1] to get a to 0 and more of [\eqref=rxn:claims-example-2] to get c to 0; this will fail because these transitions conserve the quantity a + c. To drive each of these states to 0, we must find some ordering on them so that each can be driven to 0 using a transition that does not affect the count of any state previously driven to 0.

Lemma [\ref=lem:ordering] gives us a way to eliminate such dependency systematically. In the example above, we can find the ordering [formula], [formula], and [formula], with respective transitions [\eqref=rxn:claims-example-1] to drive a to 0 (3 executions), [\eqref=rxn:claims-example-4] to drive c to 0 (4 executions: 1 to consume the 1 copy of c in [formula], and 3 more to consume the extra 3 copies that were produced by the 3 extra executions of [\eqref=rxn:claims-example-1]), and [\eqref=rxn:claims-example-5] to drive b to 0 (6 executions: 2 to consume 2 copies of b in [formula], and 4 more to consume the extra 4 copies that were produced by the 4 extra executions of [\eqref=rxn:claims-example-4]).

Intuitively, Claim [\ref=claim:secondfixing] below works toward generating the vector of states [formula] that we needed for Claim [\ref=claim:firstfixing]. The vector [formula] can be split into the Δ component and the Γ component; we will handle the Γ component later. The "cost" for Claim [\ref=claim:secondfixing] is that the path must be taken "in the context" of additional agents in states captured by [formula]. Importantly, the net effect of the path preserves [formula], which will give us a way to "interleave" Claims [\ref=claim:firstfixing] and [\ref=claim:secondfixing] as shown in Claim [\ref=claim:interleaving].

Example.

Recall the example above illustrating Claim [\ref=claim:firstfixing]. Claim [\ref=claim:secondfixing] is more difficult than Claim [\ref=claim:firstfixing] for two reasons. First, we need to be able to obtain any counts of states a, b, c (ie [formula]) and not only a  =  b  =  c  =  0. Second, we no longer have the freedom to add extra states as [formula] and consume them. Note that [formula] cannot fulfill the same role as [formula] because [formula] must be recovered at the end.

For instance suppose [formula] is a = 7, b = 2, c = 1. Recall that [formula] has a = 3, b = 2, c = 1. How can we generate additional 4 copies of a? Note that all transitions preserve or decrease the sum a + b + c. Thus we cannot solely add interactions to pm to get to our desired [formula]. The key is that we can increase a by removing existing interactions from pm that consumed it. Indeed, Lemma [\ref=lem:ordering] helps us by giving a lower bound on the number of instances of transitions [\eqref=rxn:claims-example-1],[\eqref=rxn:claims-example-4],[\eqref=rxn:claims-example-5] that must have occurred in pm. (Note that in Claim [\ref=claim:firstfixing], we didn't need to use the fact that these transitions occurred in pm. Now, we need to ensure that there are enough instances for us to remove.) In our case, we can remove 4 instances of interaction [\eqref=rxn:claims-example-1], which also decreases c by 4. To compensate for this, we can remove 4 instances of interaction [\eqref=rxn:claims-example-4], which also decreases b by 4. Finally, we remove 4 instances of interaction [\eqref=rxn:claims-example-5]. The net result is that we reach the configuration a = 7, b = 2, c = 1, f = 130.

Note that unlike in Claim [\ref=claim:firstfixing], we have more potential for circularity now because we cannot add the other input to a transition as [formula]. For example, we can't use transition [\eqref=rxn:claims-example-3] to affect c because it affects a (which we have previously driven to the desired count). Luckily, the ordering given by Lemma [\ref=lem:ordering] avoids any circularity because the other input and both of the outputs come later in the ordering.

Importantly, as we remove interactions from pm, we could potentially drive the count of some state temporarily negative. Performing these interactions in the context of more agents ([formula]) ensures that the path can be taken.

Finally, Theorem [\ref=thm:main-q-locking] is proven because [formula] is Q-stable and it contains zero count of states in Δ. To see that [formula] is Q-stable recall that [formula] for sufficiently large m' since [formula] and [formula] contains only states in Γ. Since stability is closed downward, and [formula] is Q-stable, we have that [formula] is Q-stable as well.