Is Entanglement Sufficient to Enable Quantum Speedup?

Introduction

The mere fact that a quantum computer realises an entangled state is ususally concluded to be insufficient to enable it to achieve quantum computational speedup. To support this conclusion, appeal is usually made to the Gottesman-Knill theorem [\citep=nielsenChuang2000]. According to this theorem, any quantum algorithm or protocol which exclusively utilises the elements of a certain restricted set of quantum operations can be efficiently simulated by classical means. Yet among the quantum computational algorithms and informational protocols which exclusively utilise operations from this set are some that are interesting and important— for instance, the teleportation and superdense coding protocols— and both of these (and others) involve the use of entangled quantum states. Thus [\citet=datta2005], for instance, write: "the Gottesman-Knill theorem ... demonstrates that global entanglement is far from sufficient for exponential speedup".

In this short note I will argue that this conclusion is misleading. As I will explain, the quantum operations to which the Gottesman-Knill theorem applies are precisely those which will never cause a qubit to take on an orientation, with respect to the other subsystems comprising the total system of which it is a part, that yields a violation of the Bell inequalities. The fact that the Gottesman-Knill theorem holds should therefore come as no surprise.

While it is true that more than entanglement is required to realise quantum computational speedup in the sense that a quantum computer implementing an entangled quantum state must utilise more than the relatively small portion of its state space that is accessible from the Gottesman-Knill group of transformations alone if it is to outperform a classical computer; i.e., while it is the case that one must use such a state to its full potential, it is nevertheless the case that if one is asked what physical resources suffice to enable one to bring about a quantum performance advantage— a more interesting question if one is seeking for a physical explanation for quantum speedup— then one can legitimately answer that entanglement alone is sufficient for this task.

The Gottesman-Knill theorem

Call an operator A a stabiliser of the state |ψ〉 if

[formula]

For instance, consider the Bell state of two qubits:

[formula]

For this state we have

[formula]

[formula] and [formula] are thus both stabilisers of the state |Φ+〉. Here, X and Z are the Pauli operators:

[formula]

The remaining Pauli operators, I (the identity operator) and Y, are defined as:

[formula]

The Pauli group, Pn, of n-fold tensor products of Pauli operators (for instance, for n  =  2, [formula]) is an example of a group of operators closed under matrix multiplication.

Call the set, VS, of states that are stabilised by every element in S, where S is some group of operators closed under matrix multiplication, the vector space stabilised by S. Consider a state |ψ〉∈VS. From the definition of a unitary operator, we have, for any s∈S and any unitary operation U,

[formula]

Thus [formula] stabilises U|ψ〉 and the vector space UVS is stabilised by the group [formula]. Consider, for instance, the state |0〉, stabilised by the Z operator. To determine the stabiliser of this state after it has been subjected to the (unitary) Hadamard transformation H|0〉  =  |  +  〉 we simply compute [formula]. Thus the stabiliser of |  +  〉 is X.

Now let s1,...,sn be elements of S. s1,...,sn are said to generate the group S if every element of S can be written as a product of elements from s1,...,sn. For instance, the reader can verify that the subgroup, A, of P3, defined by [formula] can be generated by the elements [formula] [\citep=nielsenChuang2000]. We may thus alternately express A in terms of its generators as follows: [formula].

In order to compute the action of a unitary operator on a group S it suffices to compute the action of the unitary operator on the generators of S. For instance, [formula] is the unique state stabilised by 〈Z1,Z2,...,Zn〉 (where the latter expression is a shorthand form of [formula]). Consequently, the stabiliser of the state [formula] is 〈X1,X2,...,Xn〉. Note that this state, expressed in the standard state vector formalism,

[formula]

specifies 2n different amplitudes. Contrast this with the stabiliser description of the state in terms of its generators 〈X1,X2,...,Xn〉, which is linear in n and thus capable of an efficient classical representation.

It turns out that, using the stabiliser formalism, all (as well as all combinations) of the following gates are capable of an efficient classical representation: Pauli gates, Hadamard gates, phase gates (i.e.,π / 2 rotations of the Bloch sphere for a single qubit about the ẑ-axis), and CNOT gates; as well as state preparation in the computational basis and measurements of the Pauli observables. This is the content of the Gotteman-Knill theorem [\citep=nielsenChuang2000].

In fact, many important quantum algorithms utilise gates from this set of operations exclusively. One of these, for instance, is the well-known teleportation algorithm [\citep=bennett1993]. But what is especially notable about this theorem from the point of view of our discussion is that some of the states which may be realised through the operations in this set are actually entangled states. In particular, by combining a Hadamard and a CNOT gate, one can generate any one of the Bell states (which one is generated depends on the value assigned to the input qubits); i.e.,

[formula]

In fact many quantum algorithms utilise just such a combination of gates. If all of the operations from this set are efficiently classically simulable, however, then it appears as though entanglement, by itself, cannot be a sufficient resource for realising quantum speedup, for evidently there are quantum algorithms utilising entangled states that are efficiently simulable classically.

In what follows I will argue that this conclusion is not warranted. An entangled state does, in fact, provide sufficient resources to enable quantum computational speedup. What the Gottesman-Knill theorem actually shows is not that entanglement is insufficient, but that (not surprisingly) it is possible to utilise the resource provided by an entangled state to less than its full potential.

Bell's theorem

For a system in the singlet state (|Ψ-〉), joint experiments on its subsystems are related by the following expression for the expectation value of these combined experiments:

[formula]

Here σm,σn represent spin-m and spin-n experiments on the first (Alice's) and second (Bob's) system, respectively, with ,n̂ the unit vectors representing the orientations of the two experimental devices, and θ the difference in these orientations. Note, in particular, that when θ  =  0, [formula] (i.e., experimental results for the two subsystems are perfectly anti-correlated), when θ  =  π, [formula] (i.e., experimental results for the two subsystems are perfectly correlated), and when θ  =  π / 2, [formula] (i.e., experimental results for the two subsystems are not correlated at all).

Consider the following attempt [\citep=bell1964] to reproduce the quantum mechanical predictions for this state by means of a hidden variables theory. Let the hidden variables of the theory assign, at state preparation, to each subsystem of a bipartite quantum system, a unit vector λ̂ (the same value for λ̂ is assigned to each subsystem) which determines the outcomes of subsequent experiments on the system as follows. Let the functions Aλ(),Bλ(n̂) represent, respectively, the outcome of a spin-m and a spin-n experiment on Alice's and Bob's subsystem. Define these as:

[formula]

where (x) is a function which returns the sign (+, -) of its argument.

The reader can verify that the probability that both Aλ() and Bλ(n̂) yield the same value, and the probability that they yield values that are different (assuming a uniform probability distribution over λ̂), are respectively:

[formula]

with θ the (positive) angle between [formula] and n̂. This yields, for the expectation value of experiments on the combined state:

[formula]

When θ is a multiple of π / 2, this expression yields predictions identical to the quantum mechanical ones: perfect anti-correlation for θ∈{0,2π,...}, no correlation for θ∈{π / 2,3π / 2,...}, and perfect correlation for θ∈{π,3π,...}. However, for all other values of θ there are divergences from the quantum mechanical predictions.

It turns out that this is not a special characteristic of the simple hidden variables theory considered above. No hidden variables theory is able to reproduce the predictions of quantum mechanics if it makes the very reasonable assumption that the probabilities of local experiments on Alice's subsystem (and likewise Bob's) are completely determined by Alice's local experimental setup together with a hidden variable taken on by the subsystem at the time the joint state is prepared. Consider the following expression relating different spin experiments on Alice's and Bob's respective subsystems for arbitrary directions ,',n̂,n̂':

[formula]

As before, let Aλ()∈{  ±  1},Bλ(n̂)∈{  ±  1} represent the results, given a specification of some hidden variable λ, of spin experiments on Alice's and Bob's subsystems. We make no assumptions about the nature of the 'common cause' λ this time— it may take any form. What we do assume is that, as I mentioned above, the outcomes of Alice's experiments depend only on her local setup and on the value of λ; i.e., we do not assume any further dependencies between Alice's and Bob's local experimental configurations. This allows us to substitute 〈Aλ()  ·  Bλ(n̂)〉 for [formula], thus yielding:

[formula]

which, since |Aλ(  ·  )|  =  1, is

[formula]

where the last inequality follows from the fact that Bλ(  ·  ) can only take on values of ±  1. This expression, a variant of the 'Bell inequality' [\citeyearpar=bell1964], is known as the Clauser-Horne-Shimony-Holt (CHSH) inequality [\citep=chsh1969] [\citep=bell1981].

Quantum mechanics violates the CHSH inequality for some experimental configurations. For example, let the system be in the singlet state; i.e., such that its statistics satisfy [\eqref=rol:eqn:singlet]; and let the unit vectors ,',n̂,n̂' (taken to lie in the same plane) have the orientations 0,π / 2,π / 4,  -  π / 4 respectively. The differences, θ, between the different orientations (i.e.,   -  n̂,  -  n̂','  -  n̂, and '  -  n̂') will all be in multiples of π / 4 and we will have:

[formula]

The predictions of quantum mechanics for arbitrary orientations ,',n̂,n̂' cannot, therefore, be reproduced by a hidden variables theory in which all correlations between subsystems are due to a common parameter endowed to them at state preparation. They can, however, be reproduced by such a hidden variables theory for certain special cases. In particular, the inequality is satisfied (as the reader can verify) when [formula] and n̂, [formula] and n̂', ' and n̂, and ' and n̂' are all oriented at angles with respect to one another that are given in multiples of π / 2.

Entanglement as a sufficient resource

Recall the content of the Gottesman-Knill theorem: Pauli gates, Hadamard gates, phase gates, and CNOT gates; as well as state preparation in the computational basis and measurements of the Pauli observables are efficiently simulable by a classical computer. It is commonly concluded, from this, that entanglement cannot therefore be sufficient to enable a quantum algorithm to achieve a speedup over its classical counterpart. When one notes that all of the operations which comprise this set involve rotations of the Bloch sphere that are multiples of π / 2, however, the fact that algorithms restricted to just these operations are classically simulable should come as no surprise. In a multi-partite system, no amount of kπ / 2 transformations of one of the constituent qubits will cause it to take on an orientation with respect to the other subsystems that is not a multiple of π / 2 (unless it was so oriented initially). And as we have seen above, the statistics of compound states for which the difference in orientation between subsystems is a multiple of π / 2 are capable in general of being reproduced by a classical hidden variables theory.

In light of this it is misleading, I believe, to conclude, on the basis of the Gottesman-Knill theorem, that entanglement is not a sufficient resource to enable quantum computational speedup. What the Gottesman-Knill theorem shows us is that simply having an entangled state is not enough to enable one to outperform a classical computer; one must also use such a state to its full advantage; i.e., one must not limit oneself to transformations which utilise only a small portion of the system's allowable state space. In this sense, it is indeed correct to say that entanglement is insufficient to enable quantum speedup. However, if one intends by the claim that entanglement is insufficient— something very different— that further physical resources are required to enable speedup, then I submit that this claim is incorrect.

It is possible to characterise the distinction between classical and quantum mechanical systems as follows. Whereas the nature of quantum mechanical systems is such that they allow us to fully exploit the representational capacity of Hilbert space, this is not so for classical systems [\citep=ekert1998]. Thus the state space of an n-fold quantum system that is efficiently simulable classically is only a tiny portion of the system's overall state space. The reason for the larger size of a quantum state space, however, is the possibility of entangled quantum systems. It is because composite classical systems must always be representable by product states that their state space is smaller. If we have an n-fold entangled quantum system, therefore, it follows straightforwardly that such a system cannot, in general, be simulated classically.

Evidently, it is possible to utilise only a small portion of the state space of such a system— exactly that portion of the state space that is accessible efficiently by an n-fold classical system— but this has no bearing on the nature of the actual physical resources that are provided by the quantum system. Analogously, a life vest may be said to be sufficient to keep me afloat on liquid water. I must actually wear it if it is to perform this function, of course; but that is not a fact about this piece of equipment's capabilities, only about my choice whether to use it or not.

What if the waves are rough? It may be that in this case my life vest will not be sufficient to save me. Analogously, in the presence of noise, as noted by [\citet=linden2001], entanglement may not be sufficient to enable one to achieve exponential quantum speedup. Nevertheless, even in rough weather I will at least have a better chance of surviving with my life vest on than I will without it. Likewise, even in the presence of noise, an entangled quantum state will be sufficient to enable some (though perhaps only a sub-exponential) quantum speedup.

Far from being a problem for the view that entanglement is a sufficient resource to enable quantum speedup, the Gottesman-Knill theorem serves to highlight the role that is actually played by entanglement in the quantum computer and to clarify exactly why and in what sense it is sufficient.