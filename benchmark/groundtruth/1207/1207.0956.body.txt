LAPTH-029/12

[formula] Université Montpellier 2, Laboratoire Charles Coulomb, UMR 5221, F-34095 Montpellier, France

[formula] Laboratory of Theoretical Physics, JINR, 141980 Dubna, Moscow reg., Russia, Moscow Institute of Physics and Technology, 141700, Dolgoprudny, Moscow reg., Russia, Institute of Theoretical and Experimental Physics, 117259 Moscow, Russia

[formula] Laboratoire de Physique Théorique LAPTH, CNRS and Université de Savoie, BP 110, 74941 Annecy-le-Vieux Cedex, France

[formula] Steklov Mathematical Institute, Moscow, Russia

Introduction

In the present paper we consider the problem of calculating scalar products in the framework of the algebraic Bethe Ansatz.

The algebraic Bethe Ansatz is a powerful method to study quantum integrable models [\cite=FadST79] [\cite=BogIK93L] [\cite=FadLH96]. It gives an effective tool for the evaluation of the spectrum of quantum Hamiltonians [\cite=KulS79] [\cite=FadT79]. The computation of form factors of local operators and correlation functions for many integrable models also can be performed in the framework of the algebraic Bethe Ansatz [\cite=Kor84] [\cite=IzeK84]. This last problem in various cases can be reduced to the calculation of scalar products between off-shell Bethe vectors, that is Bethe vectors where the Bethe parameters are not required to satisfy Bethe Ansatz equations.

The problem of scalar products was first considered for [formula]-based integrable models [\cite=Kor82] [\cite=IzeK84]. In these works a recursive formula for the scalar product of generic off-shell Bethe vectors was obtained (Izergin-Korepin formula). Important progress in this study was achieved in [\cite=Ize87], where a determinant representation for the highest coefficient of a scalar product was derived. This made the Izergin-Korepin formula explicit, however it still remained rather cumbersome for applications. The next step was done in [\cite=Sla89], where a determinant representation for the scalar products involving on-shell Bethe vectors was obtained. Determinant representations for particular cases of scalar products became extremely important after the quantum inverse scattering problem was solved [\cite=KitMT99] [\cite=MaiT00]. Using the explicit solution of the inverse scattering problem one can reduce the calculation of correlation functions and form factors of local operators to scalar products, in which one of the vectors is an on-shell Bethe vector. In this way various integral representations were obtained for correlation functions of the XXX and XXZ spin-1 / 2 chains and of the model of one-dimensional bosons [\cite=KitMT00] [\cite=KitMST02] [\cite=KitKMST09b] [\cite=GohKS04] [\cite=GohKS05] [\cite=SeeBGK07]. Determinant formulas were also used for numerical analysis of correlation functions [\cite=CauHM05] [\cite=PerSCHMWA06] [\cite=PerSCHMWA07] [\cite=CauCS07].

A wide class of quantum integrable models is associated with higher rank algebras [formula]. An algebraic Bethe ansatz for these type models is called hierarchical (or nested) and was introduced in [\cite=KulR83] (see also [\cite=VarT95] [\cite=VarT07] [\cite=BelR08]). The first result concerning the scalar products in the models with SU(3)-invariant R-matrix was obtained by Reshetikhin in [\cite=Res86]. There, an analog of Izergin-Korepin formula for the scalar product of generic off-shell Bethe vectors and a determinant representation for the norm of the on-shell vectors were found. Recently various particular cases of scalar products were studied in [\cite=BelPR] [\cite=Whe12] [\cite=PozOK12] [\cite=EGSV].

In this paper we study a particular case of the scalar products in a generalized model with the SU(3)-invariant R-matrix

[formula]

where [formula] is the identity matrix, [formula] is the permutation matrix, c is a constant. Keeping in mind possible generalization of our results to models with q-deformed SU(3)-symmetry we do not stress that the function g(x,y) depends on the difference x - y.

The result obtained in this paper is a determinant representation for the product of an on-shell Bethe vector and an eigenvector of the twisted transfer-matrix (twisted on-shell vector). The notion of a twisted transfer-matrix was found to be very useful for evaluation of certain correlation functions in [formula]-based integrable models [\cite=KitMST05]. One can use this object in the case of higher rank algebras as well. The twisted monodromy matrix is introduced as follows. The monodromy matrix T(w) satisfies the algebra

[formula]

Equation [\eqref=RTT] holds in the tensor product [formula], where [formula] are auxiliary linear spaces, and H is the Hilbert space of the Hamiltonian for the model under consideration. The R-matrix acts non-trivially in [formula], the matrices Tk act non-trivially in [formula]. Let ρ be a matrix such that its tensor square commutes with the R-matrix: = 0. Define a twisted monodromy matrix as T̃  =  ρT. Then it is easy to see that

[formula]

that is, the twisted monodromy matrix enjoys the same algebra as the original one. Thus, the eigenvectors of the twisted transfer-matrix [formula] can be found in the framework of the standard scheme. Below we consider a special case of the matrix [formula], where κ is a complex number (twist parameter). Therefore we denote the twisted monodromy matrix by Tκ(w).

The article is organized as follows. In section [\ref=S-N] we introduce the model under consideration and describe the notations used in the paper. Section [\ref=S-MR] contains the determinant representation for the scalar product of twisted and standard on-shell Bethe vectors. This is the main result of the paper. In section [\ref=S-XXX] we show how our result can be applied to the calculation of form factors of some local operators in the SU(3)-invariant XXX chain. In section [\ref=S-ST] we consider several particular cases of the obtained determinant representation. In particular, we reproduce the formula for the norm of on-shell Bethe vectors [\cite=Res86]. Finally, in section [\ref=S-CSP] we give the derivation of the determinant representation for the scalar product. Appendix [\ref=A-IHC] presents some properties of the domain wall partition function (DWPF), and Appendices [\ref=Pmain-ident]-[\ref=Wonderful] gather several auxiliary Lemmas.

Notations

First of all we give a list of notations and conventions used in the paper.

Apart from the function g(x,y) we also introduce a function f(x,y) as

[formula]

Clearly that in our case f(x,y) = 1 + g(x,y); however the q-analogues of these functions do not satisfy this property. Two other auxiliary functions will be also used

[formula]

The following obvious properties of the functions introduced above are useful

[formula]

Before giving a description of the Bethe vectors we formulate a convention on the notations. We always denote sets of variables by bar: [formula], [formula], [formula] etc. Individual elements of the sets are denoted by subscripts: wj, [formula] etc. As a rule, the number of elements in the sets is not shown explicitly in the equations; however, we give these cardinalities in special comments after the formulas. Subsets of variables are denoted by roman indices: [formula], [formula], [formula] etc. We assume that the elements in every subset of variables are ordered in such a way that the sequence of their subscripts is strictly increasing. We call this ordering natural order.

In order to avoid too cumbersome formulas we use shorthand notations for products of scalar functions. Namely, if functions g, f, h, t, as well as r1 and r3 (see [\eqref=ratios]), depend on sets of variables, this means that one should take the product over the corresponding set. For example,

[formula]

Now we pass to the description of Bethe vectors. A generic Bethe vector is denoted by |ū,〉. It is parameterized by two sets of complex parameters [formula] and [formula] with [formula]. Dual Bethe vectors are denoted by 〈,ū|. They also depend on two sets of complex parameters [formula] and [formula]. The state with [formula] is called a pseudovacuum vector |0〉. Similarly the dual state with [formula] is called a dual pseudovacuum vector [formula]. These vectors are annihilated by the operators Tjk(w), where j > k for |0〉 and j < k for [formula]. At the same time both vectors are eigenvectors for the diagonal entries of the monodromy matrix

[formula]

where λj(w) are some scalar functions. In the framework of the generalized model, λj(w) remain free functional parameters. Actually, it is always possible to normalize the monodromy matrix T(w)  →  λ- 12(w)T(w) so as to deal only with the ratios

[formula]

On-shell Bethe vectors are eigenvectors of the transfer matrix, while twisted on-shell Bethe vectors are eigenvectors of the twisted transfer matrix. We will consider the scalar product of on-shell vector and dual twisted on-shell vector. Then

[formula]

where

[formula]

Hereby the sets [formula] and [formula] (respectively [formula] and [formula]) satisfy the system of nested Bethe ansatz equations (respectively the twisted system of nested Bethe ansatz equations) [\cite=KulR83]. We give these systems in a slightly unusual form

[formula]

[formula]

These equations should hold for arbitrary partitions of the sets [formula] and [formula] into subsets [formula] and [formula] respectively. Obviously, it is enough to demand that the system [\eqref=AEigenS-1], [\eqref=AEigenS-2] is valid for the particular case, when the sets [formula] and [formula] consist of only one element. Then it turns into the standard system of Bethe equations.

The twisted equations have the similar form

[formula]

[formula]

where [formula] and [formula].

The scalar products of Bethe vectors are defined as

[formula]

If [formula] and [formula] are generic off-shell Bethe vectors, then the parameters [formula], [formula], [formula], and [formula] are arbitrary complex numbers. We will consider the particular case of Sa,b, when [formula] and [formula] satisfy the system [\eqref=AEigenS-1], [\eqref=AEigenS-2], while [formula] and [formula] satisfy the system [\eqref=ATEigenS-1], [\eqref=ATEigenS-2].

To conclude this section we introduce the partition function of the six-vertex model with domain wall boundary conditions (DWPF) [\cite=Kor82] [\cite=Ize87]. This is one of the central object in the study of scalar products of [formula]-based models. It also plays an important role in the case of SU(3) invariant mosels. We denote the DWPF by Kn(x̄|). It depends on two sets of variables x̄ and [formula], the subscript shows that #  x̄  =    #   = n. The function Kn has the following determinant representation:

[formula]

where Δ'n(x̄) and Δn() are

[formula]

It is easy to see that Kn is symmetric over x̄ and symmetric over [formula]; however, Kn(x̄|)  ≠  Kn(|x̄). Below we consider Kn depending on combinations of sets of different variables, for example Kn(|, + c). Due to the symmetry properties of the DWPF Kn(|, + c) = Kn(| + c,).

Results

The scalar product of on-shell and twisted on-shell Bethe vectors has the following determinant representation:

[formula]

where N is a block-matrix of the size (a + b)  ×  (a + b),

[formula]

The diagonal block [formula] is an a  ×  a matrix with entries

[formula]

The entries of a b  ×  b block [formula] are

[formula]

The off-diagonal blocks have asimpler form

[formula]

and

[formula]

Observe that the entries of the matrix N can be written in a more compact form in terms of Jacobians of the transfer-matrix and the twisted transfer-matrix eigenvalues (similarly to [\cite=KitMT99])

[formula]

and

[formula]

In the calculation of partial derivatives in these formulas, one has to consider r1(w) and r3(w) as arbitrary functions. Then, to compute the limit, one should express [formula] and [formula] via [\eqref=AEigenS-1], [\eqref=ATEigenS-2]. Altogether, they turn into [\eqref=R-P11]-[\eqref=R-P21].

Form factors in SU(3) invariant XXX chain

In this section we consider an application of our result to the calculation of form factors of local operators of the SU(3)-invariant XXX chain. This model is a particular case of the generalized model considered in this paper.

The monodromy matrix of the periodic XXX chain with N sites is given as a product of R-matrices

[formula]

Here R0m acts in [formula], where [formula] is the the auxiliary space and [formula] is the local quantum space associated with the mth site of the chain. Thus, T(w) is a 3  ×  3 matrix in the space V0, whose entries are operators in [formula].

The local operators acting in the quantum space Vm are elementary units

[formula]

The inverse scattering problem for this model was solved in [\cite=MaiT00]. Using this solution one can express the operators Eε,ε'm in terms of the entries of the monodromy matrix

[formula]

Suppose that we want to compute correlation functions involving the operators E2,2m. For this we consider a form factor of the operator E2,2m

[formula]

Here |ψ〉 and 〈ψ̃| are some on-shell Bethe vectors. Let [formula]. Obviously

[formula]

Due to (E2,2k)n = E2,2k for n  ≥  1 we have

[formula]

Using the solution of the quantum inverse scattering problem [\eqref=gen-sol-T] we obtain

[formula]

where we have set κ  =  eβ. Then, due to [\eqref=bQ], we find

[formula]

Let now 〈ψ̃κ| be a twisted on-shell Bethe vector, such that 〈ψ̃κ|  →  〈ψ̃| at κ  →  1 (that is, at β  →  0). Consider

[formula]

Using [\eqref=bQ1] we immediately obtain

[formula]

Here τ(0) is the eigenvalue of [formula] on |ψ〉 and κ(0) is the eigenvalue of [formula] on 〈ψ̃κ|. Now we simply take derivative of Fβm over β at β = 0. Differentiating [\eqref=QTb] we find

[formula]

On the other hand, taking the derivative of [\eqref=QTb-a] we obtain

[formula]

where δψ̃,ψ = 1 if [formula] and δψ̃,ψ = 0 otherwise. 〈ψ|ψ〉 is the norm of the vector |ψ〉, as computed in section [\ref=S-Norm]. Comparing [\eqref=d-QTb] and [\eqref=d-QTb1] we arrive at

[formula]

It remains to use that E2,2m = Qm - Qm - 1 and we obtain the representation of the form factor 〈ψ̃|E2,2m|ψ〉 in terms of the scalar product 〈ψ̃κ|ψ〉 between twisted and standard on-shell Bethe vectors,

[formula]

Several tests

In this section we make several tests of our result. In particular, at κ = 1 we deal with the scalar product of two on-shell Bethe vectors. Hence, we should obtain either zero for [formula], or the expression for the norm [\cite=Res86] if [formula].

Norm of eigenvector

To approach the case of the norm we should set [formula], [formula], and κ = 1. There is no problem to take this limit in the off-diagonal blocks [\eqref=R-P12] and [\eqref=R-P21]. In the diagonal blocks the limit is a bit more complicated. It is more convenient to take this limit in the equations [\eqref=Upper-tau] and [\eqref=Down-tau]. Taking the partial derivatives we obtain for the diagonal blocks

[formula]

and

[formula]

Consider, for example, the block [\eqref=P11]. Let [formula] and [formula]. Then up to ε2 terms we have

[formula]

where we have used [\eqref=ATEigenS-1], [\eqref=desand] and [\eqref=propert]. Substituting this into [\eqref=P11] and setting [formula] we obtain for diagonal entries of the matrix [formula]

[formula]

Now we can safely proceed to the limit ε = 0. This gives us

[formula]

where [formula].

In the off-diagonal entries of the matrix [formula] we can simply set [formula] and [formula] and use [\eqref=ATEigenS-1]. Altogether, the diagonal block [\eqref=P11] takes the form

[formula]

Here we have already set κ = 1 and [formula].

Note that it would be much more sophisticated to take the limit [formula] in expression [\eqref=R-P11]. Then we should consider the parameters [formula] as functions of κ: [formula] and take the limit [formula]. It is clear that after taking this limit we obtain an expression containing derivatives [formula] at κ = 1, and one should prove that all these derivatives can be combined into X(1)k. Certainly this method is more cumbersome than the technics described above.

The limit [formula] in the matrix [formula] can be taken in a similar way. After simple algebra we obtain for the norm of eigenvector

[formula]

Here the diagonal blocks are

[formula]

[formula]

where X(3)k = r'3(vk) / r3(vk) and vjk = vj - vk. This result coincides with the one of [\cite=Res86] up to notations.

Scalar product of two different on-shell vectors

If [formula] or [formula] at κ = 1, then the result obtained describes the scalar product of two different eigenvectors of the transfer-matrix. Hence, we should have Sa,b = 0 in this case. Below we prove that Sa,b does vanish at κ = 1 except for the case of the norm. For this we construct an eigenvector of the block-matrix N [\eqref=R-fin1] having zero eigenvalue at κ = 1. This means that the determinant in [\eqref=R-fin1] vanishes at κ = 1.

The zero eigenvector has the following components

[formula]

We should prove that

[formula]

Equations [\eqref=act-Omega] can be checked straightforwardly. Let us compute, for instance, the action of the left blocks [\eqref=R-P11] and [\eqref=R-P21] on the vector Ω. Assume that [formula], [formula] and [formula], [formula]. Then in order to calculate the sum

[formula]

we introduce

[formula]

The sums H±k can be computed by means of an auxiliary integral

[formula]

The integral is taken over the contour |z| = R and we consider the limit R  →    ∞  . Then I = 0, because the integrand behaves as 1 / z2 at z  →    ∞  . On the other hand the same integral is equal to the sum of the residues within the integration contour. Obviously the sum of the residues at [formula] gives H±k. There is also one additional pole at [formula]. Then we have

[formula]

From this we find

[formula]

Using these results we immediately obtain

[formula]

The action of the block [formula] on Ωa + j can be calculated in the similar way. Using an auxiliary contour integral

[formula]

we find that

[formula]

This implies

[formula]

and hence, the first equation [\eqref=act-Omega] is proved. The proof of the second equation [\eqref=act-Omega] is similar.

The proof given above should be slightly modified in the case when some parameters [formula] and [formula] (or [formula] and [formula]) coincide. Consider without loss of generality the case [formula] for [formula] and [formula] for [formula]. We also assume that [formula] for [formula]. Then first of all we should take the limit [formula] in the first n rows of the block [formula], just like we did in section [\ref=S-Norm]. As a result the explicit expressions for the corresponding entries change; in particular, they depend on the logarithmic derivatives X(1)k. However, at the same time, the first n elements of the vector Ω vanish: Ωj = 0, for [formula]. Therefore, independently of the explicit form of the entries in the first n rows of the block [formula], their action on the vector Ω gives zero. The action of the remaining part of the block [formula] can be calculated exactly in the same way as we did before. One can easily check that the same vector Ω remains the zero eigenvector of the matrix N.

The only case where the proof fails is the case [formula] and [formula], that is, the case of the norm. In this case the vector Ω turns into zero vector; hence, by definition it can not be an eigenvector.

Remark. We have seen in Section [\ref=S-XXX] that form factor of the operator E2,2m can be expressed in terms of the β-derivative (recall that κ  =  eβ) of the scalar product (see [\eqref=QQ]). Knowing the zero eigenvector Ω one can calculate this derivative explicitly. Indeed, it follows from the results of this section that if we add to the first row of the matrix N all other rows multiplied by the coefficients Ωj  /  Ω1, then the first row becomes proportional to κ - 1. Then taking the β-derivative of the determinant at β = 0 one should simply differentiate this modified first row, setting κ = 1 in all other rows.

Spurious poles

The pre-factor in [\eqref=R-fin1] contains the product [formula], which has poles at [formula] and at [formula]. On the other hand, the scalar product should not have singularities in such points. One can check that this is really so. Let, for example, [formula]. Then we have

[formula]

[formula]

Since [formula] at [formula] (see [\eqref=propert]), we conclude that the first columns of these blocks are proportional to each other. After simple algebra we obtain

[formula]

where we have used [\eqref=AEigenS-1] and [\eqref=ATEigenS-2].

Similarly we find

[formula]

[formula]

Using again [\eqref=propert], [\eqref=AEigenS-1] and [\eqref=ATEigenS-2] we obtain

[formula]

and, hence, the first and the (a + 1)-th columns of the matrix N are proportional to each other at [formula]. Thus, the determinant vanishes.

The same effect takes place at [formula].

Calculation of the scalar product

In this section we prove the representation [\eqref=R-fin1]. We start our calculations with the formula for the scalar product of generic off-shell Bethe vectors obtained in [\cite=Res86]

[formula]

Here the sum is taken over the partitions of the sets [formula], [formula], [formula], and [formula]

[formula]

The partitions are independent except that [formula] with [formula], and [formula] with [formula].

The functions Za - k,n and Zk,b - n are the highest coefficients of the scalar product [\cite=Res86]. Generically Za,b(;x̄|s̄;) depends on four sets of variables with #    =    #  x̄ = a and #  s̄  =    #   = b. We use two equivalent representations for the highest coefficient [\cite=Whe12] [\cite=BelPRS12a]. The first one reads

[formula]

Here   =  {s̄,  x̄}. The sum is taken with respect to all partitions of the set [formula] into subsets [formula] and [formula] with [formula] and [formula]. The functions Kn are DWPF [\eqref=K-def].

The second representation has the following form

[formula]

Summation over partitions of [formula] and [formula]

Recall that in the framework of the generalized model we consider r1(u) and r3(v) as arbitrary functions. Then every term in the representation [\eqref=Resh-SP] is labeled by a certain product [formula]. The terms corresponding to different partitions are labeled by different products, therefore their summation is impossible. However, in the particular case of the scalar product of on-shell and twisted on-shell Bethe vectors one can express the products [formula] in terms of rational functions due to [\eqref=AEigenS-1]-[\eqref=ATEigenS-2]. Therefore we obtain a possibility to sum up the terms corresponding to different partitions. At the first step we calculate the sum over partitions of the sets [formula] and [formula].

The highest coefficients Za - k,n and Zk,b - n in [\eqref=Resh-SP] themselves are given as sums over partitions of certain sets of their arguments. Therefore substituting explicit representations for these functions into [\eqref=Resh-SP] we create additional partitions. For example, using [\eqref=RHC-IHC] we have

[formula]

Here [formula]. The sum is taken with respect to all partitions of the set [formula] into subsets [formula] and [formula] with [formula] and [formula]. We see that in fact we create additional subpartitions of the subsets [formula] and [formula] into sub-subsets. If we use the same formula [\eqref=RHC-IHC] for the second highest coefficient [formula], then we will create additional subpartitions of the subsets [formula] and [formula]. Thus, all the subsets of variables will be divided into sub-subsets.

However if we use [\eqref=Al-RHC-IHC] for [formula], then

[formula]

Here [formula], and we see that we still deal with subpartitions of the sets [formula] and [formula], while the subsets of [formula] and [formula] remain intact.

Thus, the use of different representations [\eqref=RHC-IHC], [\eqref=Al-RHC-IHC] for the two highest coefficients in [\eqref=Resh-SP] allows us to keep original partitions at least for two sets of variables, namely for [formula] and [formula].

As we have explained above, we start with the summation over partitions of the sets [formula] and [formula]. Therefore at the first stage of the calculations it is enough to substitute [\eqref=AEigenS-2] and [\eqref=ATEigenS-1] into [\eqref=Resh-SP], considering for some time the functions [formula] and [formula] as free parameters.

Substituting [\eqref=AEigenS-2] and [\eqref=ATEigenS-1] into [\eqref=Resh-SP] we obtain

[formula]

Now we use [\eqref=RHC-IHC1] for Za - k,n, and [\eqref=Al-RHC-IHC1] for Zk,b - n. This gives us

[formula]

where

[formula]

Recall that here [formula] and [formula]. Observe that in the last line of [\eqref=Resh-form-red1] we have gathered all the terms depending of the sets [formula] and [formula]. The sum over partitions of these sets can be calculated explicitly due to

Let [formula], [formula] and [formula] be sets of complex variables with #  α = m1, #  β = m2, and #  ξ = m1 + m2. Then

[formula]

The sum is taken with respect to all partitions of the set [formula] into subsets [formula] and [formula] with [formula] and [formula]. Due to [\eqref=Red-K] the equation [\eqref=Sym-Part-old1] can be also written in the form

[formula]

The proof of this Lemma is given in Appendix [\ref=Pmain-ident].

We use the equation [\eqref=Sym-Part-old1] for the calculation of the sum over the partitions of the set [formula] and the equation [\eqref=Sym-Part-old2] for the calculation of the sum over the partitions of the set [formula]. Then we obtain

[formula]

New subsets

To proceed further we need to introduce sub-subsets of the sets [formula] and [formula]. We define these sub-subsets as follows:

[formula]

The cardinalities of the introduced sub-subsets are [formula] and [formula] for [formula]. It is easy to see that ki + kiii = k, ni + niii = n, kii = niii, and kiii = nii.

Due to [\eqref=K-K], [\eqref=Red-K] we have

[formula]

Similarly

[formula]

In terms of the introduced sub-subsets the equation [\eqref=Part-sum1] takes the form

[formula]

where

[formula]

and we also have used [\eqref=propert] for some functions f.

Now we combine sub-subsets [formula] and [formula] into new subsets

[formula]

Due to [\eqref=part-2] we have [formula]. Observe that these new subsets are different from the subsets used, for example, in [\eqref=Resh-SP]. We use, however, the same notation, as we deal with the sum over partitions, and therefore it does not matter how we denote separate terms of this sum.

Then the equation [\eqref=SubSubsum] can be written in the form

[formula]

where the sum is taken over the partitions of the set [formula] into subsets [formula] and the set [formula] into subsets [formula]. In this formula

[formula]

and

[formula]

Finally, the function [formula] is given by

[formula]

where

[formula]

and

[formula]

We stress that the representation [\eqref=Sub-new-part] follows from [\eqref=SubSubsum] without any additional transforms. One can check that the straightforward substitution of [\eqref=La]-[\eqref=hr3] into [\eqref=Sub-new-part] gives exactly [\eqref=SubSubsum]. Thus, at the second step of our calculations we have not sum up any sum over partitions in [\eqref=SubSubsum]; however, we have factorized the original sum into several subsums.

Summation over subpartitions of [formula] and [formula]

The functions [formula], [formula], [formula], which appear in [\eqref=Sub-new-part] are given in terms of sums over partitions. These sums can be computed explicitly. We begin with the functions [formula] and [formula].

Let [formula] and [formula] be two sets of generic complex numbers with #    =    #   = m. Let also C1(w) and C2(w) be two arbitrary functions of a complex variable w. Then

[formula]

and

[formula]

Here the sums are taken over all possible partitions of the set [formula] into subsets [formula] and [formula]. Recall that Δ'm and Δm are given by [\eqref=def-Del].

The proof is given in Appendix [\ref=PLong-Det].

We see that we can apply Lemma [\ref=Long-Det] in order to obtain determinant representations for [formula] [\eqref=La] and [formula] [\eqref=Lb]. For instance, if we set in [\eqref=SumDet2]: m = a, [formula], [formula] and

[formula]

then we obtain the equation [\eqref=La]. Indeed, in this case one has [formula] due to the product [formula] in [\eqref=C1C2]. Hence, we automatically have [formula], otherwise the corresponding contribution to the sum vanishes. This means that when splitting the set [formula] into two subsets we actually should consider only the partitions of the set [formula] into [formula] and [formula], as we have in [\eqref=La]. We obtain

[formula]

with

[formula]

and [formula]. Similarly the sum in [\eqref=Lb] can be calculated via [\eqref=SumDet1]. We have

[formula]

with

[formula]

and [formula].

Observe that up to now we did not use the constraints [\eqref=AEigenS-1], [\eqref=ATEigenS-2]. However, we should use them for the calculation of [formula] [\eqref=Gn1]. Then [formula], [formula], and [\eqref=Gn1] turns into

[formula]

For this calculation, we need one more lemma:

Let [formula] and [formula] be two sets of generic complex numbers with #    =    #   = m. Then

[formula]

where the sum is taken over all possible partitions of the sets [formula] and [formula] with [formula] and [formula].

The proof is given in Appendix [\ref=Wonderful]. Obviously, equation [\eqref=Gn1-red] coincides with [\eqref=Ident-G] after appropriate identification of the subsets. Thus,

[formula]

Substituting this into [\eqref=Sub-new-part] we arrive at

[formula]

where [formula] and [formula] are given by [\eqref=ALa] and [\eqref=ALb] respectively.

Note that although we have used already [\eqref=AEigenS-1] and [\eqref=ATEigenS-2], we still can keep the explicit dependence on [formula] and [formula] in the formulas [\eqref=ANa] and [\eqref=ANb] for the matrices [formula] and [formula]. Of course, we cannot consider [formula] and [formula] as arbitrary functional parameters anymore, but on the other hand it is not necessary to replace these functions immediately via the constraints [\eqref=AEigenS-1] and [\eqref=ATEigenS-2]. On the contrary, it is useful to keep [\eqref=ANa] and [\eqref=ANb] in their present form, since it is more convenient for taking the limit [formula] and [formula], as we have seen in Section [\ref=S-Norm].

Final summation over partitions of [formula] and [formula]

It remains to sum up the equation [\eqref=Sub-new-part-red] into a single determinant. For this we introduce new matrices

[formula]

Respectively we define

[formula]

Observe that if we set [formula] in [\eqref=AN-def1] and use [\eqref=AEigenS-1], then N(u) and N(v) turn into [\eqref=R-P11] and [\eqref=R-P21] respectively. Setting in [\eqref=AN-def1] [formula] and using [\eqref=ATEigenS-2] we obtain the blocks [\eqref=R-P12] and [\eqref=R-P22].

It is easy to see that in terms of the introduced objects equation [\eqref=Sub-new-part-red] takes the form

[formula]

The last sum, in fact, is an expansion of the determinant of an (a + b)  ×  (a + b) matrix.

Let N be an (a + b)  ×  (a + b) matrix with block structure

[formula]

Then

[formula]

Proof. Let [formula], that is,

[formula]

Then the matrix N can be written as a matrix consisting of two block-rows:

[formula]

Let us develop det a + bN with respect to the first block-row:

[formula]

The sum in [\eqref=lemma-prove1] is taken over all partitions of [formula] with [formula]. We also have denoted by [formula] (respectively by [formula]) the kth element of the subset [formula] (respectively [formula]). The symbol [formula] means the parity of the permutation that maps the sequence [formula] into the ordered set [formula]. In particular,

[formula]

Substituting [\eqref=Del-Del] into [\eqref=lemma-prove1] and using [formula] we obtain

[formula]

where we have used the definitions [\eqref=AL-def1]. Now we set [formula] and [formula], and we arrive at

[formula]

which ends the proof. [formula]

Finally, using [\eqref=S-hS] we arrive at the representation [\eqref=R-fin1].

Conclusion

We have conjectured in our recent paper [\cite=BelPRS12a] that in the SU(3) case a single determinant representation for the highest coefficient Za,b (see [\eqref=RHC-IHC], [\eqref=Al-RHC-IHC]) does not exist. It follows from this conjecture that there is not a single determinant representation for the scalar product of on-shell and generic off-shell Bethe vectors. We have seen, however, that it is possible to derive the determinant representation for the scalar product, if we deal with a twisted on-shell Bethe vector that can be considered as a particular case of an off-shell Bethe vector. Moreover, this particular case is important from the viewpoint of its application to the calculation of form factors of local operators. Therefore a natural development of our method would be to study special cases of scalar products involving specific off-shell vectors. In particular, one can consider off-shell vectors arising as the result of the action of the monodromy matrix entries Tjk(w) on on-shell vectors. The corresponding scalar products then can be used for the calculation of form factors and correlation functions.

It is worth mentioning that following this route one has to solve an additional problem. Namely, it is necessary to express the action of the matrix elements Tjk(w) on Bethe vectors in terms of a linear combination of off-shell vectors. This problem has a well known solution for [formula]-based models (see e.g. [\cite=BogIK93L] [\cite=FadLH96]). However, in the case of higher rank algebras this question has not been studied yet. We will give a solution of this problem in our forthcoming publication [\cite=BelPRS12c].

Acknowledgements

The work of SZP was supported in part by RFBR grant 11-01-00980-a, grant of Scientific Foundation of NRU HSE � 12-09-0064 and grant of FASI RF 14.740.11.0347. ER was supported by ANR Project DIADEMS (Programme Blanc ANR SIMI1 2010-BLAN-0120-02). NAS was supported by the Program of RAS Basic Problems of the Nonlinear Dynamics, RFBR-11-01-00440, RFBR-11-01-12037-ofi-m, SS-4612.2012.1.

The properties of the DWPF

The DWPF is symmetric function of [formula] and symmetric function of [formula]. It behaves as 1 / xn (respectively 1 / yn) as xn  →    ∞   (respectively yn  →    ∞  ) for other variables fixed. It has simple poles at xj = yk. The behavior of Kn near these poles can be expressed in terms of Kn - 1,

[formula]

where [formula] and [formula] and reg means the regular part at xn  →  yn.

One can also easily check that the DWPF possesses the properties

[formula]

[formula]

Proof of the Lemma [\eqref=main-ident]

The proof will be given by the induction over m1. For m1 = 0 the identity [\eqref=Sym-Part-old1] is obviously valid. Suppose that it is valid for some m1 - 1 and consider the l.h.s. of [\eqref=Sym-Part-old1] as a function of α1,

[formula]

This function decreases as α1  →    ∞   and it has poles at α1  =  ξk, [formula]. Consider the behavior of Fl(α1) near the pole at α1  =  ξ1 (due to the symmetry of Fl(α1) over [formula] its properties near other poles are similar).

Obviously the pole at α1  =  ξ1 occurs if and only if [formula]. Let [formula],  [formula] and [formula]. Then using [\eqref=Rec-Ky] we have

[formula]

where the symbol [formula] means that the summation is taken over the partitions of the set ' into subsets [formula] and [formula]. The factors g(ξ1,α1)f(α1,') and [formula] can be moved out of the sum over these partitions. Applying the induction assumption for the remaining sum we arrive at

[formula]

Consider now the rhs of [\eqref=Sym-Part-old1] as a function of α1,

[formula]

Here the pole at α1  =  ξ1 occurs only in the prefactor f(,). Using [\eqref=K-K] we immediately obtain

[formula]

Thus, the residue of the difference Fl(α1) - Fr(α1) at α1  =  ξ1 vanishes. Due to the symmetry over [formula] the difference Fl(α1) - Fr(α1) has no poles at α1  =  ξk, [formula]. Hence, this is a holomorphic function of α1 in the whole complex plane. Since this function decreases at infinity, we conclude that [formula].

The identity [\eqref=Sym-Part-old2] follows from [\eqref=Sym-Part-old1] due to [\eqref=Red-K]. [formula]

Proof of the Lemma [\eqref=Long-Det]

We shall prove only the identity [\eqref=SumDet1], as the proof of [\eqref=SumDet2] is identical. Let us denote by M the matrix in the rhs of [\eqref=SumDet1]. Obviously det mM is a linear function of every C1(wk) and every C2(wk), where [formula]. This function can be presented in the form

[formula]

where [formula] does not depend on C1 and C2. The sum is taken over all possible partitions of the set [formula] into subsets [formula] and [formula] with [formula], [formula], [formula]. In order to find the coefficient [formula] one should simply set [formula] and [formula] in the rhs of [\eqref=SumDet1]. We obtain

[formula]

Here [formula] is the parity of the permutation mapping the set [formula] into the ordered set [formula] (recall that in every subset the elements are ordered in the natural order). The determinant in [\eqref=A-formul] consists of two parts. The first n columns are associated with the parameters [formula], while the last m - n columns are associated with the parameters [formula]. Therefore, just like in [\eqref=lemma-prove1] we have denoted by [formula] (respectively by [formula]) the k-th element of the subset [formula] (respectively [formula]).

Thus, the rhs of [\eqref=SumDet1] has the following representation

[formula]

On the other hand in the lhs of [\eqref=SumDet1] it is enough to write the DWPF [formula] explicitly. We have

[formula]

Here we have used [\eqref=propert]. Hence,

[formula]

Finally, using

[formula]

and substituting this into the rhs of [\eqref=K-expl1] we arrive at [\eqref=RHS-1]. [formula]

Proof of Lemma [\ref=Wau]

Let us denote by Λ(l)m(|) and Λ(r)m(|) the lhs and the rhs of [\eqref=Ident-G] respectively. Then these functions possess the following properties:

they are rational functions of [formula] and [formula];

they are symmetric functions of [formula] and symmetric functions of [formula];

they vanish if some αj or βj goes to infinity;

they have poles only at αj  =  βk and αj + c = βk;

[formula]

Therefore it is enough to check that the residues of both functions at α1  =  β1 and α1 + c = β1 coincide. In fact, we can prove that both functions possess the same recurrence in the mentioned poles. Then, similarly to the proof of Lemma [\ref=main-ident] we can use the induction over m.

It is straightforward to establish the following recursions:

[formula]

where [formula] and [formula]. It is not difficult to see that Λ(l)m(|) has the same recursion properties.

Consider, for example, the pole at α1  =  β1. This pole appears if and only if [formula] and [formula]. Let [formula] and [formula]. Then, using the recursion properties of the DWPF we obtain

[formula]

where [formula] means that the sum is taken over partitions of the sets ' and '. It is easy to see that

[formula]

and these factors can be moved out off the sum over partitions. We obtain

[formula]

Similarly one can prove that

[formula]

Then the induction over m ends the proof. [formula]