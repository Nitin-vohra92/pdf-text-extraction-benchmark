Stochastic geometry and topology of non-Gaussian fields

Random fields pervade all areas of science. A disparate class of phenomena, ranging from the cosmic background radiation [\cite=cite_Dodelson] and surface roughness [\cite=cite_KPZ] to medical images of brain activity [\cite=cite_Worsley] and optical speckle patterns [\cite=cite_Flossmann], produce data that can be regarded as random fields. The statistics of geometrical features of these fields, such as the density of extrema of various types, can be used to characterize them [\cite=cite_Gruzberg] [\cite=cite_Dennis1]. When the fields can be approximated as Gaussian fields, the physical meaning of these statistical properties is generally well understood [\cite=cite_Longuet2] [\cite=cite_Berry]: the statistics of extrema reflects the amount of field fluctuations at short distances.

Though analytical investigations are often restricted to Gaussian fields, phenomena described by nonlinear laws (such as the dynamics of inflation that produced the cosmic background radiation) produce non-Gaussian signals. Quite often, the observable signal is averaged over a large scale, producing approximately Gaussian statistics on account of the central limit theorem, and masking the nonlinearity. Nevertheless, the surviving tiny departures from Gaussianity can carry the crucial signature of the nonlinear microscopic mechanisms at the heart of the phenomena. As an illustration, consider a low resolution measurement of the spatial magnetization of a material well above the critical temperature. The magnetization fluctuates like a Gaussian random variable - each region contains many domains oriented up or down in arbitrary proportion. However, a small non-Gaussian contribution remains, because there is a maximum possible magnetization per unit area which can be traced all the way down to the quantization of the spin of the electrons and hence the probability distribution cannot exhibit Gaussian tails.

In order to unveil such elusive effects, one needs an indicator that is sensitive to both short distances and small signals.

The most common tool used to probe the statistics of a random field is to measure its correlation functions. For example, the statistical properties of a random scalar field, h(x,y), with Gaussian statistics, are entirely determined by its two-point correlation function 〈h(x,y)h(x',y')〉, and its higher-order correlation functions can be written simply as the sum of products of two-point correlation functions. The nonfactorizability of these higher-order correlation functions is one of the standard indicators of non-Gaussian statistics.

Here we focus on a more geometric approach: view the scalar field as the height of a surface and study its random topography to infer the statistical properties of the signal (see inset of Fig. [\ref=fig_umbilics]). The densities of peaks and valleys, or of topological defects in the curvature lines known as umbilics (see Fig. [\ref=fig_umbilics]), are sensitive indicators of how jagged the height field is at short distances. As we shall see, they provide an independent pipeline to detect non-Gaussianities, distinct from multiple-point correlation functions. This geometric approach has been applied successfully to track the power spectrum of a Gaussian field and it has been the subject of extensive theoretical and experimental studies [\cite=cite_Dennis1] [\cite=cite_Longuet2] [\cite=cite_Berry] [\cite=cite_Longuet1] [\cite=cite_Dennis2].

In this paper, we introduce the key physical concepts and mathematical techniques necessary to study the stochastic geometry of signals that can be described as a Gaussian random field plus a perturbation that we wish to track. We first show how to treat non-Gaussianities within a local approximation and calculate how the statistics of extrema change when a nonlinear transformation FNL(HG) is applied locally to a Gaussian field HG. Then we consider the case of fields that cannot be probed directly, by calculating the statistics of umbilical points, which are topological defects of the lines of principal curvature [\cite=cite_Kamien]. Finally, we turn to the class of nonlinear diffusion equations [\cite=cite_KPZ] and go beyond the local approximation, by considering the effects of spatial gradients that couple values of the field at different locations. As an illustration, we solve explicitly for the nonlocal non-Gaussianities generated dynamically by the deterministic KPZ equation which models surface growth [\cite=cite_KPZ].

Critical points

To gain some insights into the physical mechanisms that generate non-Gaussianities, consider first how an isotropic Gaussian field [formula] arises from the random superposition of waves (or equivalently, Fourier modes)

[formula]

with an amplitude spectrum A(k) that depends only on the magnitude of the wave vectors, [formula]. The phases [formula] are uncorrelated random variables uniformly distributed in the range

[formula]

Umbilical points

The near-Gaussian fields under investigation are not always directly accessible experimentally. For example, the mass distribution along the line of sight responsible for weak gravitational lensing is mostly composed of dark matter and hence it cannot be detected directly [\cite=cite_Hoekstra]. If the projected gravitational potential over a flat patch of the sky is taken to be the height of a 2D surface [\cite=cite_Vitelli], the measurable shear field, is given by the lines of principal curvature [\cite=cite_Kamien], as shown in Fig. [\ref=fig_umbilics]. At some special points called umbilics, the curvature is equal in all directions, so the shear field cannot be defined and it must vanish. More precisely, a point [formula] on a surface with height function [formula] is an umbilic if the second derivatives satisfy the two conditions [formula] and [formula]. The ratio between different types of umbilical points (which is a universal number for an isotropic Gaussian field) serves as an indicator of non-Gaussianities in lieu of the extrema which cannot be detected. A similar reasoning can be applied to study polarization singularities in the cosmic microwave background [\cite=cite_Dennis3] and topological defects in a nematic or superfluid near criticality [\cite=cite_Halperin] [\cite=cite_Liu].

Inspection of Fig. [\ref=fig_umbilics] reveals that there are three types of umbilics: lemons, monstars and stars. Note that these umbilics are topological defects in the curvature-line field. The topological index of any umbilic is equal to plus (minus) 1 / 2, if the curvature-line field rotates clockwise (counter-clockwise) by an angle π, along any closed path encircling that umbilic only in the clockwise direction.

A star has three curvature lines terminating at it and a topological index of [formula]. A lemon has only one line and index [formula]. A monstar has index [formula], like a lemon, but three lines terminating at it, like a star. A striking feature of isotropic Gaussian fields is that the monstar fraction, the relative density of monstars with respect to all umbilics, equals [formula]; this is a universal number independent of the power spectrum [\cite=cite_Berry] [\cite=cite_Dennis2]. Any deviation from this special value is therefore a sure sign of non-Gaussian effects.

We will again consider a height field that is a nonlinear function of a Gaussian, h  =  FNL(HG). In this general case, we were not able to find an exact result as we were for the extrema. We shall therefore assume that the nonlinear contribution is small, such that h = HG  +  εf(HG), with f a nonlinear perturbation and ε  ≪  1 a small parameter controlling the size of the nonlinearity. We can express αM in terms of the joint probability distribution p of the second and third derivatives of h. To calculate p, we use the property that a probability distribution is determined by its moments of all orders (if the distribution is well-behaved). This is most easily accomplished by calculating the generating function of the distribution, χ - its logarithm can be directly expressed in terms of the cumulants Cn

[formula]

where [formula] are the stochastic variables given by the spatial derivatives of h. The probability distribution can then be obtained from the generating function by taking the inverse Fourier transform with respect to [formula]. The cumulants can be written in terms of expectation values, e.g. C2(ξ1,ξ2)  =  〈ξ1ξ2〉  -  〈ξ1〉〈ξ2〉. In this context, these expectation values are called moments, which are not to be confused with the moments K2n defined before.

For Gaussian variables, only the second-order cumulants are nonzero. This gives rise to a generating function of the form

[formula]

One can easily check that the inverse Fourier transform of χ in Eq. [\eqref=eq_chi] precisely yields the probability distribution for a set of correlated Gaussian variables (assuming 〈ξi〉  =  0), see Eq. [\eqref=eq_gsn_jpd]. More generally, by determining all the cumulants, one can construct the generating function and from that the probability distribution. We shall derive the monstar fraction up to first order in the perturbation εf(HG) only; consistently we need to determine all the cumulants up to first order only.

The monstar fraction (even at order ε) could in principle depend on f in a complicated way, if f is an arbitrary nonlinear function. In fact, quadratic terms in the function f produce degree 3 cumulants in the distribution function of the field h (i.e., skewness), cubic terms produce kurtosis (degree 4 cumulants) and in general degree n terms in f produce degree n + 1 cumulants. However, the monstar fraction can be determined from just the distribution of a few derivatives of h, whose cumulants vanish beyond the fourth order due to symmetry, as shown in the Supporting Information. Consequently, the final result for the monstar fraction depends only on a single parameter, [formula], where the primes indicate derivatives with respect to HG.

The calculation can be briefly summarized as follows. The monstar fraction is related to the distribution function of some of the second and third derivatives of h, which we write in terms of complex coordinates z = x + iy and z*: hzz, hzzz, and hzzz*. The definition of an umbilic point becomes hzz  =  0, where hzz is now complex. All the cumulants of these variables and their conjugates may now be calculated (up to order ε). The complex coordinates allow for optimal usage of rotational and translational symmetry. Only a few of the cumulants are nonzero and these are evaluated in Table [\ref=tbl_cumulants]. With the aid of these cumulants, the generating function can be constructed to first order using Eq. [\eqref=cum]. Taking the Fourier transform leads to the probability distribution p(hzz,hzzz,hzzz*); the explicit form is rather long, but it is basically a Gaussian perturbed by cubic and quartic terms in h and its derivatives [\cite=cite_longpaper2]. To obtain αM, we then have to set hzz  =  0 and integrate over hzzz and hzzz* (taking care to include the appropriate Jacobian factor). Integrating over all of [formula] gives the total density of umbilical points, while the density of monstars is obtained by integrating over a specific range, which can be found in Appendix B. The monstar fraction is then the ratio of these two densities. The resulting deviation from αM  =  0.053 is

[formula]

where [formula]. When applied to the local modal of the primordial field Φ described before, ΔαM in Eq. [\eqref=eq_mfr] depends only on the cubic coefficient gnl and not on fnl.

Hence, the leading order perturbation that alters the monstar fraction is f(HG)  =  H3G, for which 〈f'''(HG)〉  =  6. Note that this perturbation, like any odd and/or monotonic function of HG, does not have an effect on the density of maxima and minima. Figure [\ref=fig_mfr] shows αM, as determined by Eq. [\eqref=eq_mfr] (continuous line), together with data from computer simulations (symbols): the agreement between theory and numerics is very good in the linear regime. The spectrum used was again A(k)  ~  θ(kD - k), for which [formula]. Note that the monstar fraction is very sensitive to a small non-Gaussianity, with a 20% change when ε is just 0.01. For larger values of ε, nonlinear effects become important and prevent αM from becoming negative. In this regime, our approximate result must break down.

Nonlocal model and evolution equations

In section [\ref=sec_crit], we presented an exact expression for the imbalance between maxima and minima for a local perturbation of a Gaussian random field. This simple class of models may describe the local evolution of a system that starts out with a Gaussian distribution, as for instance the growth of a population of cells that are initially distributed on a dish and then divide without any significant migration from one region to another.

However, many dynamical systems evolve in a nonlocal, nonlinear way. Non-Gaussianities are generated dynamically from the nonlinear equations of motion that the field [formula] obeys, even if the initial condition [formula] is Gaussian. Unlike the case of local evolution, the imbalance between maxima and minima will now exhibit a power law increase, as the nonlinear perturbation grows.

A broad class of nonlinear diffusion equations describes the necessary mixing between regions. Examples include several models of structure formation in both condensed matter [\cite=cite_Chaikin] and cosmology [\cite=cite_Dodelson], the Cahn-Hilliard equation for the development of order after a phase transition [\cite=cite_Bray] and simplified models of surface growth [\cite=cite_KPZ]. We will focus on the last of these, the deterministic KPZ equation [\cite=cite_KPZ] which models the height evolution of a substrate as atoms accumulate on it:

[formula]

This equation is arrived at in the following way: to first order, the surface simply grows at a constant rate. This constant rate does not appear in the equation, however, since it is simply subtracted out; the two terms on the right-hand side are the additional effects. The first term describes the diffusion of particles along the surface, and the second nonlinear term describes approximately how the growth-rate varies with the local slope. The surface is assumed to grow at a constant rate perpendicular to itself, but since the height is measured vertically, [formula] depends on the slope: this gives rise to the term quadratic in [formula].

Our approach can be applied to other nonlinear diffusion problems well beyond surface-growth dynamics, when a different choice for the quadratic term is made. For example, if the term quadratic in the gradient in Eq. [\eqref=eq_kpz] is substituted by a term quadratic in the field, - h2, one obtains the Fisher equation which describes the growth and saturation of a population. A third possibility is to consider a mixed term [formula] which gives the Burgers' equation governing shock dynamics and traffic flow. In all of these cases, we can study the time evolution of an initially Gaussian [formula] profile. Upon setting the coefficient of the nonlinear term λ equal to zero, we always retrieve the heat equation, which preserves the Gaussianity of h for all later times. On the other hand, for λ  ≠  0, h becomes non-Gaussian.

For concreteness, we discuss how an imbalance between maxima and minima is generated by nonlocal non-Gaussianities in the context of the KPZ equation (Eq. [\eqref=eq_kpz]). The nonlinear term breaks the symmetry between positive and negative values of h which is a necessary condition to generate an imbalance. Note however that, in the case of a local evolution, this imbalance was exponentially small because the local evolution cannot create new extrema - it can only convert a maximum into a minimum whenever h happens to have a sufficiently large fluctuation. It is the presence of the diffusion term that is able to create new maxima and minima, even though, on its own, it would not be able to generate any imbalance, because of the symmetry h  →   - h. The two terms on the right-hand side of Eq. [\eqref=eq_kpz] conspire together to change the number of maxima and minima asymmetrically.

Since the imbalance between maxima and minima will now have a contribution perturbative in λ, we will determine a general expression for a field that is close to being Gaussian. The distribution of maxima and minima can be calculated from the joint distribution of hz, hzz and hzz*, which can again be determined given the cumulants of these variables. We will assume that the third order cumulants are of order λ, while higher order cumulants are of higher order. (The formula is valid for the KPZ problem, since the assumption on the cumulants is satisfied for any function that evolves nonlinearly from an initially Gaussian signal, as long as the quadratic terms have coefficients of order λ, and for times that are not too large.) The relevant cumulants up to third order are named in Table [\ref=tbl_correlations].

The expression for the imbalance Δn is derived by writing the joint probability distribution in terms of the cumulants, as before. We then set hz = 0 and integrate over the range of hzz and hzz* that defines the maxima and minima, to find

[formula]

Equation [\eqref=eq_general] is a general result. In order to apply it to the KPZ equation, we first change variables to

[formula]

Note that u is a monotonic function of h, so u has the same profile of maxima and minima as h. This new field satisfies the heat equation whose general solution is

[formula]

where [formula] denotes the Green's function.

The correlations listed in Table 2 can now be determined from the distribution of [formula], leading to an expression for Δn(t) that is valid over an arbitrary time span provided that λ is small. Analytical results can be obtained for a few convenient choices of the power spectrum of [formula]. For example, if we take a Gaussian spectrum, A(k)2  ~   exp ( - k2 / 2k20), we find

[formula]

where [formula]. The validity of this equation is illustrated in Fig. [\ref=fig_kpz], which shows an excellent agreement between theory and numerics. The imbalance starts out at zero because the initial choice for h is Gaussian. On the other hand, after long times, this expression decays back to zero. The reason for the decay is that, at long times, [formula] involves an average over a larger and larger window, so by the central limit theorem, it starts to acquire Gaussian statistics characterized by a vanishingly small imbalance between maxima and minima.

For early times, we can make an expansion in t, valid for an arbitrary power spectrum, which gives

[formula]

Note that for the Gaussian power spectrum, featured in Eq. [\eqref=eq_kpz_gsn_spec], the second order term happens to vanish.

The agreement for the entire range of times is special for the KPZ equation: for more general equations, the agreement would break down at sufficiently late times, since the nonlinearities eventually grow exponentially; the exact transformation of the KPZ equation to a linear equation implies that the nonlinearities remain bounded.

Determination of g(z)

The probability distribution g(z) can be derived using a method similar to the one outlined in [\cite=cite_Longuet1]. Consider a fixed point [formula]. We wish to know the probability density that at this point we have HG  =  z (to avoid confusion with the derivatives of HG, we shall write H from now on) given that it is a minimum. The conditions for this can be written in terms of derivatives of H, namely, Hx  =  Hy  =  0, defines a critical point while HxxHyy  -  H2xy  >  0 and Hxx + Hyy  >  0 distinguishes a local minimum from a saddle or maximum. First let us determine the joint distribution of these six variables (H and its derivatives), which form a set of correlated Gaussian variables. The joint probability distribution [formula] for any such set is completely determined by the correlations between the variables:

[formula]

where Cij  =  〈ξiξj〉 is the matrix of correlations between the variables.

Correlations between H and its first and second derivatives can be expressed in terms of the first three moments (K0,K2,K4) of its amplitude spectrum. By differentiating the Fourier expansion of H we find that [formula], and likewise that the variances of the second derivatives are proportional to K4. The only variables among the six that are correlated to one another turn out to be H, Hxx and Hyy, with 〈HHxx〉  =  〈HHyy〉  =   - K2 / 2 and 〈HxxHyy〉  =  K4 / 8. After retrieving the probability distribution, we set H  =  z, Hx  =  Hy  =  0 and integrate over Hxx, Hyy and Hxy (over the domain defining a minimum). The Jacobian determinant |HxxHyy - H2xy| must be added [\cite=cite_Longuet1] [\cite=cite_longpaper1]. The probability density we have calculated so far reflects the chance that Hx and Hy are close to zero at the point [formula] (there is a vanishing chance that they are exactly 0). However, we want to find the probability of the reverse situation, that Hx = Hy = 0 exactly at a point within a small range of [formula] (since we are looking at the distribution of extrema in the plane). The ratio of the two probabilities is given by the Jacobian determinant. The final answer reads

[formula]

where [formula].

Complex notation and cumulants

Introducing the complex variables z = x + iy and z* allows one to use isotropy to calculate the probability distribution very efficiently. The isotropy causes many of the cumulants of the distribution to vanish - this explains why the monstar fraction is always the same for Gaussian fields when they are isotropic and why the shift of the monstar fraction depends on the nonlinearity f(H) in a simple way.

The isotropy implies that a moment like 〈hzzhzz*z*〉 does not change when the field is rotated by an angle α. On the other hand this rotation transforms z  →  zeiα and z*  →  z*e- iα, which in the given example would introduce an extra factor eiα in the moment. Since the moment cannot change, it must be vanishing. In general, a moment can only be nonzero if the number of z and z* derivatives match.

In these complex variables, the definition of an umbilic is given by hzz  =  0. Monstars are distinguished from lemons and stars with the conditions which translates in complex notation the condition derived in Ref. [\cite=cite_Berry] for an umbilic to be a monstar.

First, we review why the monstar fraction is a constant for a Gaussian field H. Since by the conditions outlined above, the monstar fraction depends only on the joint distribution of Hzz, Hzzz, Hzzz* and their conjugates, and the properties of a Gaussian field are determined by covariances, there are only a few variables the monstar fraction can depend on. These are σ  =  〈|Hzz|2〉, τ  =  〈|Hzzz|2〉, and τ' = 〈|Hzzz*|2〉. The latter two are equal thanks to translational symmetry, and since there is no dimensionless function of σ and τ, αM must be a constant.

Similar arguments can be used to show that the shift in αM for the non-Gaussian h = H + εf(H) depends only on 〈f'''(H)〉 to first order. First, we need to determine all the cumulants of hzz,hzzz and hzzz* up to first order in ε. At this order, we will show that most of the cumulants vanish. We are faced with cumulants of the form [formula], where the operators Di represent two or three derivatives. Each operator acts on [formula] at the same point [formula]. For the moment, we will consider each operator Di to act on a different point [formula]. This allows us to bring all the operators outside the cumulant. This yields [formula], where [formula].

Since we are only working up to first order, we can expand the cumulant as

[formula]

which consists of one leading order term and n first order terms for which we can apply

[formula]

In this expression, the operators D2 through Dn can easily be reinserted. For the operator D1 the product rule needs to be applied, which in principle gives rise to a lot of terms. Remember though that, after setting all [formula] equal again, each moment can only be nonzero if the number of z and z* derivatives match. This criterion kills most of the terms. For example, if we consider the cumulant C3(hzzz*,hzzz*,hz*z*), we encounter the term ∂1,zzz*〈f''(H1)〉〈H1Hzzz*〉〈H1Hz*z*〉. In the product rule, after setting [formula] equal to the other [formula], the only nonzero term is 〈f''(H)〉〈Hz*Hzzz*〉〈HzzHz*z*〉.

We can now also see that there are no cumulants Cn with n  >  4 which are nonzero up to first order in ε. This is because when we apply the above recipe, we have n - 1 moments of the form 〈H1DiHi〉. The operator D1 has only three derivatives at most, therefore, in every term in the product rule there must be at least one moment of the form 〈HDiHi〉. However, the variables that we consider, hzz, hzzz, hzzz* and their conjugates, all do not have the same number of z and z* derivatives. That means that this moment must be zero, and hence the entire term too.