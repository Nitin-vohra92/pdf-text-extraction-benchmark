Clustering function: a measure of social influence

Mindaugas Bloznelis and Valentas Kurauskas1

key words: clustering coefficient, social network, intersection graph, power law

2000 Mathematics Subject Classifications: 91D30, 05C80, 05C07, 91C20

Introduction

Our study is motivated by the following question: given two vertices of a network, the presence of how many common neighbours would imply with certainty that these two vertices are adjacent. A "softer" question is about the probability that two vertices with (at least) r common neighbours establish a link. The answer is given by the clustering functions ([\ref=Cl1]) and ([\ref=Cl2]).

Let G = (V,E) be a finite graph on vertex set V and with edge set E. The number of neighbours of a vertex v is denoted d(v). The number of common neighbours of vertices vi and vj is denoted d(vi,vj). We are interested in the fraction of adjacent pairs vi  ~  vj among all pairs {vi,vj}  ⊂  V having (at least) r common neighbours. Here and below '~  ' denotes the adjacency relation of G. More formally, let us consider the random pair of distinct vertices {v*1,v*2} drawn from V uniformly at random. Define the clustering functions of G

[formula]

In the case of a social network ([\ref=Cl1]), ([\ref=Cl2]) could be interpreted as measures of social influence or pressure exercised by the neighbours on a pair of actors to establish a communication link. We remark that characteristics ([\ref=Cl1]) and ([\ref=Cl2]) are related to the clustering coefficient of G. We recall its definition for convenience. Let (v*1,v*2,v*3) be an ordered triple of distinct vertices drawn from V uniformly at random. The conditional probability that v*1 is adjacent to v*2, given that v*1 and v*2 are both adjacent to v*3, is called the (global) clustering coefficient ([\cite=Barrat2000], [\cite=Newman2001], [\cite=Newman2003], [\cite=storgatz1998]). We denote it [formula].

In this paper we study clustering functions first by considering empirical data and then by a rigorous analysis of related random graph models.

We consider clustering function ([\ref=Cl1]) of real networks admitting positive clustering coefficient: the actor network, where two actors are declared adjacent whenever they have acted in the same film ([\cite=actornetwork]), and the Facebook network ([\cite=Bakshy], [\cite=Foudalis2011], [\cite=Traud]). We remark that empirical plots show similar pattern and surprising regularity.

Our choice of the random graph model is motivated by an observation of Newman et al. [\cite=Newman+W+S2002] that the clustering property of some social networks (so called affiliation networks) could be explained by the presence of a bipartite graph structure. For example, the bipartite graph, where actors are linked to films, defines the actor network. It seems reasonable that a bipartite graph structure might also be helpful in explaining (at least to some extent) the adjacency relations of Facebook network: two members become adjacent because they share some common interests/attributes.

We secondly consider clustering function ([\ref=Cl1]) of a random intersection graph, where vertices (actors) are prescribed attribute sets independently at random and two vertices are declared adjacent whenever they share at least one common attribute ([\cite=karonski1999], [\cite=godehardt2003], see also [\cite=Barbour2011], [\cite=Guillaume+L2004]). Random intersection graphs are relatively simple objects and for them rigorous mathematical results can be obtained. We evaluate the probabilities [formula], [formula] for a random intersection graph in Sect. 3 below.

Clustering functions: empirical results

In Figure 1 we plot clustering functions ([\ref=Cl1]) and ([\ref=Cl2]) of three drama actor networks: the English actor network with n = 402622 actors, m = 66127 films and the clustering coefficient C = 0.32 (the clustering coefficients here and below are rounded up to 2 decimal places), the French actor network with n = 43204 actors, m = 5629 films and the clustering coefficient C = 0.30 and the Russian actor network with n  =  9880 actors, m = 2459 films and C = 0.44. The data has been obtained from [\cite=actornetwork]. In Figure 2 we plot clustering function ([\ref=Cl1]) of three networks describing relations between community members at three different universities (data from [\cite=Traud]): the first network has n = 17425 vertices and the clustering coefficient C = 0.16 ([formula] blue graph); the second network has n = 9414 vertices and the clustering coefficient C = 0.15 ([formula] green graph); the third network has n = 6596 vertices and the clustering coefficient C = 0.16 ( red graph).

Clustering functions of random intersection graphs

Vertices [formula] of an intersection graph are represented by subsets [formula] of a given ground set [formula]. Elements of W are called attributes or keys. Vertices vi and vj are declared adjacent if [formula]. The adjacency relations of such an intersection graph resemble those of some real networks, e.g., the collaboration network, where authors are declared adjacent whenever they have co-authored a paper, or the actor network, where two actors are linked by an edge whenever they have acted in the same film. Random intersection graphs have attracted considerable attention in the recent literature, see, e.g., [\cite=behrisch2007], [\cite=Blackburn2009], [\cite=Bloznelis2011+] [\cite=Britton2008], [\cite=eschenauer2002], [\cite=Rybarczyk2011], [\cite=Spirakis2011], [\cite=Yagan2009]. They admit a power law degree distribution and tunable clustering. We consider two models of random intesection graphs: the active graph and the inhomogeneous graph.

Active graph. In the active random intersection graph G1(n,m,P) every vertex [formula] selects its attribute set Di independently at random ([\cite=godehardt2003], [\cite=karonski1999]). We assume for simplicity that independent random sets [formula] have the same probability distribution

[formula]

In particular, all attributes have equal probabilities to be selected. Here P is the common probability distribution of the sizes of selected sets Xi: = |Di| (for each [formula] we have [formula], [formula]). We remark that [formula] are independent random variables taking values in [formula].

We study the clustering function

[formula]

of a sparse random intersection graph with large number of vertices. We remark, that the second identity of ([\ref=Cl1+]) follows from the fact that the probability distribution of G1(n,m,P) is invariant under permutation of its vertices. By sparse we mean that the number of edges scales as the number of vertices n as n  →    +    ∞  . It is convenient to consider a sequence of random intersection graphs {G(n)}n, where G(n) = G1(n,m,P) and where m = mn and P = Pn both depend on n. We remark that {G(n)}n is a sequence of sparse random graphs whenever the size X1 of the typical random set is of order (m / n)1 / 2 as m,n  →    ∞   ([\cite=Bloznelis2008]). Furthermore, assuming that

(i) [formula] converges in distribution to some random variable Z;

(ii) [formula] and [formula] converges to [formula]

one obtains the asymptotic degree distribution of {G(n)}

[formula]

see [\cite=Bloznelis2008], [\cite=Bloznelis2011+], [\cite=Deijfen], [\cite=stark2004]. Here d(v) denotes the degree of a vertex v. We remark that a heavy tailed distribution of Z yields a heavy tailed asymptotic degree distribution ([\ref=adegree]). Along with the first moment condition (ii) we shall also consider the r - th moment condition

(ii-r) [formula] and [formula] converges to [formula].

We denote [formula] and [formula] where d* is a random variable with the asymptotic degree distribution [formula], [formula]. We assume below that [formula], i.e., that the asymptotic degree distribution is non-degenerate. Furthermore, we assume for convenience that the ratio βn = m / n tends to some β∈(0, +   ∞  ] as n  →    +    ∞  .

An important property of the active random intersection graph is that the adjacency relations are statistically dependent events. In particular, the clustering coefficient of a sparse random intersection graph G(n) is bounded away from zero as n  →    +    ∞   provided that the second moment of the degree distribution is finite and β  <    ∞   ([\cite=Bloznelis2011+], [\cite=Deijfen]). In this case we have (see ([\cite=Bloznelis2011+], [\cite=Deijfen])

[formula]

We remark that for β =  +   ∞   we have α = o(1). For comparison, the (unconditional) edge probability [formula] satisfies for any β∈(0, +   ∞  ], see, e.g., [\cite=Bloznelis2011+],

Theorems [\ref=T1] and [\ref=T2] show a first order asymptotics of the conditional probabilities cl(r) as n  →    +    ∞   in the cases where β  <    ∞   and β  =    ∞  , respectively.

Empirical results of simulated random intersection graphs show that the convergence to the "limiting shape" in ([\ref=b2-4]) is rather slow, see Figures 3 and 4 below.

We conclude from ([\ref=b2-4]), ([\ref=b2-1]) that edge dependence measures cl(1) and α are closely related. In particular, we have cl(1) = 1 - o(1)  ⇔  α = 1 - o(1) and cl(1) = o(1)  ⇔  α = o(1). Furthermore, ([\ref=b3-2]) tells us that the characteristic cl(2) is able to distinguish between the cases βn = o(n) and n = o(βn). Finally, ([\ref=b2-3]) tells us that any cl(r), [formula] can't distinguish between sequences {βn} and {βn'} growing slower that any power of n (take βn  =   ln n and βn' =  ln 2n, for example).

Remark 1. It is likely that ([\ref=b3-2]) can be extended to an arbitrary r as follows Here c(r,β*) = (βr / 2*z- r - 21zr2z2r + 1)- 1. We note that numbers [formula] can be expressed in terms of moments of the asymptotic degree distribution ([\ref=adegree]).

Proofs of Theorems [\ref=T1] and [\ref=T2] are given in Sect. 5.

Fig. 3 illustrates the convergence to a step function shown by Theorem [\ref=T1]. Here we plot clustering function ([\ref=Cl1]) of simulated random intersection graphs Gi = G(ni,mi,P), where ni = mi = 102 + i, i = 1,2,3, and P(10) = 1.

In Fig. 4 we plot ([\ref=Cl1]) for simulated random intersection graphs Gi = G(n,m,Pi), where n = m = 104 and Pi(3i) = 1, i = 1,2,3. Fig. 4 illustrates the influence of the size of random sets.

Inhomogeneous graph. The inhomogeneous random intersection graph G1(n,m,P1,P2) on the vertex set [formula] is obtained as follows. We first generate independent random variables [formula] such that each Ai has the probability distribution P1 and each Bj has the probability distribution P2. Then, conditionally on the realized values {Ai,Bj}n,mi,j = 1, we include the attribute wj∈W in the set Di with probability pij  =   min {1,AiBj(nm)- 1 / 2} independently for each i and j (see [\cite=Barbour2011], [\cite=BloznelisD2012+], [\cite=Bradonjic2010], [\cite=Shang2010]). Our motivation of studying this random graph model is that its clustering function approximates empirical data remarkably well, see Figure 8 below.

We consider a sequence of inhomogeneous intersection graphs [formula], where P1, P2 remain fixed while m = mn and n tend to infinity. We denote [formula] and [formula]. A simple calculation shows (see Section 5 below) that the edge probability [formula] of G1(n,m,P1,P2) satisfies

[formula]

Hence, [formula] is a sequence of sparse graphs. We remark that this sequence admits a power law asymptotic degree distribution [\cite=BloznelisD2012+].

In Theorem [\ref=T3] below we show a first order asymptotics of the clustering function cl(  ·  ) in the case where the ratio βn = m / n has a non-zero finite limit. In addition, we show that [formula] admits a nonvanishing clustering coefficient [formula].

The proof of Theorem [\ref=T3] is given in Sect. 5.

Discussion

The first order asymptotics ([\ref=b2-4]), ([\ref=b3-2]), ([\ref=b2-3]) and ([\ref=NH]) suggests that the clustering function cl(  ·  ) of a large intersection graph with a square integrable asymptotic degree distribution can be approximated by a step - like function. Furthermore, cl(1) is closely related to the clustering coefficient.

Simulations in Figures 3 and 4 show that the convergence in ([\ref=b2-4]) can be rather slow and we observe a sigmoid function approximation of the step function. Furthermore, the larger is the average degree, the more remote is the "step" from the origin and the more gradual is the slope of the clustering function.

Clustering functions of real networks considered in Figures 1 and 3 have even more gradual slope, a phenomena perhaps related to the inhomogeneity of the degree sequence. We remark that the actor network and the Facebook are considered as having power law degree sequences which do not admit a finite (theoretical) second moment, see, e.g., [\cite=Durret2007], [\cite=Foudalis2011]. In order to learn more about the influence of the inhomogeneity of the degree sequence on the slope of the clustering function r  →  cl(r) we select various subnetworks of real networks according to certain regularity conditions satisfied by their degree sequences. We observe that the inhomogeneity (heavy tail) of the degree sequence affects the slope of the clustering function: the heavier the tail the more gradual is the slope of the clustering function. We illustrate these observations in Figures 5 and 6.

Figure 5 plots clustering function ([\ref=Cl1]) of subgraphs of the first university network (see Sect 2.) sampled as follows. G1 is the subgraph that includes all vertices of degree not larger than 50. It has n0 = 7165 vertices. G2 is a subgraph induced by n0 vertices drawn uniformly at random (without replacement) from the vertices of degree not larger than 150. G3 is a subgraph of induced by n0 vertices drawn uniformly at random (without replacement) from the set of all vertices. Now all three graphs have the same number of vertices.

In Figure 6 we plot two subgraphs of the French actor network (data from [\cite=actornetwork]). The subgraph G4 is induced by the set of marked vertices obtained as follows: we put a mark on each vertex v with probability d-  τ(v) and independently of the other vertices. Choosing τ = 0.5 we obtain a random subgraph denoted G4. In our case the realized number of marked vertices n1 = 8871. G5 is the subgraph of the French actor network induced by n1 vertices drawn uniformly at random (without replacement) from the set of all vertices. Now both subgraphs have the same number of vertices, but the degree sequence of G4 is much more regular than that of G5.

Finally, we examine how well a random intersection graph fits the real data. For this purpose we consider a memoryless actor network obtained as follows. Assume every actor of a given actor graph has forgotten about the titles of movies he or she acted in and only remembers the number of movies.

We first simulate an instance of the active memoryless graph where each actor chooses films independently and uniformly at random from a given set of [formula] films so that the number of films chosen by each actor is the same as in the true actor graph. In the active memoryless graph all films have equal chances to be selected by any of actors. We remark that in the case where [formula], i.e., the number of films in the active memoryless graph is the same as in the real underlying actor network, the expected degree of the memoryless graph does not match the average degree of the real network. We can easily adjust the number of films (of the memoryless graph) so that these degrees match. We denote this number m' and call the active memoryless graph with [formula] adjusted one. In Figure 7 we plot clustering function ([\ref=Cl1]) of two instances of memoryless graphs for comparison with the underlying French actor network: one with the true number of films and another with the adjusted number of films.

We secondly simulate an instance of the inhomogeneous memoryless graph where an actor vi chooses the film wj with probability aibjM- 1 independently for each i and j. Here the numbers ai,bj are observed characteristics of the underlying actor network: vi acted in ai films; bj actors acted in the film wj. [formula] is the total number of links of the bipartite graph where actors are linked to films. In Figure 8 we plot clustering function ([\ref=Cl1]) of an instance of the inhomogeneous memoryless graph of the French actor network. Here we observe a remarkable accuracy of the approximation of the real clustering function by that of the memoryless graph. We remark that in comparison with active memoryless graphs of Figure 7, that only use the data [formula], the inhomogeneous memoryless graph of Figure 8 uses, in addition, the numbers [formula].

We remark that Theorems [\ref=T1], [\ref=T2] and [\ref=T3] establish a first order asymptotics to the clustering function cl(  ·  ) of random intersection graphs having a square integrable asymptotic degree distribution. An interesting question were about a power law random intersection graph whose asymptotic degree distribution has infinite second moment: Is there a limiting shape of the clustering function for n  →    +    ∞   in this case? Is there a theoretically valid approximation to the clustering function that explains the gradual slope of cl(  ·  ) of observed empirical plots? It would also be interesting to learn about a higher order asymptotics of the clustering function cl(  ·  ) that refines results of Theorems [\ref=T1], [\ref=T3] and could perhaps better explain the empirical data.

Proofs

The section is organized as follows: we first we formulate two auxiliary lemmas, then we prove Theorems [\ref=T1], [\ref=T2] and [\ref=T3].

Let [formula] be the sum of independent random indicators with probabilities [formula]. Let Λ be Poisson random variable with mean [formula]. The total variation distance between the distributions PS of PΛ of S and Λ

[formula]

Given integers 1  ≤  s  ≤  d1  ≤  d2  ≤  m, let D1,D2 be independent random subsets of the set [formula] such that D1 (respectively D2) is uniformly distributed in the class of subsets of W of size d1 (respectively d2). The probabilities [formula] and [formula] satisfy

[formula]

Here we denote [formula].

5.1. Active graph. By Xi = Xni we denote the size of the set Di in G(n). Furthermore, we write Zi = Zni  =  β- 1 / 2nXni and put Z01: = Z. We denote [formula] and introduce the function

[formula]

We remark that conditions (i), (ii-2) imply φ(t) = o(1) as t  →    +    ∞   (see, e.g., [\cite=Bloznelis2011+]) and [formula]. By [formula] and [formula] we denote the conditional probability and expectation given X1, X2. By [formula] and [formula] we denote the conditional probability and expectation given D1, D2. We introduce events A  =  {v1  ~  v2}, [formula] and probabilities By fr(λ) = e-  λλr / r! we denote the Poisson probability.

We have

[formula]

In order to evaluate the numerator we write [formula] and apply the total probability formula

[formula]

Here [formula]. Similarly we expand the denominator of ([\ref=b4-3])

[formula]

In order to prove Theorem [\ref=T1] we choose k = 1 in ([\ref=A-k]), ([\ref=d-12-k]) and invoke the asymptotic expressions of pi(r) and the upper bound for [formula] shown in Lemma [\ref=pagrindine]. Then, observing that as n  →    +    ∞   we have [formula], for k = 1,2, and α  =  β- 1 / 2z1 / z2 + o(1) (see ([\ref=cc])), we obtain ([\ref=b2-4]).

Theorem [\ref=T2] is obtained in the same way, but now we choose k = 2.

Given a sequence of random variables {Yn} and [formula] we write [formula] to denote the fact that [formula], for r = 0,1, and [formula], for r  ≥  2.

Assume that βn  →  β∈(0, +   ∞  ]. Suppose that (i), (ii-2) hold. Denote [formula] and [formula]. We have as n  →    +    ∞

[formula]

Furthermore, we have

[formula]

Before the proof we introduce some notation and collect auxiliary inequalities. Then we give an outline of the proof. Afterwards we prove ([\ref=zzz]), ([\ref=zzz+]) and ([\ref=www]), ([\ref=ttt]).

By c* we denote a generic positive constant. By [formula] we denote the indicator of an event B and write [formula]. In the proof we use several indicators

[formula]

Some of them depend on ε > 0, value of which will be clear from the context. We denote

[formula]

and, for i = 1,2 we write We note that ([\ref=xx]) implies

[formula]

In particular, we have

[formula]

We will use the following properties of the function λ  →  fr(λ). For [formula], it follows from the mean value theorem fr(t) - fr(s) = fr'(ξ)(t - s), where 0 < s  ≤  ξ  ≤  t, combined with inequalities |fr'(ξ)|  ≤  1 and |f2 + r'(ξ)|  ≤  ξ that

[formula]

Now we outline the proof. In order to evaluate pi(r) we write

[formula]

and observe that, given D1,D2 satisfying [formula], the random variable has binomial distribution [formula]. We first approximate [formula] in ([\ref=pir]) by the Poisson probability fr(λi). Then, we approximate λi by λ̃i, and fr(λi) by fr(λ̃i). We obtain

[formula]

where, for [formula], we denote

[formula]

Next we show that the remainder term [formula] of ([\ref=pir222]) is negligible. For this purpose we estimate using LeCam's lemma (see Lemma [\ref=LeCamLemma])

[formula]

and estimate Δr,i'' combining ([\ref=meanvalue]) with the approximations [formula]. We briefly explain these approximations. Let [formula] denote the intersection [formula] provided it is non empty. Denote [formula], j = 1,2. We split where

[formula]

and approximate [formula], [formula] and [formula].

Proof of ([\ref=zzz]), ([\ref=zzz+]). In order to prove ([\ref=zzz]), ([\ref=zzz+]) we show that

[formula]

We firstly prove ([\ref=g13-1]). In the case where β  <    ∞   we find n0 > 0 such that β < 2βn for n  ≥  n0. In the case where β =  +   ∞   we find n0 such that βn > 1 for n  ≥  n0. In order to prove ([\ref=g13-1]) we show that for any 0 < ε  <   min {0.5β1 / 2,0.1} and n  ≥  n0 we have

[formula]

We remark that ([\ref=g14-1]) combined with the relation lim t  →    +    ∞φ(t) = 0 implies ([\ref=g13-1]).

Let us prove ([\ref=g14-1]). Given ε, we write [formula] and show that

[formula]

The first inequality of ([\ref=g14-3]) is obvious. In order to prove the second one we combine the inequalities which follow from Markov's inequality, with the inequalities Here we applied the inequality [formula] and then Markov's inequality.

In order to prove ([\ref=g14-2]) we write [formula], see ([\ref=g25-1]), and invoke the inequalities

[formula]

The first inequality of ([\ref=g27-5]) follows from ([\ref=g23-1]), ([\ref=pirf]) and inequalities [formula], and

[formula]

The second inequality of ([\ref=g27-5]) follows from ([\ref=meanvalue]) and ([\ref=g14-7]).

We complete the proof of ([\ref=g13-1]) by showing ([\ref=g14-7]). To this aim we prove that for D1,D2 satisfying [formula] the following inequalities hold true

[formula]

Let us prove ([\ref=g13-3]). We write

[formula]

and apply ([\ref=xx]) to probabilities τ1 and τ2. We obtain Here [formula], [formula] and [formula]. Next, we observe that, by our choice of ε, we have ε  ≤  β1 / 2n for n  ≥  n0. In particular, the inequality X1 + X2  ≤  ε2nβ1 / 2n implies X1 + X2  ≤  εm. Assuming, in addition, that X3  ≤  ε- 1β1 / 2n, we obtain XiX3  ≤  εm, for i = 1,2. These inequalities imply θi  ≤  ε / (1 - ε), i = 1,2, and θ3  ≤  1 + 2ε. Note that ε < 0.1. Hence, we have Now, we write and, using identities [formula], we obtain

[formula]

In the last step we used the inequalities [formula].

Now we prove ([\ref=g13-7]). To this aim we write and show that for D1,D2 satisfying [formula] the following inequalities hold true

[formula]

We only prove ([\ref=2013-02-16]) for j = 4 (both cases j = 3,4 are identical). Observing that probabilities [formula] satisfy the inequality p2 *  ≤  p1 *, we write

[formula]

Next, we split and apply ([\ref=xx]) to the probabilities τ* and τk *. We have We recall that θ3 = m / (m - X1) satisfies [formula]. Collecting these inequalities in ([\ref=g13-4]) we obtain ([\ref=2013-02-16]):

[formula]

In the last step we used identity [formula] and inequalities

We secondly prove ([\ref=g14-9]). Denote

[formula]

We observe that 1 - e-  λ̃0  ≤  λ̃0 implies |R01|  ≤  λ̃r + 10. Furthermore, from the inequality

[formula]

see ([\ref=xx]), we obtain |R02|  ≤  λ̃r0X1X2m- 1. We remark that, for r = 0,1, relation ([\ref=g14-9]) follows from the bounds [formula] and [formula]. Indeed, we have

In the case where r = 2 we invoke the truncation argument. Denote

[formula]

We observe that inequalities

[formula]

imply, for j = 3,4,

[formula]

Finally, we obtain ([\ref=g14-9]) from the identities

[formula]

combined with bounds ([\ref=2013-03-09++X]) and

Let us prove ([\ref=g25-5]). We write and apply the inequalities fr(t)  ≤  tjfr - j(t)  ≤  tj, 0  ≤  j  ≤  r. For r  ≥  3 we obtain

[formula]

Proof of ([\ref=www]), ([\ref=ttt]). We remark that ([\ref=www]), ([\ref=ttt]) follows from ([\ref=pir222]) and the bounds, for i = 1,2,

[formula]

We first prove ([\ref=g18-1]). For this purpose we combine identities with the bounds, which are shown below,

[formula]

We remark that the third bound of ([\ref=g27-1]) is an easy consequence of Markov's inequality, Now we prove the first and second bound of ([\ref=g27-1]) in the case where i = 1. In the proof we use the simple identity [formula] and inequality

[formula]

which hold whenever conditions of event A1 are satisfied. We note that ([\ref=g19-8]) follows from identities

[formula]

and inequalities, see ([\ref=xx]),

Let us prove the first bound of ([\ref=g27-1]). Combining ([\ref=pirf]) with inequality q21  ≤  2q211 + 2q212 we write [formula]. Hence, we obtain Furthermore, invoking inequality [formula], which follows from ([\ref=g19-1]), and bound [formula], which follows from ([\ref=g19-8]), we obtain the first bound of ([\ref=g27-1]).

Let us prove the second bound of ([\ref=g27-1]). In the proof we use the inequalities

[formula]

For r = 0,1 we apply ([\ref=meanvalue]) and obtain

[formula]

Then we invoke the bounds [formula], see ([\ref=g19-1]), and

[formula]

see ([\ref=g19-1]), ([\ref=g19-8]). Clearly, ([\ref=2013-03-11]), ([\ref=2013-03-11+]) imply the second bound of ([\ref=g27-1]).

For r  ≥  2 we derive the second bound of ([\ref=g27-1]) from inequalities, see ([\ref=meanvalue]), ([\ref=kovo14]),

[formula]

combined with relations

[formula]

Here ([\ref=03-11+A]) follows from ([\ref=g19-1]). ([\ref=03-11+B]) follows from ([\ref=2013-03-11+]). The first inequality of ([\ref=03-11+C]) follows from ([\ref=g19-8]). To show the second inequality of ([\ref=03-11+C]) we invoke ([\ref=g19-2]) and write

Now we establish the first two bounds of ([\ref=g27-1]) for i = 2. In the proof we use the relations

[formula]

where |R*|  ≤  c*n- 2(β- 3 / 2n  +  β- 1n). Here ([\ref=g21-7]) is obtained in the same way as ([\ref=g19-8]) above, and ([\ref=g21-6]) follows from ([\ref=xx]). Furthemore, the first identity of ([\ref=g28-1]) is obvious and second one is obtained from the identities To prove the first bound of ([\ref=g27-1]) for i = 2 we write, see ([\ref=pirf]), and invoke the bounds, which follow from ([\ref=g21-7]), ([\ref=g21-6]), ([\ref=g28-1]), In the last step we used inequalities [formula], see ([\ref=g19-1]).

The second bound of ([\ref=g27-1]) for i = 2 follows from the relations shown below

[formula]

Here the first inequality of ([\ref=kovo15+3]) follows from ([\ref=meanvalue]), and the second inequality follows from ([\ref=g28-1]) and the identity Furthermore, ([\ref=kovo15+1]) follows from ([\ref=g21-6]), ([\ref=g28-1]) and inequality [formula]. Finally, the first inequality of ([\ref=kovo15+2]) follows from ([\ref=g21-7]), and in the the last step of ([\ref=kovo15+2]) we use the inequality [formula], which follows from ([\ref=g19-2]).

Now we prove ([\ref=g18-2]). Since fr(λ̃i)  ≤  1 it suffices to show that [formula]. For i = 1 we write, see ([\ref=g19-1]),

[formula]

where

[formula]

Hence, we have [formula].

For i = 2 we proceed as follows. Given 0 < ε < 1 we write, see ([\ref=g19-1]),

[formula]

where

[formula]

We let ε  =  εn  →  0 slowly enough to get [formula]. Then we obtain [formula]

Proof of ([\ref=b4-1]). We write, for short, [formula]. We have, see ([\ref=xx]),

[formula]

Taking the expected values in ([\ref=b4-2]) we obtain ([\ref=b4-1]) for k = 1,2. For k = 3 we apply ([\ref=g19-2]) and write Hence, we have [formula].

5.2. Inhomogeneous graph. Before the proof of Theorem [\ref=T3] we introduce some notation and show ([\ref=p-e-inh]). By [formula] and [formula] we denote the conditional probability and expectation given A1,A2,Bm. Given i,j,l∈[m] and k,s,t∈[n], denote

[formula]

Introduce the random variable [formula] and probability [formula].

Let us prove ([\ref=p-e-inh]). It follows from identity [formula], by inclusion-exclusion, that

[formula]

We derive ([\ref=p-e-inh]) from these inequalities using relations

[formula]

To show the first relation we apply the inequality [formula] and write

[formula]

Then we take the expected values in ([\ref=sest-06-1]), use the identity [formula] and the bound [formula].

In order to prove ([\ref=NH]) we write [formula], where and invoke relations

[formula]

Here we denote Λ = a1Bmβ- 1 / 2n.

Let us prove ([\ref=p*]). For r = 0 we write and invoke the bounds The first bound follows from ([\ref=p-e-inh]). In order to show the second bound we note that the event [formula] implies that there exist i,j∈[m], [formula] and 3  ≤  k  ≤  n such that [formula]. Hence, by Markov's inequality, By the inequality [formula], the right hand side sum is O(n- 1).

For r  ≥  2 we write [formula], where [formula], and invoke the bound [formula]. Let us prove this bound. Given 3  ≤  s < t  ≤  n introduce events

[formula] such that [formula] and [formula];

[formula] such that [formula], [formula] and [formula];

[formula] such that [formula] and [formula], [formula];

[formula] such that [formula], [formula] and [formula], [formula]

and observe that [formula]. Next, using the identity [formula] we obtain

[formula]

In the last step we invoke the bounds that follow by Markov's inequality

[formula]

Proof of ([\ref=p*]) is complete.

Let us prove ([\ref=p**]). We have, see ([\ref=U-st]), Furthermore, from the identity [formula] we obtain, by inclusion-exclusion, In the last step we used ([\ref=U-st]). It remains to evaluate the sum [formula]. We observe that [formula], where M is the set of vectors (i,j)∈[m]2 satisfying [formula]. We write, by inclusion-exclusion, [formula], where and complete the proof of ([\ref=p**]) by showing that

[formula]

The first relation of ([\ref=2013-04-08-4]) follows from the identity which is obtained using the same truncation argument as in ([\ref=sest-06-1]) above. The second bound of ([\ref=2013-04-08-4]) follows from the inequalities that hold for any ε > 0

[formula]

In order to show ([\ref=2013-04-08-5]) we write [formula], where [formula] and invoke the inequalities in the identity [formula]. Here we also use the bound [formula]. To show ([\ref=2013-04-08-6]) we invoke the inequality in the identity [formula]. Proof of ([\ref=p**]) is complete.

Now we prove ([\ref=p*r]). Firstly, from relations [formula] we derive inequalities

[formula]

Here [formula], since [formula]. Secondly, we write, by symmetry,

[formula]

and approximate [formula] by p̃r. We remark that relations imply inequalities

[formula]

and observe that the probability

[formula]

because

It follows from ([\ref=04-22+1]), ([\ref=04-22++1]), ([\ref=04-22+2]), ([\ref=04-22+3]) that

[formula]

We complete the proof of ([\ref=p*r]) by showing that

[formula]

Let us show ([\ref=04-22+6]). Using LeCam's inequality, see ([\ref=LeCam]), we write

[formula]

Here [formula]. In particular, we have Δ  ≤  a21B2mm- 1. This inequality and ([\ref=04-22+5]) imply

[formula]

Here we used inequalities

[formula]

Let us now evaluate the term [formula] of ([\ref=04-22+7]). From relations we obtain inequalities [formula] which yield the approximation

[formula]

Furthermore, we have

[formula]

In the last step we replaced p1mp2m by A1A2B2m(mn)- 1 as in ([\ref=sest-06-1]) above.

Now we are going to replace fΛ0(r) by fΛ(r). For this purpose we combine the mean value theorem and the inequality [formula]. We obtain

[formula]

Furthermore, we write [formula] and [formula] and estimate The latter inequalities and ([\ref=04-22+9]) yield

[formula]

since [formula]. Finally, ([\ref=04-22+7]), ([\ref=04-22+8]), ([\ref=04-23+1]) and ([\ref=04-22+10]) imply ([\ref=04-22+6]). Proof of ([\ref=p*r]) is complete.

Let us prove ([\ref=clcoef]). To this aim we write [formula], where D denotes the event {v1  ~  v3,v2  ~  v3} and [formula], and show that

[formula]

Here κ1: = a31b3n- 3 / 2m- 1 / 2 and κ2: = a21a2b22n- 2. To show the first relation of ([\ref=BA17]) we observe that event L implies B and event B implies [formula]. In particular, we have [formula]. Here Hence, [formula]. Next we approximate [formula] using inclusion-exclusion

[formula]

and obtain [formula]. Here we invoked the bound and approximated, see ([\ref=sest-06-1]),

Let us prove the second relation of ([\ref=BA17]). We observe that [formula] and approximate Our rigorous proof is a bit more involved since we operate under minimal moment conditions. Introduce event A*  =  {A3 < n1 / 4} and its indicator function [formula]. We derive upper and lower bounds for [formula] from the inequalities By the union bound, the right hand side is bounded from above by Next we show a matching lower bound for [formula]. Proceeding as in ([\ref=B1-17]) we write where Hence, we have [formula]. It remains to show that

[formula]

Let us prove the first inequality of ([\ref=lija]). We write, by inclusion-exclusion, Here and below [formula] denotes the sum over all vectors (s,t) with [formula], 1  ≤  s,t  ≤  m. By [formula] we denote the sum over unordered pairs of distinct vectors {(s,t),(x,y)} with [formula], [formula] and 1  ≤  s,t,x,y  ≤  m. Next, we calculate and estimate Here

[formula]

In the last step we used inequalities [formula] and [formula].

It remains to prove the second bound of ([\ref=lija]). We apply the union bound where satisfy rs = rt and estimate

[formula]

Acknowledgement. Research was supported in part by the Research Council of Lithuania grant MIP-067/2013.