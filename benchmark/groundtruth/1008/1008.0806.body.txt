Overlapping Optimized Schwarz Methods for Parabolic Equations in n-Dimensions

Introduction

In the pioneer work [\cite=Lions:1987:OSA], [\cite=Lions:1989:OSA], [\cite=Lions:1990:OSA], P. L. Lions laid the foundations of the modern theory of Schwarz Methods. With the development of parallel computers, the interest in Schwarz Methods have grown rapidly, as these methods lead to inherently parallel algorithms. However, with Classical Schwarz Methods, high frequency components converge very fast, while low frequency components converge slowly and that slows down the performance of the methods. By replacing Dirichlet Transmission Condition in Classical Schwarz Methods by Robin or higher order Transmission Conditions, we can correct this weekness of Schwarz Method. The new methods are called Optimized Schwarz Methods and have been introduced in [\cite=GanderHalpernNataf:1998:OCO], [\cite=GanderHalpernNataf:1999:OSM]. Since then, the convergence properties of the Optimized Schwarz Methods have been studied deeply, based on the following two main tools: Energy Estimates and Laplace and Fourier Transforms. Energy Estimates allow us to study the convergence of the methods in the case of nonoverlapping subdomains. With Energy Estimates, both linear and nonlinear problems have been studied and Optimized Schwarz Methods have been proven to converge, while applying to these equations (see for example, the papers [\cite=BenamouDespres:1997:DDM], [\cite=halpern:2009:DGN], [\cite=HalpernSzeftel:2009:NNS]). On the other hand, Laplace and Fourier Transforms allow us to study the convergence of the Overlapping Optimized Schwarz Methods, but for only a few simple equations (see, for example [\cite=Bennequin:09:AHB], [\cite=Gander:2007:OSW], [\cite=GanderHalpernNataf:1998:OCO], [\cite=GanderHalpernNataf:1999:OSM]), and the convergence problem of the Domain Decomposition Methods with Robin Transmission Conditions still remains an open problem up to now. In this paper, we introduce a new tool to prove the convergence of the Optimized Schwarz Methods for multisubdomains and apply it into an n-dimensional linear parabolic equation of the following form

[formula]

The idea of the technique is to estimate carefully the difference between the values of the errors at the boundaries of the overlapping strips. The technique has the potential to be applied to many other kinds of Partial Differential Equations including nonlinear ones.

Problem Description and Main Results

We consider the following parabolic equation

[formula]

where Ω = D  ×  (α,β), D is a bounded and smooth enough domain in [formula]. We impose the following conditions on the coefficients of () (A1) For all i,j in [formula], ai,j(t) = aj,i(t). There exists ν0 > 0 such that A(t) = (ai,j(t))  ≥  ν0I for all t belongs to (0,T) in the sense of symmetric positive definite matrices. (A2) The functions ai,j, bi, c are bounded in [formula]; f and g are bounded functions in [formula]. With the conditions (A1) and (A2), Equation () has a unique bounded solution u in C∞((0,T)  ×  Ω). The proof of this result can be infered from Theorems 9 and 10, page 71 [\cite=Friedman:1964:PDE]. We now divide the domain Ω into I subdomains, with Ωi = D  ×  (ai,bi) and [formula]. The Optimized Schwarz Waveform Relaxation Algorithm solves I equations in I subdomains instead of solving directly the main problem (). The iterate #  k in the l-th domain, denoted by ukl, is defined by

[formula]

here, p is a constant and for each vector x in [formula], we denote x = (X,xn), with [formula] and [formula]. Each iterate inherits the boundary conditions and the initial values of u:

[formula]

and a special treatment for the extreme subdomains,

[formula]

A bounded initial guess h0 in [formula] is provided, i.e. we solve at step 0 Equations (), with boundary data on left and right

[formula]

By using an induction argument and the same arguments as in Theorem 2, page 144 [\cite=Friedman:1964:PDE], we can see that each subproblem () in each iteration has a unique solution. Theorem 10, page 71 [\cite=Friedman:1964:PDE] shows that these solutions belong to C∞(Ω  ×  (0,T)). This means that the algorithm is well-posed. Denote by ekl the difference between ukl and u, and substract Equation () with the main equation (), we get the following equation on ekl

[formula]

Similarly, each iterate inherits the boundary conditions and the initial values of u

[formula]

and the special treatment for the extreme subdomains,

[formula]

The following theorem states that the algorithm converges.

Let φ be a strictly positive function in [formula] such that

[formula]

is large enough, the Optimized Schwarz Waveform Relaxation Method converges in the following sense

[formula]

Moreover, for l in [formula], the sequence {ukl - u} converges pointwisely to 0 as k tends to infinity.

We can see that if we choose φ(xn) =  exp ( - γxn), then if γ is large enough, [formula] [formula] is large enough. The condition of our theorem is then satisfied.

Since ai,j, bi are functions of t, and the domain is divided in to n-subdomains, we cannot use Fourier and Laplace Transforms. Moreover, since the subdomains are overlapping, the Energy Estimates Method cannot be used in our case. In the next section, we introduce a new technique to prove the convergence of the algorithm, the technique is based on the observation that we can estimate the difference between the values of ekl on the boundary and in the interior.

The result in the theorem remains true if we let ai,j, bi be bounded and continuous functions of t and x, but not depend on the n-th space variable xn, as we can see in the proof in the following section.

The Convergence of the Algorithm

This section is devoted to the proof of Theorem [formula]. We divide the proof into two steps. Step 1: The Error Estimates. For [formula] and [formula], setting εkl = ekl exp (pxn), we get ekl  =  εkl exp ( - pxn). Equation () then leads to

[formula]

and for the extreme subdomains,

[formula]

Setting

[formula]

we infer from Equation () that for l in [formula]

[formula]

We can observe that these systems are with Dicrichlet tramission conditions. On [formula], we define

[formula]

where φ is a strictly positive function in [formula] to be chosen later, with the notice that [formula] is large enough. Our purpose is to construct an operator [formula] of Φ, such that [formula] is negative and then on [formula], we can apply the maximum principle to get some estimates on the boundaries for Φ. With these estimates, we can direclty infer some good estimates for [formula] and that lead to our result on the convergence. We now consider the following operator

[formula]

A simple calculation gives

[formula]

Since the second term on the right hand side of the previous inequality is negative, it directly leads to

[formula]

Our purpose is to transfer the right hand side of () into the sum of a negative term and a term of Φ, in order to do that, we replace () into () and get the following bound for [formula]

[formula]

Replacing

[formula]

and

[formula]

into (), we get

[formula]

We now get the formula for [formula]

[formula]

then if we choose φ such that [formula] is large enough, since an,n, bn, c, [formula], [formula] are all bounded in [formula], we can obtain a negative sign on the right hand side of (), which means [formula] is negative. Since [formula], the maximum of Φ can only be attained on the boundary of Ωl  ×  (0,T). Since Φ = 0 on [formula] and on Ω  ×  {0}, we have the following three estimates. Estimate 1: 1  ≤  l  ≤  I. The maximum value(s) of Φ can be achived on both [formula] and [formula] and

[formula]

Estimate 2: l = 1. The maximum value(s) of Φ can be achived on both [formula] and [formula]. If the maximum of Φ is achived on [formula], then at the maximum point, we need that [formula] due to Hopf's Lemma. We compute

[formula]

Since

[formula]

we get

[formula]

Combining this equation and the fact that εkl(.,a1,.) = 0 on D  ×  (0,T), we can deduce

[formula]

and as a consequence, we can write [formula] in a different way

[formula]

With the functions φ satisfying

[formula]

we can see that

[formula]

which means that the maximum of Φ can be achived only on [formula], then

[formula]

Estimate 3: l = I. The maximum value(s) of Φ can be achived on both [formula] and [formula]. If the maximum of Φ is achived on [formula], then at the maximum point, we need that [formula] due to Hopf's Lemma. Similar as in Estimate 2, we can get

[formula]

With the functions φ satisfying

[formula]

we can see that

[formula]

which means the maximum of Φ can be achived only on [formula], then

[formula]

Step 2: Proof of convergence,

[formula]

In the proof of convergence, we will use the three estimates (), () and () by fixing the function φ(t) and replacing φ(xn) by appropriate functions [formula], φ̃i, [formula], φ̃* [formula] in each subdomain. Before coming to the details of the proof, we need a notation

[formula]

Step 2.1: Estimate of the right boudaries of the sub-domains. Consider the I-th domain, at the k-th step, () infers

[formula]

where [formula] is a strictly postive function and will be chosen later. Replace xn by bI - 1, we get

[formula]

Since νkI(X,bI - 1,t) = νk + 1I - 1(X,bI - 1,t),

[formula]

The inequality becomes

[formula]

We can choose [formula] such that [formula], and deduce

[formula]

Moreover, on the (I - 1)-th domain, at the (k + 1)-th step, () leads to

[formula]

where [formula] is a strictly postive function and will be chosen later. Since νk + 1I - 1(X,bI - 2,t) = νk + 2I - 2(X,bI - 2,t),

[formula]

Hence

[formula]

Combining this inequality with (), we get

[formula]

We choose [formula] such that

[formula]

which is equivalent to

[formula]

As a consequence,

[formula]

Using the same techniques as the ones we use to achive () and (), we can prove that

[formula]

where [formula] is a strictly positive function satisfying

[formula]

with [formula]. Now, with (), we can choose a strictly postive function [formula] such that [formula], then

[formula]

and as a result

[formula]

which implies

[formula]

Step 2.2: Estimate of the left boundaries of the sub-domains. Consider the 1-th domain, at the k-th step, () infers

[formula]

where φ̃1 is a strictly postive function and will be chosen later. Replacing xn by a2, we get

[formula]

Since νk1(X,a2,t) = νk + 12(X,a2,t), then

[formula]

We choose φ̃1 such that

[formula]

and deduce

[formula]

Moreover, on the 2-th domain, at the (k + 1)-th step, () leads to

[formula]

where φ̃2 is a strictly postive function and will be chosen later. Since νk + 12(X,a3,t) = νk + 23(X,a3,t), then

[formula]

Hence

[formula]

Combining this with (), we get

[formula]

We choose φ̃2 such that

[formula]

which is equivalent to

[formula]

We then obtain

[formula]

Using the same techniques as the ones that we use to achive () and (), we can prove that

[formula]

where φ̃j - 1 is a stricly positive function satisfying

[formula]

with j belongs to [formula]. Now, with (), we can choose a strictly positive function φ̃* such that φ̃*(b1) < φ̃*(a1), and get

[formula]

which is equivalent to

[formula]

That implies

[formula]

Step 2.3: Convergence result. From (), (), () and (), there exists γ in (0,1) such that

[formula]

and

[formula]

Using () for [formula], we have that

[formula]

Combining (), () and (), we get

[formula]

Hence, Ek tends to 0 as k tends to infinity. That gives

[formula]

Step 3: Proof of convergence: for l in [formula], the sequence {ekl} converges pointwisely to 0 as k tends to infinity. Since for l in [formula],

[formula]

then [formula] converges to 0 pointwisely and the sequence is bounded by a constant M0. Since φ is strictly positive on

[formula]

,

[formula]

converges to 0 as k tends to infinity. Hence the sequence

[formula]

converges to 0 as k tends to infinity. Since εk1(X,a1,t) = 0, then the sequence {εk1} converges to 0 pointwisely. For l = 2, with a fixed value of (X,t), again by the Lebesgue Dominated Convergence Theorem, for xn belongs to

[formula]

{(X,ζ,t)dζ}

[formula]

{ε(X,x,t)-ε(X,a,t)}

[formula]

(X,a,t)+pe(X,a,t)=(X,a,t)+pe(X,a,t),

[formula]