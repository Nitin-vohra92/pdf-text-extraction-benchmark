Minkowski sum of polytopes defined by their vertices

Introduction

Tolerance analysis is the branch of mechanical design dedicated to studying the impact of the manufacturing tolerances on the functional constraints of any mechanical system. Minkowski sums of polytopes are useful to model the cumulative stack-up of the pieces and thus, to check whether the final assembly respects such constraints or not, see [\cite=Homri2013] and [\cite=Srinivasan1993]. We are aware of the algorithms presented in [\cite=Fukuda20041261], [\cite=Fukuda2005_882], [\cite=Teissandier-hal-00635842] and [\cite=Delos-CMCGS] but we believe that neither the list of all edges nor facets are mandatory to perform the operation. So we only rely on the set of vertices to describe both polytope operands. In a first part we deal with a "natural way" to solve this problem based on the use of the convex hulls. Then we introduce an algorithm able to take advantage of the properties of the sums of polytopes to speed-up the process. We finally conclude with optimization hints and a geometric interpretation.

Basic properties

Minkowski sums

Given two sets A and B, let C be the Minkowski sum of A and B

[formula]

Polytopes

A polytope is defined as the convex hull of a finite set of points, called the V-representation, or as the bounded intersection of a finite set of half-spaces, called the H-representation. The Minkowski-Weyl theorem states that both definitions are equivalent.

Sum of V-polytopes

In this paper we deal with V-polytopes i.e. defined as the convex hull of a finite number of points. We note VA, VB and VC the list of vertices of the polytopes A, B and C = A + B. We call VC the list of Minkowski vertices. We note k  =  Card(VA) and l  =  Card(VB).

Uniqueness of the Minkowski vertices decomposition

Let A and B be two [formula]-polytopes and VA, VB their respective lists of vertices. Let C  =  A  +  B and c  =  a + b where a∈VA and b∈VB.

[formula]

We recall that in [\cite=Fukuda20041261], we see that the vertex c of C, as a face, can be written as the Minkowski sum of a face from A and a face from B. For obvious reasons of dimension, c is necessarily the sum of a vertex of A and a vertex of B. Moreover, in the same article, Fukuda shows that its decomposition is unique.

Reciprocally let a∈VA and b∈VB be vertices from polytopes A and B such that c  =  a + b is unique. Let c1∈C and c2∈C such as [formula] with [formula] and [formula] because the decomposition of c in elements from A and B is unique. Given that a and b are two vertices, we have a1  =  a2 and b1  =  b2 which implies c1  =  c2. As a consequence c is a vertex of C.

Summing two lists of vertices

Let A and B be two [formula]-polytopes and VA, VB their lists of vertices, let C  =  A  +  B.

[formula]

We know that VC  ⊂  VA  +  VB because a Minkowski vertex has to be the sum of vertices from A and B so C  =  Conv(VC)  ⊂  Conv({a + b,a∈VA,b∈VB}).

The reciprocal is obvious as Conv({a + b,a∈VA,b∈VB})  ⊂  Conv({a + b,a∈A,b∈B})  =  C as C  =  A + B is a convex set.

At this step an algorithm removing all points which are not vertices of C from VA  +  VB could be applied to compute VC. The basic idea is the following: if we can build a hyperplane separating (au + bv) from the other points of VA  +  VB then we have a Minkowski vertex, otherwise (au + bv) is not an extreme point of the polytope C. The process trying to split the cloud of points is illustrated in Figure [\ref=vsum].

To perform such a task, a popular technique given in [\cite=Fukuda2004_faq] solves the following linear programming system. In the case of summing polytopes, testing whether the point (au + bv) is a Minkowski vertex or not, means finding [formula] from a system of k  ×  l inequalities:

So if we define the matrix [formula]

then [formula]

The corresponding method is detailed in Algorithm [\ref=algbrut]. Now we would like to find a way to reduce the size of the main matrix Γ as it is function of the product k  ×  l.

Constructing the new algorithm

In this section we want to use the basic property [\ref=basicprop] characterizing a Minkowski vertex. Then the algorithm computes, as done before, all sums of pairs (au,bv)∈VA  ×  VB and checks whether there exists a pair (a',b')  ≠  (au,bv) with a'∈A, b'∈B such as (a' + b')  =  (au + bv). If it is the case then (au + bv)∉VC, otherwise (au + bv)∈VC.

[formula] with [formula] and [formula]

[formula] with [formula] and [formula].

We get the following system:

[formula]

That is to say with matrices and under the hypothesis of positivity for both vectors α and β:

[formula]

We are not in the case of the linear feasibility problem as there is at least one obvious solution:

[formula]

The question is to know whether it is unique or not. This first solution is a vertex pu,v of a polyhedron in [formula] that verifies (n + 2) equality constraints with positive coefficients. The algorithm tries to build another solution making use of linear programming techniques. We can note that the polyhedron is in fact a polytope because it is bounded. The reason is that, by hypothesis, the set in [formula] of convex combinations of the vertices ai is bounded as it defines the polytope A. Same thing for B in [formula]. So in [formula] the set of points verifying both constraints simultaneously is bounded too.

So we can write it in a more general form:

[formula]

where only the second member is function of u and v.

It gives the linear programming system:

[formula]

Thanks to this system we have now the basic property the algorithm relies on:

[formula]

f* = 0  ⇔   there exists only one pair (αu,βv)  =  (1,1) to reach the maximum f* as [formula] and [formula] ⇔   the decomposition of c  =  (au  +  bv) is unique   ⇔  c∈VC

It is also interesting to note that when the maximum f* has been reached:

αu  =  1  ⇔  βv  =  1  ⇔  f* = 0

Optimizing the new algorithm and geometric interpretation

The current state of the art runs k  ×  l linear programming algorithms and thus is solvable in polynomial time. We presented the data such that the matrix P is invariant and the parametrization is stored in both the second member and the objective function, so one can take advantage of this structure to save computation time. A straight idea could be using the classical sensitivity analysis techniques to test whether (au  +  bv) is a Minkowski vertex or not from the previous steps, instead of restarting the computations from scratch at each iteration.

Let's switch now to the geometric interpretation, given a∈VA, let's consider the cone generated by all the edges attached to a and pointing towards its neighbour vertices. After translating its apex to the origin O, we call this cone CO(a) and we call CO(b) the cone created by the same technique with the vertex b in the polytope B.

The method tries to build a pair, if it exists, (a',b') with a'∈A, b'∈B such that (a + b)  =  (a' + b'). Let's introduce the variable δ  =  a' - a = b - b', and the straight line [formula].

So the question about (a + b) being or not a Minkowski vertex can be presented this way:

[formula]

The existence of a straight line inside the reunion of the cones is equivalent to the existence of a pair (a',b') such that (a + b)  =  (a' + b') which is equivalent to the fact that (a' + b') is not a Minkowski vertex. This is illustrated in Figure [\ref=vsum2]. The property becomes obvious when we understand that if (a',b') exists in A  ×  B then (a' - a) and (b' - b) are symmetric with respect to the origin. Once a straight line has been found inside the reunion of two cones, we can test this inclusion with the same straight line for another pair of cones, here is the geometric interpretation of an improved version of the algorithm making use of what has been computed in the previous steps.

We can resume the property writing it as an intersection introducing the cone - CO(b) being the symmetric of CO(b) with respect to the origin.

[formula]

Conclusion

In this paper, our algorithm goes beyond the scope of simply finding the vertices of a cloud of points. That's why we have characterized the Minkowski vertices. However, among all the properties, some of them are not easily exploitable in an algorithm. In all the cases we have worked directly in the polytopes A and B, i.e. in the primal spaces and only with the polytopes V-descriptions. Other approaches use dual objects such as normal fans and dual cones. References can be found in [\cite=Teissandier-hal-00635842], [\cite=Delos-CMCGS] and [\cite=Weibel3883] but they need more than the V-description for the polytopes they handle. This can be problematic as obtaining the double description can turn out to be impossible in high dimensions, see [\cite=Fukuda20041261] where Fukuda uses both vertices and edges. Reference [\cite=Teissandier-hal-00635842] works in [formula] in a dual space where it intersects dual cones attached to the vertices, and it can be considered as the dual version of property [\ref=primcone] where the intersection is computed with primal cones. It actually implements Weibel's approach described in [\cite=Weibel3883]. Such a method has been recently extended to any dimension for HV-polytopes in [\cite=Delos-CMCGS].

Special thanks

We would like to thank Pr Pierre Calka from the LMRS in Rouen University for his precious help in writing this article.