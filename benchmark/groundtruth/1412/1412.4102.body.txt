Representing Data by a Mixture of Activated Simplices

Introduction

The curse of dimensionality motivates machine learning researchers to search for low-dimensional structures in high-dimensional data. These low-dimensional structures help us understand the data, and they enable us to build data models that avoid over-fitting.

There are several strategies for finding low-dimensional structures. One approach is to project the data into a single low-dimensional linear or non-linear manifold [\cite=tenenbaum2000global] [\cite=Saul:2003us] [\cite=Ham:2004ut] [\cite=Belkin:2003va] [\cite=Donoho:2003tu] while preserving properties of a local neighborhood graph. These methods are global, in that a single low dimensional structure is used in the representation of the data. One drawback of those methods is that it is difficult to represent some closed manifolds in familiar spaces (such as Euclidean spaces) of a useful low dimension. These closed manifolds are prevalent in computer vision, for example, in data from repeated human walking motion.

A second approach is to represent data using a combination of simple local structures in the original data space. k-means and its variants represent data by assigning data points to one of k clusters. These methods provide coarse piecewise constant approximations to high-dimensional structures. More recently, k-flats [\cite=Canas:2012vf] [\cite=Bradley:2000cm], Atlas learning [\cite=Pitelis:2013ik], and Sparse Subspace Clustering [\cite=Elhamifar:2013uz] represent data using a vocabulary of hyperplanes. These methods work very well when the data come from a union of hyperplanes, but are limited when data are from a curved manifold. Since the hyperplanes are unbounded, they don't provide for strict constraints, such as might be appropriate for range of motion restrictions in human pose data.

In this paper we represent data using an arrangement of simplices. Simplices are points, line segments, triangles, tetrahedra, and other higher dimensional analogs of the triangle; see Figure [\ref=fig:simplex]. The simplices act as local models of the data manifold. In general, learning a model which represents data using a mixture of simplices is quite difficult. However, we show in Section [\ref=sec:activated_simplices] that, under some reasonable assumptions, the optimal simplices have a convenient geometry, which makes learning dramatically easier.

We assume that the data are normalized to have norm one and hence lie on a unit sphere, and we build the simplices using bases that have norm at most one. With these restrictions, learning the best simplices amounts to finding boundary facets on the convex hull of the bases that are close to the data. We call the boundary facets activated in this way activated simplices. Once a collection of activated simplices is learned they are pruned to prevent over-fitting.

The Activated Simplices representation has several advantages: (i) Each simplex provides a tight approximation of a local region of the data manifold. (ii) Curved and closed manifolds can be represented using an arrangement of simplices. (iii) The simplices can have different dimensions allowing the representation of an inhomogeneous data source; see Figure [\ref=fig:ribbonCircle]. While the total number of bases is a parameter of the model, the number and dimensions of the individual simplices are learned. (iv) The representation is bounded. This reduces the risk of generating data which violate constraints in certain applications. See Figure [\ref=fig:teasing]. (v) Generative models can be constructed on the simplices using Dirichlet distributions which can be used to synthesize realistic data. (vi) The model is interpretable: points on the simplices are convex combinations of the vertices, and extremes among the data can be found among the vertices. See Figure [\ref=fig:face_illumination] and [\ref=fig:pose_basis].

The requirement that data lie on the unit sphere may seem restrictive, however many data sources are normalized in that way, and we present some alternatives to the standard normalization in the Appendix.

The paper is organized as follows. Section [\ref=sec:related_work] reviews related work. Sections [\ref=sec:activated_simplices] and [\ref=sec:pruning_activated_simplices] describe the activated simplices learning and pruning methods, and Section [\ref=sec:optimization] discusses optimization strategies. The remainder of the paper is devoted to experiments on digits and poses, followed by a brief conclusion. In the Appendix, we discuss some projections onto the sphere which are useful as alternatives to the usual normalization, we present several low dimensional examples, we discuss the geometry of the standard sparse coding model, and we discuss our method in the context of methods for triangulating manifolds.

Related Work

Our method represents data as a mixture of activated simplices. So it is natural to make comparisons with methods which represent data using a mixture of simple structures, such as k-means, k-flats [\cite=Canas:2012vf] and its generalizations and improvements including Sparse Subspace Clustering [\cite=Elhamifar:2013uz] and Atlas learning [\cite=Pitelis:2013ik]. Since our method builds on a convex hull, it is also natural to compare with Archetypal Analysis [\cite=cutler1994archetypal] [\cite=chen2014fast] which models the data globally as a convex hull and learns convex extremes.

k-means is a clustering algorithm where the data in each Voronoi region is represented by its mean. k-flats extends k-means by using a vocabulary of hyperplanes, usually of the same dimension. The number of hyperplanes and their dimensions are parameters of the model. k-flats is limited in its ability to model curved manifolds, as it must use many hyperplanes for accurate reconstruction.

Sparse Subspace Clustering[\cite=Elhamifar:2013uz] analyses the self expression (i.e., sparse linear interrelations) of the data and groups them according to hyperplanes. Atlas [\cite=Pitelis:2013ik] learns hyperplane charts by fitting hyperplanes, with the restriction that an entire local neighbourhood of each point can be represented by the same hyperplane. This improves the assignment of points to hyperplanes at points of ambiguity. These methods give good performance when the data source resembles a small collection of hyperplanes. But they are limited when modelling data from a curved manifold, and the structures learned are not naturally bounded.

Our simplicial model is more flexible in its vocabulary, since it assembles an arrangement of simplices to fit the data. It can manage curved manifolds and inhomogeneous sources (see Figure [\ref=fig:ribbonCircle] and the Appendix for some pictures). It naturally accommodates constraints such as anatomical constraints, and allows for generative models by fitting a Dirichlet density to each simplex. It allows classification by nearest neighbour classification on the simplices. It will be preferable to hyperplane methods when the data is not close to a union of hyperplanes.

Archetypal Analysis [\cite=cutler1994archetypal] [\cite=chen2014fast] learns a global convex model for the data. It naturally discovers convex extremes. However when the data manifold is not a convex set, it ignores the details in the interior. The Activated Simplices method constructs local convex structures to describe the data. While it does construct a convex hull to approximate the data on the sphere, it is the boundary simplices of this hull, not the convex hull itself that are important.

A Mixture of Simplices Model

In our method we represent data using a mixture of simplices. Simplices are points, line segments, triangles, tetrahedra, and other higher dimensional analogs of the triangle; see Figure [\ref=fig:simplex]. A point on a k-dimensional simplex with vertices [formula] is a convex combination [formula], where αi  ≥  0 and [formula]. A simplicial model built using p bases [formula] is a family of simplices [formula] each of whose vertices is a subset of the bases [formula]. Learning a simplicial model from data needs to solve the complex problem of learning the bases [formula], learning the simplices [formula], learning the assignment of each data point to a simplex, that is, picking a simplex for each data point, and learning the projection of each data point on its chosen simplex. For training data [formula] this is the following minimization:

[formula]

where V is a binary indicator variable assigning each point to exactly one simplex in the family, each α(j)t is a convex coefficient vector that attempts to express data point y(j) in terms of the [formula] simplex Δt.

We now assume that the data are normalized to have [formula] norm 1 and hence lie on a unit sphere, and that the bases have l2 norm at most 1, so that they are comparable to the data. This simplifies the assignment problem dramatically, since the data now lie on the surface of a sphere, and the simplices Δi are convex combinations of bases within the sphere. It simplifies the problem of identifying optimal simplices, since the convex combinations of the bases that are closest to the data are on boundary facets of the convex hull of the bases. The optimal construction of F from the bases X is the set of boundary facets activated in this way by the data. Since facets of a convex hull in general positions are simplices, we call these facets activated simplices. The optimal coefficients α(j)t are those from the projection of the data point y(j) onto the boundary of the convex hull.

We've observed that the best projection of y(j) onto the optimal simplices is the projection of y(j) onto the convex hull of the bases. This means that in the optimization

[formula]

subject to the constraints β(j)  ≥  0, [formula], which expresses y(j) as a convex combination of all the bases, the non-zero entries in the coefficient vector β(j) identify the boundary simplex on which y(j) is projected. Thus we can learn a mixture of simplices model by the following minimization

[formula]

subject to β(j)  ≥  0, [formula], for [formula], and [formula] for [formula].

We then derive the activated simplices by studying the activations β(j).

The Activated Simplices Model

To summarize the observations above, we develop a mixture of simplices model for data [formula] which is assumed to be unit normalized. The simplices are learned from co-activated bases in the optimization ([\ref=eq:newformulation]). The optimization ([\ref=eq:newformulation]) can be understood as learning a convex hull CX of the bases X, such that its boundary facets are close to the training data. We call the boundary facets that are closest to the data activated simplices -- these can be determined from activations of the coefficients β(j).

The collection of simplices that are learned from ([\ref=eq:newformulation]) can be pruned to obtain a more efficient representation. This is discussed in Section [\ref=sec:pruning_activated_simplices].

Activated Simplices are Low Dimensional

We find in experiments that the activated simplices have low dimension. However the boundary facets for a generic convex body in d-dimensional space are d dimensional simplices. Our method learns facets (that is, sub-simplices of boundary simplices) that have dimension much less than d. We now give an explanation for this phenomenon.

Suppose that the data Y are from a low dimensional manifold embedded in Rd. Recall that in the minimization ([\ref=eq:newformulation]), a basis X is learned so that boundary facets of the convex hull CX are close to the data. The learning process constructs X so that this representation is as efficient as possible.

The interaction of the curved geometry of the sphere with the linear geometry of the boundary facets of CX, means that it is most efficient to position low dimensional facets close to the data. Figure [\ref=fig:low_dimensional_motivation] shows a segment (a 1-simplex) with its vertices in the circle, and it shows a triangle (a 2-simplex) with its vertices in the 2-sphere. Notice that the interior of the segment is further from the sphere than its endpoints, similarly the interior of the triangle is further from the sphere than its boundary segments. In general, it is more efficient to approximate points on the sphere locally with low dimensional facets, than with high dimensional facets. Hence the optimization ([\ref=eq:newformulation]) learns a structure that approximates the data with low dimensional facets of CX.

Of course if the data is distributed uniformly over the sphere, it will be impossible to position low dimensional facets close to the data points, without a vast number of bases. But we see in our experiments, with what are understood to be low dimensional data sources, that the activated simplices are low dimensional. This makes sense as it provides a most efficient representation of the data.

Relation to Sparse Coding, and a Penalized Version of Activated Simplices

The coefficients vectors β(j) learned in ([\ref=eq:newformulation]) are sparse, that is, most entries are zero, and the non-zero entries identify a low dimensional boundary facet of the convex hull of the bases X. Some readers will be reminded of sparse coding. Indeed it is possible to understand sparse coding using similar ideas -- we discuss this in the Appendix.

In the usual formulation of sparse coding [\cite=tibshirani1996regression] [\cite=Osborne:2000ha] [\cite=Bradley:2004tz] [\cite=Huggins] data Y are represented by bases X through the following [formula] penalized optimization:

[formula]

The bases xi are constrained to have [formula] norm at most 1. Notice there is no constraint here that the coefficients β(j) are positive. The method learns sparse representations of the data as combinations of the bases and negative bases.

The bases learned in sparse coding can be used as a regularizer for pose data, in a similar spirit to our experiments. See [\cite=Wang:2014kv]. However the usual prior associated with a sparse coding representation, is that any combination Xβ can occur, provided that [formula] is small. This allows co-activations of the bases that don't occur in the training data. Figure [\ref=fig:teasing_2] shows a regularizing structure that might be learned in this way. Compare with Figure [\ref=fig:teasing], to see that the Activated Simplices method learns a more realistic representation.

It is interesting to experiment with a penalized version of the Activated Simplex method. A formulation with positive penalty parameter r  ≤  1 is

[formula]

subject to β(j)  ≥  0, [formula], for [formula], and [formula] for [formula].

This will force representations on lower dimensional facets when r < 1. We've experimented with this penalized version and found that the unpenalized version works well with the data we considered. But we can imagine that the additional sparsity provided in ([\ref=eq:spenalizedactivatedsimplices]) might be useful in managing some high dimensional data.

Pruning The Activated Simplices

Each training point y(j) proposes (activates) a simplex Δ. Gathering the activated simplices, we obtain a set of simplex proposals [formula]. The number of proposed simplices will typically be much less than the number of training data, since several data points will activate the same simplex.

To prevent over-fitting, we propose a principled way to prune the simplices F to a proper subset F* without degrading the reconstruction results much. For example, F might contain a high dimensional simplex Δ that received few activations, but its low dimensional sub-simplices might have received many activations. We may obtain a better model if we remove this large simplex from the model.

We prune so as to obtain a small number of simplices and so that the remaining simplices have low dimensions. We use the following to balance the goals of few and low dimensional with the goal of good reconstruction:

[formula]

where L(Y,) represents the reconstruction error using the set [formula] of simplices to approximate the data, and #  () is the number of simplices in the set [formula], and dim (i) is the dimension of the [formula] simplex in the set [formula]. The two penalty terms λ1  #  () and [formula] encourage fewer simplices and encourage lower dimensions. We set λ1 and λ2 to be 0.001 / T and 0.01 / T, respectively, for our experiments. In general, these can be set by cross-validation. Figure [\ref=eq:prune] shows the influence of pruning.

Optimization

The formulation ([\ref=eq:newformulation]) is non-convex, but it is convex with respect to each of the variables, X and β, when the other is fixed. Optimizing the two convex sub-problems alternately leads to a local minimum, but using classic convex optimization methods may be slow when the number of training data is large. Inspired by [\cite=Mairal:2009um], we solve the problem in an online way, based on stochastic gradient descent. This scales up gracefully to large dataset. When we fix β and optimize the bases X, we obtain the same dictionary update problem as in [\cite=Mairal:2009um]. So we refer the readers to [\cite=Mairal:2009um] for more information. When we fix X and update β, we obtain a least-squares problem with a simplex constraint. We use an active-set algorithm [\cite=wright1999numerical] to benefit from the sparsity of β.

The problem ([\ref=eq:prune]) is difficult to optimize directly because of the large search space. Hence we use a greedy approach which successively adds simplices to [formula] which most reduce the objective ([\ref=eq:prune]). We terminate the process when the objective stops decreasing. On a regular Desktop equipped with 3.4GHz CPU, the overall simplices learning time is about 0.19 seconds for a digit dataset containing 800 training data of dimension 256. Projecting data on the simplices is fast.

Data Reconstruction

In this section we evaluate the reconstruction errors by computing the Euclidean distance between data and their projections on the nearest simplices. We evaluate the influence of the model parameters p, i.e., the number of bases. We also show some results when the convex hull radius r is smaller than one.

We conduct experiments on a large human pose dataset H3.6M [\cite=ionescu2013human3] which contains 3.6 million poses. We select 11,000 poses of 11 actions including "walking", "taking photo", "smoking", "sitting down", "sitting", "purchases", "posing", "phoning", "greating", "eating" and "discussion".

We first evaluate on the training data-- we train and test on the same 11,000 poses. We learn a single set of simplices for the eleven actions together. Figure [\ref=fig:pose_reconstruction_quan] (left) shows the average reconstruction errors for each choice of p and r. The smallest average reconstruction error is about 0.0423 (achieved when r = 1 and p = 500) which indicates that the activated simplices can represent the training data well. The reconstruction errors decrease fast as radius r increases. The reconstruction errors also decrease as the number of bases p increases but in a more stable manner.

In the second scenario, we split the 11,000 poses into training and testing subsets each containing 5,500 poses of the 11 actions. We learn the activated simplices from the training data and test on the testing data. Figure [\ref=fig:pose_reconstruction_quan] (right) shows the results. We can see that the reconstruction error is similar to that of the first experiment. The smallest reconstruction error is about 0.05 (achieved when r = 1 and p = 500). The results justify that the activated simplices model can reconstruct the data well. Figure [\ref=fig:pose_reconstruction_qual] shows three sample reconstruction results whose reconstruction errors are 0.06, 0.1 and 0.2, respectively.

Nearest Neighbour Classification

We conduct digit classification on the Semeion handwritten digit dataset [\cite=semeion_dataset] and action classification on a more challenging MSR-Action3D dataset [\cite=li2010action]. We use simple nearest neighbour classifiers on the simplicial model and achieve the state-of-the-art performance on both tasks.

Handwritten Digit Classification

The Semeion dataset [\cite=semeion_dataset] contains 1593 grey scale images of handwritten digits ([formula]) generated from about 80 people who each wrote all ten digits twice. The images are of size 16  ×  16 and each pixel in the image is converted into a boolean value using a fixed threshold. We randomly select 796 images for training and 797 images for testing following [\cite=Pitelis:2013wg]. The process is repeated for 100 times and the average result is reported. We compare with the standard manifold learning methods such as LTSA [\cite=Zhang:2004ht], Atlas [\cite=Pitelis:2013ik], Archetypes [\cite=chen2014fast] and the usual sparse coding.

In the training stage, for our method, we learn a set of activated simplices for each of the ten classes using the same parameters. In the testing stage, for each data, we project it to the ten classes of simplices independently and obtain the class having the smallest reconstruction error. We set the number of bases p to be ten for each class (100 in total). We finally obtain 100 simplices whose dimensions are from four to eight. For sparse coding and Archetypes methods, we learn a set of bases for each of the ten classes and project test data to the ten sets of bases independently and obtain the class which has the smallest error.

Table [\ref=table:digit] shows the recognition results. We outperform all of the methods. Our approach automatically determines the simplex dimensions which vary from simplex to simplex. For other methods, different choices of dimensions have been tried and the one that achieves the best performance is reported. The number of bases is 100 for sparse coding and archetype for fair comparison. Figure [\ref=fig:influence] shows the influence of the number of bases and the radius of the convex hull on the classification results.

Action Recognition

MSR-Action3D dataset [\cite=li2010action] provides 557 human pose sequences of ten subjects performing 20 actions which are recorded with a depth sensor. There are about 50 frames in each sequence. This is a challenging dataset because many of the actions are highly similar to each other. We use the cross-subject evaluation scheme as in [\cite=li2010action].

To make the poses more discriminative between similar classes, for each pose in the sequence, we stack it with its consecutive ten poses as a high dimensional pose snippet. Weak temporal coherence can be achieved by this simple stacking operation. The activated simplices are learned based on snippets rather than a single pose.

In the training stage, for each of the 20 classes, we learn an independent set of activated simplices using the same parameters. In the testing stage, for each sequence, we project the 3D snippets onto the 20 sets of activated simplices and select the class which has the smallest reconstruction error. We set the number of bases for each class to be 25 (500 in total) by cross-validation.

Table [\ref=table:msr_action3d] shows the results. Our method outperforms [\cite=li2010action] and sparse coding, and achieves comparable performance as [\cite=wang2012mining] and [\cite=Wang:2013kv]. However, actionlet ensemble uses sophisticated feature learning methods and multiple kernel learning classifiers. Spatial-temporal-part model uses data mining techniques to remove the noisy joints and then use support vector machine for classification. In contrast, our method is the simplest in terms of both features and classifiers.

We have an interesting observation from the experiment. For each test sequence, if we select the top K classes which have the smallest reconstruction errors and regard the classification is correct when any of the K predictions is correct, then we can considerably improve the performance. For example, when K = 2, the accuracy increases to 95.54%; when K = 5, the accuracy increases to 97.03%; when K = 8, the accuracy is 100%.

3D Human Pose Estimation

In this section, we apply the simplicial model to the task of 3D human pose estimation from 2D poses. This allows us to compare our method with the more standard application of sparse coding [\cite=Wang:2014kv].

The 3D and 2D poses are represented by n joint locations P∈R3  ×  n and O∈R2  ×  n, respectively. We conduct experiments on the H3.6M Human motion capture dataset [\cite=ionescu2013human3] which provides ground truth 3D human joint locations of 11 actions. To evaluate the generalization ability of the method, we select the poses from the first five actions for training and the remaining six actions for testing.

We obtain the 2D joint locations by projecting the 3D pose into 2D using synthetic weak perspective camera parameters M, i.e., O = M  ·  P, where [formula]. We assume the joint locations are mean-centered hence eliminate the translation component for simplicity. We now have 3D joint locations P which we use as ground truth, and we have the corresponding 2D joint locations O -- our goal is to reconstruct P from O with the help of the activated simplices.

We represent the 3D poses by activated simplices. We first learn a set of activated simplices [formula] from the training 3D poses. Then for a 2D pose O, we optimize for the simplex [formula] and the simplex coefficients β* by minimizing the following:

[formula]

This minimization can be done naively since the number of simplices is small. Then we reconstruct its 3D pose P by P̂  =  S*β*. The reconstruction error is the average Euclidean distance between each joint of P and P̂.

We compare our method with the classical sparse coding [\cite=Mairal:2009um] and archetypal analysis [\cite=cutler1994archetypal] methods. For these two methods, we first learn a set of bases or archetypes X on the training data and then for each test data, we optimize the basis coefficients β* by minimizing the error between the 3D pose projection and the 2D pose:

[formula]

For Archetypal method we constrain β is non-negative and sum to one. The estimated 3D pose is P̂ = Xβ*.

Figure [\ref=fig:pose_estimation] (left) shows the human pose estimation results. Our method achieves better performance than the other two alternatives. There could be two reasons accounting for this: (1) compared with sparse coding, the activated simplices constrain the combinations of bases to combinations that occur in reality, whereas the restrictions in sparse coding methods are looser. Figure [\ref=fig:pose_estimation] (right) shows that the estimated limb lengths of our method are close to the ground-truth while those of the sparse coding and archetypes are considerably different from the ground-truth. The experimental results show that the sparse representation cannot implicitly enforce the limb length constraint; (2) compared with archetypal analysis method, the activated simplices explore the local structures including the interior of the manifold which makes the method more accurate. In contrast, archetype can only learn the convex hull of the manifold and fail to explore the interior.

3D Human Pose Synthesis

Our method also allows to synthesize realistic data. For each simplex Si, we learn a Dirichlet distribution [\cite=minka2000estimating] from the coefficients [formula] of the m data that are projected to the simplex. To generate a data, we first sample a simplex and then sample the coefficients β from the Dirichlet distribution of that simplex. We output the corresponding combination of bases as the synthesized data.

Dirichlet distribution is often used as prior distributions in Bayesian statistics. The probability density function is defined as: [formula], where β  >  0 and [formula]. B(α) is a normalization factor. We learn the parameters α by Maximum Likelihood Estimation.

We conduct experiments on the H3.6M human pose dataset. We select 55,000 poses from 11 actions and learn a single set of simplices. We set the number of bases to be 100. The algorithm ends up with 83 simplicies. We learn Dirichlet distributions on each simplex. We display some typical synthesized poses in Figure [\ref=fig:synthesis]. We can see that they are divergent and realistic. In addition, Figure [\ref=fig:synthesize_boundary] shows that the synthesized poses also respect well the limb length and bending angle constraints.

Conclusion

We propose a method for representing data using a mixture of activated simplices. The Activated Simplices representation allows accurate reconstruction by preventing combinations of bases that do not occur in the data.

Acknowledgement: The project is supported by US Army Research Office ARO Proposal 62250-CS and NSF STC award CCF-1231216 and Center for Minds, Brains and Machines (CBMM)

Introduction

In the appendix we provide more details on the following:

The relationship between Activated Simplices and traditional sparse coding.

Alternatives to standard normalization for projection onto the sphere.

Triangulating Manifolds.

Extremes in data and a comparison with Archetypal Analysis.

Activated Simplices and Sparse Coding

In Section 3 of the Main Paper we discussed how a mixture of simplices model can be learned by constructing a convex hull inside the sphere whose boundary facets are close to the data. This will remind readers of traditional sparse coding [\cite=olshausen1996emergence], since the projections of the training data on this hull are sparse, i.e., they involve relatively few of the bases. We now explore this connection in more detail.

Our model requires normalized data [formula] and it constructs a convex hull of p bases [formula] such that boundary facets are close to the data. It constructs this hull by the following minimization

[formula]

subject to β(j)  ≥  0, [formula], for [formula], and [formula] for [formula]. The activated simplices correspond to co-activated bases.

Figure [\ref=fig:simple_data_on_sphere] shows a very simple situation where a convex hull is constructed from data on the circle using 6 bases. The activated simplices are the three boundary segments closest to the data.

In the usual formulation of sparse coding, a dictionary of p bases [formula] is constructed to represent data [formula]. The dictionary is constructed by the following minimization

[formula]

subject to [formula] for [formula]. Here, λ is a non-negative penalty parameter.

Notice some differences between ([\ref=eq:newformulation]) and ([\ref=eq:standardsparsecoding]). In ([\ref=eq:newformulation]) the coefficients β(j) are required to be non-negative, but there is no such constraint in ([\ref=eq:standardsparsecoding]). In ([\ref=eq:newformulation]) the coefficients β(j) are constrained to have [formula] norm 1, whereas in ([\ref=eq:standardsparsecoding]) the [formula] norms of the coefficients are penalized through the λ||β(j)||1 term. But both formulations have a similar quadratic data reconstruction term ||y(j) - Xβ(j)||22.

It is possible to interpret this sparse coding in geometrical terms [\cite=Donoho:2005we] [\cite=Huggins], and it is likely that this geometrical understanding was behind Tibshorani's original formulation of the lasso [\cite=tibshirani1996regression].

To begin, we describe the geometry of a single penalized regression. In this situation the bases X are known, and we are interested in the coefficients β for a single data point y. This corresponds to the minimization [\cite=tibshirani1996regression] [\cite=Osborne:2000ha]

[formula]

In this regression the penalty parameter λ and the data point y control the [formula] norm of the coefficients, that is, they determines a radius r  =  r(y,λ) such that the coefficients β solve

[formula]

subject to [formula]. As the penalty parameter λ increases, the radius r decreases.

We can interpret this minimization in terms of convex geometry. The set of Xβ such that [formula] is the convex hull of the bases [formula] and the negative bases [formula], scaled by a factor of r. Figure [\ref=fig:basesnegbases] shows bases, and negative bases, and their convex hull, scaled by r.

For the regression of a single point, the penalty λ determines a convex hull of radius r, and then the regression coefficients β correspond to the closest point on the boundary of the scaled convex hull. See Equation [\ref=eq:penalizedregressionexpanded].

The geometry is more complicated when more than one point is regressed on X, as the radius r depends on the penalty λ and on the data point y. Figure [\ref=fig:variation_in_radius] shows that r varies with y. In this figure points on the circle are regressed on 3 bases with λ  =  0.15 and λ = 0.6. The blue curve shows how r(y) varies as y moves along the circle.

This gives us a geometrical understanding (albeit a somewhat complicated one) of the learning process in the usual formulation of sparse coding. The method positions the convex hull of the bases and negative bases, so that boundary facets of some scalings of this hull are close to the data. The complication here is that the scalings are not uniform, they depend on the y(j).

Our method ([\ref=eq:newformulation]) makes two major changes to the sparse coding formulation. First, the radius r is set uniformly to 1 for all data points y(j), thus we can think of the data as projecting on the same convex hull. Second, the coefficients β(j) are restricted to be non-negative, thus we consider the convex hull of the bases, rather than the hull of the bases and negative bases.

We might have learned co-activations from the original sparse coding formulation, but the modifications we've made improve performance as well as interpretability. The uniform radius requirement r = 1 encourages the fitting of low-dimensional facets to the data. This encouragement is weaker in the usual sparse coding. Figure [\ref=fig:projection_plot] shows the projection (blue curves) of the circle learned using the usual sparse coding with three bases and their negatives. Notice that the projections are no longer polygonal. This fitting of a bulging polytope lessens the incentive to fit low dimensional facets close to the data. The left panel in Figure [\ref=fig:projection_plot] uses λ  =  0.25 and the right panel used λ  =  0.6.

The second modification restricts the coefficients β(j) to be non-negative. Without this restriction, a basis might be used with a positive coefficient in some combination to approximate data in some region of the data manifold and it might be used with a negative coefficient to represent data somewhere else, far off on the data manifold. The positive restriction means that bases are used in a more focused way in reconstruction and learning.

Penalized Activated Simplices

We presented a penalized version of our activated simplices formulation in Section 3.3 of the Main Paper. We might have applied an [formula] penalty as in the usual sparse coding ([\ref=eq:standardsparsecoding]), but we prefer to control the geometry uniformly and explicitly through r. The penalized formulation with penalty parameter r  ≤  1 is

[formula]

subject to β(j)  ≥  0, [formula], for [formula], and [formula] for [formula].

This can be understood geometrically as learning a convex hull of radius r, such that boundary facets are close to the data. Figure [\ref=fig:sparsity_shrinkage] shows how decreasing r encourages sparsity. In the figure, points in the orange regions project onto the vertices, and as r decreases more of space is covered by these orange regions.

This penalization will necessarily worsen reconstruction, but it is useful if one is interested in dimension reduction. In our experiments, which focused on reconstruction from real low dimensional data sources, we found that r = 1 was best. See Figure 9 and 11 of the Main Paper where we experiment with the number of bases p and the radius r for reconstruction of poses and digits. We experiment with r in reconstructions of the torus from synthetic data in Section [\ref=sec:alternative_projections].

Alternative Projections

The Activated Simplices method requires that training data lie on the sphere. This is usually accomplished by directly normalizing the data, or by centering and then normalizing.

The standard normalization is the transformation

[formula]

and centering and normalizing is the transformation

[formula]

where [formula] is the data mean [formula].

For many signals little information is lost in replacing data by its normalization. Indeed this normalization is a common first step in many analyses, for example, images are often contrast normalized. In the experiments in this paper the data was centered and normalized.

However some structure may collapse under direct normalization. Consider, for example, the usual 2 dimensional torus. Figure [\ref=fig:torus_sphere] shows the torus and its normalized image in the sphere -- the normalization flattens the torus into a band around the equator and the inner cavity is lost.

To avoid flattenings such as this we use stereographic projection to map data in [formula] into the d dimensional sphere [formula] in [formula]. This is a standard technique in map making where our world (the 2-dimensional sphere) is mapped onto a flat sheet ([formula]). Figure [\ref=fig:stereographic_projection] shows stereographic projection from the equatorial plane onto the sphere, through the north pole; the point P maps to the point Q. The point Q is the point on the line through N and P that lies on the sphere.

Stereographic projection maps [formula] onto the d-sphere with the north pole removed (the points at infinity map to the north pole.) It is an invertible conformal map (it preserves angles between curves). The map is

[formula]

and the inverse is

[formula]

where Qd + 1 is the [formula] coordinate of Q.

In some situations the entire data analysis can be carried out in [formula] rather than in [formula]. For a classification task, one might map the data to the sphere with stereographic projection, learn a simplicial structure, and carry out classification tasks there. For synthesis one might map the synthesized points back to [formula] with inverse stereographic projection.

But it can also be useful to map the simplicial structure back to [formula]. This is simply a matter of keeping track of activations. The simplex in [formula] interpolating [formula] maps to the curved simplex in [formula] with vertices [formula], which lies over the flat activated simplex with vertices [formula] on the convex hull! Figure [\ref=fig:simplex_to_simplex] illustrates the relationship between a simplex in the plane and a curved simplex on the sphere.

This relationship between a simplicial structure in Euclidean space and a convex structure in the sphere will remind some readers of [\cite=Brown:1979dj], where it is revealed that the Delaunay triangulation for some data can be constructed by mapping the data into the sphere with stereographic projection, finding the convex hull of the projected points, and mapping the faces of this hull back to Euclidean space. Our method approximates the convex hull of the projected points and builds a simplicial approximation to the data in Euclidean space by mapping some facets of this hull back to Euclidean space. It is also interesting to compare with [\cite=Edelsbrunner:1986wt] which shows that the Delaunay triangulation can be found from a convex hull after mapping the data into a paraboloid. The common theme is that mapping data into the boundary hyper-surface of a convex region allows useful triangulations to be constructed by convex approximation.

We'll say a little more about Delaunay triangulations in Section [\ref=sec:triangulating_manifolds].

Low Dimensional Examples.

We now discuss some experiments with some data from some low dimensional manifolds. We sample data from some 2 dimensional manifolds embedded in [formula]; we map the data into the 3-dimensional sphere [formula] using stereographic projection and build a simplicial structure; we map the simplicial structure back into [formula] and show some plots. No pruning was used here.

Figure [\ref=fig:torus_1] shows a structure learned form N = 1000 data points sampled from the torus, with p = 60 bases using r = 1 (unpenalized), and with no pruning. Some 3-dimensional simplices were activated but only their 2-dimensional boundaries are shown here.

Figure [\ref=fig:hemisphere_1] shows a simplicial structure learned from 1000 points sampled from the hemisphere, using 50 bases and r = 1. No simplices of dimension more than 2 were activated and there are no holes in the structure. This is an excellent reconstruction of the hemisphere.

Figure [\ref=fig:swiss_roll_and_plane] shows a structure learned from 2000 points sampled on the union of a ribbon and a planar segment, using 100 bases and r = 1. A small number of 3-dimensional simplices were learned.

Figure [\ref=fig:torus_reconstructions] shows simplicial structures learned from the torus, using 1000 samples, and for several values of p and r. Notice that as r gets smaller the activations become more sparse, and for small values of r the structure is a wireframe. A heavily penalized structure constructed using 5 bases and r = 0.4 and r = 0.1 captures the medial axis of the torus.

Triangulating Manifolds

In the main paper we focused on Activated Simplices as a method for data reconstruction, regularization and synthesis. We now discuss Activated Simplices as a tool for manifold reconstruction. This hasn't been a priority in this work, but it is a natural extension. The illustrations in Section [\ref=sec:low_dimensional] show the potential for reconstructing low dimensional manifolds. Figure ([\ref=fig:swiss_roll_and_plane]) shows a reconstruction of a structure with intersecting components.

It is useful to distinguish the task to building a structure for data reconstruction and regularization from that of manifold reconstruction. Figure [\ref=fig:sphere_wireframe] shows a sphere and a wireframe. A fine wireframe is a good enough structure to regularize data from the sphere but it is a poor reconstruction of the manifold. The goal in manifold reconstruction is usually to construct a smooth manifold, or a union of a small number of smooth manifolds, that approximate a data source.

The pruning process in Section 4 of the Main Paper is aimed at economical reconstruction, but it may be inappropriate for manifold reconstruction where smoothness is a priority. The plots in Section [\ref=sec:low_dimensional] show unpruned structures.

It is interesting to compare Activated Simplices with methods which construct simplicial structures for manifold reconstruction, especially those that use the Delaunay complex [\cite=Edelsbrunner:1983fe] [\cite=Edelsbrunner:1998wx] [\cite=Amenta:2000it] [\cite=Edelsbrunner:2003wp] [\cite=Dey:2003jf] [\cite=Cheng:2005vy]. The Delaunay complex for a set of data points is a simplicial structure that is dual to the Veronoi cells for the points. For points in general position in the plane, three points are connected by a Delaunay triangle if their Voronoi regions meet at a point. Figure [\ref=fig:voronoidelaunay] shows Voronoi boundaries and the corresponding Delaunay triangles for 6 points in the plane. Figure [\ref=fig:delaunay_ellipse] shows the Voronoi cells and Delaunay triangles for 50 points sampled on a ellipse. The Delaunay complex in d dimensions is defined analagously: d + 1 points are connected by a d-dimensional simplex if their Voronoi regions intersect.

The Delaunay complex for points in [formula] is a d dimensional structure. It must be pared back to a lower dimensional structure to reconstruct a lower dimensional manifold. The methods that use Delaunay complexes differ in how this paring back is done. For example, α-shapes [\cite=Edelsbrunner:1983fe] extracts sub-simplices of bounded diameter, whereas co-cone methods [\cite=Amenta:2000it] select simplices by their proportions.

Activated Simplices doesn't construct a sub-complex of the Delaunay complex, but it is related to Delaunay complex methods in that it learns from the convex hull of the data in the sphere -- [\cite=Edelsbrunner:1986wt] shows that the Delaunay complex can be constructed from the convex hull of the stereographic projection of data onto the sphere. The main difference between Activated Simplices and methods which pare back the Delaunay complex is that the simplices are selected by Activated Simplices because they are activated by data, whereas in the Delaunay complex methods, sub-simplices of the complex are selected if they meet come geometric requirements such as size or proportion.

Extremes and Archetypes

We now discuss how extremes within data might be identified with Activated Simplices. But first we must define some notions of extreme. A first notion is what might be called a convex extreme point. This is a point on the data manifold that is not a convex combination of any other points on the manifold. For example, in a cube, the corner points are convex extremes because they are not convex combinations of other points. On a 2-dimensional sphere, every point is a convex extreme point. This is an extrinsic notion of extreme -- a person looking on the manifold from afar can identify convex extremes, but a short sighted ant crawling on the manifold might notice nothing unusual as it crawls past a convex extreme. Figure [\ref=fig:boundary_tyre] shows a tire and it's convex extremes. The convex extremes of a finite set of points are the vertices on the convex hull of the points.

Archetypal Analysis [\cite=cutler1994archetypal] [\cite=chen2014fast] learns a convex model for the data (it learns bases such that the convex hull encloses the data). The bases that are learned are approximations to extreme points.

A second notion of extreme point comes from the mathematical notion of a manifold with boundary. In this formulation an interior point has neighborhoods homeomorphic to disks, but boundary points have neighborhoods homeomorphic to half disks. Figure [\ref=fig:boundary_definition] (a) shows a neighborhood for an interior point p and a boundary point q on the square. Figure [\ref=fig:boundary_definition] (b) shows the boundary points of the bowl and Figure [\ref=fig:boundary_tyre] shows the boundary points of the tire.

Boundary point is an intrinsic notion -- a short sighted ant will notice that the neighborhood is different at a boundary point. Boundary points correspond to extreme configurations. For example, a pose, where a limit of the range of motion at some joint is reached, is a boundary point on the manifold of poses.

Figure [\ref=fig:boundary_tyre] illustrates that convex extremes and boundary points may not coincide.

Boundaries and Activated Simplices

We now develop a notion of boundary for a simplicial structure. Figure [\ref=fig:bow_triangulation] shows the bowl and part of a triangulation. The blue segments are boundary simplices. Figure [\ref=fig:boundary_simplices_3] shows another simplicial structure; the blue simplices are boundary simplices, the red segment is an internal segment. These pictures suggest a definition of boundary simplex -- a simplex is a boundary simplex if it has co-dimension 1 in a maximal simplex and it is not a sub-simplex of two maximal simplices. In Figure [\ref=fig:boundary_simplices_3] the blue segments are sub-simplices of only one maximal simplex, whereas the red segment is a sub-simplex of two maximal simplices.

We can use this notion to detect extremes using Activated Simplices. Figure [\ref=fig:boundary_face] shows some boundary faces found in the Yale B face data. We used 64 face images of the same person under different lighting conditions. We learn 10 bases, obtain 27 simplices and identify 14 maximal simplices. Seven of the maximal simplices are in the interior of the manifold. It means all of their co-dimension 1 sub-simplices are sub-simplices of other maximal simplices. Each of the remaining seven maximal simplices has one co-dimension 1 sub-simplex that is a boundary. Figure [\ref=fig:boundary_face] shows vertices for the seven boundary simplices. We can see that the boundary simplices include the images corresponding to extreme lighting directions.

The utility of the boundaries found from Activated Simplices depends on the data manifold and on the simplicial structure that is constructed. If the simplicial structure is stringy and lumpy there will be many boundary simplices, and it will be hard to make sense of these extremes. This kind of simplicial structure can arise because it reflects the reality of the data manifold, or it can occur when the data manifold is under-sampled.

Comparison with Archetypal Analysis

Archetypal Analysis learns a global convex model for the data. This is appropriate when the data manifold is a convex subset of Euclidean space. In other situations the Archetypal Analysis fails to learn the details of the data. Figure [\ref=fig:archetype] shows some structures that might be constructed by Archetypal Analysis.

In contrast, Activated Simplices learns a local convex model for the data. Figure [\ref=fig:simplices] shows structures that might be learned by Activated Simplices.

Archetypal Analysis learns convex extremes but it can fail to find intrinsic boundaries. Activated Simplices can find convex extremes among the bases (though not all bases will be extremes), and it can find intrinsic boundaries when the manifold is well reconstructed.