Exact confidence intervals and hypothesis tests for parameters of discrete distributions

Introduction

Hypothesis testing and interval estimation of parameters in discrete distributions are two of the classic statistical problems, particularly for the binomial and Poisson distributions, which remain two of the most important statistical models. The fact that these distributions are discrete makes it impossible to construct non-randomized confidence intervals that have coverage equal to 1 - α for all values of the unknown parameter θ, and, equivalently, impossible to construct two-sided tests with size equal to α for all pairs (α,θ0), where θ0 denotes the value of θ under the null hypothesis. It is however possible to construct confidence intervals that have coverage at least equal to 1 - α for all values of the unknown parameter, and tests that have size at most equal to α. Such intervals and tests are called exact, and are the topic of this paper.

Given an observation x, the classic method of constructing exact confidence intervals for parameters of some common discrete distributions is to use the fiducial interval of Fisher [\citep=fisher30] [\citep=wang00]: (θL,θU) where θL and θU are such that

[formula]

For the binomial parameter, the fiducial interval is known as the Clopper-Pearson interval [\citep=cp1] and for the mean of a Poisson distribution it is known as the Garwood interval [\citep=garwood36].

The hypothesis H0:θ  =  θ0 can be tested against the alternative H1:θ  ≠  θ0 by checking whether θ0 is contained in the fiducial interval. The p-value λf(θ0,x) of this test is two times the smaller p-value of two one-sided tests:

[formula]

In their seminal paper on binomial confidence intervals, [\citet=bcd1] write: "The Clopper-Pearson interval is wastefully conservative and is not a good choice for practical use, unless strict adherence to the prescription C(p,n)  >  1 - α is demanded", where C(p,n) denotes the coverage probability. Instead they recommend using approximate intervals, which obtain the nominal confidence level 1 - α in some average sense, but have lower coverage for some values of θ. Such intervals are typically shorter than exact intervals, and their corresponding tests typically have higher power. These advantages comes at the cost that the actual confidence levels may be much lower than stated and that the size of tests may be inflated. For popular approximate intervals the deviations in coverage from 1 - α may be non-negligible even for large sample sizes [\citep=thu2]. For this reason, some statistician prefer to use exact methods like those discussed in this paper, in order to guarantee that confidence levels are not exaggerated and type I error rates are not understated.

When other criteria than merely coverage levels and expected lengths are considered, exact confidence intervals can moreover compare favourably to approximate intervals [\citep=vh2] [\citep=ne2]. Finally, even if one prefers to use average coverage as a criterion for comparing confidence intervals, it is of interest to study exact intervals due to the facts that these intervals can be adjusted to have coverage 1 - α on average, and that such adjusted intervals tend to have shorter expected length than other approximate intervals [\citep=re1] [\citep=thu1]. For comparisons of exact and approximate intervals in the binomial setting, and further arguments for using exact methods for discrete distributions, see [\citet=thu2].

Regarding the fiducial Clopper-Pearson interval, [\citet=bcd1] also write "better exact methods are available; see, for instance, Blyth and Still (1983) and Casella (1986)." Fiducial intervals are equal-tailed, meaning that the lower bound is a 1 - α / 2 lower confidence bound and that the upper bound is a 1 - α / 2 upper confidence bound. Several authors, including those mentioned by [\citet=bcd1] in the above quote, have proposed shorter exact intervals that improve upon fiducial intervals by letting the tail-coverages vary for different x, so that their bounds no longer are 1 - α / 2 confidence bounds [\citep=st3] [\citep=st2] [\citep=crow56] [\citep=bs1] [\citep=ca1] [\citep=casella89] [\citep=bl1] [\citep=byrne01b] [\citep=lurz] [\citep=schilling14] [\citep=wang14]. Such intervals, known as strictly two-sided intervals, tend to have less conservative coverage and are typically shorter than fiducial intervals. Their use has been advocated by [\citet=agresti1], [\citet=re1], [\citet=agresti2], [\citet=hirji06], [\citet=fay10a] [\citet=fay10b], [\citet=sommerville13] and [\citet=lp14], among others.

Unlike the equal-tailed fiducial intervals, the p-values of tests corresponding to strictly two-sided confidence intervals can not be written as two times the smaller p-value of two one-sided tests. Instead, for some test statistic T(θ0,X) satisfying mild regularity conditions detailed in Section [\ref=nested], the p-value of a strictly two-sided test is defined as

[formula]

If the the null distribution of T(θ0,X) is asymmetric, the level α rejection region of such a test is not the intersection of the rejection regions of two one-sided level α / 2 tests.

The main goal of this paper is to show that strictly two-sided confidence intervals and hypothesis tests suffer from several problems. These are illustrated in Figure [\ref=fig0], in which the p-values and interval bounds for the mean of a Poisson distribution are shown for two tests and their corresponding confidence intervals. The first of these is the strictly two-sided [\citet=st3] interval, the other being the fiducial [\citet=garwood36] interval.

In the spirit of [\citet=birnbaum], the p-values are plotted as a function of the value θ0 of the parameter under the null hypothesis. In the Poisson model it is reasonable to expect that a small change in the null value of θ should lead to a small change in the p-value, since θ(X = x) is continuous in θ, so that there is no concernable difference between the Poisson(θ) and Poisson(θ  +  ε) models when ε is infinitesimal. This is not the case for the strictly two-sided test: its p-value is discontinuous when viewed as a function of θ0. The evidence against two models, which for all practical purposes are indistinguishable, can therefore differ greatly. Several examples of this are seen in Figure [\ref=fig0]; the p-value for θ0 = 4.954163, for instance, is 0.0722, so that the null hypothesis is rejected at the 10 % level, while the highly similar hypothesis θ0 = 4.954164 cannot be rejected as its p-value is 0.1071.

Moreover, we would expect that the p-value increases as θ0 goes from 0 to the observed x, and that it thereafter decreases, since this would mean that the p-value becomes smaller when the null hypothesis agrees less with the data. This is not the case for the strictly two-sided test. Instead, the p-value sometimes increases when the null θ is changed to agree less with the observed x. As an example, consider the p-values shown in Figure [\ref=fig0]. When x = 9 has been observed from a Poisson distribution, the p-value when θ0 = 15.6 is 0.0993, so that the null hypothesis is rejected at the 10 % level. However, even though x = 9 disagrees even more with the null hypothesis θ0 = 15.95, the p-value for this θ0 is 0.1011, and the hypothesis can not be rejected. The test corresponding to the fiducial interval does not suffer from either of these problems.

The strictly two-sided confidence interval is no better than its corresponding test. When the interval bounds are plotted as functions of the confidence level 1 - α, we see two phenomenons. The first is that the interval bounds are discontinuous in 1 - α, meaning that a small change in α can cause one of the interval bounds to leap. The second is that the bounds sometimes are constant, meaning that a change in α not necessarily will lead to a change in the bounds. For some α, both bounds remain unchanged in an interval (α  -  ε,α  +  ε). There is therefore no guarantee that accepting a larger α will lead to a shorter interval; we say that the interval is not strictly nested. The fiducial interval does not suffer from either of these problems.

These properties can also cause strictly two-sided test and intervals to behave strangely as more data is collected. As an example, consider the [\citet=bl1] test for the negative binomial proportion θ. When k = 19 successes are observed after x = 38 trials, the maximum likelihood estimator is  = 0.5 and Blaker p-value for the test of the hypothesis θ = 0.625 is 0.0.0929, causing us to reject the null hypothesis at the 10 % level. If we then decide to collect more data by requiring that k = 20 successes should be observed, and observe one failure and one success so that x = 40, [formula] is still 0.5. We would now expect the p-value to decrease as this outcome appears to be even less in line with θ = 0.625. Instead, the Blaker p-value for k = 20 and x = 40 is 0.106, and we can no longer reject the null hypothesis at the 10 % level. Analogous problems arise for confidence intervals. The 90 % Blaker confidence interval for θ given k = 19 and x = 38 is (0.35992, 0.62279), while for k = 20 and x = 40 it is (0.36202, 0.62689). The latter interval is not, as we normally would expect, a subset of the former. Moreover, the interval based on more data is wider than the interval based on less data: the interval widths are 0.263 and 0.265, respectively.

As we will see, intervals lacking strict nestedness is equivalent to their corresponding p-values being discontinuous in θ. Consequently, intervals which are not strictly nested correspond to tests that attach widely differing evidence to indistinguishable hypotheses. We believe that this is an unacceptable property of a hypothesis test, and argue that such intervals and tests should be avoided.

In this paper we show that these problems are universal for strictly two-sided intervals and tests, when the data is generated by a class of discrete distributions that includes the binomial, Poisson and negative binomial distributions. They also carry over to exact analysis of contingency tables and discrete models with nuisance parameters, when such analyses are based on conditioning that reduces the problem to a one-parameter framework.

In Section [\ref=nested] we give a formal description of the setting for our results. We then show that the p-values of strictly two-sided tests are discontinuous, and that their corresponding intervals have bounds that are not strictly monotone. Finally, we show that strictly two-sided intervals never are strictly nested, meaning that both interval bounds simultaneously may remain unchanged when α is changed. Section [\ref=strictly] is devoted to showing that strictly two-sided intervals typically have bounds that moreover are discontinuous in α, and that the corresponding p-values lack desirable monotonicity properties. In Section [\ref=optimality] it is then demonstrated that fiducial intervals not only are strictly nested but also are the shortest equal-tailed intervals. The paper concludes with a discussion in Section [\ref=discussion]. Most proofs and some technical details are contained in two appendices.

The lack of strict nestedness and its implications

Setting

This section is concerned with nestedness. We start by defining this concept.

A confidence interval is nested if the 1 - α interval is a subset of the 1 - α0 interval when 1 > α  >  α0 > 0, and strictly nested if the 1 - α interval always is a proper subset of the 1 - α0 interval.

If an interval is not strictly nested, accepting a lower confidence level does not always yield a shorter interval, so that sometimes nothing is gained by increasing α. Despite the importance of nestedness, this property has not been discussed much in the literature, likely because it is taken for granted. Notable exceptions are [\citet=bl1], who proved that the binomial Blyth-Still-Casella interval is not strictly nested and [\citet=vh1], who showed by example that the Blaker interval for a binomial proportion lacks strict nestedness. Next we give some definitions and state the assumptions under which strictly two-sided intervals are not strictly nested. We will limit our study to parameters of discrete distributions Pθ belonging to a class P(Θ,X).

Let θ∈Θ denote an unknown parameter, with Θ being a connected open subset of [formula], and let [formula] be a sample space consisting of consecutive integers. A family of distributions Pθ on X parameterized by θ∈Θ belongs to P(Θ,X) if

[formula], θ(X = x) > 0,

Pθ is stochastically increasing, i.e. θ(X  ≤  x) is strictly decreasing in θ for any fixed [formula],

For any fixed x∈X, θ(X = x) is differentiable in θ.

Conditions A1-A3 are satisfied by for instance the binomial, Poisson and negative binomial distributions as long as Θ is the natural parameter space, i.e. as long as it has not been restricted. This follows directly from the proposition below, the proof of which is given in Appendix [\ref=proofs]. The conditions are typically also satisfied for other common parameterizations.

If Pθ constitutes a regular discrete one-parameter exponential family with an increasing likelihood ratio, where θ is the natural parameter, then Pθ∈P(Θ,X).

To fully understand the implications of the lack of nestedness, we will study the hypothesis tests to which non-nested intervals correspond, so-called strictly two-sided tests:

Consider a two-sided test of H0:θ  =  θ0 versus H1:θ  ≠  θ0, with a test statistic T(θ0,x). The test is called strictly two-sided if the p-value of the test is λ(θ0,x) = θ0(T(θ0,X)  ≥  T(θ0,x)) and it satisfies conditions B1-B2 below. Moreover, in case λ(θ,x), viewed as a function of θ, has a jump at θ0 we define λ(θ0,x) =  lim inf θ  →  θ0λ(θ,x).

For any x∈X, there exists a θx∈Θ such that T(θx,x) < T(θx,y) for all [formula].

There exists a θ0∈Θ such that there does not exist a μ∈Θ for which θ0(T(θ0,X) = μ - k) = θ0(T(θ0,X) = μ + k) for all k:μ  ±  k∈X.

Condition B1 is included to ensure that the test does not yield the same result for all x and θ. The name strictly two-sided comes from condition B2, which ensures that the p-value must be computed by comparing the test statistic to both tails of the null distribution simultaneously. The p-value of a strictly two-sided test can be written as

[formula]

For simplicity, we will assume that the test statistic is such that

For any θ∈Θ, there exists xθ∈X such that T(θ,x) is decreasing in x when x < xθ and increasing in x when x > xθ.

Under B3, the set Aθ,x has a particularly simple form.

Under B3 the functions k1(θ,x): =  min {k  ≥  xθ:T(θ,k)  ≥  T(θ,x)} and k2(θ,x): =  max {k  ≤  xθ:T(θ,k)  ≥  T(θ,x)} are such that

[formula]

For any x, at least one of k1(θ,x) and k2(θ,x) is non-constant in θ.

The proof of the proposition is given in Appendix [\ref=proofs]. When x is fixed and θ is varying we will refer to λ(θ,x) as the p-value function. We define the corresponding confidence interval using the convex hull of {θ:λ(θ,x) > α} to ensure that it in fact is an interval; as we will see in Section [\ref=strictly], {θ:λ(θ,x) > α} itself is not always connected. The interval in the following definition is guaranteed to be nested: if α  >  α0 the convex hull of {θ:λ(θ,x) > α} is a subset of the convex hull of {θ:λ(θ,x) > α0}.

The 1 - α confidence interval Iα(x) = (Lα(x),Uα(x)) corresponding to a test is

[formula]

A confidence interval is said to be strictly two-sided if it is based on the inversion of a strictly two-sided test.

Examples of strictly two-sided tests

We will focus on four commonly used strictly two-sided tests, which satisfy conditions B1, B2 and B3 for some common discrete distributions, including the binomial, Poisson and negative binomial distributions. These tests are briefly described below. Further details, as well as conditions for B1-B3 to hold, are given in Appendix [\ref=app1].

The likelihood ratio test, for which T(θ,x) is the likelihood ratio statistic [\citep=hirji06] [\citep=sommerville13].

The score test, for which T(θ,x) is the score statistic [\citep=hirji06] [\citep=sommerville13].

The Sterne test, for which T(θ,x) = 1 / θ(X = x) [\citep=st3].

The Blaker test, which in fact is a class of tests. Given a statistic S(x), the Blaker statistic is T(θ,x) = 1 /  min {θ(S(X)  ≤  S(x)),θ(S(X)  ≥  S(x))}, was introduced in [\citet=bl1]. See also [\citet=xie] for a interpretation based on confidence curves. In the binomial, negative binomial and Poisson settings, we will use the sufficient statistic S(x) = x, as is common.

In Section [\ref=nonnest] we will discuss confidence intervals that have varying tail-coverage but are based on minimization algorithms rather than test inversion. Because these intervals do not fall under Definition [\ref=def3] we will refer to them as being of strictly two-sided-type rather than as being strictly two-sided.

Lack of strict nestedness and its interpretation

We will now show that strictly two-sided intervals lack strict nestedness, and that this is caused by jumps in the p-value function λ(θ,x), viewed as a function of θ.

Assume that Pθ∈P(Θ,X). Let λ(θ,x) be the p-value function of a strictly two-sided test and let Iα(x) denote its corresponding strictly two-sided confidence interval. Then for any x∈X,

λ(θ,x) is not continuous in θ,

The bounds of Iα(x) are not strictly monotone in α,

Iα(x) is not strictly nested.

First, we show that λ(θ,x) has jumps. For any fixed x∈X, by Proposition [\ref=B3prop] we have, under B3,

[formula]

where at least one of the ki(θ,x) is non-constant in θ. ki(θ,x) are integer-valued step-functions. Thus, for ε > 0 whenever ki(θ,x) < ki(θ  +  ε,x), ki must have a jump between θ and θ  +  ε. This induces a jump in the p-value function as well. To see this, assume without loss of generality that k1(θ  +  ε,x) = k1(θ,x) and k2(θ  +  ε,x) = k2(θ,x) + 1. Then

[formula]

but by A1 and A3,

[formula]

Thus [formula] as [formula] and the function is hence not continuous in θ. In particular, we have shown that λ(θ,x) has the following property:

Under the assumptions of Theorem [\ref=thm3], λ(θ,x) as a function of θ has a jump whenever a point is added to or removed from Aθ,x.

Values of α for which Iα(x) is not strictly nested correspond to the jumps in λ(θ,x). To see this, note that if the interval (α0,α1)  ⊆  (0,1) is such that

[formula]

then for α∈(α0,α1), we have λ(θ,x) > α if and only if λ(θ,x) > α1, which means that the lower interval bound

[formula]

so that Lα(x) is not strictly monotone in α. By definition, the interval is not strictly nested if there exists an α such that both Lα(x) and the upper interval bound Uα(x) simultaneously are constant in a neighbourhood of α. The proof that there always exists such an α is somewhat technical, and is deferred to Appendix [\ref=proofs].

In particular, Proposition [\ref=thm3] holds when the test and its corresponding confidence interval are exact. The proposition is illustrated for exact tests and intervals in Figures [\ref=fig1]-[\ref=fig2]. In Figure [\ref=fig1], p-values for the strictly two-sided [\citet=st3], [\citet=bl1], likelihood ratio and score tests [\citep=hirji06] [\citep=sommerville13] are compared to the p-values of the non-strictly two-sided test that corresponds to the fiducial interval in the Poisson and binomial settings. It is readily verified that the strictly two-sided tests satisfy B1-B3; see Appendix [\ref=app1]. In Figure [\ref=fig2], the interval bounds of some strictly two-sided intervals are compared to the bounds of the fiducial interval. In the Poisson case, the Sterne, Blaker, likelihood ratio, score, Crow-Gardner [\citep=crow56] [\citep=casella89] and [\citet=byrne01b] (the latter two being of strictly two-sided-type) intervals are compared to the Garwood interval. In the binomial case, the Sterne, Blaker, likelihood ratio, score, Crow [\citep=st2] [\citep=bs1] [\citep=ca1] (which is of strictly two-sided-type) and [\citet=lurz] intervals are compared to the Clopper-Pearson interval.

The largest α for which an interval is strictly nested

Proposition [\ref=thm3] tells us that strictly two-sided confidence intervals lack strict nestedness and that their bounds are not strictly monotone in α. This may however not be a great problem if the lack of strict nestedness and monotonicity occurs only for α close to 1.

Under some stronger assumptions on T(θ,x), X and Pθ we can derive expressions for the largest α for which Iα(x) is strictly nested and the largest α for which each interval bound is strictly monotone. As we will see, these bounds for α are usually close to 0, meaning that the lack of strict nestedness and monotonicity occurs also for α that are used in practice.

We restrict our attention to samples spaces of the form [formula] or [formula], for some known n <   ∞  . Moreover, we will require some additional conditions, which essentially make up stronger versions of A2 and B3:

θ(X  ≤  x) is strictly decreasing in θ for any [formula].

For any θ∈Θ, there exists xθ∈X such that T(θ,x) is strictly decreasing in x when x < xθ and strictly increasing in x when x > xθ.

For any x∈X, there exists a θx∈Θ such that λ(θx,x) = 1 and T(θ,x) is strictly decreasing in θ when θ  <  θx and strictly increasing in θ when θ  >  θx.

xθ is an increasing function of θ.

Assume that [formula] or [formula]. Under A2+, B3+ and the assumptions of Proposition [\ref=thm3] it holds that

There exists an αnest > 0 such that Iα(x) is strictly nested for all x∈X and α  ≤  αnest.

Let αL  =   inf x∈X inf θ∈{θ:T(θ,0) > T(θ,x)}λ(θ,x). Then (i) αL > 0, (ii) for all x > 0, Lα(x) is continuous and strictly increasing in α when α  ≤  αL, and (iii) there exists an x > 0 and an ε > 0 such that Lα(x) is constant in (αL,αL  +  ε).

For [formula], let αU  =   inf x∈X sup θ∈{θ:T(θ,n) > T(θ,x)}λ(θ,x). Then (i) αU > 0, (ii) for all x < n, Uα(x) is continuous and strictly decreasing in α when α  ≤  αU, and (iii) there exists an x > 0 and an ε > 0 such that Uα(x) is constant in (αU,αU  +  ε).

Proposition [\ref=smallprop] deals with α guaranteeing strict monotonicity and nestedness for all x. We can also study monotonicity and nestedness for fixed x. For any x∈X, let αL(x) denote the largest α for which Lα(x) is strictly monotone, and αU(x) denote the largest α for which Uα(x) is strictly monotone. Finally, let αnest(x) be the largest α for which Iα(x) is strictly nested. In Figure [\ref=fig3] (a), these quantities are shown for the Blaker interval for a binomial proportion, with n = 20 and [formula]. In this example, αnest(x) < 0.1 for most x. As is seen, αnest(x) is often equal to or very close to max (αL(x),αU(x)). Figures for other intervals, other n and other distributions are similar.

Figure [\ref=fig3] (b) shows αnest for the binomial Blaker interval as a function of the sample size n. It is seen that when 7  ≤  n  ≤  100 we have αnest < 0.01 for the Blaker interval, meaning that the interval lacks strict nestedness for virtually all values of α that actually are used in practice for these sample sizes.

Confidence intervals not based on test-inversion

An interesting class of confidence intervals are based on minimization algorithms. This class includes the [\citet=st2], [\citet=crow56], [\citet=bs1], [\citet=ca1], [\citet=casella89], [\citet=byrne01b] and [\citet=schilling14] intervals. For such intervals the shortest interval is determined for each α. What typically occurs for these intervals is that they correspond to inversion of different tests for different α. Often this will result in intervals that lack nestedness (and not only strict nestedness), as it leads to some values of θ having multiple p-values attached to them. This can be seen in Figure [\ref=fig2]: neither the Crow interval for the binomial parameter nor the Crow-Gardner and Kabaila-Byrne intervals for the Poisson parameter are nested.

If a two-sided 1 - α interval is [formula] then the p-values for the corresponding two-sided tests of the hypotheses [formula] and θ0  =  θu are α. Using this relationship, we can plot the p-value functions of tests corresponding to intervals that are not defined in terms of test inversion, such as minimization-based intervals. The lack of nestedness means that the p-value function λ(θ,x) of the corresponding test is not a proper function for x∈X fixed, since some values of θ are mapped to more than one p-value. For some intervals, this problem becomes extreme. Two examples of this are the Kabaila-Byrne and Crow-Gardner intervals for a Poisson mean, shown in Figure [\ref=fig4]. For other intervals, the lack of nestedness results in less extreme p-value functions. An example of this is the Schilling-Doi interval for a binomial proportion; in Figure [\ref=fig4] the jumps in its p-value function are shown as vertical lines, in order to make the consequences of the non-nestedness easier to spot.

Continuity and bimonotonicity

For [formula], we say that a function [formula] is strictly bimonotone on Θ if there exist θ0,θ1∈Θ such that f is strictly increasing on ( inf Θ,θ0), constant on (θ0,θ1) and strictly decreasing on (θ1, sup Θ).

As have been argued e.g. by [\citet=hirji06] and [\citet=vh1], this type of bimonotonicity is a highly desirable property of p-values when viewed as a function of θ. Ideally λ(θ,x) should increase monotonically from 0 to 1 and then decreases monotonically to 0, just like the p-values of the tests corresponding to fiducial intervals do in Figure [\ref=fig1]. One reason that this property is desirable is the following result.

The bounds of a confidence interval are discontinuous in α if their corresponding p-value function is not strictly bimonotone in θ.

Assume without loss of generality that there exist θ0  <  θ1  <   inf {θ:λ(θ,x) = 1} such that λ(θ,x) is increasing in θ in the interval ( inf Θ,θ0) and decreasing or constant in the interval (θ0,θ1). Let α0  =  λ(θ0,x). Then θ1  =   inf {θ  >  θ0:λ(θ,x) > α0}. Thus Lα0(x) = θ0 but for all ε > 0, Lα  +  ε(x)  ≥  θ1, meaning that Lα(x) has a jump of length θ1  -  θ0 > 0 at α  =  α0. An analogous argument holds for the upper bound.

[\citet=hirji06] mentions that p-value functions of strictly two-sided tests need not be bimonotone, whereas [\citet=vh1] showed by example that the Blaker test for a binomial proportion lacks bimonotonicity. Upon closer inspection of Figures [\ref=fig1] and [\ref=fig2] it can be seen that all the strictly two-sided tests considered here suffer from this problem.

Next we give a condition under which the p-value function of a strictly two-sided test is strictly bimonotone for fixed x, the derivation of which is given in Appendix [\ref=proofs]. The bimonotonicity condition requires the following additional assumptions, which are satisfied by the binomial, negative binomial and Poisson distributions.

For [formula], lim θ  →   inf Θθ(X  ≤  x) = 1 and lim θ  →   sup Θθ(X  ≤  x) = 0.

For k1,k2∈X such that k1  ≥  k2 + 2, [formula] has a unique minimum in the interior of Θ.

Under the assumptions and notation of Proposition [\ref=thm3], assume that Pθ satisfies conditions A4 and A5. Let θr(θ0,x) be the solution to

[formula]

in the interior of Θ. Then

λ(θ,x) is strictly bimonotone in θ for any fixed [formula],

The bounds of Iα(x) are continuous in α,

if and only if there does not exist (θ0,x) such that either

[formula]

For any given Pθ, we can evaluate numerically whether the bimonotonicity condition [\eqref=bimcond] is violated for a pair (θ0,x). We have not been able to find a strictly two-sided test that passes [\eqref=bimcond] for any x. Proposition [\ref=proposition1] is illustrated in the Poisson and binomial settings in Figures [\ref=fig1]-[\ref=fig2]. When x = 2 from a Poisson random variable has been observed, the p-value functions of the Sterne and Blaker tests are non-bimonotone for the first time when θ = 3. For the likelihood ratio test, the first occurrence is at θ = 1 and for the score test the first occurrence is at [formula].

A consequence of λ(θ,x) lacking bimonotonicity is that the confidence "interval" {θ:λ(θ,x) > α} may contain holes, and therefore not be an interval at all. The common remedy for this is to redefine the intervals as the convex hull of {θ:λ(θ,x) > α}, as we did in Definition [\ref=def3]. This does not change the infimum or supremum of the set, and does therefore not affect nestedness or continuity of the bounds. Similarly, [\citet=fay10a] proposed handling the problem of non-bimonotone p-value functions by redefining the p-values using the convex hull of {θ:λ(θ,x) > α}. The redefined p-values are constant where they previously were non-monotone. By Proposition [\ref=propbim], the bounds of the corresponding intervals are however still discontinuous in α.

For the binomial and negative binomial distributions the left-hand side of ([\ref=Heq]) is a polynomial of order k1(θ0,x) - k2(θ0,x) - 1. For the Poisson distribution, it is straightforward to find a general solution to ([\ref=Heq]), which yields the following proposition, the proof of which is omitted.

For X  ~  Poisson(θ), the p-value function λ(θ,x) belonging to a strictly two-sided test is bimonotone in θ if and only if there does not exist (θ,x) such that either

θ  <   inf {θ:λ(θ,x) = 1} and [formula], or

θ  >   sup {θ:λ(θ,x) = 1} and [formula].

Note that if we let n = k1(θ,x) - k2(θ,x) - 1 then

[formula]

the geometric mean of Acθ,x.

Some results for fiducial intervals

Fiducial intervals are strictly nested and have continuous bounds

The test corresponding to the fiducial intervals is not strictly two-sided. Its p-values are defined by [\eqref=fidtest]. The following proposition, the proof of which can be found in Appendix [\ref=proofs], states that fiducial intervals do not suffer from the problems associated with strictly two-sided intervals.

Under A1, A2, A3 and A4, fiducial intervals are strictly nested. Moreover, for any x∈X the bounds of the interval are continuous in α and λf(θ,x) is continuous in θ.

Optimality results

For a binomial proportion, [\citet=wang06] presented results claiming that under certain conditions on α and n the fiducial Clopper-Pearson interval is the shortest interval in the class of exact confidence intervals with monotone bounds. A counterexample to the optimality result of [\citet=wang06] is the strictly two-sided Blaker interval [\citep=bl1], which always is contained in the Clopper-Pearson interval. Among equal-tailed intervals however, fiducial intervals posses length optimality properties. We expect that this is known, but have not been able to find such results in the literature, for which reason we briefly cover length optimality below.

Our main tool for showing length optimality is a theorem due to [\citet=bolshev65]. Under assumptions A1, A2 and A3, consider the class ML,α of one-sided 1 - α confidence bounds [formula] for θ∈Θ based on an observation x of X  ~  Pθ satisfying the following three criteria:

Lα(x)  ≤  Lα(x + 1),

inf θ∈Θθ(Lα(x)  ≤  θ)  ≥  1 - α,

Lα(x) only depends on x, α and Pθ.

Criterion C3 rules out randomized bounds, which can be shorter while maintaining exact coverage, but rely on conditioning on information not contained in the sufficient statistic; see e.g. [\citet=thu3]. C3 is implicit in Bolshev's paper; we have added it here for clarity. ML,α is the class of monotone exact lower confidence bounds. We call an interval (or a bound) Iα(x) in a class of intervals K the smallest interval in K if, for any other interval I*α(x)∈K, [formula]. For the ML,α class, [\citet=bolshev65] proved that the one-sided lower fiducial bound is the smallest bound in ML,α. Under analogous conditions, the upper fiducial bound is similarly the smallest bound in the set MU,α of exact monotone upper confidence bounds.

The extension of Bolshev's theorem to two-sided confidence intervals is straightforward and does not require the additional conditions that [\citet=wang06] used in the binomial setting. Consider the class Mα of exact equal-tailed confidence intervals (Lα / 2(x),Uα / 2(x)) for θ based on an observation x of X  ~  Pθ satisfying

Lα / 2(x)  ≤  Lα / 2(x + 1) ~  and ~ Uα / 2(x)  ≤  Uα / 2(x + 1),

inf θ∈Θθ(Lα / 2(x)  ≤  θ)  ≥  1 - α / 2 ~  and ~   inf θ∈Θθ(Uα / 2(x)  ≥  θ)  ≥  1 - α / 2,

(Lα / 2(x),Uα / 2(x)) only depends on x, α and Pθ.

Note that if an interval belongs to Mα then it is the intersection of a bound in ML,α / 2 and a bound in MU,α / 2.

The fiducial interval is the smallest interval in Mα.

Let Iα(x) = (Lα / 2(x),Uα / 2(x)) denote the fiducial interval and assume that there is an interval I*α(x) = (L*α / 2(x),U*α / 2(x)) in Mα such that [formula]. Then L*α / 2(x) > Lα / 2(x) or U*α / 2(x) < Uα / 2(x). Consequently at least one of the one-sided bounds [formula] or [formula] is smaller than the corresponding fiducial bound. By Bolshev's theorem, this means that I*α(x) is not in Mα, which is a contradiction.

Similar results can be obtained for intervals with fixed but unequal tails, in a completely analogue manner.

Finally, the fact that the fiducial interval is the smallest interval in Mα leads to the following proposition, in which the smallness is expressed in the more familiar terms of the interval length Uα / 2(x) - Lα / 2(x).

Among the intervals in Mα, the fiducial interval minimizes the expected length for all θ∈Θ as well as the length for all x∈X.

For an interval (L*α / 2(x),U*α / 2(x))∈Mα to have shorter length than the fiducial interval (Lα / 2(x),Uα / 2(x)) it must hold that L*α / 2(x) > Lα / 2(x) or U*α / 2(x) < Uα / 2(x). By Proposition [\ref=thm4] neither condition can be fulfilled. Since the fiducial interval therefore minimizes the length for each x, it also minimizes the expected length [formula].

A consequence of Proposition [\ref=cor1] is that, in the class of equal-tailed two-sided tests of θ  =  θ0, the test that corresponds to the fiducial interval is admissible in the sense of [\citet=cohen].

Conclusion

There exist a large number of methods for obtaining exact confidence intervals that are shorter than the equal-tailed fiducial intervals. The use of such an interval comes at the cost of losing control over the balance between the coverage levels of the corresponding lower and upper confidence bounds. In many situations it is preferable to use an equal-tailed interval, in order to guard equally against overestimation and underestimation and not to bias the inference in some direction. The case for equal-tailed intervals is further strengthened by the fact that strictly two-sided confidence intervals lack strict nestedness. This causes difficulties with the interpretation of the intervals: what does it mean that, for a particular x, the 92 % interval equals the 95 % interval? Which confidence level should be reported for such an interval? More seriously, we have also seen that such intervals may yield highly disparate conclusions for two indistinguishable models Pθ and Pθ  +  ε. From a hypothesis testing perspective, this occurs when the null hypothesis θ0 is changed slightly. From a confidence interval perspective, it can occur for small changes in α, since the bounds of strictly two-sided intervals typically are discontinuous in α. These problems have been pointed out for specific intervals in the past [\citep=bl1] [\citep=vh1]. We have shown that they in fact are inherent to strictly two-sided confidence intervals.

The problems discussed in this paper arise also for strictly two-sided methods for discrete distributions not covered by Definition [\ref=def2]. Examples include the hypergeometric distribution and the joint distribution of two binomial proportions. We have restricted our attention to the class of distributions given by Definition [\ref=def2] in order to keep the proofs reasonably short.

Strictly two-sided and equal-tailed confidence intervals are the most commonly used types of two-sided confidence intervals. We have seen that strictly-two sided intervals lack strict nestedness and that an extension of Bolshev's theorem shows that the standard fiducial intervals are the shortest equal-tailed exact intervals. While fiducial intervals have been criticized for being overly conservative and too wide [\citep=bcd1] [\citep=agresti2] [\citep=byrne05], the conclusion of this paper is that they for practical purposes in fact are the optimal strictly nested intervals.

The authors wish to thank the editor and the reviewers for comments that helped improve the paper.

Appendix: Strictly two-sided tests

The likelihood ratio and Sterne tests

Let L(θ,x) = θ(X = x) be the likelihood function of Pθ. The likelihood ratio statistic is

[formula]

and the Sterne statistic is

[formula]

Both these statistics are minimized when θ0 is the maximum likelihood estimator of θ given x. Thus for B1 to be satisfied it suffices that the maximum likelihood estimator of θ is well-defined and strictly monotone in x. B2 is satisfied when there exists a θ such that L(θ,x) is an asymmetric function of x. By definition, B3 is satisfied if there exists an x0 such that L(θ,x) is increasing when x < x0 and decreasing when x > x0. This is guaranteed if Pθ has a monotone likelihood ratio.

The binomial, negative binomial and Poisson distributions all have well-defined and strictly monotone maximum likelihood estimators and monotone likelihood ratios. Moreover, their probability functions are in general asymmetric in x. The likelihood ratio and Sterne tests therefore satisfy conditions B1-B3 for these models.

The score test

Let [formula] and let I(θ) be the Fisher information of Pθ. The score test statistic is

[formula]

If the maximum likelihood estimator of θ exists and is unique, then B1 is satisfied, with θx being the maximum likelihood estimator of θ given x. B2 is satisfied if the distribution of U(θ,x)2 is asymmetric for some θ. B3 is satisfied if there exists an x0 such that U(θ,x)2 is decreasing when x < x0 and increasing when x > x0.

If Pθ is a regular exponential family with natural parameter θ, then U(θ,x) = x - θ(X) and I(θ) = θ(X). B2 is satisfied if the distribution of X2 is asymmetric for some θ and B3 is satisfied since (x - θ(X))2 is convex in x. B1-B3 are therefore satisfied for the binomial, negative binomial and Poisson distributions, using the natural parametrizations. These conditions are also satisfied for the most commonly used alternative parametrizations.

The Blaker test

The Blaker statistic is

[formula]

where λT(θ0,x) is the p-value of a test with a rejection region that is the union of the rejection regions of two one-sided level α / 2 tests. The properties of T(θ0,x) therefore depend on the choice of λT(θ0,x). A typical choice is the fiducial p-value [\eqref=fidtest].

Under A3 and A4, for any x∈X there exist θx such that [formula] and [formula]. Then we have [formula] and [formula], so that λf(θ,x) = 1. Let Θ1(x) denote the set of such θx.

Now, let y = x - 1. Then [formula] but [formula], so if θx∈Θ1(x) then θx∉Θ1(y). Similarly, if we let y = x + 1, [formula], so if θx∈Θ1(x) then θx∉Θ1(y). Thus A3 and A4 are sufficient for B1 to hold for the Blaker statistic based on the fiducial p-value.

B2 holds if the distribution of λT(θ,x) is asymmetric in x for some θ. For λf(θ,x) this holds if θ(X = x) is asymmetric as a function of x for some θ.

Finally, B3 is satisfied since the monotonicity of θ(X  ≤  x) in x implies that λT(θ,x) is a bimonotone function of x. B1-B3 are therefore satisfied for the binomial, negative binomial and Poisson distributions.

Appendix: Proofs

Proof of Proposition [\ref=expfamprop]

If Pθ is a discrete one-parameter exponential family in natural form, for (θ,x)∈Θ  ×  X its probability function can be written as

[formula]

where [formula] is a function that does not depend on θ and [formula] is infinitely often differentiable in Θ since Pθ is regular [\citep=liese]. θ, T(x) and K(θ) are all finite for (θ,x)∈Θ  ×  X, and thus [\eqref=expfam] is strictly positive when (θ,x)∈Θ  ×  X, yielding A1. Moreover, A3 follows from the fact that when x is fixed [\eqref=expfam] is differentiable in θ since θT(x) and K(θ) are infinitely differentiable.

To see that an increasing likelihood ratio implies A2, let [formula] for θ1  <  θ2 in Θ. The likelihood ratio [formula] is increasing in x. Let

[formula]

and

[formula]

We consider the cases when [formula] and [formula] separately.

If [formula] then for s < t, Fθ2(s)  ≤  Fθ1(s) since pθ2(x)  ≤  pθ1(x) for all x < t.

If [formula] then pθ2(x)  ≥  pθ1(x) when x > t and for s > t, Gθ2(s)  ≥  Gθ1(s). Since Fθ(x) = 1 - Gθ(x), it follows that Fθ2(s)  ≤  Fθ1(s).

Proof of Proposition [\ref=B3prop]

First, assume that k  ≥  xθ. Then by B3 T(θ,  ·  ) is increasing at k. There are two possible scenarios:

k  ≥  k1(θ,x): By definition, T(θ,k1(θ,x))  ≥  T(θ,x). Since T(θ,  ·  ) is increasing for x  ≥  xθ it follows that T(θ,k)  ≥  T(θ,k1(θ,x))  ≥  T(θ,x), meaning that k∈Aθ,x.

k < k1(θ,x): it follows from the definition of k1(θ,x) that T(θ,k) < T(θ,x), so k∉Aθ,x.

In summary, if k  ≥  xθ then k∈Aθ,x if and only if k  ≥  k1(θ,x). An analogous argument shows that if k  ≤  xθ then k∈Aθ,x if and only if k  ≤  k2(θ,x), and the first part of the proposition follows.

To see that at least one of k1(θ,x) and k2(θ,x) is non-constant in θ, note that by B1, for any pair (x,y)∈X2 there exist (θx,θy)∈Θ2 such that x∉Aθx,y but x∈Aθy,y. The set Aθ,x is therefore not constant in θ, and thus at least one of k1(θ,x) and k2(θ,x) must be non-constant in θ.

Proof of Proposition [\ref=thm3]

(a) and (b) were proved in Section [\ref=lackofstrict]. We will now prove (c). Let Lα(x) and Uα(x) denote the lower and upper bounds of the interval. We will show that for any x∈X there exists an α0∈(0,1) such that Lα(x) and Uα(x) simultaneously are constant in a neighbourhood of α0, so that the confidence interval is not strictly nested.

We introduce the mutually disjoint sets

[formula]

which are such that [formula]. We also define

[formula]

By condition B1, given x∈X there exists θx∈Θ such that

[formula]

so Θ1(x) is non-empty. First, we investigate the behaviour of the bounds when either [formula] or Θu(x) is empty. Let α(x) be the closure of Θα(x). Since Θ1(x)  ⊆  α(x) for all α∈(0,1),

[formula]

If inf Θ1(x) =  inf Θ then [formula]. Then

[formula]

so Lα(x) =  inf Θ for all α∈(0,1). Similarly, if sup Θ1(x) =  sup Θ then [formula], and

[formula]

so Uα(x) =  sup Θ for all α∈(0,1). Thus, when [formula] is empty Lα(x) is constant and when Θu(x) is empty Uα(x) is constant. In this case, whether or not the interval is strictly nested therefore depends on whether there exists an α∈(0,1) such that the other bound is constant in a neighbourhood of α. We will therefore without loss of generality assume that neither [formula] nor Θu(x) are empty.

Let

[formula]

Since Aθ,x  ≠  X for θ  <   inf Θ1(x), by A1 [formula], and similarly αu < 1. Thus a point is added to or removed from Aθ,x at θ  =   inf Θ1(x) and θ  =   sup Θ1(x), and by Lemma [\ref=B4] the p-value function λ(θ,x) must have jumps at θ  =   inf Θ1(x) and at θ  =   sup Θ1(x). Then for [formula], there is an α1∈(α0,1) for which there exists δ > 0 such that

[formula]

Thus both the upper and the lower bound of Iα(x) are constant in a neighbourhood of α  =  α1, and the interval is not strictly nested.

An auxiliary lemma

The following auxiliary lemma will be used in the proof of Proposition [\ref=smallprop].

With X as in Proposition [\ref=smallprop], for any y,x∈X such that 0  ≤  y < x, let

[formula]

and define θx,x: =  inf Θ1(x). Under A2+ and B3+,

[formula]

Moreover,

[formula]

and

[formula]

First, we establish some facts about θy,x and the behaviour of T(θ,  ·  ) for such θ. If θ∈Θ1(x), then it follows from [\eqref=Aset] that T(θ,x)  ≤  T(θ,y). Thus, by [\eqref=lemma1] we have θy,x  ≤   inf Θ1(x), so by [\eqref=Thetas], [formula].

With xθ as defined in B3+ (i), T(θ,  ·  ) is increasing at x if x > xθ. If θ∈Θ1(x) then xθ = x. By B3+ (iii), xθ is an increasing function of θ. Thus, if θ  ≤   inf Θ1(x), i.e. [formula], we have x > xθ. Since [formula], T(θy,x,  ·  ) is increasing at x.

It now follows that for any y < x, T(θ,x) < T(θ,y) can happen only if T(θ,  ·  ) is decreasing at y. Whenever T(θ,x) < T(θ,y) and T(θ,  ·  ) is decreasing at y, we have T(θ,x) < T(θ,y) < T(θ,y - 1), and [\eqref=lemma4] follows since {θ:T(θ,x)  ≤  T(θ,y)}  ⊂  {θ:T(θ,x)  ≤  T(θ,y - 1)}.

Let x  ≥  1 be fixed. If θ  ≤  θ0,x then T(θ,x) < T(θ,0) and [\eqref=lemma4] ensures that T(θ,x) < T(θ,y) for all other y < x as well. [\eqref=lemma3] now follows from [\eqref=Aset].

Next, for some y < x, let [formula] be such that θ  >  θy,x. Under B3+ (ii) we have θ  <  θx∈Θ1(x), so T(  ·  ,x) is decreasing in [formula]. However, if T(θ,x) < T(θ,y) then y < xθ, so θ  ≥   sup Θ1(y). Thus θx,y  >  θy, implying that T(  ·  ,y) is increasing at θy,x. Thus T(θ,x) < T(θ,y) for all θ  >  θy,x. [\eqref=lemma3] and [\eqref=lemma2] now follow from [\eqref=Aset].

Proof of Proposition [\ref=smallprop]

We start by showing (b) and finish by proving (a). The proof of (c) is analogous to the proof of (b), and is therefore omitted.

(b) We wish to find the largest αL such that, for all x∈X, Lα(x) is strictly monotone in α when α  <  αL. For a given x, let αL(x) be the largest α such that Lα(x) is strictly monotone in α when α  <  αL(x). Then αL  ≤  αL(x) for all x, with equality for some x. We therefore show the statement by showing that αL(x) =  inf θ∈{θ:T(θ,0) > T(θ,x)}λ(θ,x) > 0.

As in the proof of Lemma [\ref=lemmat], it suffices to study [formula], where [formula] is defined as in [\eqref=Thetas].

(i) Let x  ≥  1 be fixed. If θ  ≤  θ0,x, defined as in [\eqref=lemma1], then by [\eqref=lemma3], Aθ,x  =  {k:k  ≥  x}. Thus, by [\eqref=Aset], λ(θ,x) = θ(X  ≥  x). The p-value function λ(  ·  ,x) is therefore non-negative (by A1), yielding (i).

(ii) λ(  ·  ,x) is strictly increasing (by A2+) and continuous (by A3). We extend the p-value function by defining [formula]. Then λ(θ,x) is a continuous strictly monotone bijection from the compact set [ inf Θ,θ0,x] to the compact set [λ( inf Θ,x),αL(x)]. It is therefore a homeomorphism, and it follows that its inverse Lα(x) is continuous and strictly monotone in α, which yields (ii).

(iii) From Lemmas [\ref=lemmat] and [\ref=B4] it follows that the first discontinuity in λ(θ,x) occurs at θ0,x. From Definition [\ref=def3] it follows that there exists an ε > 0 such that Lα(x) is constant in (αL(x),αL(x) + ε) if and only if λ(θ,x) > αL(x) for all θ∈[θ0,x, inf Θ1(x)].

By [\eqref=lemma2] for any θ∈[θ0,x, inf Θ1(x)], there exists a y < x such that θ∈[θy,x,θy + 1,x), so that

[formula]

where the first inequality follows from A1 and the second inequality follows from A2+. (iii) now follows.

(a) For any x∈X, let AL(x) denote the set of α for which Lα(x) is locally constant in α and AU(x) denote the set of α for which Uα(x) is locally constant constant in α. By definition, the largest α for which Iα(X) is strictly nested is

[formula]

Using Proposition [\ref=thm3] (c), [formula] has a connected uncountable subset for all x, so αnest always exists. By part (b) of Proposition [\ref=smallprop], αnest  ≥  αL > 0.

Proof of Proposition [\ref=proposition1]

By Proposition [\ref=thm3] (a) and A3, λ(θ,x) is a piecewise continuous function. By Lemma [\ref=B4] it is not continuous at the boundaries of the set Θ1(x). Hence λ(θ,x) can only be bimonotone if it is monotone whenever it is continuous. Each of its continuous parts can be represented by equation ([\ref=lambdaeq]) with fixed k1 and k2. Such a part can be written as

[formula]

By A2, [formula] is strictly increasing and [formula] is strictly decreasing. By condition A4 ([\ref=lambdaeq2]) equals 1 at the boundaries of Θ. If it is not constant it must therefore by condition A5 have a unique minimum in the interior of Θ. Rewriting the expression again, we have

[formula]

so that the minimum is given by the root θr of the equation

[formula]

that is in the interior of Θ. Next, we let k1 and k2 vary as functions of (θ,x) and use θr(θ,x) to denote the solution of [\eqref=root] with k1 = k1(θ,x) and k2 = k2(θ,x).

By Proposition [\ref=thm3] (a), λ(θ,x) has jumps corresponding to changes in k1(θ,x) or k2(θ,x). λ(θ,x) fails to be bimonotone if

[formula]

i.e. if it does not jump before the root θr(θ,x) that corresponds to (k1(θ,x),k2(θ,x)), since for [formula],

[formula]

Assume that θ∈Θu(x). Then λ(θ,x) should be decreasing in θ. If θ  >  θr(θ,x) then ([\ref=lambdaeq2]) with k1 = k1(θ,x) and k2 = k2(θ,x) is increasing, so that λ(θ,x) is not bimonotone. If instead we assume that [formula] so that λ(θ,x) is in its increasing part, we similarly get that λ(θ,x) is not bimonotone if θ  <  θr(θ,x). This establishes (a). Part (b) then follows from Proposition [\ref=propbim].

Proof of Proposition [\ref=fidpropr]

Let [formula] be the extended real line and [formula] be the closure of Θ. Let F(θ,x) = θ(X  ≤  x). By A1-A4, F(  ·  ,x) is a continuous monotone bijection from [formula] to [0,1] for all [formula]. Since [formula] and [0,1] both are compact, it follows that F(  ·  ,x) is a homeomorphism, which ensures that the bounds given by ([\ref=fidint]) are continuous in α. The monotonicity of Fθ(  ·  ,x) ensures that both F- 1θ(  ·  ,x) and the bounds are monotone, so that the interval is strictly nested.

Finally, by condition A3, the p-value function ([\ref=fidtest]) is continuous in θ when x∈X is fixed.