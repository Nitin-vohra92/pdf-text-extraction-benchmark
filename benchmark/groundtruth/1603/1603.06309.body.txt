Stochastic optimal control using semidefinite programming for moment dynamics

Introduction

Stochastic optimal control problems frequently arise in a variety of settings such as engineering, management, finance, ecology, etc. where a cost function is minimized by choosing the inputs to a stochastic differential equation [\cite=flemingcontrolled2006]. The solution to a stochastic optimal control problem is typically formulated using the value function approach [\cite=YongZhou99]. It turns out that aside from a few special cases such as linear quadratic control problems, it is generally not possible to find explicit solutions. For other problems, numerical methods are employed which require discretization of the state-space and time, incur significant computational cost, and generally suffer from the curse of dimensionality. Another prevalent approach to study nonlinear stochastic control problems has been to linearize the system to be able to apply the linear stochastic control methods[\cite=youngoptimal1988] [\cite=jumarie1996improvement] [\cite=Socha05]. However, in these methods it is difficult to get solutions with satisfactory accuracy as the linearization is only valid for small deviations.

Alternatively, one can transform the problem to moment-space wherein the cost function to be optimized is viewed as a function of moments of the state and control variables. Particularly when the cost function and the system dynamics are polynomial, the moment dynamics of the state is well characterized by linear ordinary differential equations, which allows one to study the problem as a deterministic optimal control problem. In [\cite=jumarie1995practical] [\cite=jumarie1996], this approach has been used for few examples considering the system dynamics to be linear. In general, when the system dynamics is nonlinear, the system of differential equations for moment dynamics become infinite dimensional.

Here, we provide a method to approximate the solution to stochastic optimal control problems wherein the system dynamics, and cost are polynomials. A lower bound for the optimal value of the cost function is computed using a semidefinite programming approach. Moreover, a polynomial control policy with time-varying coefficients can be extracted from the semidefinite program, using which an upper bound on the optimal value of the cost function can be computed via Monte Carlo simulations. The idea here is that if the difference between the upper and lower bounds is small, the controller extracted from the semidefinite program must be close to the optimal controller. Whereas for the systems for which moment dynamics is finite dimensional, the lower bound computed is unique; one can obtain an increasing sequence of lower bounds for a system with infinite-dimensional moment dynamics by increasing the number of moment equations and the number of constraints on the moment dynamics in the semidefinite program. For details on semidefinite programming, see [\cite=cominetti2012modern] [\cite=boyd2004convex].

The paper is structured as follows. Section [\ref=sec:problem] discusses the problem statement, introduces some examples that we use to illustrate the method proposed in the paper, and briefly describes the results. In Section [\ref=sec:momentdynamics], a system of ordinary differential equations characterizing the moment dynamics is derived for a stochastic differential equation. Section [\ref=sec:results] presents the main results of the paper. These results are illustrated via examples in Section [\ref=sec:examples]. In section [\ref=sec:conclusion], conclusion of the paper and some directions of future work are given.

Notation

Random variables will be denoted in bold: [formula], and [formula]. Non-random variables will be non-bold. For example, a specific value taken by [formula] would be denoted by x. The expected value of a random variable, [formula] is denoted by [formula].

Problem

Setup

This paper will provide a method to approximate the solution to scalar polynomial optimal control problems of the form:

Here [formula] is the state and [formula] is the control; [formula] and [formula] are polynomials that describe the system dynamics; [formula] are polynomials describing constraints; and [formula] is a Weiner process satisfying

[formula]

The control input [formula] is minimized over all Borel measureable functions that are adapted to the filtration generated by [formula]. Typically, there is no loss of generality in restricting the search to Markov control policies, i.e. policies of the form, [formula], where γ is a Borel-measurable function. For details, see [\cite=flemingcontrolled2006].

Since it is assumed that all of the functions, c, h, f, and g are polynomials, without loss of generality they can be expressed in the form:

A simple example where explicit solutions can be calculated is the linear quadratic regulator problem. For concreteness, a special case is given by See [\cite=brysonapplied1975] [\cite=lewisoptimal2008] for more detailed discussion of this problem.

Another problem, which will display some of the more interesting aspects of the problem is given by: Unlike the linear quadratic regulator problem, it is not clear how to compute exact solutions to this optimal control problem.

The previous examples had no constraints constraints of the form [\eqref=eq:polyConstraint]. Such constraints often arise in applications. For example, consider the modified version of the optimal fisheries management from [\cite=alvarezoptimal1998] [\cite=lunguoptimal1997] Here [formula] models the population in a fishery and [formula] models the rate of harvesting. As in the earlier works, a constraint that [formula] is required to be physically meaningful. Also, without this constraint, the optimal strategy would be to set [formula]. In other words, the objective would be unbounded without the constraint. The constraint that [formula] encodes the idea that fish are only being taken out, not put into the fishery.

The primary difference between this formulation and that of [\cite=alvarezoptimal1998] and [\cite=lunguoptimal1997], is that the cost is not discounted, and operates over a fixed, finite horizon.

Note that this is a maximization problem, but this is equivalent to minimizing the objective multiplied by - 1.

The systems are assumed to be scalars for notational simplicity. Vector systems could be considered at the expense of extra book-keeping.

Description of Results

Let [formula] be the optimal value of [\eqref=eq:polyCost]. For polynomial systems, this paper provides a method based on semidefinite programming to compute a lower bound on the optimal value, [formula].

Furthermore, a control policy of the form

[formula]

can be computed from the result of the semidefinite program. Let vp denote the value of [\eqref=eq:polyCost] resulting from this controller, which can be computed or estimated by simulations. It follows that

[formula]

While the true optimal value, [formula] is typically unknown, if [formula] is small, the controller from [\eqref=eq:uCompute] must be close to optimal.

Moment Dynamics of a Controlled SDE

This paper will derive lower bounds for the problem [\eqref=eq:polyProb] by solving an optimal control problem for the moments of [formula]. This section will derive differential equations for these moments.

If q(x) is a twice-differentiable, real-valued function, then the Itô formula implies that [\cite=oksendal03]

[formula]

Taking expected values of both sides results in a deterministic differential equation:

[formula]

The moments of [formula] and [formula] will be denoted by:

[formula]

When q(x) is a monomial, q(x)  =  xk, and f and g are polynomials, [\eqref=eq:ExpectationDiffEq] becomes a linear differential equation with respect to the moments.

Recall the dynamics from [\eqref=eq:cubicDyn]. Then [\eqref=eq:ExpectationDiffEq] has the form

[formula]

For q(x)  =  x, we have that [formula] and [formula]. Thus, the following holds:

[formula]

A similar argument shows that

[formula]

In this example, we see that the differential equation for μxt depends on the third moment, μx3t. More generally, the differential equation for μxkt depends on the higher moment, μxk + 2t. In this case, no moment, μxkt, can be described using a finite set of differential equations. In this case, it is said that the moments are not closed. Several moment closure methods have been developed to approximate moment dynamics using a finite number of differential equations both for discrete, and continuous state Markov models[\cite=socha2008linearization] [\cite=Kuehn16] [\cite=naasell03] [\cite=SinghHespanhaLogNormal] [\cite=SinghHespanhaDM] [\cite=soltani2015conditional]. Future work will involve combining the work in this paper with moment closure methods.

Results

Lower Bounds by Semidefinite Programming

The moment differential equations described in the previous section must be satisfied for any choice of input strategy for [formula]. Thus, they form a natural candidate for constraints in an optimization problem.

Another constraint arises from the fact that outer products are positive semidefinite, and this semidefinite constraint is perserved by taking expectations. For example:

[formula]

Furthermore, if the system has inequality constraints of the from [\eqref=eq:polyConstraint], then for any r  ≥  1, it must be the case that [formula], and thus the following must hold

[formula]

Recall the notation for the polynomials from [\eqref=eq:polyNotation]. The following theorem gives a lower bound of the original problem, [\eqref=eq:polyProb], based on continuous-time semidefinite programming.

For any integers K  ≥  1, [formula], dx  ≥  1, and du  ≥  1, the optimal value of [\eqref=eq:polyProb] is always at least as large as the optimal value of the following optimal control problem: In [\eqref=eq:momentIneq], the sums over [formula] range from 0 to nx, while the sums over [formula] range from 0 to nu.

The cost function, [\eqref=eq:momentObjective], is exactly, the original cost, [\eqref=eq:polyCost], expressed in terms of the moments. Given any policy for [formula], the moments of [formula] must satisfy [\eqref=eq:momentDyn] with initial conditions given by [\eqref=eq:momentIC]. If the system has inequality constraints, as in [\eqref=eq:polyConstraint], then [\eqref=eq:constraintMomentIneq] must hold. The constraint from [\eqref=eq:momentIneq] is exactly [\eqref=eq:constraintMomentIneq] written in terms of the moments.

The final constraint on the the matrix of moments, from [\eqref=eq:momentMat], expresses the following semidefiniteness constraint on the expected value of an outer product: Thus, for every policy, the moments of [formula] and [formula] must satisfy [\eqref=eq:momentMat]. Thus, the constraints [\eqref=eq:momentDyn], [\eqref=eq:momentIC],[\eqref=eq:momentIneq] and [\eqref=eq:momentMat] are satisfied by every feasible solution for [\eqref=eq:polyProb]. Since their cost functions coincide, [\eqref=eq:momentOpt] is a relaxation of [\eqref=eq:polyProb], and so its optimal solution is a lower bound to the optimal solution of [\eqref=eq:polyProb].

Recall that in some systems, as seen in Example [\ref=ex:cubicNonClosed], the moments are not closed. Thus, no finite number of moment equations will be sufficient to describe the dynamics exactly. In this case, [\eqref=eq:momentOpt] can be used to construct a sequence of increasing lower bounds by increasing the number of moment equations, K, and increasing the size of the moment matrix from [\eqref=eq:momentMat] correspondingly. The value of the lower bound increases because the feasible set becomes more constrained.

There is a large amount of flexibility in choosing the size of the semidefinite program in [\eqref=eq:momentOpt]. One sensible procedure for choosing the sizes is as follows. Fix dx and du. This will constrain the moment matrix from [\eqref=eq:momentMat] to be of size (1 + dx + du)  ×  (1 + dx + du). Then choose the number of moment differential equations, K, and the number of inequality constraints, [formula] to be the largest values such that every moment in the corresponding constraints is contained in the moment matrix. This procedure is used in the examples in this paper.

As with deterministic continuous-time optimal control problems [\cite=raosurvey2009], the cost integral, [\eqref=eq:momentObjective], can be discretized as a Riemann sum, and the dynamic constraints, [\eqref=eq:momentDyn], can be discretized using Euler integration. This results in a finite-dimensional semidefinite program. Reasonably sized problems, can be handled with off-the-shelf tools for numerical optimization [\cite=diamondcvxpy2016] [\cite=odonoghueconic2016]. Future work will developed specialized methods for solving this problem that take advantage of the specialized structure as an optimal control problem.

Constructing the Controller

This subsection will describe a procedure for computing a control strategy of the form in [\eqref=eq:uCompute] from a collection of moments of [formula] and [formula].

Assume that the [formula] is generated according to [\eqref=eq:uCompute]. Then for every k  ≥  0, the following holds:

[formula]

Given a collection of moments, as computed from [\eqref=eq:momentOpt], coefficients that approximately satisfy [\eqref=eq:gainConstraint] may be computed using least-squares optimization, with the following objective function:

[formula]

Of course, to pose this optimization problem, the number of moment differential equations, and the size of the moment matrix from [\eqref=eq:momentOpt] must be large enough so that all of the moments required for [\eqref=eq:pLSTSQ] are computed.

In practice, the coefficients, pi(t) are computed at the discrete time points at which the moments of [formula] and [formula] are computed.

The controller computed from [\eqref=eq:pLSTSQ] is a Markov policy, and thus feasible. As discussed in Subsection [\ref=sec:description], the value of the average cost produced by this controller will always give an upper bound on the true optimal value.

Examples

Recall the linear quadratic regulator problem from Example [\ref=ex:LQR]. This problem can be cast in the form of [\eqref=eq:momentOpt] as:

In this example, the moment equations are closed, since moments higher than 2 are not required to compute the solution. The classical theory of optimal control shows that the optimal solution to the original regulator problem is of the form where Lt is a gain computed from a Riccati differential equation. Using the Pontryagin maximum principle, it can be shown that the optimal solution to [\eqref=eq:LQRMomentProb] is given by:

[formula]

Recall the system from Examples [\ref=ex:cubicSys] and [\ref=ex:cubicMoments]. The cost function, [\eqref=eq:cubicCost] can be written in moment form as The problem can be approximated using [\eqref=eq:momentOpt] using this cost, as well as the moment dynamics from [\eqref=eq:cubicFirstM], [\eqref=eq:cubicSecondM], and [\eqref=eq:cubicKthM]. Recall that these moment equations are not closed. Thus, the optimal value can be approximated by solving [\eqref=eq:momentOpt] for increasingly large numbers of moment equations and increasingly large moment matrices.

For comparison purposes, Fig. [\ref=fig:cubicCTG] plots the cost-to-go function,

[formula]

for various sizes of the optimization problem in [\eqref=eq:momentOpt]. For sufficiently large semidefinite programs, an optimal value of 0.60 is obtained.

Using the least-squares method from Subsection [\ref=sec:construction], an order-3 controller was constructed from the solution to the SDP with K = 4 moment equations, and moment matrix dx = 3 and du = 1. (This corresponds to a moment matrix of size (1  +  dx  +  du)  ×  (1  +  dx  +  du)  =  5  ×  5.) Running 2000 trials with this controller resulted in an average cost of 0.67. Thus, the true optimal value is likely to lie between 0.60 and 0.67. In contrast, with no control, the average value obtained was 2.4.

Recall Example [\ref=ex:fisheries] on optimal harvesting for fisheries. This problem has moment dynamics given by

[formula]

As with the previous example, the moments are not closed. Furthermore, this problem has inequality constraints, which imply moment inequalities, [\eqref=eq:momentIneq], of the form for r  ≥  1.

A plot of the results of the SDP, [\eqref=eq:momentOpt], and a controller computed from the least squares procedure, [\eqref=eq:pLSTSQ], is shown in Fig. [\ref=fig:fisheries]. From these figures, we can see that a strategy that emerges as the SDP size increases. Through most of the horizon, harvesting is low and the population is kept near a constant level. Then, near the end of the horizon, a large harvest drives the population to 0.

Conclusion

This paper studied a method of solving stochastic optimal control using moment equations. The approach consists of formulating a semidefinite program, with constraints and cost function represented in terms of the moments. Several extensions of this work are possible. For example, it would be interesting to investigate whether by using an appropriate moment-closure for nonlinear systems, we can get a lower bound to the optimal value at low orders of moment truncation. Furthermore, several other works have used moment approximations in conjugation with other techniques for stochastic optimal control [\cite=crespo2002stochastic] [\cite=crespo2003stochastic] [\cite=xu2012moment] [\cite=xu2009nonlinear] [\cite=wojtkiewicz2001moment]. We would like to compare the performance of different controllers, including the computational cost of each.

Acknowledgments

A.S. is supported by the National Science Foundation Grant DMS-1312926.