Going the Distance: Mapping Host Galaxies of LIGO and Virgo Sources in Three Dimensions Using Local Cosmography and Targeted Follow-up

=-1

Introduction

Advanced [\citep=AdvancedLIGO] began operations in 2015 [\citep=AdvancedLIGODiscoveryDetectors] and almost immediately recorded the first ever signal from a merger, GW150914 [\citep=GW150914-DETECTION]. It should soon observe from binary mergers [\citep=LIGORates] too. These systems should present several kinds of transients that are detectable by existing and planned facilities (e.g., [\citealt=MostPromisingEMCounterpart]). Joint broadband observations would tell the full story of these rare events and solve longstanding puzzles from the nature of (; [\citealt=1986ApJ...308L..43P] [\citealt=1989Natur.340..126E] [\citealt=1992ApJ...395L..83N] [\citealt=2011ApJ...732L...6R]) to the astrophysical sites of r-process nucleosynthesis ([\citealt=2014MNRAS.439..744R] [\citealt=2015MNRAS.447..140V]; etc.) and enable these systems to be used as standard siren probes of the evolution history of the universe [\citep=StandardSirens1986] [\citep=StandardSirens2006] [\citep=StandardSirens2010]. [\citet=MostPromisingEMCounterpart] consider the radioactively powered  [\citep=kilonova] to be the most promising signature to find in coincidence with a event, though [\citealt=BarnesKasenKilonovaOpacities] have shown that the high optical opacities of the ejecta will cause this signature to be faint ([formula]) and red (r  -  i  ~  1) and to peak quickly, within days to weeks (e.g. [\citealt=KilonovaDiscWindsOutflows]). A consortium of partner gamma-ray, X-rays, optical, and radio facilities have embarked on an unprecedented campaign to search for counterparts of signals [\citep=S6LowLatencyImplementationAndTesting] [\citep=SwiftFollowupGWTransients] [\citep=S6Optical] [\citep=GW150914-EMFOLLOW].

localizations are currently ~  100-1000 deg2 [\citep=NissankeKasliwalEMCounterparts] [\citep=FirstTwoYears] [\citep=FirstTwoYearsRecolored] [\citep=BurstFirstTwoYears] and should shrink to ~  10-100 deg2 [\citep=LIGOObservingScenarios] over years of detector upgrades and construction of additional detectors: Advanced Virgo [\citep=aVirgo], KAGRA, and LIGO-India. Even the most accurate imaginable localizations of [formula] deg2 will be grossly larger than the [formula]-[formula] of CCD cameras that are common on the world's largest optical and infrared telescopes. Consequently, robotic and low-overhead synoptic survey telescopes with primary mirror diameters of 1-8 m and of up to tens of deg2 have been heralded as the most promising tools [\citep=MostPromisingEMCounterpart] for finding those fast and faint counterparts.

[\citet=CBCG] and [\citet=GWGC] recognized that targeting individual galaxies can reduce the area to be searched while eliminating false positive candidates. A galaxy catalog was central to the follow-up strategy during Initial [\citep=CBCLowLatency] [\citep=SwiftFollowupGWTransients] [\citep=S6Optical]. Although the increasing number of galaxies within the expanding range decreases the utility of this technique, [\citet=UtilityGalaxyCatalogsWideFieldTelescopes] and [\citet=KasliwalTwoDetectors] argued that using both sky positions and distance estimates from can still reduce the number of galaxies, especially in the early years when localizations are particularly coarse. [\citet=NissankeKasliwalEMCounterparts] showed that the region bracketed by the upper and lower limits of the 95% credible distance interval can reduce the volume, and hence number of galaxies, by a factor of 60%.

While the Advanced commissioning plan calls for several steps in sensitivity and range, parallel construction of additional detectors will result in shrinking sky localization uncertainty [\citep=Veitch:2012] [\citep=RodriguezBasicParameterEstimation]. Intriguingly, [\citet=GalaxyStrategy] point out that these effects roughly cancel each other, such that the typical error volume may scarcely vary over the next decade.

The obvious next step is to exploit the correlated structure of the reconstructed volumes. This immediately raises the questions: How accurately can distance be measured with detectors, particularly in the early two-detector configurations? What is the shape of the reconstructed volumes? What is the minimal amount of information that is needed to faithfully describe these volumes?

In [\citet=FirstTwoYears], we elucidated the localization areas and shapes that we expect in early Advanced and Virgo. In a similar spirit and using the same catalog of simulated events, we now reveal the shape, scale, and overall character of the reconstructed volumes--enabled by a new and extremely efficient encoding of the probability distributions. We provide a representative sample of volume reconstructions in a format that could be made available beginning with the second Advanced observing run. Complementing existing technologies to detect [\citep=Cannon:2011vi] [\citep=GW150914-GSTLAL] and localize [\citep=BAYESTAR] mergers within minutes of data acquisition, our approach can provide distance-resolved sky maps in near real time.

All classes of instruments can benefit from the new localizations, but they are especially powerful for conventional, large-aperture telescopes with narrow- instruments, and particularly at near infrared wavelengths, where large- cameras are scarce [\citep=VISTA]. Our galaxy-targeted strategy of monitoring the most probable ~  100 galaxies for several nights following a trigger could be implemented on large infrared facilities. However, even a pilot program on robotic 2 m telescopes could be surprisingly powerful for the first few Advanced -Virgo observing runs.

Distance constraints

The amplitude, or , of a signal is determined by a degenerate combination of inclination and distance. The Malmquist bias leads to a broad universal distribution of binary inclination angles, peaking at [formula] [\citep=ShutzThreeFiguresOfMerit]. The distance of a source can generally be estimated with ~  30% fractional uncertainty [\citep=1994PhRvD..49.2658C] [\citep=FirstTwoYearsRecolored].

The effective distance [formula] of a signal is the maximum distance at which it could have produced the observed . The horizon distance [formula] of a detector is the farthest distance at which the most favorably oriented source (at the detector's zenith, and with a binary inclination of [formula]) would register a threshold (generally defined as   =  8). We give approximate formulae for the horizon distance in Eqs. (1, 2) of [\citet=FirstTwoYears]. The range is the direction- and orientation-averaged distance of sources detectable at a threshold , [formula] [\citep=1993PhRvD..47.2198F] [\citep=ShutzThreeFiguresOfMerit].

The effective distance description has two major limitations. First, the source may sometimes lie beyond the effective distance because of measurement noise. Worse, there is no obvious way to describe the probability enclosed within, say, the 90% credible region on the sky and the effective distance; this number is always ≤  90%. Second, notwithstanding the large fractional distance uncertainty, there is nontrivial structure to the full reconstructed volumes that can be exploited to reduce the volume under consideration.

During , the network [\citep=LIGOObservingScenarios] consisting of and tends to produce probability sky maps consisting of one to two long, thin sections of a great circle [\citep=KasliwalTwoDetectors] [\citep=FirstTwoYears]. We provide this as an illustration of the main features for a two-detector network. We assume, as in [\citep=LIGOObservingScenarios], a range of 54 Mpc, though the range during was about 40% better. The corresponding geometry is shown in Figs. [\ref=fig:volume-rendering] and [\ref=fig:volume]. The degenerate arcs correspond to either one or two thin, rounded, slightly oblique petals, about 1-5[formula] wide, 10-100[formula] broad, and 10-100 Mpc deep. The "forked tongue" sky localization features due to the degeneracy of the sign of the binary inclination angle [\citep=FirstTwoYears] are evident as narrow crevices running along the outside edges of the petals. The shape irresistibly suggests a tree ear fungus or a seed of the jacaranda tree.

The configuration [\citep=LIGOObservingScenarios], may include and with improved sensitivity at a range of ~  100 Mpc, as well as Advanced Virgo, leads to more compact and elaborate combinations of petal-shaped regions. In the most favorable three-detector cases where the area on the sky is localized to a single compact region, the reconstructed volume is a spindle a few degrees in radius and ~  100 Mpc long.

Rapid volume reconstruction

Although the reconstructed regions are highly structured, the posterior probability distribution along a given is simple and generally unimodal--once again, a consequence of the Malmquist bias and the universal distribution of binary inclination angles.

This intuition leads us to suggest that the conditional distribution of distance is well fit by an ansatz whose location parameter [formula], scale [formula], and normalization [formula] vary with sky location [formula]:

[formula]

This form is equivalent to the product of a Gaussian likelihood and a uniform-in-volume prior. We show that this is a good fit in § of the [\citetalias=GoingTheDistanceSupplement].

The outputs of the -Virgo localization pipelines are () all-sky images whose [formula] pixels give the posterior probability ρi that the source is contained inside pixel i. We add three additional layers: [formula], [formula], and (for convenience) [formula]. The first layer, ρi, is unchanged and still represents the probability sky map.

The probability that a source is within pixel i and at a distance between r and [formula] is ρi times Eq. ([\ref=eq:conditional-distance-distribution-ansatz]):

[formula]

The sky map is normalized such that

[formula]

so Eq. ([\ref=eq:posterior-probability-distribution-ansatz]) is also normalized such that

[formula]

The r2 term is necessary in Eqs. ([\ref=eq:conditional-distance-distribution-ansatz], [\ref=eq:posterior-probability-distribution-ansatz]) so that the probability density per unit volume vanishes at the origin. Eq. ([\ref=eq:posterior-probability-distribution-ansatz]) should be thought of as the probability distribution in spherical polar coordinates. If, however, one needs to perform a calculation in Cartesian coordinates, one converts using volume element, given by

[formula]

The r2 cancels in the resulting probability density per unit volume:

[formula]

Sky maps for compact binary merger candidates are produced by two codes with complementary sophistication and speed. The first is , which rapidly triangulates matched-filter estimates of the times, amplitudes, and phases on arrival at the sites [\citep=BAYESTAR]. The second is LALInference, which stochastically samples from sky location, distance, and component masses and spins [\citep=LALInference]. Both methods directly sample the full posterior probability distribution. The ansatz parameters are extracted using the method of moments as elaborated upon in § of the [\citetalias=GoingTheDistanceSupplement].

Implications for early Advanced LIGO and Virgo

We use this encoding to demonstrate the utility of the structure of the posteriors. As an example, we minimize the total exposure time required to observe every galaxy within the 90% credible volume to a given flux limit. We neglect intrinsic scatter in absolute magnitude; the resulting conservative figure of merit allows us to focus on the effect of the distance posterior itself.

If mergers have hosts that are similar to , then their local rates are likely traced by a combination of recent star formation (measured by B-band luminosity) and stellar mass (measured by K-band luminosity; e.g. [\citealt=2010ApJ...725.1202L] [\citealt=2013ApJ...769...56F]). As in [\citet=GalaxyStrategy], we attempt to mitigate these concerns as the limited completeness of galaxy catalogs by considering only the brightest galaxies. If we assume a B-band Schechter function with α =  - 1.25, φ* = 1.2  ×  10- 2 h3 Mpc- 3, and L*  =  1.2  ×  1010 h- 2 [formula] [\citep=LongairGalaxyFormation] as a proxy for the merger rate, then we find that 2.8  ×  10- 3 galaxies per Mpc3 comprise half of the total luminosity (see Fig. [\ref=fig:mass-quantiles]). The areal density of galaxies out to a distance r and with a luminosity greater than L is

[formula]

at most a handful per deg2 within distances that are relevant for mergers.

As a proof of concept, in the right panel of Fig. [\ref=fig:volume], we show the potential host galaxies that are consistent with a simulated early Advanced localization. We use the galaxy group catalog of [\citet=2MASSGalaxyGroups]. This may not be an ideal galaxy catalog for follow-up; among other reasons, being derived from 2MASS, its magnitudes trace mass rather than recent star formation. Better alternatives that should be available in the near future include the Census of the Local Universe ([\citealt=GalaxyStrategy]; Cook et al., in preparation) and the Galaxy List for the Advanced Detector Era. However, pending the availability of larger compilations of galaxy catalogs, it serves to illustrate our idea because it is ~  ∼50% complete out to ~  150 Mpc. Furthermore, incompleteness is encoded self-consistently by placing a variable bandwidth weighted kernel at the position of each galaxy.

Our control observing strategy takes all galaxies within a given 2D credible region, out to an optimal direction-independent distance inferred from the estimated mass of the source, the loudness of the signal, and the sensitivity of the detectors. It employs the same exposure time for every galaxy. This naive construction is already more sophisticated than what is now available. However, it suffices here as the optimal naive galaxy selection if we provide only a single point estimate of the distance with the sky maps.

Different facilities demand different figures of merit. For [formula], most observations pick out single galaxies. In this case, the optimal selection of galaxies exploits both the upper and lower limits of the reconstructed volume, and the total exposure time is dependent on the number density of galaxies. For [formula], most observations pick out many galaxies; an exposure tuned to reach a fixed luminosity limit for a distant galaxy also captures all of the galaxies at intervening distances. In this case, we tune the exposure time to reach the most distant galaxy in each field, and the total exposure time is independent of the number density of galaxies. The instrument sensitivity is also important. In the source limited regime, the exposure time to reach a fixed limiting luminosity for a source at a distance r varies as r2. For sky background limited imaging, the time scales as r4. The three cases of greatest interest are summarized below:

[formula]

Here, T* is the time required to reach a fiducial flux limit for a source at a distance r*, φ is the average number density of galaxies, and ω is the of the instrument in steradians. The integral is over solid angle (case I) or volume (cases II and III) and is minimized over all possible regions D that contain 90% posterior probability. Table [\ref=table:medians] presents the results of this exercise: volumes, numbers of galaxies, and exposure times. Each case typifies a search for a different signature with a different kind of instrument:

Case I

describes a search with a synoptic optical survey instrument. We adopt the our example and assume a of 47 deg2. Adopting Mi  =   - 13 as the absolute magnitude of a , we derive from Table 1 of [\citet=KasliwalTwoDetectors] a fiducial exposure time of T*  ≈  6600 s for a limiting magnitude of i  ≈  23.5 at a distance of r*  =  200 Mpc. In , a -like survey would have taken ~  0.4 h to tile the entire region to an appropriate depth in exposures that average ~  2 min in duration. The number of exposures decreases to a handful in the HLV configuration in , but the exposure duration increases to 35 min per field.

Case II

models an afterglow search with the Swift (considered in detail by [\citealt=SwiftFollowupGWTransientsEvans]). Following [\citet=KannerSwiftLIGOFollowUp], we adopt a fiducial exposure time of T*  =  100 s at r*  =  200 Mpc. In , we find an average exposure time of 7 s per field, increasing to 25 s per field in . These are unrealistically short due to Swift's slew rate ([formula] s- 1) and overhead (25 s; [\citealt=SwiftFollowupGWTransientsEvans]). However, even adding an overhead of ~  30 s per galaxy, we suggest that a galaxy-targeted Swift campaign could be accomplished within a few 90-minute orbits.

Case III

describes a search with a traditional small optical telescope. Since we need to examine tens to hundreds of galaxies, we restrict ourselves to fully robotic telescopes dedicated to time-domain science and select the and Liverpool 2-m telescopes as our models. Using the exposure time calculator, we find an exposure time of T*  ≈  2500 s to reach a depth of i  =  23.5 mag at =5 during half moon phase on the Spectral camera. In we find an average exposure time of about 0.2 min, for a total exposure time of 0.4 hr. Overhead would dominate. The average exposure time increases to ~  2.5 min in . The total exposure time increases dramatically from 0.4 to over 13.4 h due to the rapid increase in exposure time with distance and the modest increase in the number of galaxies. However, the total exposure time is still short enough that two 2-m telescopes working in coordination could conceivably monitor all of the selected galaxies at a 1-2 night cadence.

Discussion

In order to focus on the utility of distance and structure information, we neglected several details. [\citet=LoudestGWEvents] addresses optimal selection of which events to follow up. We set aside the feasibility of imaging tens to hundreds of targets in rapid succession with Swift, though this is being implemented [\citep=SwiftFollowupGWTransientsEvans]. We ignored the question of whether the exposure time can be finely tuned from one target to the next, though our results justify doing so if possible. We ignored variation in observability conditions such as Sun and Earth avoidance, weather, passages, and Moon phase--details better left to a facility-specific paper. We did not consider optimizing field selection given limited time resources, for which we refer the reader to [\citet=ChanKilonovaDetectability].

We did not address the significant issues of galaxy catalog completeness, construction of a galaxy prior from an incomplete galaxy catalog [\citep=BayesianMultiMessenger], or the suitability of any particular galaxy catalog, though targeting the brightest and most massive galaxies (those with [formula]) should simplify these concerns [\citep=GalaxyStrategy].

[\citet=2MASSPhotoZLIGOOptimization] proposed using photometric redshifts to optimize follow-up, improving completeness at the expense of accurate distances. Improved completeness mitigates the concern that mergers like GW150914, which are probably formed in low-metallicity environments [\citep=GW150914-ASTRO], may display host environment preferences similar to long and probably do not track with massive galaxies. However, our present work focuses on binary mergers, which are expected to be found in fairly eclectic host environments due to the long time delay between formation and evolution of the binary and its -driven inspiral into the band. Therefore, the completeness of existing spectroscopic redshift surveys seems tolerable for our approach and for .

One possible concern for small- telescopes is the offsets that mergers may have from their host galaxies due to kicks. [\citet=LocationsShortGRBs] find that have a median offsets of 4.5 kpc from their hosts. For even an improbably nearby merger at z  =  0.005 or a luminosity distance r  =  22 Mpc, the projected radius of the [formula] is 74 kpc, and of the [formula] imager, 31 kpc, encapsulating well over 90% of offsets.

In principal, our exposure time estimates should account not only for sky background, but additional image subtraction background due to the light of the host galaxy. Offsets should help here too because are typically found at separations > 1.5 times the effective radii of their host galaxies.

One particular advantage of galaxy-targeted searches is the reduction in false positives. In a magnitude-limited snapshot, of Types Ia, Ibc, and II are found in proportions of 68.6%:4.3%:27.1% [\citep=LickSNRateII]. Assuming a volumetric rate of [formula] Mpc- 3 yr- 1 [\citep=LickSNRateII], an average absolute magnitude of -19 over a duration of 1 week, and a limiting magnitude of 23.5, we calculate an areal rate of about 2 Type Ia per deg2. A typical wide-field follow-up campaign searching an area of ~  100 deg2 will be contaminated by hundreds of . However, if we consider only [formula] patches around 100 nearby galaxies, the on-sky footprint of < 3 deg2 translates to a background of merely 6  Ia and 3 core-collapse .

This points toward a new role in follow-up for small-, large-aperture telescopes, in addition to and beyond their role of vetting candidates identified by synoptic surveys. Setting aside scheduling and proposal processes for the time being, suitable facilities for our strategy should have primary mirror diameters of 4-10 m and optical or infrared imagers with [formula] that are either permanently installed at one of the foci or are rapidly deployable (e.g., mounted on Nasmyth platforms). Candidates include ALFOSC on the Nordic Optical Telescope, LMI on the Discovery Channel Telescope, WIRC on the Hale Telescope at Palomar, FourStar on Magellan, GMOS on Gemini North and South, FLAMINGOS-2 on Gemini South, FORS2 on VLT, LRIS at Keck, or GTC equipped with OSIRIS. As a pathfinder, we encourage deploying existing 2-m class robotic optical telescopes in this manner during the early Advanced and Virgo observing runs.