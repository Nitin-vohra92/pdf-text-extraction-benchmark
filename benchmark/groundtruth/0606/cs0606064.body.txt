Improved Exponential Time Lower Bound of Knapsack Problem under BT model

Key Words:   Knapsack Problem, Exponential Time Lower Bound, Restricted Models of Algorithms

introduction

Many combinatorial optimization problems are NP-complete and probably have no polynomial time algorithms[\cite=Garey1979]. It is presumed that there are only exponential time algorithms for these problems, however, this has not been proved. It is very hard to prove exponential time lower bound for these problems under universal model of algorithms, unless prove P  ≠  NP. Nevertheless, under some restricted model of algorithms, it is possible to prove exponential lower bounds for NP-complete problems. Alekhnovich et al have proposed a restricted model of algorithms, called BT model, which covered greedy algorithm, backtrack and simple dynamic programming [\cite=Alekhnovich2005], and have proved exponential lower bound for Knapsack, Vertex Cover and SAT under this model. In this note, we slightly improved their lower bounds of exact and approximation algorithms for Knapsack problem under the adaptive BT model.

A Glimpse on BT model

In this section we quickly recall the relevant notions from BT models [\cite=Alekhnovich2005].

A description of BT model

A combinatorial optimization problem P is represented by a set of data items D and a set of choices H. Each data item represents a partial structure of an instance. The set of choices contains all the possible choices which can be applied to data items. For example, in Knapsack problem, each item can be a data item and "chosen to be in the knapsack" and "chosen not to be in the knapsack" can be the set of choices. In the following, O(S) denotes the set of all the orderings of all the elements in S.

A BT algorithm A to a problem P is comprised of an ordering function rkA and a choice function ckA:

[formula]

is the ordering of unprocessed data items made by algorithm after the first k data items has been processed;

[formula]

represents the constraints made by algorithm when it makes choice for the k + 1th item according to the processed k data items and the choices for them. The algorithm consider only the choices before [formula]. If rkA is a constant function and does not depend on Dk or Hk, then it's called fixed. If rkA depends on Dk but not on Hk, then it's called adaptive. If rkA depends on both Dk and Hk, then it's called fully adaptive. In this note, only adaptive BT algorithm is considered.

Lower bound strategies for BT model

The lower bound strategies for BT model takes the form of a game between the adversary and the solver(the BT algorithm)[\cite=Pudlak2000]. In the game, since at the beginning the solver cannot see all the input data items, so the adversary always tries to produce a difficult problem instance for the solver. The game can be viewed as a series of rounds. The ith round is composed of three parts: Pi, PIi and Ti(i = 0,1,2...). Pi is the finite set of data items owned by the adversary which cannot be seen by the solver in the ith patter. PIi is the set of data items representing a partial instance of the problem which have been seen by the solver in the ith pattern. And Ti is the set of partial solutions to PIi. See figure [\ref=chap2:update:2_1].

At the beginning of the game, the solver gives an ordering rule on the input data items. And the adversary constructs rule of deleting data items according to the solver's rule and gives P0. In this pattern, PI0 is empty and T0 is also empty. In the ith[formula] pattern, solver picks a data item a from Pi - 1 and add it too PIi - 1, and gets [formula]. Then computes Ti in which every solution is an extension of some solution in Ti - 1. Then adversary deletes a from Pi - 1 and some other data items and gets Pi. This process continues until Pi is empty. In the last pattern, if PIi is not a valid instance or Ti contains the optimum solution of PIi, then solver wins, or else adversary wins.

If the set of all the solutions to PIi can be classified to some equivalent classes and for any partial solution PS to any equivalent class, there exists an instance [formula] so that every optimum solution of A contains PS, then PS is called "indispensable". If there exists a pattern in which the number of all the indispensable solutions is exponential with the scale of the problem, then the exponential lower bound of the problem can be achieved under the fixed or adaptive BT model.

Improved lower bound of Knapsack

In this section we give the improved exponential lower bounds of exact algorithm and approximation algorithm on Knapsack under adaptive BT model. This improvement is obtained by setting parameters differently in original proofs in the work of M.Alekhnovich et. al [\cite=Alekhnovich2005].

Knapsack Problem

Input: n pairs of non-negative integers, (x1,p1),...,(xn,pn) and a positive integer N. xi represents the weight of the ith item and pi represents the value of the ith item. N is the volume of the knapsack.

Output:

Simple Knapsack Problem

Input: n non-negative integers {x1,...,xn} and a positive integer N. xi is the weight and value of the ith item and N is the volume of the knapsack.

Output:

Simple Knapsack problem is also NP complete[\cite=Garey1979]. So it is only needed to prove the exponential lower bound for simple Knapsack. In the following, we denote a simple Knapsack problem with n items and knapsack volume of N with (n,N).

Lower Bound of Exact Algorithm

M.Alekhnovich et. al proved the following theorem in [\cite=Alekhnovich2005].

Theorem 1. For simple Knapsack problem (n,N), the time complexity of any adaptive BT algorithm is at least

[formula]

Next we prove the following theorem.

Theorem 2.For simple Knapsack problem (n,N), [formula] when N > N0, the time complexity of any adaptive BT algorithm is at least

[formula]

Proof: Let [formula], all the weights of the items are from I.

This is an constructive proof containing three steps.

Step 1.

Solver chooses the first (2 - ε)n / 3 items. After each, adversary deletes some items from the remaining by the following two rules. Let S be the set of the items which have been seen by the solver.

(1) If S1,S2  ⊆  S, then delete items with weight of [formula];

(2) If S1  ⊆  S, then delete items with weight of [formula];

Step 2.

Let P be the set of the first (2 - ε)n / 3 items chosen by solver. Now we prove: [formula] and [formula] and [formula]. See figure [\ref=chap3:update3_3]:

[formula], let [formula] (later we will prove J  ⊂  I). Adversary chooses [formula] items in J. After each, adversary will delete some items from the remaining by the following two rules. Let S be the set of items chosen by solver and adversary.

(1) If S1,S2  ⊆  S, then delete items with weight of [formula];

(2) If S1  ⊆  S, then delete items with weight of [formula];

Let the sum of the weighs of these [formula] items be w. Then the adversary can choose items with weight bigger or smaller than a so that

[formula]

Step 3.

Adversary choose a pair of items from the following U + 1 pairs(later we will prove they are in I), such that the weight of these two items and the weight of the previously chosen items sum to N:

[formula]

in which [formula].

Since in the process of choosing items, the number of all the items does not exceed n, let this number be nt. Order these nt items by a fixed order, then every item corresponds to a single bit of a nt-bit 0-1-(-1) string. And every such string corresponds to a deleted item in the previous process. In detail, let the sum of the weights of items corresponding to 1 in the string be s1, and let the sum of the weights of items corresponding to -1 in the string be s- 1. If s1 - s- 1 > 0, then delete item with weight of s1 - s- 1 > 0; if s1 = 0, then delete item with weight of N - s- 1 > 0. So the number of the deleted items does not exceed U. So in these U + 1 pairs of items, there must be one pair which is not deleted. Then we can choose this pair in the third step.

Next we prove all the weights of the chosen items are in I.

Because

[formula]

and

[formula]

so

[formula]

clearly,

[formula]

Since

[formula]

[formula]

and

[formula]

so

[formula]

that is

[formula]

So in the third step, the possible lightest and heaviest items are [formula] and [formula]. So in order that all the items chosen in the third step are from I, it is only needed that

[formula]

that is

[formula]

So it is only need that [formula]. In fact, [formula] is also sufficient to J  ⊂  I.

Next we prove that solver must keep all Q in P as partial solution in the computation tree, or else adversary can let the solver cannot find the optimum solution.

We use the reduction to absurdity. Let Q1,Q2  ⊂  P and |Q1| = |Q2| = (2 - ε)n / 6. R1 and R2 correspond to Q1 and Q2 respectively. If solver does not keep Q1, then adversary deletes all the items except R1. If solver keeps Q2 to get the optimum solution, then there are only three cases(see figure [\ref=chap3:update:3_4]):

1) [formula]

The optimum solution N cannot be achieved in this case.

2) [formula]

So [formula]. This is impossible. Since according to the first rule in the first step, the last chosen item in the first step which is contained in Q1 or Q2 but not both cannot be chosen in the first step.

3) [formula], that is [formula]

Assume R1' is a subset of R1 and it leads to the optimum solution with Q2. Then there are two cases:

3.1) there is only one item in R1 - R1'

According to the first rule in the first step, this item should be deleted.

3.2) there are two or more than two items in R1 - R1'

If there is only one item in R1 - R1' which is chosen in the third step, then according to the first rule in the second step, it should be deleted.

If there are two items which are chosen in the third step, then all the items in R1' are chosen in the second step. Let the choosing order of these items be i1,...,is, then according to the second rule in the second step, the last item is should be deleted.

So every Q in P is indispensable. So the time complexity is at least

[formula]

[formula]

Lower bound of approximation algorithm

M.Alekhnovich et. al proved the following theorem in [\cite=Alekhnovich2005].

Theorem 3. For simple Knapsack problem, using adaptive BT algorithm, to achieve 1 - ε approximation ratio, the time complexity is at least Ω((1 / ε)1 / 3.17).

Next we prove the following theorem:

Theorem 4. For simple Knapsack problem, using adaptive BT algorithm, to achieve 1 - ε approximation ratio, the time complexity is at least Ω((1 / ε)1 / 2.38).

Proof:In theorem 2 we proved that for given [formula], the time complexity of simple Knapsack problem is [formula]. So the optimum solution cannot be achieved by algorithm with complexity of [formula]. Since the weight of item is integer, so the upper bound of approximation ratio is

[formula]

so

[formula]

For [formula], let [formula]. So we can set the weights of n - n0 items in the n items to 0.

[formula]

Discussion

In this paper, we slightly improved the exponential time lower bounds of exact and approximation algorithms under adaptive BT model for Knapsack problem which are [formula] and Ω((1 / ε)1 / 2.38)  ≈  Ω((1 / ε)0.420).

We do not know whether our lower bounds are optimal. An interesting question is: what are the best achievable lower bounds for Knapsack problem under adaptive BT model?