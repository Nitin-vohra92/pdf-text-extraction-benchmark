=1

On Solving Non-preemptive Mixed-criticality Match-up Scheduling Problem with Two and Three Criticality Levels

INTRODUCTION

The communication buses in modern vehicles are an essential part of advanced driver assistants. Those systems depend on the data gather by sensors, such as LIDAR, cameras, and radars. The data about the surrounding environment are communicated through communication buses to ECUs (Electronic Control Units) where they are processed, and appropriate actions are taken. For example, if an obstacle is detected in front of the vehicle, the car starts break automatically. Not only driver assistants rely on the communication. Different ECUs are responsible for running car as a whole. The fuel is injected accordingly to the current combustion and outside conditions, mod- ern cars with drive-by-wire system steer via electronic signals, even the windows are controlled by the central infotainment system.

The modern vehicle is considered as a fault-tolerant and dependable system. If one part of it breaks or does not work as expected, the human life is threatened. Since the intra-vehicular communication is the key element of the car, it is subject to safety certification. Safety certification is a process, where the manufacturer proves that his safety-critical systems such as autonomous driving are working correctly to a high degree of assurance. If they are not able to demonstrate the correct behavior of the central communication bus, then the whole certification process breaks down.

Traditionally, event-triggered communication protocols such as CAN (Controller Area Network) are commonly used. In the event-triggered environment, the actions are performed on-demand, i.e. triggered by some event. The communication is governed by scheduling policies that react to the observed situations during the run time execution. The capabilities of driver assistance systems are rapidly improving; hence the amount of data transferred through the network in a vehicle is growing. Traditional event-triggered protocols like CAN were not designed for a high data throughput; therefore their usage in modern cars is limited. Moreover, the response time analysis (i.e. the analysis of the behavior of the system) in real-life event-triggered communication systems including gateways and precedence relations is a very complex problem, therefore the safety certification of systems utilizing event-triggered environment is a difficult task.

Messages in time-triggered communication are transferred through the network at specific times prescribed by a static pre-computed static schedule. When constructing the schedule, a designer imposes a set of constraints the communication that is met in every feasible solution to the scheduling problem. Therefore, the certification of the system is be achieved via showing the feasibility of the produced communication schedule. This advantage of time-triggered environments leads to the design of new protocols that includes time-triggered communication for safety-critical systems. For example, FlexRay bus is used nowadays in the automotive industry (e.g. Porsche Panamera, Nissan Infinity Q50). The scheduling of FlexRay static segment can be solved very efficiently due to [\cite=dvorak2016using]. Moreover, the modern time-triggered buses such as Time-Triggered Ethernet [\cite=kopetz2005time] offer a high throughput and determinism guarantees and enable applications like valet parking and autonomous driving.

One of the disadvantages of time-triggered protocols is their non-flexibility. For example, the static schedule does not take into consideration the message retransmission. The retransmission occurs when a highly critical message is not delivered e.g. due to electromagnetic noise. Typically in the complex systems functionalities with different criticality co-exists on a single bus. Suppose a typical case in a car with messages with three different levels of criticality:

messages with high criticality (criticality level 3) are used for safety-related functionalities (their failure may result in death or serious injury to people), such as steering and braking;

messages with medium criticality (criticality level 2) are used for mission-related functionalities (their failure may prevent a goal-directed activity from being successfully completed), such as combustion engine control;

messages with low criticality (criticality level 1) are used for infotainment functionalities, such as audio playback.

Possible solution how to enable message retransmissions in static time-triggered schedules is to allocate more processing time for each message to account for possible retransmissions. If no retransmission occurs during an actual execution, then the resource is idle until the start time of the next message. However, since retransmissions are not that frequent, the average resource utilization is low.

We use a different strategy. We build static schedules that allow message retransmission to some degree. Extra time needed for retransmissions is compensated by skipping less critical messages (e.g. in our example, breaking versus audio playback). Even though this is a very elegant solution that achieves efficient resource utilization, the price we pay for it is that it modifies traditional scheduling problem into the challenging one - the schedule has to assume alternative schedules based on the observed runtime scenario. There is an exponential number of possible runtime scenarios, and for each of them, the static schedule needs to be well-defined.

For this automotive application, the criticality of a message corresponds to its maximum number of possible (re)transmissions. See an example of a static schedule that accounts for retransmissions in Fig. [\ref=fig:feasible]. There T2 and T3 have low criticality, and no retransmissions are allowed. T1 and T5 correspond to messages with medium criticality; thus they can be re- transmitted once. The most critical message is T4, that can be retransmitted twice. The retransmission of the messages causes a prolongation of the processing time that depicted in levels on the vertical axis. The top level of each message represents its WCET (the worst case execution time), so this is the time that it takes to transmit the message under the most pessimistic conditions. The prolongations are compensated by skipping less critical messages. With this mechanism, the successful transmission of highly critical messages is guaranteed while in the average case runtime scenario the resource (i.e. communication bus) is efficiently utilized. Schedules with three criticality levels arise from the application in the automotive domain. The adaptation of IEC 61508 safety standard [\cite=bell2006introduction], the ASIL, defines the application levels with a hazard assessment corresponding to three Safety Integrity Levels.

Scheduling of safety-critical messages on this time-triggered network can be modeled as a scheduling problem where tasks having a set of different processing times represent messages, and the resource is a communication channel in the network. A solution of the scheduling problem is given by a schedule that switches to the higher criticality level when a prolongation of a task occurs. After its successful completion, it matches-up with the original schedule. The trade-off between the safe and efficient schedules is achieved by skipping less critical messages when the prolongation of a more critical one takes place.

The problem of mixed-criticality message retransmission in time-triggered environments leads to an interesting combinatorial problem, where we are given a set of shapes that are aligned on the left side with the right side that is jagged (see an example in Fig. [\ref=fig:feasible]). The goal is to pack these shapes as tight as possible so that they do not overlap.

Contribution and Paper Outline

In this paper, we solve the scheduling problem of message retransmission in time-triggered environments. The objective is to find a static schedule that accounts for unforeseen message retransmissions while minimizing the length occupied by time-triggered communication. The uncertainty about the processing time is modeled using an abstraction that considers F-shaped tasks. We show the relation be- tween F-shaped tasks and the underlying probability distribution functions. Furthermore, we show a new complexity result that establishes the membership of the considered problem into [formula] complexity class, and we provide an approximation algorithm. We study the characterization of the set of optimal solutions for the problem with two criticality levels. Finally, we propose efficient exact algorithms for problems with two and three criticality levels, which solve instances with up to 200 tasks, beating the best-known method by a large margin.

The rest of the paper is organized as follows. In Sec. [\ref=sec:relwork] we survey the related work. In Sec. [\ref=sec:mcproblem] we show the relation between F-shaped tasks and discretization of cumulative probability distribution functions. In Sec. [\ref=sec:genprop] we prove approximability of the problem. In Sec. [\ref=sec:two] and [\ref=sec:three] we show properties of the problem with two and three criticality levels and we propose efficient exact algorithms. Finally, in Sec. [\ref=sec:results] we present computational results on sythetic data demonstrating the efficiency of the proposed approach.

RELATED WORK

The exhaustive survey on mixed-criticality in real-time systems is presented by [\cite=burns2013mixed]. This research is traditionally concentrated around event-triggered approach to scheduling. In the seminal paper [\cite=vestal2007preemptive] Vestal proposed a method that assumes different WCETs (the worst case execution time) obtained for discrete levels of assurance. Apart from this proposition, the paper presents modified preemptive fixed priority schedulability analysis algorithms. However, the preemptive model is not suitable for communication protocols, and it significantly changes the scheduling problem. [\cite=baruah2010towards] formulated the basic model of mixed-criticality systems. They study MC schedulability problem with two criticality levels under special restrictive cases in the event-triggered environment. [\cite=theis2013schedule] argued that mixed-criticality shall be pursued in time-triggered systems. Baruah's approach [\cite=baruah2011certification] in the time-triggered environment assumed preemptive tasks with up to two criticality levels. It makes it unsuitable for communication protocols since the preemption would be costly. [\cite=hanzalek2016mc] proposed the problem of non-preemptive mixed-criticality match-up scheduling motivated by scheduling messages on a highly used communication channel. They showed how a schedule with F-shaped tasks can be used to deal with a task disruption by skipping less critical tasks. They provide the relative order MILP model for [formula] scheduling problem, but it can deal with instances with only about 20 messages.

The concept of match-up scheduling was introduced by [\cite=bean1991matchup]. In a case of a disruption, the goal is to construct a new schedule that matches the original one at some point in the future. This concept is mostly studied in the context of manufacturing problems [\cite=qi2006disruption].

Taking broader perspective, the problem can be viewed as a case of robust and stochastic optimization due to uncertainty about transmission times while satisfying safety requirements. [\cite=bertsimas2011theory] surveys robust versions of various optimization problems, but rather continuous than discrete ones. The field of stochastic optimization is reviewed by [\cite=sahinidis2004optimization]. They state that integer variables introduced to stochastic programming complicate its solution, yielding suboptimal results even for small-sized problems.

As in our problem, some of the less critical messages are allowed to be skipped, the problem is related to the scheduling with a job rejection. [\cite=shabtay2013survey] reviews offline scheduling with a job rejection. These approaches consider two criteria, a measure associated with schedule quality and the cost incurred by rejected jobs. The solution to this problem is a set of accepted jobs and a set of rejected jobs. However, rejected jobs cannot be executed in any execution scenario; thus this model is not suitable for communication protocols mentioned in our motivation. Our problem also embeds scheduling with setup times. [\cite=allahverdi2015third] shows that problems with sequence-dependent (i.e. where a setup time is given for a pair of consecutive tasks) setup times are mostly studied. However, in our problem the feasible start time of a task depends on a permutation of all preceding tasks, not just the immediate predecessor; therefore it represents a more general problem.

To the best of our knowledge, the problem of offline non-preemptive mixed-criticality match-up scheduling was addressed by [\cite=hanzalek2016mc] only, but it lacks an efficient solution method which is suggested in this paper.

NON-PREEMPTIVE MIXED-CRITICALITY SCHEDULING

We assume that a set of communication messages is given to be scheduled on a single communication bus segment. For each message Ti, the criticality [formula] is specified. It denotes the number of allowed transmissions. Each message (task) is specified by its criticality levels. For each criticality level [formula], we define the associated processing time with this level. See an example in Fig. [\ref=fig:feasible]. Here, T1 has criticality X1  =  2; therefore it can be retransmitted once. The processing time at the first level is given by its BCET (the best case execution time) while the processing time at the second level is its WCET (the worst case execution time). During the run time execution, exactly one processing time of the message is realized; however, it is not known in advance which it will be.

We can view processing time prolongations as a retransmission of the whole message content. However, this mixed-criticality scheduling model is useful also for scheduling of computational tasks, where the exact computational time is not known in advance, but only a probability distribution is known. Let us consider the processing time of task Ti to be a random variable Ti. Let us assume an arbitrary probability distribution over a discrete set of processing times from [formula] for a particular task stating [formula]. The same information given by the probability distribution is captured by the CDF (cumulative distribution function) Fi giving the probability that processing time Ti is at most t. See Figs. [\ref=fig:pst_pdf] and [\ref=fig:pst_cdf] for such an example. Corresponding processing times [formula] for each criticality level [formula] are taken from Fi as [formula], where F- 1i is the quantile function. The criticality of a task is a user-defined parameter. For example, if we identify criticality levels with a safety standard IEC 61508 SIL (Safety Integrity Levels) [\cite=bell2006introduction], then the task criticality Xi is given by the SIL of the functionality carried out by the content and [formula] is defined as 1 - probability of failure defined by SIL [formula].

Processing times obtained according to criticality levels then form a single task like the one depicted in Fig. [\ref=fig:fshape]. Since CDFs are non-decreasing functions, a set of processing times [formula] yields shapes like the F letter rather than ordinary rectangles, hence the name F-shape. See an example in Fig [\ref=fig:disretization]. There we see discretization for a task with criticality three at corresponding levels 1, 2 and 3 with the vertical axis on the logarithmic scale.

Execution Policy

The solution to the scheduling is a feasible static schedule of the given set of F-shaped tasks. Consider a particular example of the schedule with tasks having up to three levels of criticality that is shown in Fig. [\ref=fig:feasible]. A feasible schedule with F-shaped tasks describes alternative schedules for any realization of the processing time of messages. Observed prolongations of more critical messages are compensated by skipping execution of less critical messages.

The black line denotes a scenario, where T1 was disrupted once. The actual processing time of T1 was 9 instead of 5 due to a disturbance. When the disruption occurred, execution switched to the next higher criticality level. There, by the assumption, the execution was successful with a probability given by the [formula] criticality level. After upon T1 finished, the execution matched-up back with the lowest criticality level. In general, if a task Ti is prolonged to level [formula], then all tasks Tj for which [formula] are not executed. Therefore, in this execution scenario, after T1 finished, T4 was up next. Moreover, if we unify the F-shape from Fig. [\ref=fig:fshape] with task T4 in Fig. [\ref=fig:feasible], then we can say that T5 will be executed with very high probability of 0.99, but in rare cases, it won't be executed since T4 is more critical and needs more time to complete.

PROBLEM STATEMENT

We assume a set of non-preemptive F-shaped tasks [formula] to be processed on a single machine. We define an F-shaped task and its criticality as follows: The F-shape is an abstraction for non-preemptive tasks with multiple different processing times. See for example T4 in Fig. [\ref=fig:feasible]. It is F-shaped task with criticality X4  =  3; therefore it has 3 different processing times. Having a set [formula] of F-shaped tasks, we define the feasible schedule as follows: Feasibility of a schedule with F-shaped tasks requires that tasks do not overlap on any criticality level. For example in Fig. [\ref=fig:feasible], since T5 follows after T4, it cannot start earlier than s4  +  p(2)4, since min {X4,X5}  =  2 is the highest common criticality level of T4 and T5.

We deal with the problem of finding a feasible schedule for a set of F-shaped tasks with criticality at most L such that the makespan (i.e. max si  +  p(Xi)i) is minimized. In the three-field Graham-Blazewicz notation it is denoted as [formula], where mc = L stands for the mixed-criticality aspect of tasks of maximal criticality L and mu stands for the match-up. This problem is known to be [formula]-hard in the strong sense even for mc = 2 (two criticality levels) as shown by reduction from 3-Partition Problem in [\cite=hanzalek2016mc].

GENERAL PROPERTIES

Since the problem [formula] is strongly [formula]-hard, it does not admit FPTAS unless P  =  . However, we show that the problem is polynomial-time approximable within a constant multiplicative factor.

For any given fixed L, the problem [formula] is contained in [formula] complexity class.

Suppose the algorithm LCF (Least Criticality First) that takes an input instance [formula] and schedules tasks in a non-decreasing sequence by their criticalities without waiting. Then the makespan of resulting schedule is A sum of processing times on a given criticality level over a set of tasks is a lower bound on the makespan. Therefore we have where [formula] denotes the optimal makespan of [formula] problem instance.

In fact, this result shows more than that there exists a polynomial-time algorithm producing schedules with a constant bounded quality. For example, for the problem with L = 2 criticality levels, actually any left-shifted schedule will be at most twice as worse as the optimal makespan since LCF actually produces the worst ordering of tasks in terms of the makespan.

In the following sections, we present exact algorithms for the problem with 2 and 3 criticality levels. Due to the [formula] criterion, it can be shown that the search for an optimal solution can be reduced to finding a permutation of tasks. Therefore, any optimal schedule is given by a permutation of tasks π. Hence we denote the makespan of the left-shifted schedule of permutation π by [formula]. In Section [\ref=sec:two] we give a characterization of the set of optimal permutations for problem [formula] and we introduce a MILP model utilizing it. In Section [\ref=sec:three], we introduce an operator acting on F-shapes, and we show how the optimal solutions for problems with two and three criticality levels are related.

TWO CRITICALITY LEVELS

We showed that optimal solutions to [formula] are given by a permutation π of tasks. For the problem with two criticality levels, the optimal permutations can be characterized more precisely. Let us refer to tasks with criticality Xi  =  2 as Hi-tasks and tasks with criticality Xj = 1 as Lo-tasks. The key structure of the optimal permutations are covering blocks:

See an example in Fig. [\ref=fig:feasible]. There T1 is covering T2 and T3. All these tasks form a covering block. Although the definition of covering block given above is meant for the problem with two criticality levels, the notion of covering can be generalized for more criticality levels. We assign a length to each covering block. The length is given as the maximum between the processing time p(2)i of the Hi-task Ti and the sum of processing times of tasks covered by Ti plus the processing time of Ti at the first level p(1)i.

Given the covering block Bi, its length defined as

[formula]

is invariant with respect to the ordering of Lo-tasks Tj for which [formula].

Clearly, the ordering of Lo-tasks Tj for which [formula] does not affect the block length since all Lo-tasks are running without waiting. Furthermore, we say that task Tj is fully covered by the block Bi, if Bi  =  p(2)i and [formula]. If exists a task covered by the block Bi that is not fully covered, then we say that Bi is saturated. The makespan Cmax of the schedule is given by a permutation of covering blocks. However, actually any permutation of covering blocks contributes to the makespan by the same amount; hence it is not subject to optimization.

For every instance of the problem [formula] there exists an optimal solution that is given by an arbitrary permutation of covering blocks.

A characterization of optimal solutions for [formula] directly follows from Proposition [\ref=prop:lo-comm] and [\ref=prop:blocks-comm]:

The optimal solution for [formula] is given by an assignment of Lo-tasks to Hi-tasks.

Covering MILP Model for [formula]

The following MILP model relies on Corollary [\ref=cor:mc2]. The model assigns Lo-tasks to the Hi-tasks in order to form covering blocks such that the sum of their lengths is the minimal one. The decision variable xij indicates whether the Lo-task Tj is covered by the Hi-task Ti; therefore if [formula], then xij = 1. The makespan is then given by the sum of lengths of covering blocks and the sum of processing times of all Lo-tasks that are not covered.

[formula]

The main advantage of this model over the model proposed by [\cite=hanzalek2016mc] is that it has much stronger linear relaxation. In Section [\ref=sec:results] we show that it can solve instances with about the order of magnitude more tasks.

THREE CRITICALITY LEVELS

Although two criticality levels are often sufficient for safety-critical application and this case is frequently studied in the field of mixed-critical systems [\cite=burns2013mixed], sometimes the application naturally contains three or more criticality levels. We capture the direct relation between problems with different maximum criticality levels by introducing a transformation given bellow. It is based on the observation that omitting some criticality levels provides an instance of the problem with less criticality level while maintaining a lower bound property. Furthermore, we introduce the Bottom-up algorithm that uses this observation. The algorithm is used then together with Covering MILP model for three criticality levels (L = 3) shown in Section [\ref=milp:mc3] to form an efficient solution method.

The transformation is defined as h± restrictions: The h- restriction takes an F-shape and cuts off all criticality levels above level h. Similarly, given the set of F-shaped tasks, h+ restriction drops all tasks with criticality below h, and for the rest, it cuts off criticality levels less than h. Restricting an [formula] instance yields to a mixed-criticality instance since omitting some of the criticality levels for an F-shape gives us an F-shape. The application of the restriction can be viewed as a relaxation the problem.

For the problem [formula] expressions lb-, lb+ defined as

[formula]

are lower bounds on the makespan, where [formula] and [formula] denote the set of all permutations of elements [formula], [formula] respectively.

The lb- is a lower bound on the makespan of [formula] since it relaxes on the overlapping condition at the third criticality level. Similarly, lb+ is a lower bound on the makespan since it relaxes on the overlapping condition at the first criticality level.

Bottom-up Algorithm

We introduce a heuristic algorithm for the problem [formula]. Let us refer to tasks with Xi = 3 (i.e. criticality 3) as to Great-tasks. The Bottom-up algorithm is based on the idea of constructing the schedule in two stages. In the first stage, the relaxed problem is solved up to the optimality, which minimizes a lower bound on the optimal makespan of the original problem. The second stage takes the relaxed solution and constructs a locally optimal solution for the original problem.

The first stage of the algorithm solves 2- restriction of the given problem instance; hence it is an instance of [formula] problem that can be solved with the model described in Section [\ref=sec:two]. It assigns Lo-tasks to Hi-tasks and Great-tasks; therefore it forms covering blocks. In the second stage, the algorithm defines a new problem instance [formula] of the problem [formula]. The instance is constructed as follows. It contains Lo-tasks with processing time equal to the length of covering blocks from the stage one. Lo-tasks that are not part of any covering block are assigned to an arbitrary covering block. The assignment of Lo-tasks to 2- restricted Great-tasks from the first stage defines Hi-tasks in the new instance [formula]. Then, the [formula] instance is solved once again as an instance of [formula] problem. See the complete description of the Bottom-up algorithm in Alg. [\ref=alg:botup].

In general, the Bottom-up algorithm produces suboptimal solutions even though they are provably bounded by a factor of 3 from the optimal solution, as stated by Proposition [\ref=prop:approx]. However, there are cases when we can verify if the produced schedule is optimal. This is achieved by the concept of critical paths that captures the cause of achieved makespan.

Essentially, for any given left-shifted schedule, the critical path is a subset of tasks and their criticality levels such that [formula] holds that if the processing time [formula] is increased by some ε  >  0, then the makespan of the same schedule is also increased by ε.

If one of following conditions holds, then the schedule produced by the Bottom-up algorithm is optimal for problem [formula].

There exists a critical path going through the first and the second levels only.

Every Lo-task is fully covered by the second criticality level.

When none of the optimality conditions is satisfied, e.g. a critical path is coming through every criticality level, we fallback to the MILP model [\ref=milp:mc3] for the problem [formula] in order to find an optimal solution or for the proof that the current solution is the optimal one. The solver is supplied with the initial solution and a lower bound obtained by the Bottom-up algorithm.

Covering MILP Model for [formula]

The Covering MILP model for three criticality levels uses a similar idea as the model for [formula]. It assigns Lo-tasks to covering blocks and covering blocks to the Great-tasks. The model utilizes the idea that optimal solutions are made of blocks (in this case formed by Great-tasks that cover less critical tasks) whose order is interchangeable within a solution. It assigns Lo-tasks to the Hi-tasks and to 2- restriction of Great-tasks to form covering blocks. Blocks are assigned to the Great-tasks in order to create a solution. The big M constant is as large as the number of Lo-tasks contained in the problem instance.

[formula]

When Bottom-up fails to prove optimality, it fallbacks to this model while supplying the lb- lower bound and the initial solution. The reason for executing Bottom-up ahead solving MILP model [\ref=milp:mc3] is two-fold. First, we have observed the solver struggles to prove optimality when the solution is clearly optimal regarding the critical path. The other observation is that if the problem instance contains the majority of tasks with criticality one and two, then solving its 2- restriction frequently yields optimal solution since the highest criticality levels are not likely to be utilized. Similar holds for the instances with a large number of tasks with higher criticality. Furthermore, solving 2± restrictions of [formula] is cheap compared to the solving the whole MILP model [\ref=milp:mc3] as it can be seen in Tab. [\ref=tab:mc2].

COMPUTATIONAL EXPERIMENTS

For the problem [formula] we have randomly generated sets of 20 instances with n tasks for each [formula]. Criticalities of tasks were distributed uniformly. The processing time of a task at level 1 is sampled from the uniform distribution U(1,11). For tasks with the criticality of 2, the prolongation at level 2 is sampled from uniform distribution U(1,10). For the problem [formula] we have randomly generated sets of 20 instances with n tasks for each [formula]. For each n, the set contains instances with different splits of tasks' criticalities and different distributions for prolongation (e.g. U(1,10) and U(1,7) for the second level, U(1,10) and U(1,14) for the third level, etc.) in order to generate instances of various properties.

The column avg t (max t) in Tab. [\ref=tab:mc2] and [\ref=tab:mc3] denotes the average (maximal) computational time for instances that were solved within the time limit of [formula]. The column unsl contains the percentage of instances that were not solved within the time limit and avg gap denotes average optimality gap proven by the solver for the unsolved instances. Results were obtained with two Intel Xeon E5-2620 v2 [formula] processors using Gurobi Optimizer 6.5 with the algorithms implemented in Python 3.4.

In Tab. [\ref=tab:mc2] it can be seen that our model is able to solve about an order of the magnitude larger problem instances. The Relative Order model proposed by [\cite=hanzalek2016mc] consistently fails to narrow optimality gap for instances with more than 40 tasks. In Tab. [\ref=tab:mc3] it is shown that the combination of Bottom-up heuristic and MILP [\ref=milp:mc3] is able to solve reliably instances with 60 tasks up to the optimality and almost all instances with 80 tasks. Moreover, the proven gap is much smaller than for the Relative Order model; therefore it shows that our model has stronger linear relaxation.

CONCLUSION

In this paper, we have proposed two exact approaches for the problem of non-preemptive mixed-criticality match-up scheduling for solving the problem of message retransmission in time-triggered communication protocols. The algorithms outperform the approach recently proposed by a large margin. Furthermore, we showed the membership of [formula] problem in [formula] complexity class for an arbitrary fixed L.