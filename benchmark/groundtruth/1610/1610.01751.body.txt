Lemma Corollary Definition Proposition Fact Claim Remark Example

On the norm of a random jointly exchangeable matrix

Introduction

Given an n  ×  n random matrix M = (Mij) and a permutation σ on n elements, we denote by σ(M) the n  ×  n matrix

[formula]

i.e. the (i,j)-th element of σ(M) is equal to Mσ(i)σ(j). Further, we say that the matrix M is jointly exchangeable if M is equidistributed with σ(M) for any non-random permutation σ. Note that if B is any random matrix and σ is a random uniform permutation independent of B then σ(B) is jointly exchangeable.

The jointly exchangeable matrices (arrays) have been previously studied in literature; see, in particular, paper [\cite=hoover] and [\cite=kallenberg]. Let us emphasize that the above definition is different from the notion of a separately exchangeable matrix as well as a matrix with exchangeable entries. In the former case, we assume that M is equidistributed with (Mσ(i)π(j))ni,j = 1 for any two permutations σ and π, whereas the latter means that M, considered as a sequence of n2 elements, is exchangeable. We refer to [\cite=aldous] [\cite=hoover] for a discussion of separately exchangeable arrays, and to book [\cite=kallenberg] for extensive information on the subject.

Limiting properties of the spectral distribution of random matrices with exchangeable entries were considered, in particular, in [\cite=chatterjee] [\cite=ACW]. In this note, we are interested in the problem of estimating the spectral norm of a jointly exchangeable matrix in terms of the norm of its submatrix located in the top right corner. Motivation for such a specific setting comes from a problem in the spectral theory of random graphs, and can be seen in a more general context as a way to "de-symmetrize" a random matrix. We will return to this in the second part of the introduction.

Let us note that the problem has a trivial solution if instead of joint exchangeability we consider a separately exchangeable matrix. Namely, if M is separately exchangeable then it is easy to see that, denoting by [formula] ([formula]) its block decomposition into four n / 2  ×  n / 2 submatrices, all the blocks [formula] are equidistributed. Hence, in view of the triangle inequality,

[formula]

for any t  ≥  0. In the jointly exchangeable model, however, the principal submatrices M(11) and M(22) are generally not equidistributed with M(12), M(21), and the above argument fails.

We address the problem in the following theorem:

There exists a universal constant [formula] with the following property. Let n  ≥  8; let M be a random n  ×  n matrix with zero diagonal and let σ be the uniform random permutation of [formula] independent of M. Further, let E be an event such that [formula] everywhere on the probability space. Then, denoting by T the ⌊n / 2⌋  ×  ⌊n / 2⌋ top right corner of σ(M), we have

[formula]

for all τ > 0.

Let us note that we did not attempt to evaluate the constant [formula]. Event E in the above theorem provides additional flexibility, which will be important in applications. In the particular case when E coincides with the entire probability space, we obtain the following

Let n  ≥  8, let M be an n  ×  n jointly eachangeable random matrix with zero diagonal and let T be the ⌊n / 2⌋  ×  ⌊n / 2⌋ top right corner of M. Then

[formula]

It turns out that, under some extra assumptions, the above result can be turned into a relation between second largest singular values. In what follows, given an n  ×  n matrix M, we denote by [formula] its singular values arranged in non-increasing order (counting multiplicities).

Given an n  ×  n matrix A with nonnegative entries, let us define n-dimensional vectors u(A) and v(A) via their coordinates as follows:

[formula]

where coli(A) and rowi(A) denote the i-th column and i-th row of A, respectively. Now, given [formula] with ||u||1  =  ||v||1, we define An(u,v) as the set of all (non-random) n  ×  n matrices A with nonnegative entries satisfying u(A) = u and v(A) = v. When [formula] for some d > 0, we will use a shorter notation An(d) for the corresponding set.

It is easy to see that for any matrix A from An(d), d is equal to its largest singular value s1(A), and the corresponding singular vector is [formula] (this can be checked, in particular, by considering the matrix AtA which has constant row and column sums equal to d2). Using the Courant-Fischer formula, or the singular value decomposition, we can express the second largest singular value of A as

[formula]

In the situation when A is a random jointly exchangeable matrix with values in An(d), formula [\eqref=eq:_s2-courant-fischer] enables us to use Theorem [\ref=th:_main] to estimate s2(A). Generally, by passing to a submatrix of A we destroy the double stochastic structure. However, as we show below, with a high probability the submatrix will have "almost constant" row and column sums. Given [formula] and two positive numbers d and δ, define

[formula]

Loosely speaking, when δ is small compared to d and [formula], matrices from Am(u,v) are "almost" in Am(d) in the sense that their row and column sums are close to d. Let us remark that the definition of [formula] can be equivalently restated using the Orlicz norm in [formula] with the Orlicz function exp (t2). We are now ready to state the second main result of this note.

There exist positive universal constants c,C such that the following holds. Let n  ≥  C and let d,δ > 0 satisfy [formula]. Let A∈An(d) be an n  ×  n jointly exchangeable random matrix satisfying

[formula]

Further, let T be the ⌊n / 2⌋  ×  ⌊n / 2⌋ top right corner of A. Then for any L  ≥  C we have

[formula]

The above statement is used in an upcoming paper by the same authors [\cite=TY]. In fact, applying Theorem [\ref=th:_main2] in [\cite=TY], we show that the spectral gap of random d-regular undirected graphs in the uniform model can be bounded in terms of the second singular value of "almost d-regular" random directed graphs.

The note is organized as follows: In Section 2 we set the notation and provide several auxiliary statements. In Section 3 we prove Theorem [\ref=th:_main] and complete the paper with Section 4 with a proof of Theorem [\ref=th:_main2]. Let us emphasize that, although the primary application of all the results from this note consists in "de-symmetrization" of d-regular random graphs, we think that the simple arguments given here may turn out useful in other contexts, which has been the main reason for grouping them in the separate paper.

Preliminaries

Given a vector [formula], we denote by [formula] its coordinates. Further, by [formula] we denote the canonical [formula]-norms (1  ≤  p  ≤    ∞  ). Given an n  ×  n matrix M, [formula] stands for the spectral norm of M. A vector of ones will be denoted by [formula]. Given a natural number m, the set [formula] will sometimes be denoted by

[formula]

of cardinality k. Then

[formula]

for a sufficiently small universal constant [formula].

For each i  ≤  m, let χi be the indicator variable of the event {i∈S}, so that [formula]. We have

[formula]

where the last equality is due to the fact that [formula]. Next, denoting

[formula]

we can compute the fourth moment of the sum as follows:

[formula]

Simplifying, we obtain

[formula]

whence, in view of the straightforward relations [formula],

[formula]

Finally, we consider two cases.

Assume that [formula]. Let [formula]. From [\eqref=eq-second-moment-symetrization], we clearly have

[formula]

Thus,

[formula]

Using Markov's inequality together with the relation [formula], we get

[formula]

whence

[formula]

Assume that [formula]. From [\eqref=eq-second-moment-symetrization], it is easy to see that

[formula]

Therefore we can write

[formula]

Applying the Paley-Zygmund inequality, we deduce

[formula]

Using that [formula] together with [\eqref=eq-4th-moment], we get

[formula]

for some large positive constant C. Moreover, in view of [\eqref=eq-second-moment-symetrization], we have

[formula]

Plugging the last two estimates into [\eqref=eq:_paley-zygmund], we get the result.

The next statement is, in a sense, converse to the last one as it establishes concentration of the random sum around its mean.

Let [formula] and 1  ≤  k  ≤  ⌈m / 2⌉. Further, let a: = (ai)mi = 1 be a sequence of reals, and S be a uniformly distributed random subset of

[formula]

P | a - a |≥ t ≤ 2exp(-).

[formula]

Fix a [formula]. For each i  ≤  m, let χi be the indicator variable of the event {i∈S} so that [formula]. It is known that (χi)i  ≤  n are negatively associated (see for example [\cite=NA] or [\cite=Permantle]). Note that [formula] and that the random variable aiχi lies in an interval of length |ai| for any i  ≤  m. Hence, applying Hoeffding's inequality for negatively associated random variables [\cite=roussas], we get the result.

Note that a Bennett-type inequality can be derived in a similar manner. However, Lemma [\ref=l:_subsum2] is sufficient for our purposes.

Finally, the following linear algebraic statement will be useful for us. For the proof, see, for example, [\cite=horn].

Let M be an n  ×  n matrix with non-negative entries and let ρ be its spectral radius. Assume that x is an eigenvector of M and all coordinates of x are strictly positive. Then Mx = ρx, i.e. the eigenvalue associated to x is equal to the spectral radius.

Proof of Theorem [\ref=th:_main]

The next lemma is the key to prove the main theorem.

There is a universal constant [formula] with the following property: Let n  ≥  8, M be an n  ×  n non-random matrix with zero diagonal, and let σ be a uniform random permutation on

[formula]

T≥ cM.

[formula]

Let x be a unit vector in [formula] which realizes the norm of M, i.e. [formula]. Denote by X the random ⌊n / 2⌋-dimensional vector defined as

[formula]

We will show that [formula] with probability at least [formula], for a sufficiently small universal constant [formula].

Fix for a moment any i  ≤  ⌊n / 2⌋. Note that the inner product of the i-th row of T with X can be written as

[formula]

Conditioned on any realization of σ(i), the set [formula] is uniformly distributed in [formula], whence, by Lemma [\ref=l:_subsum], and because of the assumption on the matrix diagonal, we have

[formula]

for some universal constant c > 0. Next, observe that

[formula]

where χi is the indicator of the event

[formula]

Therefore ||TX||22  ≥  c2η where η is defined as

[formula]

In view of [\eqref=eq:_aux_1640], we have

[formula]

On the other hand, deterministically

[formula]

whence [formula]. Applying the Paley-Zygmund inequality to η, we obtain

[formula]

Since ||TX||22  ≥  c2η and [formula] then

[formula]

with probability at least [formula], and the proof is complete.

Equipped with the above lemma, we are now ready to prove Theorem [\ref=th:_main].

Let [formula], and let M, σ, T and event E be as in the statement of the theorem. Conditioning on any realization of M, we get, by Lemma [\ref=l:_submatrix],

[formula]

Hence,

[formula]

Now, fix any τ > 0 and denote [formula]. Using the above relation, we obtain

[formula]

It remains to use the definition of conditional probability.

The second singular value

To deduce Theorem [\ref=th:_main2] from Theorem [\ref=th:_main], we have to identify "the right" event for conditioning. In the following lemma, we show that with high probability, the property of having constant row and column sums is "almost true" for the top right corner of our random matrix provided that it is jointly exchangeable.

There exists a universal constant [formula] with the following property. Let A∈An(d) be an n  ×  n random matrix and let δ > 0 be such that

[formula]

Further, let σ be the uniform random permutation on

[formula]

P(E | A)≥ 1-c.

[formula]

Set

[formula]

First, let us condition on any realizaton [formula] of the matrix A, so that the randomness comes only from the permutation σ. By the definition of σ(A) and Ts, we have

[formula]

Since σ is uniformly distributed on

[formula]

,

[formula]

η:=|i≤ n/2:  | v(T)-|>+|.

[formula]

(η | A=) = P| v(T)-|>+ | A= ≤ 2mexp-.

[formula]

Pη> me | A=≤ 2expt-,  t>0.

[formula]

Pη> me for some t∈ | A= ≤ 2expt-≤ ,

[formula]

P|i≤ n/2: |v(T)-|> kδ| ≤ me for all k∈ | A= ≥ 1-.

[formula]

The next linear algebraic lemma can be viewed as an extension of relation [\eqref=eq:_s2-courant-fischer] to the case when a matrix has "almost constant" row and column sums.

Let [formula] and let u,v be two vectors in [formula] with strictly positive coordinates and [formula]. Further, assume that d,δ > 0 are such that

[formula]

and

[formula]

Then for any A∈Am(u,v) we have

[formula]

Denote by Du and Dv diagonal matrices having ui and vi (i  ≤  m) as diagonal elements. First note that [formula] is an eigenvector of the matrix

[formula]

with the corresponding eigenvalue equal to 1, and, obviously, [formula] has positive coordinates. Hence, by Lemma [\ref=l:_eigenvalue_of_positive_vector],

[formula]

Thus, [formula], and [formula] and [formula] are the associated right and left singular vectors. Moreover,

[formula]

Therefore, applying the singular value decomposition, we get

[formula]

From the last relation and by the triangle inequality, denoting by β the expression

[formula]

we obtain

[formula]

where in the last step we used the relation [formula]. By the assumptions on vectors u,v and on d, we have

[formula]

Hence, by [\eqref=eq1:_s2-reduction], we get

[formula]

It remains to estimate β. By the triangle inequality,

[formula]

where we used the identity ||yzt||  =  ||y||2  ||z||2 which holds for any two vectors [formula]. By the assumptions on u and v and a standard relation between [formula] and [formula]-norms, we have

[formula]

This, together with [\eqref=eq:_bounds-in-d], implies that β  ≤  6δ. Combining this relation with [\eqref=eq2:_s2-reduction], we finish the proof.

Let A∈An(d) be an n  ×  n jointly exchangeable random matrix and let δ > 0 be such that

[formula]

where the constant [formula] comes from Lemma [\ref=lem:_degree-event], and such that

[formula]

Let σ be a uniform random permutation on

[formula]

Ps(A)≥ Lδ≤ s(T)≥ cLδ  AND u(T),v(T)∈d/2,δ.

[formula]

f(τ):= P{B≥ τ} ≤ P{T-·≥ cτ AND E holds}

[formula]

u(T)-, v(T)-≤}⊃ E.

[formula]

u(T)-, v(T)-≤ 4δ⊃ E.

[formula]

P{s(A)≥ δ+τ}≤ Ps(T)≥ τ-24δ AND E holds,  τ>0.

[formula]

Acknowledgments. The first named author is partially supported by the Simons Foundation (Collaboration on Algorithms and Geometry).

Konstantin Tikhomirov, Department of Mathematics, Princeton University, E-mail: kt12@math.princeton.edu

Pierre Youssef, Laboratoire de Probabilités et de Modèles aléatoires, Université Paris Diderot, E-mail: youssef@math.univ-paris-diderot.fr