Efficient Probabilistic Group Testing Based on Traitor Tracing

INTRODUCTION

Group testing

Suppose a large population has to be tested for a certain illness, to determine which people are ill. One way to do this is to take blood samples from each person and test these samples one by one. However, if only few people are ill, many tests are wasted on non-infected people. It may then be advantageous to test bigger pools of several blood samples with group tests. If one of the tested people in a pool is ill, the test will come back positive and further tests are required, but if the test comes back negative, we may conclude that none of the people in the tested group are ill and many tests are saved. Group testing concerns the identification of a small subset of K defectives hidden among N total items, using the aforementioned group tests. The goal of group testing is to minimize the number of group tests T required to identify the defectives, by carefully choosing which groups to test.

Adaptive group testing

In 1943, Dorfman [\cite=dorfman43] published a seminal paper studying practical ways of testing many blood samples of soldiers for syphilis, which is widely regarded as the first work on group testing. In the decades to follow, a lot of research was done in the area of adaptive group testing, where many sequential rounds of testing are considered, and the selection of samples for the next pool may be influenced by the results of previous group tests. In this adaptive setting, using a binary search, T  =  K⌈ log 2N⌉ tests suffice to detect K defectives in a sample of size N. Up to a constant factor, this number of tests is optimal.

Non-adaptive group testing

For practical and economical reasons, the focus of later work in group testing shifted more towards the non-adaptive setting, where many tests are run in parallel in one or few rounds. With certain combinatorial designs it is possible to find all K defectives in one round with T  =  O(K2 log (N / K)) tests [\cite=dyachkov82], while a lower bound of T  =  Ω(K2 log N /  log K) [\cite=dyachkov89] shows that this number of tests is nearly optimal, when one round of tests is done and when the group testing algorithm always has to identify the correct subset of defectives. If we allow for a small positive probability ε of not detecting the right set of defectives, then even in one round of tests, T  =  O(K log N) parallel tests suffice to isolate all defectives with high probability. Together with the lower bound of T  ≥  K log 2N for large N [\cite=sebo85], this shows that T  =  Θ(K log N) is optimal. Chan et al. [\cite=chan11] recently gave a computationally efficient algorithm that belongs in the latter category that uses T  =  eK log (N / ε) tests to get a success probability of at least 1  -  ε.

Variants

Besides the pure group testing model, variants have also been studied, such as noisy group testing [\cite=atia09] [\cite=atia12] [\cite=chan11] [\cite=cheraghchi09] [\cite=cheraghchi11] [\cite=sejdinovic10] and threshold group testing [\cite=chan13] [\cite=damaschke06] [\cite=lebedev10]. In these models a positive outcome of a test is not equivalent to at least one defective being present in the tested group, as there may be a small probability of making a mistake in the testing procedure, or because the test might not come back positive if very few defectives are present in the tested group. The trivial adaptive group testing algorithm of doing a binary search does not work in these models, and so even finding an efficient adaptive group testing scheme in these models is not easy.

Collusion-resistant traitor tracing

A completely different, but in fact closely related area of research is that of collusion-resistant traitor tracing. To protect digital content from unauthorized redistribution, copyright holders embed watermarks in the content such that, if an illegal copy is made and distributed, the watermark can be linked to the responsible user. Things become more complicated when several pirates collude, and start mixing their copies to create a new pirated copy of the content that does not match any of their copies of the content exactly. If in some segment of the data all pirates receive the same watermarked version, the marking assumption [\cite=boneh98] says that they are forced to output this version of the content. However, if they receive several different versions, they may choose any of them to output. Traitor tracing concerns assigning watermarks to N users in such a way that, even if K users mix their copies as described above, we may still be able to find the colluders. The goal of traitor tracing is to minimize the number of segments T needed to trace (part of) the coalition, by carefully choosing which watermarked versions of each segment to assign to each user.

Static (non-adaptive) traitor tracing

Work on traitor tracing started only in the late 20th century. In many of the early constructions, the number of segments required was polynomial in N, until Boneh and Shaw [\cite=boneh98] gave an efficient construction that uses T  =  O(K4 log (N / ε)) segments to find at least one of the colluders with high probability in the static (non-adaptive) setting. Upper and lower bounds on T were further improved until in 2003, Tardos [\cite=tardos03] showed that T  =  O(K2 log (N / ε)) segments are both necessary and sufficient. In the same paper he presented an efficient scheme that achieves this lower bound up to a constant factor. Later research focused on establishing the exact (asymptotic) lower bound [\cite=huang12], which turned out to be [formula], and decreasing the upper bounds by improving Tardos' scheme [\cite=blayer08] [\cite=skoric08] [\cite=laarhoven12dcc] [\cite=oosterwijk13], which eventually lead to an asymptotic bound of [formula].

Dynamic (adaptive) traitor tracing

While the above results are based on the static setting where the assignment of watermarks is fixed in advance, some work was also done on dynamic (adaptive) schemes. Besides the well-known deterministic scheme of Fiat and Tassa [\cite=fiat01] which requires a large bandwidth, Tassa [\cite=tassa05] constructed a low bandwidth dynamic scheme with a length of O(K4 log N). Recently, Laarhoven et al. [\cite=laarhoven13tit] gave a more efficient dynamic scheme where the number of segments is only O(K2 log N), and in [\cite=laarhoven12wifs] a trade-off construction was given to build schemes that require a higher bandwidth but with a smaller constant T. In these schemes, all colluders are caught with high probability, whereas in non-adaptive schemes, at least one colluder is caught with high probability.

Relation to group testing

Oosterwijk et al. [\cite=oosterwijk13] recently considered optimizing Tardos' scheme to the scenario where the pirate strategy is known, e.g., when the pirates always randomly choose one of their versions (the interleaving attack) or when the pirates always output the same watermarked version if at least one of them received this version (the all-1 attack). The latter pirate strategy corresponds to getting a pirate output of 1 if and only if at least one traitor is present in the set of users who received a 1. This shows that the traitor tracing game with the all-1 attack is in fact equivalent to the group testing game, and more generally that many group testing models correspond to specific pirate strategies in the traitor tracing game. Traitor tracing can therefore be seen as a generalization of group testing, or group testing as a special case of traitor tracing.

Contributions

In this paper, we will show that combining and improving several of the aforementioned results from traitor tracing [\cite=tardos03] [\cite=oosterwijk13] [\cite=laarhoven13tit] [\cite=laarhoven13wifs] leads to a group testing framework that can deal with many different group testing models efficiently. The resulting group testing algorithms we present are computationally efficient and, for sufficiently large K, require fewer tests than many known algorithms from the literature. For large N, the number of tests required in our schemes scales as follows, depending on the model. Here r is a noise-parameter, which informally corresponds to the probability of not getting the expected result.

Traditional group testing: T  ~  2K ln N.

Noisy group testing (dilution): T  ~  2K ln N  /  (1  -  r).

Noisy group testing (additive): [formula].

Threshold group testing (majority): T  ~  πK ln N.

Threshold group testing (Bernoulli gap): T  ~  4K ln N.

Threshold group testing (linear gap): T  ~  2K2 ln N.

These asymptotics apply to both adaptive and non-adaptive group testing, but the first order terms are considerably smaller in adaptive group testing than in non-adaptive group testing. Although we have worked out the details for several models, this paper aims to provide a framework to efficiently deal with any group testing model. For instance, for threshold group testing with small gaps we did not provide explicit formulas, but one may derive them as we will explain below.

Besides these improvements and this framework, one goal of this paper is to further stimulate a cooperation between the areas of group testing and traitor tracing, as these areas are surprisingly similar. Much work has been done in both areas in similar directions (combinatorial designs, probabilistic analyses, information-theoretic lower bounds), and although the connection between the two areas has been made a few times before (e.g., [\cite=meerwald11b] [\cite=colbourn10]), a further exchange of ideas may lead to improved results in both areas.

The outline of this paper is as follows. In Sect. [\ref=sec:framework] we provide the aforementioned framework to deal with arbitrary group testing models. Then, in Sect. [\ref=sec:ord], [\ref=sec:noise], and [\ref=sec:threshold] we apply our results to some previously considered models and present our results. Finally, in Sect. [\ref=sec:conc] we conclude by mentioning an important open problem in traitor tracing that might be of interest to the group testing community. All proofs and many details are omitted due to space limitations, but will appear in the full version.

SCORE-BASED GROUP TESTING

In this section, we will look at a framework for probabilistic group testing with average-case errors. We will cover both adaptive and non-adaptive group testing. Before introducing this framework, we first introduce some more notation. We write X to denote the group testing matrix, or code matrix, indicating which items are included in which tests. We denote its length by T, which we will also call the code length. We denote test outcomes with y. Throughout, we will generally index items with j and tests with i, i.e., yi is the outcome of the ith test, and Xj,i  =  1 if and only if item j is included in the ith test. Finally, we write ε1 for an upper bound on the probability that one or more non-defective items are marked as defective by our algorithm (getting one or more false positives), and ε2 for an upper bound on the probability that some defective item is not marked defective (a false negative).

Non-adaptive group testing

In 2003, Tardos [\cite=tardos03] introduced a collusion-resistant traitor tracing scheme, which he showed to be order-optimal in the number of segments needed. In group testing terminology, this scheme relies on assigning test scores to items based on the results of each test, such that if we add up all test scores for each item, defective items will eventually get much higher scores than non-defective items. Given a certain probability p, a score function h, and a threshold Z, this scheme works as described in Fig. [\ref=fig:non]. Here i refers to the ith test, and j refers to the jth item.

For the time being we develop the theory for a generic score function h, but it is generally chosen such that it assigns positive scores to matches (Xj,i  =  yi) and negative scores to differences, and gives large positive (negative) scores to the matches (differences) that were the least likely. For each test, the expected score for a non-defective item is usually 0, while for defective items it is strictly positive. Therefore, by running sufficiently many tests, with high probability we are able to distinguish between the scores of non-defective items (which have mean 0) and the scores of defective items (which have a large positive mean).

To analyze the performance of score-based schemes, we need to estimate the probabilities that (a) a non-defective item is still marked as defective, and (b) a defective item is not marked as defective. To do this, first note that for each item j, the scores for each test i are independently and identically distributed. For convenience, let us introduce the following notations for the mean and variance of the scores of non-defective items and defective items for each test. Below, we omit subscripts i on y, and we use x ([formula]) to denote the symbol Xj,i for non-defectives (defectives). Throughout, we will consistently use tildes to indicate variables corresponding to defective items.

[formula]

Now, the total score of an item j is given by [formula], where Sj,i  =  h(Xj,i,yi). This is a sum of many i.i.d. random variables, and due to the Central Limit Theorem, for large T we expect Sj to be approximately normally distributed with mean μT (T) and variance σ2T (σ̃2T). So if we look at the average score per test [formula], non-defective items (defective items) will have a mean of μ ([formula]) and a standard deviation of [formula] ([formula]), as shown in Fig. [\ref=fig:gauss]. Therefore, when μ  <   and σ and σ̃ are sufficiently small, increasing T will make both curves more narrow, and allow us to distinguish between the two curves with high probability. Working out the details, this leads to the following result about T and Z. The proof, as well as many other details, can be found in the full version of this paper.

Suppose we use the score-based non-adaptive group testing scheme described in Fig. [\ref=fig:non], and the average item scores for each item follow a perfect Gaussian curve. Then, to guarantee that (i) a non-defective item is marked defective with probability at most [formula], and (ii) a defective is marked as non-defective with probability at most [formula], the following parameters suffice:

[formula]

[formula]

In particular, it then follows that with probability at least 1  -  ε1, all non-defectives are correctly classified as non-defective, and with probability at least 1  -  ε2, all defective items are correctly marked as defective.

For notational convenience, let us write

[formula]

so that the formula for the parameter T in Thm. [\ref=thm:non-gauss] can be concisely expressed as

[formula]

We generally have [formula], while for small K and large N, the value of η will be very small. In fact, for K  =  No(1) and N  →    ∞   we have [formula], leading to the following corollary.

Suppose that K  =  No(1), that ε1 and ε2 are fixed, and that B  =  O(1). Then, for large N we have

[formula]

To minimize the number of tests, we are therefore mostly aiming to minimize the value of A. This parameter depends on the choices of p and h, and on the model of how the test result y is produced.

Adaptive group testing

The procedure described in Fig. [\ref=fig:non] can be adapted to the adaptive setting by making the following small modification: instead of only marking items defective if their final scores exceed Z, we mark an item defective (and do not include it in any of the remaining group tests) as soon as its score exceeds the threshold Z. This modification was recently proposed in [\cite=laarhoven13tit] to build efficient adaptive traitor tracing schemes from Tardos' non-adaptive scheme, but can also be used to make score-based group testing work even more efficiently. The modified scheme is presented in Fig. [\ref=fig:ada].

It was shown in [\cite=laarhoven13tit] [\cite=laarhoven13wifs] that with this modification, proving that the average defective item score exceeds Z is roughly enough to prove that all defective items are found. This means that instead of looking at scores of single defective items, we should now look at the average score of all defective items. Compared to the right curve in Fig. [\ref=fig:gauss], this curve has the same mean [formula], but because it is an averaged score over K individual scores, the normalized standard deviation σ* will be [formula] times smaller. This leads to the following result, a proof of which can be found in the full version.

Suppose that we use the score-based adaptive group testing scheme described in Fig. [\ref=fig:ada], and suppose that the average item scores of all items follow a perfect Gaussian curve. Then, to guarantee that (i) a non-defective item is marked defective with probability at most ε1 / N, and (ii) a defective item is not marked defective with probability at most ε2 / K, the following parameters suffice:

[formula]

Similar to the non-adaptive group testing setting, we now write [formula] so that the formula for the parameter T in Thm. [\ref=thm:ada-gauss] can be concisely expressed as

[formula]

The parameter [formula] is generally really small due to the factor [formula]. So without making any assumptions on K and N, we may already claim that for large K and/or N, the parameter [formula] will go to 0.

Suppose that ε1 and ε2 are fixed, and that B  =  O(1). Then, for large N, we have

[formula]

To summarize, the asymptotics of T will generally be the same as in the non-adaptive model, but the convergence to this limit will be much faster due to the extra factor [formula]. Also, as noted in [\cite=laarhoven13tit], the actual number of tests needed to find all defectives is generally much less than the theoretical upper bounds suggest.

Dealing with unknown K

In [\cite=laarhoven13tit], a scheme is discussed to effectively deal with adaptive scenarios where the number of defectives is not known in advance (the universal Tardos scheme), while maintaining equivalent asymptotics on T. This roughly comes down to using several thresholds Z, and the same idea may also be applied to adaptive group testing with an unknown number of defectives. For details, see [\cite=laarhoven13tit].

Reducing the number of stages

In [\cite=laarhoven13tit], a setting somewhere between non-adaptive and adaptive traitor tracing is also discussed (the weakly dynamic Tardos scheme), and how one could adapt the adaptive scheme to such a setting effectively. Translating those results to group testing, the same asymptotics on T hold even if the number of stages is reduced to O(K) (with O(T / K) tests in each stage). But reducing the number of rounds does lead to larger first order terms and larger practical code lengths. For details, see [\cite=laarhoven13tit].

Optimal score functions h

Recently, Oosterwijk et al. [\cite=oosterwijk13] studied the score functions used in traitor tracing, and showed that if the attack strategy of the pirates is known, then the score function h that minimizes A is given as follows. This choice of h is such that it is both centered (μ  =  0) and quasi-normalized (σ2  =  ).

[\cite=oosterwijk13] The optimal, centered (μ  =  0) and quasi-normalized (σ2  =  ) score function h that minimizes A under the Gaussian assumption is given by

[formula]

where py  =  P(yi  =  y) and px  =  P(Xj,i  =  x).

For several attack strategies explicit formulas for h were derived in [\cite=oosterwijk13], some of which we will encounter later. For one particular strategy they obtained a score function that turned out to achieve capacity in the non-adaptive traitor tracing game.

Optimal probabilities p

Once the model (in traitor tracing: attack) is fixed, we can now compute the optimal score function h as described above, and we are almost done. To finalize the scheme, we then only need to choose a parameter p. Since the parameters A and B, and therefore a Gaussian-based estimate of the code length T, can be explicitly computed as a function of p, what remains is a straightforward optimization of p minimizing the estimate of T. Asymptotically, as shown in Cor. [\ref=cor:non] and [\ref=cor:ada], we would like to choose p so as to minimize A, but in practice there is a trade-off between minimizing A and minimizing B. We will further discuss this below.

TRADITIONAL GROUP TESTING

With the framework in place, we are ready to start building group testing schemes in arbitrary models, and we will discuss the results in the next few sections. We will naturally start with the most often considered, traditional group testing model, where the outcome of a test is positive if and only if at least one defective item is present in the tested pool. We will first give a scheme based on a straightforward optimization of h and p, and then discuss how the score function can be slightly refined in this particular model, leading to smaller constants T.

The direct approach

First, Oosterwijk et al. [\cite=oosterwijk13] showed that the following centered and quasi-normalized score function is optimal in the ordinary group testing model, in that it minimizes A under the Gaussian assumption.

[formula]

Using this score function, we can compute the parameters A and B as a function of p, and find the optimal value of p that minimizes T. For arbitrary values of K, these parameters are somewhat ugly functions of p, but the optimization of p is just a straightforward procedure. These details can be found in the full version, but here we will focus on the cleaner asymptotics of T. Note that "asymptotics" here refers to considering the case of large K, although the results may already provide good approximations of the actual value of T when K is small.

First, as is well known in group testing, one generally has to use small values of p and sparse matrices X. It is generally assumed that [formula] for some α which is constant or almost constant in K. Using the same parametrization here, we obtain the following asymptotics for the code length constants A and B:

[formula]

Here, it should be noted that the leading term of A is a strictly increasing function of α, while the leading term of B is strictly decreasing in α. There is a clear trade-off between A and B, and the optimal choice of α depends on the exact set of parameters K, N, ε1 and ε2. If we focus on the regime of large K, we see that α  →  0 is optimal to minimize A, in which case we get

[formula]

Setting α  =  O(η2 / 3) balances the order terms, and leads to a first order term of the order O(η2 / 3). But the important thing to note here is the leading term of T:

[formula]

For sufficiently large K, this improves upon results of Chan et al. [\cite=chan11]. It has to be noted that in their schemes, there are never any false positives (i.e., ε1  =  0), which is not true with the above construction. But if a small margin of error is present anyway (e.g., due to errors in the testing procedure), marked items may have to be tested individually anyway to confirm that the items are defective. In that case, allowing ε1  >  0 makes sense. Note that the asymptotics of T are only a factor 2 ln 2  <  1.39 above the information-theoretic lower bound of Seb [\cite=sebo85].

To give an idea of how the scheme actually works, an example is given in Fig. [\ref=fig:sim1] with toy parameters K  =  10, N  =  1000, and ε1,2  =  10- 2. For the non-adaptive scheme, optimizing p then gives us p  ≈  0.091 leading to T  ≈  941 and Z  ≈  37, while for the adaptive setting we get p  ≈  0.055 with T  ≈  486 and Z  ≈  29.

Fine-Tuning the Score Function

Taking a step back from the score-based construction and looking at the traditional group testing model, we know that if an item is included in a test (x  =  1) while the test result is negative (y  =  0), this item is certainly not defective. So in those cases, instead of assigning this item a somewhat negative score of - 1 (which may not be enough to guarantee that the item is not marked defective), we may also assign items a score of -    ∞   when they are included in a test which comes back negative. So we may fine-tune h by setting h(1,0)  =    -    ∞  . Then in each segment, with probability q  =  p(1  -  p)K a non-defective item is assigned a score of -    ∞  . So with probability 1  -  (1  -  q)T a non-defective has a score of -    ∞   after T segments. Setting [formula] maximizes the latter probability, as was previously noted in [\cite=chan11], and eventually leads to an asymptotic code length of

[formula]

So also for [formula] we end up with improved asymptotics for T, compared to the [formula] of [\cite=chan11].

NOISY GROUP TESTING

We saw in Sect. [\ref=sub:finetune] that we may use the fact that the result of a test is never positive when one of the defective items is present in the pool, to fine-tune the score function and find all defectives even more efficiently. However, such certainties generally do not exist, as tests may have a small probability of not returning the correct result. Here we discuss two noisy group testing models previously considered in the literature, and show what the asymptotics on T become. Details on how these results were obtained are in the full version.

Dilution model

In the dilution model [\cite=atia09] [\cite=atia12] [\cite=cheraghchi09] [\cite=cheraghchi11] [\cite=sejdinovic10], we assume that a test may not come back positive even if a defective item is present in the tested pool, because this defective item may be inactive with a small probability r. This means that the probability that a defective item contributes a 1 to the test result is now not p, but p'  =  p(1  -  r). In this model, optimizing h leads to the centered and quasi-normalized score function given in Table [\ref=tab:1]. To minimize A, we again need to take α close to 0, in which case the asymptotic code length becomes

[formula]

This is somewhat comparable to a result of [\cite=atia12] which has a factor [formula] in the denominator.

Additive model

Another commonly considered noise model is that of additive noise [\cite=atia09] [\cite=atia12] [\cite=sejdinovic10], where the final extraction of the test result may not always be correct. In particular, we assume that we are in the ordinary group testing model, but the output y may also be 1 with probability r if no defectives were actually present in the test. For this model, after fine-tuning h we get the score function given in Table [\ref=tab:1]. To optimize the leading term of A for fixed r  >  0, one should choose α to satisfy eα(1  -  α)  =  1  -  r, which corresponds to [formula]. For the asymptotics of the code length we then get

[formula]

Note that Atia and Saligrama [\cite=atia12] showed that a code length of the order [formula] is already sufficient, and that our result, although practical, does not achieve this bound.

THRESHOLD GROUP TESTING

Finally, a model that has also been considered before is threshold group testing [\cite=damaschke06] [\cite=chan13], where a test result may only be positive if sufficiently many defective items are present in the tested pool. We will restrict our attention to the case where the test result is a (non-deterministic) function only of the number of defectives in a tested pool. This means that all defectives are treated symmetrically, and the test result does not depend on how many non-defectives were present in the tested group. In all models, it is assumed that: if at most [formula] defectives are present in a test, the output will be negative; if at least u defectives are present, the test result is positive; and if the number of defectives β in a group test lies between [formula] and u  -  1, the result depends on the specific model. Details on the following results can be found in the full version.

Majority group testing

This model was introduced in [\cite=lebedev10], and considers the case where y  =  1 if and only if more than half the defectives are present in the tested pool. This corresponds to [formula] and [formula]. In this case, the score function h becomes a mess, but not if we immediately set p to its optimal value, which turns out to be [formula]. In that case, the score function reduces to the trivial function of + 1 for matches and - 1 for differences, as shown in Table [\ref=tab:1]. Working out the details for large K leads to an asymptotic code length of

[formula]

Interpolating between the ordinary group testing model and majority group testing, one might expect that if [formula] with [formula], the optimal value of p is around [formula] and the asymptotics on T are between 2K ln N and πK ln N.

Bernoulli model

The Bernoulli gap model was previously considered in [\cite=chan13], and says that if the number of defectives in a pool is between [formula] and u  -  1, the probability that the test outcome is positive equals [formula]. We will focus on the extreme case of [formula] and u  =  K, although a similar analysis may be done for other values of [formula] and u. First, the optimal score function follows from [\cite=oosterwijk13] and is given in Table [\ref=tab:1]. As in ordinary group testing, the optimal value of p lies close to 0, and for large K the asymptotic scaling of T is given by

[formula]

Again, interpolating between several results, if the gap between [formula] and u decreases, we conjecture that the constant T goes down from 4K ln N to 2K ln N if [formula] or [formula], and from 4K ln N to πK ln N if [formula].

Linear model

In the linear gap model [\cite=chan13] [\cite=dellungo05], the probability of the test result to be positive scales linearly with the number of defectives in the tested pool. We will again only focus on the case of an extreme gap ([formula] and u  =  K) for ease of computation. First, the optimal centered and normalized score function follows from [\cite=oosterwijk13] and is given in Table [\ref=tab:1]. As shown in [\cite=oosterwijk13], for this model we have [formula] regardless of p, so the best we can do is choose p such that σ̃2 is minimized. This leads to [formula] and [formula], and the asymptotic code length becomes

[formula]

For large N this slightly improves upon a previous result of Del Lungo et al. [\cite=dellungo05], who gave an adaptive scheme with a code length of T  ~  2K2 log 2N  >  2.88K2 ln N.

Unknown model

Finally, if we assume that the output will be a 0 if no defectives are present, the output is 1 if all defectives are present, and we do not know what happens when some defectives are included in the test, then we are back at the traitor tracing game. For this game it is known that in the non-adaptive setting, the capacity-achieving choice is to use the same score function as in the linear gap model, but to vary p for each test by independently drawing it each time from the arcsine distribution (with distribution function [formula] on (0,1)). This leads to the so-called interleaving defense, discussed in [\cite=oosterwijk13] [\cite=laarhoven13wifs], with an asymptotic code length of T  ~  2K2 ln N. This result is the same as in the linear gap model, which motivates why the linear gap model is the hardest group testing model to deal with.

CONCLUSION

In this paper we considered a new framework for probabilistic non-adaptive and adaptive group testing schemes, based on combining several results from traitor tracing. This lead to efficient group testing schemes for various models.

Although in this work we applied results from traitor tracing to group testing, one may wonder whether something can be done in the other direction as well. With the recent traitor tracing result of [\cite=oosterwijk13] achieving capacity in the non-adaptive traitor tracing game, the latter game seems kind of "solved". For the adaptive traitor tracing game one important open question remains, which is establishing the adaptive (dynamic) traitor tracing capacity. Not much is known about this yet, but perhaps combining previous techniques from adaptive group testing [\cite=aldridge12] [\cite=baldassini13] and non-adaptive traitor tracing [\cite=huang12] may bring us closer to a solution.

ACKNOWLEDGMENT

The author is grateful to Jan-Jaap Oosterwijk for many valuable suggestions and insightful discussions. The author further thanks Jeroen Doumen, Antonino Simone, Boris kori, and Benne de Weger for their valuable comments.