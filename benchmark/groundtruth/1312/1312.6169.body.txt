Introduction

The emergence of Social Networks and Social Media sites has motivated a large amount of recent research. Different generic tasks, such as Social Network Analysis, Social Network annotation, Community Detection or Link Prediction, are currently studied. Another active research topic is the study of temporal propagation of information through this type of media. It aims at studying how interactions between users, like sharing a link on facebook or retweeting something on Twitter, effects the spread of items such as pictures, videos or gossip on the internet. While the study of this word-of-mouth phenomenon pre-dates the development of computer science, the amount of data made available by the growth of online social networks offers an unprecedented field of study and enabled new developments. Propagation models aim at predicting and understanding the dynamic of observed propagation.

In this paper, we propose a new diffusion model based on the heat diffusion. It aims to project users in a latent space where propagation occurs like the heat diffusion. This projection is based on the order in which users have been infected in cascades of the train dataset. In order to be able to find which users have been infected and not only who is the most likely to be infected, we define a threshold to split users in two groups: infected or not. This model is an extension of the CDK model (Content Diffusion Kernel) presented in [\cite=bourigault-2008] where no threshold was defined.

Notations

Traditionally, diffusion on networks is represented with the notion of cascade. A cascade is a sequence of users infected by some information (for instance, it could be the list of users who "liked" a specific YouTube video). A cascade describes to whom and when an item spreads through the network, but not how diffusion happens: while it is easy to know when a user got infected by some content, it is usually not possible to know who infected him.

Given a social network composed of a set of N users U = (u1,....,uN), cascades correspond to sets of users infected by the propagated information. Depending on the kind of network and the task in concern, the propagated information can for instance correspond to a given topic, a particular url, a specific tag, etc... In the following, we consider C as a set of cascades over a given network, and two sets of distinct cascades: [formula] the set of training cascades and Ct  ⊆  C the set of testing cascades. A cascade c∈C is defined as:

A source sc∈U which is the user at the source of the cascade - i.e, the first user that published the item concerned by the diffusion.

A set of contaminated users Sc  ⊂  U such that ui∈Sc means that ui has participated to the cascade c [formula] is the set of users who have not participated in c.

A contamination timestamp function defined over Sc such that tc(ui) corresponds to the timestamp at which ui∈Sc has first participated in the cascade. We consider that the contamination timestamp of the source is equal to 0.

Model

The proposed model aims at predicting information diffusion. The central idea of this model is to map the observed information diffusion process into a heat diffusion process in a continuous (euclidean) space. To perform this, we learn diffusion kernels that capture the dynamics of diffusion from a set of training cascades. Let us denote [formula] an euclidean space of dimension n - also called latent space. Learning such a diffusion kernel comes down in our case to learning a mapping of each node of the network to a particular location in Z such that, for a given metric, the latent space explains the contamination timestamps observed in the training cascades.

Learning using a diffusion kernel

We define a diffusion kernel K(t,y,x) such that [formula] which models the heat diffusion in a latent space. It corresponds here to the contamination propensity of a node x at time t given a particular information source y. For learning the kernel function, there is however no full supervision available - this would correspond to a continuous time function giving the heat evolution at any point. The observations only provide the contamination time of the different nodes in a cascade. This partial supervision will be used to constrain the kernel to contaminate the different nodes in their actual temporal order of infection.

In practice, we will use the following constraints:

Given two nodes ui and uj such that ui and uj are contaminated during cascade c - i.e ui∈Sc and uj∈Sc - and respecting tc(ui)  <  tc(uj), KZ must be defined such that [formula]

We define a heat threshold hτ which determine the heat users have to reach to be contaminated. Thus:

Given a node ui such that ui is contaminated during a cascade c, KZ must be defined such that [formula]

Given a node ui such that ui is not contaminated during a cascade c, KZ must be defined such that [formula]

These constraints basically aim at finding embeddings such that users who are contaminated first are closer to the source of the contamination than users contaminated later (or not contaminated at all). hτ is a unique heat threshold which split users in two groups in order to determine which users will be contaminated and not only an order of contamination. Based on the heat equation, we can thus easily rewrite these three constraints as:

[formula]

where τ is a distance threshold. It correponds to the distance from the source of the diffusion beyond which users are not contaminated: their heat never reach hτ.

By the use of classical hinge loss functions, these constraints can be handled by defining a ranking objective Δrank such as:

[formula]

Learning Algorithm

The final training objective is:

[formula]

We name this model "Content Diffusion Kernel with Threshold" (CDKT). Different methods can be used to optimize the objective function. We propose to use a classical stochastic gradient descent method, which iterates until having reached a stop criterion (typically a number of iterations without significant improvement of the global loss). After having randomly initialized all embeddings for nodes in U, the algorithm samples at each iteration a cascade c from the training set [formula] and two nodes ui and uj with uj a node that is either non-infected, or contaminated after ui in the diffusion process described by cascade c. If constraints defined in equation [\ref=embedded_constraints] are not respected with a sufficient margin for this cascade c and the nodes ui and uj, embeddings zui, zuj, zsc and τ are modified towards their respective steepest gradient direction with a learning rate α which is a decreasing function of the number of iterations. The learning process is illustrated in algorithm [\ref=alg:sgd1].

Experimentations

Datasets

We tested our model on several datasets from various online sources: ICWSM [\cite=icwsmdata], Memetracker [\cite=memetracker] and Digg. The first two datasets are sets of blog posts crawled from the web. We define a cascade as a set of posts linked together by hyperlinks. Digg est a plateform where users can share news stories with each other. A cascade is thus the set of users who have share the same story. We filtered the users of each dataset to keep about 5000 users with the most posts.

Quality of the ranking

In order to test the quality of this model, we compared it to several baselines using the same protocol we used in [\cite=bourigault-2008]. The goal is to compute the average precision the model obtains on all cascades. We show the results of 3 baselines IC [\cite=saito-2008], Netrate [\cite=gomez-2011] and Heat Diffusion [\cite=ma-2008] and the 2 latent models CDK and CDKT. IC obtains better results than other baselines.

CDK obtains slightly better results than CDKT. They outperform baselines on both ICWSM and Digg while IC obtains better results on Memetracker.

Learning and Inference complexity

Let T be the number of iterations. The learning complexity is O(T  ×  n), where n is the size of the latent space. Once Z has been learned, the inference process is simple. For a cascade c, we just compute the distance between the user sc and every other user in U. The inference complexity for every cascade is then O(N  ×  n), where N is the number of users. Considering that n  ≪  N, this turns out to be much smaller than the complexity of most alternative discrete methods. For instance, the inference step of the very famous Independant Cascade model(IC), which is a probabilistic model where diffusion propabilities are defined on edges of the network's graph, requires to consider at each time step of the diffusion t every possible infection situation at previous time t - 1, which quickly becomes untractable. In practice, inference of graphical models is done by employing a Monte-Carlo approximation that consists in performing a high amount of simulations of the diffusion process starting from the source of the cascade and following the diffusion probabilities on links of the graph. The inference complexity of this approximation of IC is O(r  ×    ×  ), where [formula] is the average number of infected nodes in the performed simulations, [formula] is their average outdegree and r is the number of simulations used for the MCMC approximation. The weaker the probabilities defined on links are, the greater r must be set to obtain a correct approximation of the distribution of final infection probabilities.

Comparison between CDK and CDKT

We compare here the two kernel models in the task of predicting which users will be contaminated at the end of the diffusion. The main problem to achieve this task with the CDK model is that all cascades are not on the same scale and it is very difficult to find a unique threshold which properly split data in two clusters: contaminated or not. For this reason we don't have any threshold for the CDK model and thus couldn't compare clusters made.

We use the following protocol: after predicting a score of contamination for each user for each cascade, we group all cascades in a unique set. The goal is to see if the models can find users contaminated by any cascade in this set. If there is a unique threshold, they should be able to do so.

Table [\ref=tabp50] shows the precision at rank 50 (P@50) on all datasets for the two models using two latent spaces with different dimension. It corresponds to their ability to find 50 contaminated users. We see that both CDK and CDKT obtain better results on ICWSM. They also obtain a better MAP. This is because the ICWSM dataset is easier than the 2 others. While CDKT is obtain better resultats than CDK on most of the datasets and dimension spaces.

As the P@50 doesn't show all information, figure [\ref=curve] shows the precision/recall curve for the Digg datasets in 500 dimensions spaces. As for the P@50, the curve shows that CDKT is better than CDK.

Conclusion

The CDK model use the phenomenon of heat diffusion to modelize the propagation of content in a latent space. This model is based on a ranking of users and because of the different scale of each representation, there is no easy way to find which user will be contaminated. We proposed in this article an extension of this model CDKT which learns a threshold to split users in two groups: contaminated or not. On several real datasets, we showed that this model is better to find contaminated users. Our next step with this model will be to understand in which contexts (low/hight diffusion, network type, etc) it outperfoms CDK.