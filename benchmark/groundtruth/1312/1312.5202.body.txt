Consensus in the presence of interference

Introduction

In this paper, we consider the design and analysis of average-consensus protocols (averaging vectors in [formula]) in the presence of network interference. Each agent, while communicating locally with its neighbors for consensus, causes an interference in other communication links. We assume that these interferences are additive and lie on low-dimensional subspaces. Such interference models have been widely used in several applications, e.g. electromagnetic brain imaging [\cite=Anonymous:HlXifkm4], magnetoencephalography [\cite=Gutierrez:2004ca] [\cite=Sekihara:2004bn], beamforming [\cite=McCloud:1998im] [\cite=Dogandzic:2002jm], and multiple-access channels [\cite=Lupas:1989bz] [\cite=Varanasi:1998dx]. Interference cancellation, thus, has been an important subject of study in the aforementioned areas towards designing matched detectors, adaptive beamformers, and generalized hypothesis testing [\cite=Scharf:1994jv] [\cite=McCloud:1997je] [\cite=Goldstein:1997jb] [\cite=Wang:1998cm] [\cite=Dogandzic:2007dj] [\cite=Monsees:2013if].

As distributed architectures are getting traction, information is to be distributedly processed for the purposes of learning, inference, and actuation. Average-consensus, thus, is a fundamental notion in distributed decision-making, see [\cite=jadbabailinmorse03] [\cite=Xiao05distributedaverage] [\cite=Mesbahi-parameter] [\cite=Giannakis-est] [\cite=usman_hdctsp09] [\cite=olfati:cdc09] [\cite=Sayed-LMS] [\cite=KarSIAM2013] among others. When the inter-agent communication is noiseless and interference-free, the standard protocol is developed in [\cite=boyd:04]. Subsequently, a number of papers [\cite=Bucklew] [\cite=Kashyap] [\cite=Tuncer] consider average-consensus in imperfect scenarios. Reference [\cite=Kar_TSP2009] considers consensus with link failures and channel noise, while [\cite=Chen_ECDC2011] addresses asymmetric links with asymmetry in packet losses. Consensus under stochastic disturbances is considered in [\cite=Aysal_TIT2010], while [\cite=Nazer_JSTSP2011] studies a natural superposition property of the communication medium and uses computation codes to achieve energy efficient consensus.

In contrast to the past work outlined above, we focus on an algebraic model for network interference. We assume that the underlying communication on any link suffers from additive interference caused due to the communication by other agents following their own consensus protocol. The corresponding interference subspace, in general, depends on the communication link and the interfering agent. A fortiori, it is clear that if the interference by an agent is persistent in all dimensions ([formula]), there is no way to recover the true average unless schemes similar to interference alignment [\cite=Jafar11] are used. In these alignment schemes, the data is projected onto higher dimensions such that the interferences and the data lie in different low-dimensional subspaces; clearly, requiring an increase in the communication resources.

On the other hand, if the interference from each agent already lies in (possibly different) low-dimensional subspaces, the problem we address is whether one can exploit this low-dimensionality for interference cancellation, and subsequently, for consensus. Furthermore, we address how much information can be recovered when the collection of the local interferences span the entire vector space, [formula]? Our contribution in this context is to develop information alignment strategies for interference cancellation and derive a class of (vector) consensus protocols that lead to a meaningful consensus. In particular, we show that the prospoed alignment achieves the average in a subspace whose dimension is complimentary to the maximal dimension of the interference subspaces (over all of the communication links).

To be specific, if agent j sends [formula] to agent i, agent i actually receives [formula], with [formula]. In this context, we address the following challenges:

We explicitly assume that no agent in the network knows how many and which agents may be interfering with its received signals. Additionally, we assume that only the null space of the underlying interferences are known locally (singular values and basis vectors may not be known). Within these assumptions, it is clear that the aforementioned challenges are non-trivial. What we describe in this paper are completely local information alignment strategies that not only ensure that average-consensus is reached, but also characterize where this consensus is reached. In particular, we show that average of the initial conditions, vectors in [formula], can be recovered in the subspace whose dimension, [formula], is complimentary to the (maximal) dimension, [formula], of the local interferences.

The rest of the paper is organized as follows. Section [\ref=pre_not] outlines the notation and gathers some useful facts from linear algebra. Section [\ref=pf] formulates the problem while Section [\ref=aca] presents a simple architecture, termed as uniform interference, and develops the information alignment scheme. Section [\ref=aca] then identifies two generalizations of the uniform interference, namely uniform outgoing interference and uniform incoming interference, subsequently treated in Sections [\ref=s_uoi] and [\ref=s_uii], respectively. In each of these sections, we provide simulations to illustrate the main theoretical results and their implications. Section [\ref=s_discuss] provides a summary and discussion of the main results and Section [\ref=s_conclude] concludes the paper.

Notation and Preliminaries

We use lowercase bold letters to denote vectors and uppercase italics for matrices (unless clear from the context). The symbols [formula] and [formula] are the n-dimensional column vectors of all 1's and all 0's, respectively. The identity and zero matrices of size n are denoted by In and [formula], respectively. We assume a network of N agents indexed by, [formula], connected via an undirected graph, [formula], where [formula] is the set of agents, and [formula], is the set of links, (i,j), such that agent j∈ can send information to agent i∈, i.e. j  →  i. Over this graph, we denote the neighbors of agent i as i, i.e. the set of all agents that can send information to agent i: i  =  {j ~ | ~ (i,j)∈}.

In the entire paper, the initial condition at an agent, i∈, is denoted by an n-dimensional vector, [formula]. For any arbitrary vector, [formula], we use [formula] to denote the subspace spanned by [formula], i.e. the collection of all [formula], with [formula]. Similarly, for a matrix, [formula], we use [formula] to denote the (range space) subspace spanned by the columns of A:

[formula]

For a collection of matrices, [formula], [formula], we use [formula] to denote the subspace spanned by all of the columns in all of the Aj's: let [formula], then

[formula]

Let (A) =  for some non-negative integer,   ≤  n, then [formula]. The pseudo-inverse of A is denoted by [formula]; the orthogonal projection, [formula], of an arbitrary vector, [formula], on the range space, [formula], is given by the matrix [formula], i.e.

[formula]

With this notation, [formula]. Clearly, [formula] is a projection matrix from the properties of pseudo-inverse: [formula] and [formula]. Note that when [formula], then [formula]

The Singular Value Decomposition (SVD) of A is given by [formula] with [formula], then [formula] where [formula] is the pseudo-inverse of the diagonal matrix of the singular values, SA (with [formula]). When A is full-rank, we have [formula]. Since [formula], the singular vectors (UA,VA) can be arranged such that

[formula]

From the above, the projection matrix, IA, is symmetric with orthogonal eigenvectors (or left and right singular vectors), UA, such that its eigenvalues (singular values) are either 0's or 1's.

For some [formula] and some [formula] with [formula], the matrix Kronecker product is

[formula]

which lies in [formula]. It can be verified that [formula] is a block-diagonal matrix where each diagonal block is A with a total of N blocks. We have [formula] The following properties are useful in the context of this paper.

[formula]

for some non-negative integer, k. More details on these notions can be found in [\cite=hornJ].

Problem Formulation

We consider average consensus in a multi-agent network when the inter-agent communication is subject to unwanted interference, i.e. the desired communication, [formula], from agent j∈ to agent i∈ has an additive term, [formula], resulting into agent i receiving [formula] from agent j. We consider the case when this unwanted interference is linear. In particular, every link, j  →  i or (i,j)∈, incurs the following additive interference:

[formula]

where: amij = 1, if agent m∈ interferes with j  →  i, and 0 otherwise; and [formula] is the interference gain when m∈ interferes with the j  →  i communication. What agent i actually receives from agent j is thus:

[formula]

at time k, where the subscript 'ijk' introduces the time dependency on the corresponding variables, see Fig. [\ref=fig_gl].

Given the interference setup, average-consensus implemented on the multi-agent network is given by

[formula]

for [formula], with [formula]. Interference is only incurred when [formula], which is true for each j∈i, in general. In other words, interference is incurred on all the links that are allowed by the underlying communication graph, [formula]. The protocol in Eq. [\eqref=cpi1] reduces to the standard average-consensus [\cite=boyd:04], when there is no interference, i.e. when amijk = 0, for all i,j,k,m, and converges to

[formula]

However, when there is interference, i.e. amijk  ≠  0, Eq. [\eqref=cpi1], in general, either goes to zero or diverges at all agents. The former is applicable when the effect of the interference results into a stable weight matrix, W = {wij}, and the latter is in effect when the interference forces the spectral radius of the weight matrix to be greater than unity. The primary reason is that if wij's are chosen to sum to 1 in each neighborhood (to ensure [formula]), their effective contribution in Eq. [\eqref=cpi2] is not 1 because of the unwanted interference.

This paper studies appropriate modifications to Eq. [\eqref=cpi1] in order to achieve average-consensus. The design in this paper is based on a novel information alignment principle that ensures that the spectral radius of the mixing matrix, W, is not displaced form unity. We assume the following:

No agent, i∈, knows which (or how many) agents are interfering with its incoming or outgoing communication.

The interference structure, amijk and Γmijk, are constant over time, k.

This assumption is to keep the exposition simple and is made without loss of generality as we will elaborate later.

Under these assumptions, the standard average-consensus protocol is given by

[formula]

for [formula]. The goal of this paper is to consider distributed averaging operations in the presence of interference not only to establish the convergence, but further to ensure that the convergence is towards a meaningful quantity. To these aims, we present a conservative solution to this problem in Section [\ref=aca], which is further improved in Sections [\ref=s_uoi] and [\ref=s_uii] for some practically relevant scenarios.

A Conservative Approach

Before considering the general case within a conservative paradigm, we explore a special case of uniform interference in Sections [\ref=s_ui] and [\ref=ill_ui]. We then provide the generalization in Section [\ref=ui_gen] and shed light on the conservative solution.

Uniform Interference

Uniform interference is when each communication link in the network experiences the same interference gain, i.e. [formula]. In other words, all of the blocks in the interference channel of Fig. [\ref=fig_gl] represent the same interference gain matrix, [formula]. In this context, Eq. [\eqref=cpi2] is given by

[formula]

where [formula]. Here, bmi  ≠  0 means that agent m∈ interferes with agent i∈ over some of the messages (from j∈i) received by agent i. In fact, an agent m∈ may interfere with agent i's reception on multiple incoming links, while an interferer, m, may also belong to i, i.e. the neighbors of agent i. To proceed with the analysis, we first write Eq. [\eqref=cpi2] in its matrix form: Let B1 be an N   ×   N matrix whose 'im'th element is given by bmi. Define the network state at time k:

[formula]

Then, it can be verified that Eq. [\eqref=cpi3] is compactly written as

[formula]

The N  ×  N weight matrix, W, has the sparsity pattern of the consensus graph, [formula], while the N  ×  N matrix, B1, has the sparsity pattern of what can be referred to as the interference graph-induced by the interferers. We have the following result.

If [formula], then [formula]

Note that [formula] is a local operation at the ith agent. This is equivalent to multiplying [formula] with the network vector, [formula]. From the lemma's statement, we have [formula] Now note that (recall Section [\ref=pre_not])

[formula]

Subsequently, multiply both sides of Eq. [\eqref=cpm_s1] by [formula]:

[formula]

and the lemma follows.

The above lemma shows that the effect of uniform interference can be removed from the average-consensus protocol if the data (initial conditions) lies in the null space of the interference, Γ1. To proceed, let us denote the interference null space (of Γ1) by ΘΓ1. Recall that [formula] denotes the subspace spanned by all of the initial conditions, the applicability of Lemma [\ref=lem1] is not straightforward because: However, intuitively, a scheme can be conceived as follows: Project the data on a low-dimensional subspace, [formula], such that dim (  ≤   dim (ΘΓ1); and, Align this projected subspace, [formula], on the null-space, ΘΓ1, of the interference. At this point, we must ensure that this alignment is reversible so that its effect can be undone in order to recover the projected data subspace, [formula]. To this aim, we provide the following lemma.

For some 0  ≤    ≤  n, let [formula] have rank [formula], and let another matrix, [formula] have rank [formula]. There exists a full-rank preconditioning, [formula], such that [formula].

Since Γ1 has rank [formula], there exists a singular value decomposition, [formula], where the n  ×  n diagonal matrix S1 is such that its first [formula] elements are the singular values of Γ1, and the remaining [formula] elements are zeros. With this structure on [formula], the matrix V1 can be partitioned into

[formula]

(with [formula] and [formula]), where [formula] is the null-space of Γ1. Similarly, [formula] with rank [formula], where the matrices, [formula] and [formula], are arranged such that the first [formula] diagonals of [formula] are zeros and the remaining are the [formula] singular values of [formula]. Define

[formula]

where [formula] is such that  [formula], and [formula] is chosen arbitrarily such that T1 is invertile. With this construction, note that [formula] is a zero matrix because [formula] is orthogonal to the column-span of 1 (by the definition of the SVD). We have

[formula]

and the lemma follows.

The above lemma shows that the computation of the preconditioning only requires the knowledge of the (uniform) interference null-space, [formula]. Clearly, [formula] is a valid preconditioning as with this [formula] is a zero matrix, but this choice is more restrictive and not necessary.

Information alignment: Lemma [\ref=Tlem] further sheds light on the notion of information alignment, i.e. the desired information sent by the transmitter can be projected and aligned in such a way that it is not distorted by the interference. Not only that the information remains unharmed, it can be recovered at the receiver as the preconditioning T, is invertible. The following theorem precisely establishes the notion of information alignment with the help of Lemmas [\ref=lem1] and [\ref=Tlem].

Let ΘΓ1 denote the null space of Γ1 and let  dim (ΘΓ1). In the presence of uniform interference, the protocol in Eq. [\eqref=cpm_s1] recovers the average in a [formula]-dimensional subspace, [formula], of [formula], via an information alignment procedure based on the preconditioning.

Without loss of generality, we assume that [formula], where [formula] denotes the range space (column span) of some matrix, [formula], such that [formula]. Define [formula], where [formula] is the orthogonal projection that projects any arbitrary vector in [formula] on [formula]. Define the projected (on [formula]) and transformed initial conditions: [formula], where T1 is the invertible preconditioning given in Lemma [\ref=Tlem]. From Lemma [\ref=Tlem], we have

[formula]

i.e. the alignment makes the initial conditions invisible to the interference. From Lemma [\ref=lem1], Eq. [\eqref=cpm_s1] reduces to [formula], when the initial conditions are [formula], which converges to the average of the transformed and projected initial conditions, i0's, under the standard average-consensus conditions on [formula] and W. Finally, average in [formula] is recovered by

[formula]

and the theorem follows.

The above theorem shows that in the presence of uniform interference, a careful information alignment results into obtaining the data (initial conditions) average projected onto any arbitrary [formula]-dimensional subspace, [formula], of [formula]. We note that a completely distributed application of Theorem [\ref=cui_th] requires that each agent knows the null-space, ΘΓ1, of the (uniform) interference, recall Lemma [\ref=Tlem]; and thus is completely local. In addition, all of the agents are required to agree on the desired signal subspace, [formula], where the data is to be projected.

Illustration of Theorem [\ref=cui_th]

In essence, Theorem [\ref=cui_th] can be summarized in the following steps, illustrated with the help of Fig. [\ref=f11]:

Project the data, [formula], on a [formula]-dimensional subspace, [formula], via the projection matrix, [formula].

In Fig. [\ref=f11] (a), the data (initial conditions) lies arbitrarily in [formula] projected on a [formula]-dimensional subspace, [formula], in Fig. [\ref=f11] (b). Interference is given by a rank 1 matrix, Γ1; the interference subspace is shown by the black line;

Align the projected subspace, [formula], on the null space, ΘΓ1, of interference, Γ1, via the preconditioning, T1.

In Fig. [\ref=f11] (c), the projected subspace, [formula], is aligned to the null of space, ΘΓ1, of the interference via preconditioning with T1. Note that after the alignment, the data is orthogonal to the interference subspace (black line);

Consensus is implemented now on the null space of the interference, see Fig. [\ref=f11] (d).

Recover the average in [formula] via T- 11.

Finally, the average in the null space, ΘΓ1, is translated back to the the signal subspace, [formula], via T- 11. We also show the true average in [formula] by the '[formula]', see Fig. [\ref=f11] (e).

From Theorem [\ref=cui_th], when Γ1 is full-rank, i.e. [formula] the iterations converge to a zero-dimensional subspace and are not meaningful. However, if the interference is low-rank, consensus under uniform interference may still remain meaningful. In fact, we can establish the following immediate corollaries.

Let [formula] be such that [formula]. Then consensus under uniform interference, Eq. [\eqref=cpm_s1], recovers the true average of the initial conditions, [formula].

Let the initial conditions, [formula], belong to the range space, [formula], of some matrix, [formula]. Then consensus under uniform interference, Eq. [\eqref=cpm_s1], recovers the average in a  dim (ΘΓ1) subspace that can be chosen along any [formula] singular values of A.

The proofs of the above two corollaries immediately follow from Theorem [\ref=cui_th]. In fact, the protocol, Eq. [\eqref=cpm_s1], can be tailored towards the [formula] largest singular values (principal consensus), or towards any arbitrary [formula] singular values (selective consensus). The former is applicable to the cases when the data (initial conditions) lies primarily along a few singular values. While the latter is applicable to the cases when the initial conditions are known to have meaningful components in some singular values. We now show a few examples on this approach.

Consider the initial conditions, [formula], to lie in the range space, [formula], with the following:

[formula]

Clearly, [formula]. Consider any rank 1 interference, Γ:

[formula]

It can be easily verified that originally the data subspace, [formula], is aligned with the interference subspace, [formula], and standard consensus operation is not applicable as no agent knows from which agents and on what links this interference is being incurred (recall Assumption (a) in Section [\ref=pf]). In other words, each agent i, implementing Eq. [\eqref=cpi1], cannot ensure that [formula] for the above iterations to remain meaningful and convergent.

Following Theorem [\ref=cui_th], we choose [formula], which can be verified to be a diagonal matrix with 1 and - 1 on the diagonal, resulting into [formula]. The effect of preconditioning, T1, is to move the entire 1-dimensional signal subspace in the null space of the interference. Subsequently,

[formula]

when [formula], and true average is recovered via T- 11 (see Corollary [\ref=cor1]).

A Conservative Generalization

In Section [\ref=s_ui], we assume that the overall interference structure, recall Fig. [\ref=fig_gl], is such that the interference gains are uniform, i.e. Γmij  =  Γ1. We now provide a conservative generalization of Theorem [\ref=cui_th] to the case when the interferences do not have a uniform structure.

Define [formula] to be the network interference matrix such that

[formula]

Let ΘΓ be the null space of Γ with  dim (ΘΓ). The protocol in Eq. [\eqref=cpi2] recovers the average in a [formula]-dimensional subspace, [formula], of [formula], with an appropriate alignment.

The proof follows directly from Lemmas [\ref=lem1], [\ref=Tlem], and Theorem [\ref=cui_th]. Following the earlier discussion, we choose a global preconditioning, [formula], based on the null-space, ΘΓ, of the network interference, Γ. The solution described by Theorem [\ref=con_th] requires each interference to belong to some subspace of the network interference, [formula], and each agent to have the knowledge of this network interference. However, this global knowledge is not why the approach in Theorem [\ref=con_th] is conservative, as we explain below.

Consider [formula], to be such that [formula], for each i,j,m∈. In other words, each interference block in Fig. [\ref=fig_gl] is a one-dimensional line in [formula]. Theorem [\ref=con_th] assumes a network interference matrix, Γ, such that its range space, [formula], includes every local interference subspace, [formula]. When each local interference subspace, [formula], is one-dimensional, we can easily have [formula], subsequently requiring [formula]. This happens when the local interference subspaces are not aligned perfectly. Theorem [\ref=cui_th] is a very special scenario when all of the local interference subspaces are exactly the same (perfectly aligned). Extending it to Theorem [\ref=con_th], however, shows that when the local interference are misaligned, [formula] may have dimension n, and consensus is only ensured on a zero-dimensional subspace, i.e. with [formula].

This limitation of Theorem [\ref=con_th] invokes a significant question: When all of the local interferences are misaligned such that their collection spans the entire [formula], can consensus recover anything meaningful? Is it true that Theorem [\ref=con_th] is the only candidate solution? In the next sections, we show that there are indeed distributed and local protocols that can recover meaningful information. To proceed, we add another assumption, (c), to Assumptions (a) and (b) in Section [\ref=pf]:

The interference matrices, Γmij, are independent over j.

Note that in our interference model, any agent m∈ can interfere with j  →  i communication; from Assumption (a), these are unknown to either agent j or i. Assumption (c) is equivalent to saying that this interference is only a function of the interferer, m∈, or the receiver, i∈, and is independent of communication link, j  →  i.

We consider the design and analysis in the following cases:

Uniform Outgoing Interference: [formula]. In this case, each agent, m∈, interferes with every other agent via the same interference matrix, Γm, see Fig. [\ref=uoi_T] (top). This case is discussed in Section [\ref=s_uoi];

Uniform Incoming Interference: [formula] In this case, each agent i incurs the same interference, Γi, over all the interferers, m∈, see Fig. [\ref=uoi_T] (bottom). This case is discussed in Section [\ref=s_uii].

Uniform Outgoing Interference

This section presents results for the uniform outgoing interference, i.e. each agent, m∈, interferes with every other agent in the same way. Recall that agent j wishes to transmit [formula] to agent i in the presence of interference. When this interference depends only on the interfere, agent i receives

[formula]

from agent j at time k. We modify the transmission as [formula] for all m∈ for some auxiliary state variable, [formula], to be explicitly defined shortly; agent i thus receives

[formula]

from agent j at time k. Consider the following protocol:

[formula]

where [formula] is now a matrix that agent i associates with agent j; recall that earlier Wij  =  wijIn. We get

[formula]

where [formula]. We have the following result.

For some non-negative integer,   ≤  n, let each outgoing interference matrix, Γi, have rank [formula]. Let [formula] be the projection matrix that projects [formula] on [formula], where [formula]. Then, there exist Ti at each i∈, and Wij's for all (i,j)∈ such that Eq. [\eqref=cpi_uoib] becomes

[formula]

at each i∈, when [formula].

Without loss of generality, we assume that [formula], where [formula] denotes the range space of some matrix, [formula], such that [formula]. Define [formula], where [formula] is the orthogonal projection that projects any arbitrary vector in [formula] on [formula]. Define [formula] to be the projected initial conditions, i.e. [formula]. Let Ti be the locally designed, invertible preconditioning, obtained at each i∈ from the null-space, ΘΓi, of its outgoing interference matrix, Γi, see Lemma [\ref=Tlem]. Clearly, following Lemma [\ref=Tlem], we have [formula]. Choose

[formula]

From Eq. [\eqref=cpi_uoib], we have

[formula]

We claim that when [formula], then [formula], proven below by induction. Consider k = 0, then

[formula]

which is a linear combination of vectors in [formula] and thus lies in [formula]. Assume that [formula], and some k, leading to [formula] Then for k + 1:

[formula]

which is a linear combination of vectors in [formula].

The main result on uniform outgoing interference is as follows.

Let ΘΓi denote the null space of Γi, and let [formula]. In the presence of uniform outgoing interference, Eq. [\eqref=cpi_uoia] recovers the average in a [formula]-dimensional subspace, [formula], of [formula], when we choose Ti according to Lemma [\ref=Tlem], and Wij = wijT- 1j, at each i,j∈i.

The proof follows from Lemma [\ref=Tlem_uoi]. In other words, the consensus protocol in the presence of uniform outgoing interference, Eq. [\eqref=cpi_uoia], converges to

[formula]

for any [formula] We note that each agent, i∈, is only required to know the null-space of its outgoing interference, Γi, to construct an appropriate preconditioning, Ti. In addition, each agent, i∈, is required to obtain the local pre-conditioners, Tj's, only from its neighbors, j∈i; and thus, this step is also completely local.

The protocol described in Theorem [\ref=th_uoi] can be cast in the purview of Fig. [\ref=uoi_T] (top). Notice that a transmission from any agent, i∈, passes through agent i's dedicated preconditioning matrix, Ti. The network (both non-interference and interference) sees only [formula] at each k. Since the interference is a function of the transmitter (uniform outgoing), all of the agents ensure that a particular signal subspace, [formula], is not corrupted by the interference channel. The significance here is that even when the interferences are misaligned such that [formula], the protocol in Eq. [\eqref=cpi_uoia] recovers the average in  min i∈{ΘΓi} dimensional signal subspace. On the other hand, the null space of the entire collection, [formula], may very well be 0-dimensional. For example, if each Γi is rank 1 such that each of the corresponding one-dimensional subspace is misaligned, Eq. [\eqref=cpi_uoia] recovers the average in an n - 1 dimensional signal subspace. On the other hand, Theorem [\ref=con_th] does not recover anything other than [formula].

Illustration of Theorem [\ref=th_uoi]

Let the initial conditions belong to a 2-dimensional subspace in [formula] and consider N = 10 agents, with random initial conditions, shown as blue squares in Fig. [\ref=f11_uoi] (a). Uniform outgoing interference is chosen as one of the three 1-dimensional subspaces such that each interference appears at some agent in the network, see Fig. [\ref=f11_uoi] (b). Clearly, each interference is misaligned and [formula] Hence, the protocol following Theorem [\ref=con_th] requires the signal subspace to be [formula] dimensional. However, when the agent transmissions are preconditioned using Ti's, each agent projects its transmission on the null space of its interference. Each receiver, i∈, receives a misaligned data, [formula], from each of its neighbors, j∈i, see Fig. [\ref=f11_uoi] (c). Since each [formula] is a function of the corresponding neighbor, j, the data can be translated back to [formula] via T- 1j, which is incorporated in the consensus weights, Wij = wijT- 1j.

Uniform Incoming Interference

In this section, we consider the case of uniform incoming interference, i.e. each agent i∈ incurs the same interference, Γi, over all of the interferers, m∈. This scenario is shown in Fig. [\ref=uoi_T] (bottom). We note that Theorem [\ref=con_th] is applicable here but results into a conservative approach as elaborated earlier. We note that this case is completely different from the uniform outgoing case (of the previous section), since preconditioning (alone) may not work as we explain below.

When an agent, m∈, employs preconditioning, it may not precondition to account for the interference, Γi, experienced at each receiver, i, with which m may interfere. In the purview of Fig. [\ref=uoi_T] (bottom), if agent m2∈ preconditions using Tm2 to cancel the interference, Γi, experienced by agent i; the same preconditioning, Tm2, is not helpful to agent l. For example, let agent m2 choose [formula] (a valid choice following Lemma [\ref=Tlem]), then as discussed earlier [formula] and m2's interference is not seen by agent i. However, this preconditioning appears as [formula] at agent l, which is [formula] only when [formula]. This is not true in general.

We now explicitly address the uniform incoming interference scenario. In this case, Eq. [\eqref=cpi2] takes the following form:

[formula]

[formula] and where, as in Section [\ref=s_uoi], we use a matrix, [formula] to retain some design flexibility. The only possible way to cancel the unwanted interference now is via what can be referred to as post-conditioning. Each agent, i∈, chooses a post-conditioner, [formula]. As before, we assume [formula] to be the projection matrix for some subspace, [formula], and modify the transmission as [formula], for some auxiliary state variable, [formula], to be explicitly defined shortly. The modified protocol is

[formula]

The goal is to design an Ri such that [formula]. Following the earlier approaches, we assume that [formula], and [formula], such that [formula], with SVDs, [formula] and [formula], where the singular value matrices are arranged as

[formula]

The next lemma characterizes the post-conditioner, Ri.

Let [formula] and [formula] have the structure of Eq. [\eqref=SiSS]. Given the null-space of [formula], there exists a rank [formula] post-conditioner, Ri, such that [formula].

We assume that Ui is partitioned as [formula], where [formula] and [formula]. Clearly, i is the null-space of [formula]. Define

[formula]

where [formula] is such that [formula], and [formula] is arbitrary. By definition, we have [formula]; hence, by construction, [formula]. It can be verified that the post-conditioning results into

[formula]

and the lemma follows. Note that [formula] is a valid choice but it is not necessary.

With the help of Lemma [\ref=Rlem], Eq. [\eqref=cpi_uii] is now given by

[formula]

Recall that [formula] is an n  ×   matrix whose column-span is the same as the column-span of i, and the column-span of i is the null-space of [formula]. We now denote the lower   ×   sub-matrix of [formula] by i. In order to simply the above iterations, we note that

[formula]

and [formula]. It is straightforward to show that [formula] is always invertible. Based on this discussion, the following lemma establishes the convergence of Eq. [\eqref=cpi_uii].

Let [formula] and some projection matrix, [formula], have ranks [formula], and [formula], respectively (0  ≤    ≤  n), such that Si and [formula] are arranged as in Eq. [\eqref=SiSS]. When Ri is chosen according to Lemma [\ref=Rlem], and for each i∈, Wij is chosen as

[formula]

the protocol in Eq. [\eqref=cpi_uii] recovers the average of the last [formula] components of the initial conditions, i0.

We note that under the given choice for Ri's, the interference term is [formula], and Eq. [\eqref=cpi_uii] reduces to Eq. [\eqref=cpi_uii3]. Now we use Eqs. [\eqref=uii_P1] and [\eqref=uii_W] in Eq. [\eqref=cpi_uii3] to obtain:

[formula]

which in the limit as k  →    ∞   converges to

[formula]

That [formula] is invertible is always true because it is a principal minor of an invertible matrix, [formula].

Following is the main result of this section.

Let Γi's, Ri's, and Wij's, be chosen according to Lemma [\ref=lem_ui]. The protocol in Eq. [\eqref=cpi_uii] under uniform incoming interference recovers the average in a [formula]-dimensional subspace, [formula], of [formula].

Without loss of generality, assume that [formula] has a projection matrix, [formula], with SVD as defined above. Let [formula] and define [formula]. Then, from Lemma [\ref=lem_ui]

[formula]

[formula], and the theorem follows.

Some remarks are in order to explain the mechanics of Theorem [\ref=th_cui]. Let [formula] with [formula] and [formula] where [formula] is the null space of [formula].

(i) When any agent i∈ receives [formula] as an interference, it is canceled via the post-conditioning by Ri, regardless of the transmission, [formula]:

[formula]

because of the structure in the [formula] and Si from Eq. [\eqref=SiSS].

{(ii) It is more interesting to observe the effect on the intended transmission, j  →  i, after the post-conditioning and multiplication with Wij. It is helpful to note that [formula], and consider the transmission as [formula] instead of [formula]:

[formula]

The operation, [formula], by the receiver, Rx, is vital to cancel the interference as shown in the previous step. However, this measure by the receiver also 'distorts' the intended transmission. What agent i receives is now multiplied by a low-rank matrix, [formula], in general. Consider for a moment that agent j were to send j0 and agent i obtains [formula], after the interference canceling operation. How can agent i choose an appropriate Wij to undo this post-conditioning? Such a procedure is not possible unless in trivial scenarios, e.g., when the interference was a diagonal matrix and Ui = In. However, the transmitter may preemptively undo the distortion eventually incurred by the receiver's interference canceling operation. This is precisely what is achieved by sending [formula].

(iii) As we discussed, a preemptive measure, sending [formula], by the transmitter is vital so that the distortion bound to be added at the receiver is reversed. This reorientation, however, can be harmful, e.g., j0 may only contain meaningful (non-zero) information in the first [formula] components and the multiplication by [formula] destroys this information. To avoid this issue, we choose the initial condition at each agent as [formula]; the first transmission at any agent i is thus:

[formula]

which is to transform any arbitrary initial condition orthogonal to the null-space of the desired signal subspace, [formula]. Since, the signal subspace, [formula], is [formula]-dimensional, retaining only the last [formula] components, after the transformation by [formula], suffices.

(iv) We choose Wij according to Eq. [\eqref=uii_W] and obtain

[formula]

[formula], where [formula] are the interference-free consensus iterates. Now lets look at i2, ignoring the interference terms as they are [formula], regardless of the transmission:

[formula]

by the same procedure that we followed to obtain i1. In fact, the process continues and we get [formula] or [formula], and the average in [formula], is obtained by [formula]

Illustration of Theorem [\ref=th_cui]

We now provide a graphical illustration of Theorem [\ref=th_cui]. The network is comprised of N = 10 agents each with a randomly chosen initial condition on a 2-dimensional subspace, [formula], of [formula], shown in Fig. [\ref=f11_uii] (a). Incoming interference is chosen randomly as a one-dimensional subspace at each agent, shown as grey lines in Fig. [\ref=f11_uii] (b). It can be easily verified that the span of all of the interferences, [formula], is the entire [formula]. The initial conditions are now transformed with [formula] so that the transmission, [formula], does not destroy the signal subspace, [formula]. This transformation is shown in Fig. [\ref=f11_uii] (c). Consensus iterations are implemented in this transformed subspace, ik, Fig. [\ref=f11_uii] (d), and finally, the iterations, [formula], in the signal subspace, [formula], are obtained via a post-multiplication by [formula].

Discussion

We now recapitulate the development in this paper.

Assumptions: The exposition is based on three assumptions, (a) and (b) in Section [\ref=pf], and (c) in Section [\ref=ui_gen]. Assumption (a), in general, ensures that the setup remains practically relevant, and further makes the averaging problem non-trivial. Assumption (b) is primarily for the sake of simplicity; the strategies described in this paper are applicable to the time-varying case. What is required is that when any incoming (or outgoing) interference subspace changes with time, this change is known to the interferer (or the receiver) so that appropriate pre- (or post-) conditioning is implemented. Finally, Assumption (c) is noted to cast a concrete structure on the proposed interference modeling. In fact, one can easily frame the incoming or outgoing interference as a special case of the general framework. However, explicitly noting it establishes a clear distinction among the different structures.

Conservative Paradigm: We consider a special case when each of the interference block in the network, see Fig. [\ref=fig_gl], is identical. This approach, rather restrictive, sheds light on the information alignment notion that keeps recurring throughout the development, i.e. hide the information in the null space of the interference. When the local interferences, Γmij, are not identical, we provide a conservative solution that utilizes an interference 'blanket' (that covers each local interference subspace) to implement the information alignment. However, as we discussed, this interference blanket soon loses relevance as it may be n-dimensional to provide an appropriate cover. When this is true, the only reliable data hiding is via a zero-dimensional hole (origin) and no meaningful information is transmitted. This conservative approach is improved in the cases of uniform outgoing and incoming interference models.

Uniform Outgoing Interference: The fundamental concept in the uniform outgoing setting is to hide the desired signal in the null-space of the interferences, Γm's. This alignment is possible at each transmitter as the eventual interference is only a function of the transmitter.

Uniform Incoming Interference: The basic idea here is to hide the desired signal in the null-space of the transpose of incoming interferences, [formula]'s. This alignment is possible at each receiver as the eventual interference is only a function of the receiver. It can be easily verified that the resulting procedure is non-trivial.

Null-spaces: Incoming and outgoing interference comprise the two major results in this paper. It is noteworthy that both of these results only assume the knowledge of the corresponding interference null-spaces; the basis vectors of these null spaces can be arbitrary while the knowledge of the interference singular values is also not required. It is noteworthy that in a time-varying scenario where the basis vectors of the corresponding null-spaces change such that their span remains the same, no time adjustment is required.

Uniform Link Interference: One may also consider the case when Γmij  =  Γij, see Eq. [\eqref=cpi2], i.e., each interference gain is only a function of the communication link, j  →  i. Subsequently, when each receiving agent, i∈, knows the null space of [formula], a protocol similar to the uniform incoming interference can be developed.

Performance: To characterize the steady-state error, denoted by [formula] at an agent i, define [formula], where [formula] is the true average, Eq. [\eqref=pavg]. Clearly,

[formula]

i.e. the error is orthogonal to the estimate, or the average obtained is the best estimate in [formula] of the perfect average.

Conclusions

In this paper, we consider three particular cases of a general interference structure over a network performing distributed (vector) average-consensus. First, we consider the case of uniform interference when the interference subspace is uniform across all agents. Second, we consider the case when this interference subspace depends only on the interferer (transmitter), referred to as uniform outgoing interference. Third, we consider the case when the interference subspace depends only on the receiver, referred to as uniform incoming interference. For all of these cases, we show that when the nodes are aware of the complementary subspaces (null spaces) of the corresponding interference, consensus is possible in a low-dimensional subspace whose dimension is complimentary to the largest interference subspace (across all of the agents). For all of these cases, we derive a completely local information alignment strategy, followed by local consensus iterations to ensure perfect subspace consensus. We further provide the conditions under which this subspace consensus recovers the exact average. The analytical results are illustrated graphically to describe the setup and the information alignment scheme.