true in true in

Colored Coalescent Theory

Jianjun Tian

Mathematical Biociences Institute

The Ohio State University

Columbus, OH 43210, USA

Xiao-Song Lin

Department of Mathematics

University of California, Riverside

Riverside, CA 92521, USA

Introduction

In the last twenty years, coalescent theory has been developed into a powerful analytical tool for population genetics. This theory is especially significant with the rapid accumulation of DNA sequence data. First formulated in the seminal work of Kingman in 1982 [\cite=King1] [\cite=King2], coalescent theory offers various sample-based and highly efficient statistical methods for analyzing molecular data such as DNA sequence samples. For recent reviews as well as extensive references of coalescent theory, see [\cite=FL] and [\cite=RN]. A nice introduction to coalescent theory can be found in [\cite=no].

Mathematically, coalescent theory studies stochastic processes leading to the most recent common ancestor (MRCA) from a sample under various coalescent models. If one thinks of the more commonly studied branching processes as stochastic models of generating random trees from their roots, coalescent processes can be thought of as the inverse processes which recover random trees from their leaves. In a more elaborated version crucial for population genetics, a coalescent process is usually superimposed with a mutation process. This mutation process can be thought of as an independent Poisson process running on the random tree generated by the coalescent process, with the edge lengths of the random tree serving as the time scale for the mutation process.

In this article, we introduce a coalescent process which generated random colored trees. Here a coloring of a tree is to color the vertices of the tree by two colors, black (B) and white (W), such that if two vertices are joint by an edge, they may have different colors only when the vertex closer to the root is a branching point of the tree. Thus, in recovering a random colored tree using this coalescent process, we may end up at a colored tree with the root colored black or colored white. The quantities which we are interested in include the following: the probabilities for the coalescent process to reach a black or white root, respectively; the mean and the cumulative distribution function of the coalescent time, which is the time elapsed before the coalescent process reaches a black root or a white root, respectively; etc.

Our goal in the mathematical development of colored coalescent theory is to understand the geographical models of the origin of the human being. Let us take two sets of gene sequences from the different geographical locations. Designate each by different color. We then mix them as a population sample. Based upon the sample, we look at which location the most recent common ancestor was arisen from. Our theory can give a answer theoretically. We hope to incorporate genetic data analysis of gene genealogies into the colored coalescent framework in our future study.

The Wright-Fisher model in population genetics assumes discrete, non-overlapping generations [formula] in which each generation contains a fixed number N of individuals. In a so-called haploid population, each member in Gi + 1 is the child of exactly one member in Gi, but the number of children born to the j's member of Gi is a random variable νj satisfying the symmetric multinomial distribution

[formula]

We additionally assume that each individual in a generation has two possible colors B and W. In the next generation, if a member is the only child of its parent, then this child will inherit the color of its parent. But when a parent has more than one child in the next generation, the color of children of that common parent satisfies a binomial distribution. More specifically, for a parent with k children in the next generation, k > 1, let b be the number of children with B color and w be the number of children with W color (so that b + w = k), we have

[formula]

where [formula].

Following the same argument as in [\cite=King1] [\cite=King2], we have a limiting coalescent process for a sample of n colored individuals when N  →    ∞  . In this limiting coalescent process, one only allow to have two individuals in the sample to coalesce. When two colored individuals coalesce, the probability of the color of their common parent can be calculated according to Equation ([\ref=color1]). Assuming that we may express those probabilities of various cases in the following multiplication rules:

[formula]

then we must have p = 1 - q and x = 1 / 2. For other values of x, the coalescent process itself is still defined, although we no longer have it as the backward process of a branching genealogical process. Throughout this article, we will assume that 0 < x < 1. We call this limiting coalescent process the colored coalescent process. See Figure 1 for an example of a colored genealogical relation.

Figure 1. A colored genealogical relation.

The stochastic character of a state of the colored coalescent process with the parameter x turns out to depend only on the number of individuals in this state colored by B. If we start the colored coalescent process with a sample of n colored individuals, the initial state can be denoted by a pair of non-negative integers (k,n - k), where k is the number of individuals colored by B and n - k is the number of individuals colored by W. The absorbing states of the colored coalescent process are (0,1) (a white root) and (1,0) (a black root), respectively. Our main result is Theorem 2, which states the coalescent probabilities P(n1,n2)(0,1) and P(n1,n2)(1,0) from different configurations of the sample to different functions of the colored coalescent times, T(n1,n2)(0,1) and T(n1,n2)(1,0). For example, when x = 1 / 2, the probabilities to reach (0,1) and (1,0), respectively, are both 1 / 2. The mean time to reach (0,1) is 3 - 2 / n, and the mean time to reach (1,0) is 3 - 2 / n. Finally, according to Lemma 2, the mean time to reach either (0,1) or (1,0) is 2 - 2 / n, which is the same as in the classical coalescent theory. This shows the difference and similarity between our colored coalescent theory and the classical coalescent theory.

In Section 2, we discuss in details the colored coalescent process. The technique of lumping turns out to be very important to simplify computations involved. So we also include in Section 3 a general discussion about lumping of Markov processes. In Sections 4 and 5, we use the lumping technique to calculate various statistic parameters of the colored coalescent process. In the paper [\cite=tian], a comprehensive coalescent model which could accommodate the situation of mutations is studied.

A colored coalescent model and some of its basic parameters

We start with the standard Kingman coalescent process [\cite=King1] [\cite=King2]. So we have a sample of n individuals. In a unit time Δt, two of these n individuals may coalesce with probability [formula]. Let Δt  →  0, we arrive at a continuous stochastic process where the probability that no coalescent event happens within the time interval

[formula]

e.

[formula]

T=τ

[formula]

E(T)==2-.

[formula]

L={(k,l)∈ Z× Z ; k≥ 0, l≥ 0, 0<k+l≤ n}.

[formula]

C:=rr rB BB,

[formula]

E(T)==2-.

[formula]

The lumpability of Markov processes

The full details of the coalescent process Z(t) is hard to compute in general. For example, there are two absorption states, (0,1) and (1,0). The coalescent time Tπ is the time elapsed before the process Z(t) reaches any one of these two states. Can we compute the coalescent time to a particular one of these two states? In order to do this, the method of lumping seems to be quite suitable. In what follows, we will show that Z(t) can be lumped into another Markov process. For this lumped Markov process, the computation of most of its interesting parameters can be made explicit. For that purpose, we need to discuss the notion of lumpability of a Markov process first.

Let Xn be a Markov chain with finite state space [formula], and [formula] [formula] be a partition of S. Let pij be the transition probability from ei to ej. The probability that the chain moves into the set Eη in one step, given that it starts at ei, is equal to [formula]. We say that the Markov chain Xn is lumpable if for ei,ej∈Eξ,

[formula]

When the chain Xn is lumpable, we define a Markov chain [formula] on [formula] with the transition probability from Eξ to Eη equal to [formula], for ei∈Eξ. This chain [formula] is called a lumping of Xn. See [\cite=KS].

Now, we consider a Markov process X(t) on S. Let P(t) = (pij(t)) be the probability transition matrix of X(t). We define that X(t) is lumpable if for ei,ej∈Eξ,

[formula]

Suppose that X(t) is lumpable. We define

[formula]

for ei∈Eξ. Let [formula]. This is an v  ×  v matrix.

[formula] defines a Markov process on [formula].

The proof is to check the property that [formula]. It can be done directly by computation. We call the Markov process [formula] on [formula] with the probability transition matrix [formula] a lumping of X(t).

Let Q = (qik) be the infinitesimal generator of X(t), i.e. P(t) = etQ. We say that Q is lumpable if

[formula]

for ei,ej∈Eξ.

We need to introduce some notations in order to prove the following theorem which relates the lumpability of Q with that of P(t) = etQ. Recall that the finite set of states [formula] is partitioned into [formula]. Let U be the v  ×  r matrix whose ξ-th row is the probability vector having equal components for states in Eξ, [formula], and 0 elsewhere. Let V be the r  ×  v matrix with the η-th column a vector with 1's in the components corresponding to states in Eη, [formula] and 0 elsewhere. One can check by a direct computation that UV = Iv and that the Markov process X(t) is lumpable if and only if VUP(t)V = P(t)V. (This statement generalizes a theorem about lumpability of Markov chains in [\cite=KS].) Furthermore, when P(t) is lumpable, we have the [formula] for the lumping process [formula]. Similarly, the infinitesimal generator Q of X(t) is lumpable if and only if VUQV = QV. And when Q is lumpable, its lumping is [formula].

A necessary and sufficient condition for the Markov process X(t) to be lumpable is that its infinitesimal generator Q is lumpable. When Q is lumpable, we have [formula].

The intuitive idea of this theorem is clear, we therefore will not give the detailed proof here.

Parity lumping of the colored coalescent process

The state space L of Z(t) is partitioned into diagonals Δm, [formula]. We will divide each Δm into two disjoint subsets, Om and Em. A state (k,l)∈Om when k + l = m and k is odd and (k,l)∈Em when k + l = m and k is even. Let

[formula]

We will define a new Markov process on [formula] obtained by a lumping of the process Z(t). For that purpose, we need to check the lumpability of Z(t). Using Theorem [\ref=lumpable], we only need to check the lumpability of the infinitesimal generator Q = (qζη) given by Equation ([\ref=Q]).

Let ζ = (k,l)∈Om, then k + l = m and k is odd. We have

[formula]

and

[formula]

Both of them are independent of k. Other lumpability conditions for Q can be checked similarly. So, by Theorem [\ref=lumpable], Z(t) has a lumping [formula], which is a Markov process on [formula] with the infinitesimal generator [formula]. We will order the elements in [formula] by [formula]. Under this ordering, [formula] is a block matrix with diagonal ( - rnI2,..., - r2I2,02) and updiagonal (rnC,...,r2C), where C is a 2  ×  2 matrix:

[formula]

We will follow the same idea as in Section 2 to compute basic parameters of the lumped coalescent process [formula]. We shall be able to get more complete information about the process [formula] than about Z(t).

(1) The fundamental matrix of the jump chain of [formula]. The probability transition matrix of the jump chain of [formula] is a block matrix with each updiagonal entry C and each diagonal 0 except the last I2. Notice that the states E1 and O1 are absorbing states. So the fundamental matrix [formula] of the jump chain can be easily calculated. This is a block updiagonal matrix, each of whose diagonal entry is I2, each of whose updiagonal entry is C, each of whose second updiagonal entry is C2, up to the entry Cn - 2. By a straightforward computation, we may get

[formula]

(2) The sojourn coefficients of the jump chain. The sojourn coefficients ak (respectively, bk) is the expected number of times the jump chain [formula] of [formula] to visit the state Ek (respectively, Ok), given that it starts at an initial distribution π = (πE,πO) on the states {En,On}.

We have

[formula]

The sojourn coefficients (ak,bk) can be calculated as follows:

[formula]

(3) Coalescent probability for the lumped coalescent process [formula]. Since E1 and O1 are absorbing states, the coalescent probability Pπ,E (respectively, Pπ,O) is the probability of the jump chain to arrive at E1 (respectively, O1), given that it starts at a distribution π = (πE,πO) on the initial states {En,On}.

We have

[formula]

In particular, let PE,E be the probability of reaching E1, given that the process starts at En, and other quantities PE,O,PO,E,PO,O be defined similarly, then we have

[formula]

Since a minimal Markov process on a finite set of states and its jump chain have the same character of states, E1 and O1 are absorbing states for both [formula] and [formula]. So we have (Pπ,E,Pπ,O) = (a1,b1).

(4) The expected coalescent time for the lumped coalescent process [formula]. Since E1 and O1 both are absorbing states of the process [formula], the coalescent time Tπ,E to the state E1 is a random variable, which is the time elapsed before the process [formula] reaches E1, given that it starts at the initial distribution π = (πE,πO) and conditional on [formula] not reaching O1. Similarly, we have the coalescent time Tπ,O to the state O1 as a random variable. To calculate the expectation of the coalescent time, we will define a random variable [formula] first and calculate its expectation. Then the Feller relation will tell us that the expectation of [formula] is exactly the same as the expectation of the coalescent time Tπ,E to the states E1. I. e., we have [formula].

Let τk be a random variable distributed exponentially with the mean r- 1k, which is the time elapsed before the lumped coalescent process [formula] moves either to Ek - 1 or Ok - 1, given that it starts at Ek (or Ok). Recall that the sojourn coefficients ak (respectively, bk) is the expected number of times the jump chain [formula] of [formula] to visit the state Ek (respectively, Ok), given that it starts at a initial distribution π = (πE,πO) on the initial states {En,On}. Then the random variable [formula] is defined by

[formula]

Similarly, we may define a random variable [formula], whose expectation turns out to be the same as the expectation of the coalescent time Tπ,O to the state O1:

[formula]

The expectation of the coalescent time to E1 and O1 are and respectively.

The expectations

[formula]

are easy to compute since we know that E(τk) = r- 1k and τk's are independent random variables. To see why

[formula]

we define a conditional process whose state characters are all the same as that of the process [formula] except for the states E2 and O2. At these two states E2 and O2, the conditional process will move only to E1 with the mean of holding time [formula] and [formula], respectively. Then, by the Feller relation, [formula] is the expectation of the coalescent time for this conditional process to reach E1. On the other hand, the coalescent time for the conditional process to reach E1 is exactly Tπ,E. So we have [formula]. Similarly, we have [formula].

(5) The cumulative distribution function of the coalescent time of [formula]. The computation of the complementary cumulative distribution functions Pr   {Tπ,E  ≥  t} and Pr   {Tπ,O  ≥  t} is rather involved. So we will put it in the appendix and give here only the results.

We need to introduce some functions of x first. They are Kn,2, Kn,2', Kn',2, and Kn',2'. Here the indices [formula] are for the states [formula] and the indices [formula] are for [formula]. These functions are given as follows:

[formula]

We denote Tπ,E with πE = 1,πO = 0 by TE,E. Other coalescent time TO,E, TE,O, and TO,O have the same meaning.

We have and

Also, Pr   {TE,O  ≥  t}  =   Pr   {TO,E  ≥  t} and Pr   {TO,O  ≥  t}  =   Pr   {TE,E  ≥  t}.

Back to the colored coalescent process Z(t)

For the parity lumping of the colored coalescent process, we have a commutative diagram This can be shown by a simple matrix computation. Notice that, for an arbitrary lumpable Markov process, we do not know if this diagram is commutative or under what condition this diagram is commutative.

The commutativity of the above diagram for the parity lumping of our colored coalescent process Z(t) provides a way for us to recover information about Z(t) from our knowledge of the lumped coalescent process [formula]. Due to the fact that both processes Z(t) and [formula] have the same absorbing states, we can achieve a complete recovery of information for certain parameters of the coalescent process Z(t).

Let N be the fundamental matrix of the jump chain J, of Z(t), and [formula] be the fundamental matrix of the jump chain [formula] of [formula]. Notice that the absorption states of [formula] is E1  =  {(0,1)} and O1  =  {(1,0)}. Let U0 and V0 be matrices obtained from U and V by dropping the last two rows and columns corresponding to the states (0,1) and (1,0). Then it is easy to verify that N is lumpable by U0 and V0: V0U0NV0 = NV0. Furthermore, we have [formula].

The following is the main theorem of this section.

Let P(n1,n2)(0,1) and P(n1,n2)(1,0) be the probabilities that the coalescent process Z(t) reaches (0,1) and (1,0), respectively, given that it starts at (n1,n2), n1 + n2 = n. Then we have

[formula]

[formula]

Furthermore, let T(n1,n2)(0,1) (or T(n1,n2)(1,0)) be the time for the coalescent process Z(t) to reach (0,1) (or (1,0)), given that it starts at (n1,n2), n1 + n2 = n. Then the expectations of T(n1,n2)(0,1) and T(n1,n2)(1,0) are given as follows:

[formula]

[formula]

The absorption probabilities of the jump chains J and [formula] are calculated from the matrices

[formula]

respectively. So P(n1,n2)(0,1), for n1 + n2 = n and n1 even, is equal to PE,E. By Equation ([\ref=abP]), we get the desired value for P(n1,n2)(0,1) in this case. All other cases can be obtained similarly.

To compute the coalescent time, we first denote by a(n1,n2)(k1,k2) the sojourn coefficient of the jump chain J, which is the expect number of times the jump chain J visits the state (k1,k2), given that it starts at the state (n1,n2), n1 + n2 = n. Since the jump chain J is lumpable and its lumping is the jump chain [formula], we have

[formula]

where ak and bk are the sojourn coefficients of [formula] corresponding to the expected number of times [formula] visits Ek and Ok, respectively, given that it starts at the distribution

[formula]

Thus, we have

[formula]

where π is the distribution given by Equation ([\ref=pi]). So Lemma 6 gives us the desired expectation of T(n1,n2)(0,1). The calculation of E(T(n1,n2)(1,0)) is exactly the same.

Equation ([\ref=coef]) shows [formula] as claimed in the proof of Lemma [\ref=exp].

For (n1,n2)∈Δn with n1 even, it is obvious that T(n1,n2)(0,1) = TE,E. Thus Lemma 2.7 also gives us the complementary cumulative distribution function of T(n1,n2)(0,1). All other cases are the same so that the cumulative distribution functions of T(n1,n2)(0,1) and T(n1,n2)(1,0) are all known.

There is, of course, information of the coalescent process Z(t) which can not be recovered from what we know about [formula]. For example, recall that the parity of a state (k,l)∈L is the parity (even or odd) of the integer k. Let us define ρk to be the parity of a state after the k-th coalescent event. In other words, ρk is a random variable which takes the value 0 if the coalescent process Z(t) is in Ek and takes the value 1 if the coalescent process is in Ok, after the k-th coalescent event. We will use ρ0 to denote the random variable which takes the value 0 if the parity of the initial state is even and the value 1 otherwise. Then we have

[formula]

From Equation ([\ref=parity]), we can get the probability of sequences of n - 1 coalescent events with the parities of the passing states all specified. For example, the probability that all of n - 1 coalescent events happen in states with even parity, given that the parity of the initial state is also even, is

[formula]

The probability of other sequences of coalescent events with specified parities can be calculated similarly.

On the other hand, starting at (n1,n2), where  n1 + n2 = n, after k coalescent events, we do not know exactly the distribution of the states (l1,l2), l1 + l2 = n - k. The knowledge of the distribution of the parities of these states is not enough for recovering the distribution of these states.

Acknowledgments. We would like to thank Prof. Michael Clegg for introducing us to the coalescent theory and its significance in population genetics. The first author also would like to thank Prof. Bai-Lian Li for his encouragement. We also thank the referees for their comments.