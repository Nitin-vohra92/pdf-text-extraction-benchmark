=1

[formula]

Algorithmic complexity and randomness in elastic solids

[formula]Department of Electrical and Electronics Engineering, [formula]Department of Mathematics and Computer Science, Ariel University Center, Ariel 40700, ISRAEL and IJLRDA, University Pierre and Marie Curie - Paris VI, FRANCE

[formula]ratsaby@ariel.ac.il, [formula]jch@ariel.ac.il

Introduction

Consider an elastic beam having a length L, (for instance, a bridge). It has some finite descriptive complexity consisting of all the information contained in the engineering design documents. These documents can be put into a single computer file that can be represented by a finite binary string z. This binary sequence has an algorithmic complexity which is defined as the length of the shortest computer program that can generate the sequence. This is defined as the Kolmogorov complexity K(z) of the string z (see [\cite=Kolmogorov65]). Now consider a random input force sequence applied at one of the two ends of the bridge, for instance, suppose there is a person jumping up and down sporadically on the bridge at its entrance (position 0). Denote by x the binary sequence representing this up/down symbols over some fixed time-interval

[formula]

and compares it to a fixed threshold thereby producing a binary output sequence y consisting of up/down symbols that represent the movement of the beam at position L. This sequence has a finite algorithmic complexity K(y). In this paper we show that for such a physical system, the system complexity K(z), the output complexity K(y) and its level of randomness are all related and there exist statistically significant correlations between them.

Ratsaby [\cite=Ratsaby_entropy] introduced a quantitative definition of the information content of a static structure (a solid) and explained its relationship to the stability and symmetry of the solid. His model is based on concepts of the theory of algorithmic information and randomness. He modeled a solid as a selection rule of a finite algorithmic complexity which acts on an incoming random sequence of particles in the surroundings. This selection mechanism is intrinsically connected to the solid's complex non-linear structure (partly a consequence of its internal atomic vibrations) and its intricate time-response to external stimulus. As postulated in [\cite=Ratsaby_entropy], a simple solid is one whose information content is small. Its selection behavior is of low complexity since it can be described by a more concise time-response model (shorter computer program). The solid's stability over time is explained in [\cite=Ratsaby_entropy] by using the stochastic property of the frequency stability of a random sequence. Accordingly, the physical stability of the system (solid) is intrinsically and inversely proportional to the ability of the solid to deform (or distort) the input sequence and make it less random, i.e., more random-deficient.

The current paper presents first evidence that validate the model of [\cite=Ratsaby_entropy]. We choose to simulate a solid structure which consists of a one-dimensional vibrating solid-beam to which we apply a random input force sequence and observe the displacement of the beam at its other end for a finite interval of time. We determine empirically the relationship between the algorithmic complexity of the structure to the stochasticity of the output response. The relationship confirms the theory of [\cite=Ratsaby_entropy].

The paper is organized as follows: in section [\ref=sec:Algorithmic-Complexity] we give a brief introduction to the main concepts of the area of algorithmic complexity and randomness. In section [\ref=sec:Aim-of-the] we state concisely the aim of the paper. In section [\ref=sec:The-solid's-equations] we develop the equations that describe the solid deformations and compute the numerical equations needed to produce the computer simulation of the solid's response to external forces. In section [\ref=sec:Experimental-results] we state the experimental setup, results and analysis. In section [\ref=sec:Conclusions] we state the conclusions.

Background

Kolmogorov [\cite=Kolmogorov65] proposed to measure the conditional complexity of a finite object x given a finite object y by the length of the shortest binary sequence π (a program for computing x) which consists of 0s and 1s and which reconstructs x given y. Formally, this is defined as

[formula]

where [formula] is the length of the sequence π, φ is a universal partial recursive function which acts as a description method, i.e., when provided with input (π,y) it gives a specification for x. The word universal means that the function φ can emulate any Turing machine (hence any partial recursive function). One can view φ as a universal computer that can interpret any programming language and accept any valid program π. The Kolmogorov complexity of x given y as defined in ([\ref=eq:K]) is the length of the shortest program that generates x on this computer given y as input. The special case of y being the empty binary sequence gives the unconditional Kolmogorov complexity K(x).

Let Ξ be the space of all finite binary sequences and denote by Ξn the set of all finite binary sequences of length n. An admissible selection rule R [\cite=Vyugin99] is a partial recursive function on Ξ that picks certain bits from a binary sequence x. Let R(x) denote the selected subsequence. By K(R|n) we mean the length of the shortest program computing the subsequence R(x) given n. Kolmogorov introduced a notion of randomness deficiency δ(x|n) of a finite sequence x∈Ξn where δ(x|n) = n - K(x|n) and K(x|n) is the Kolmogorov complexity of x not accounting for its length n, i.e., it is a measure of complexity of the information that codes only the specific pattern of 0s and 1s in x without the bits that encode the length of x (which is log n bits). Randomness deficiency measures the opposite of chaoticity of a sequence. The more regular the sequence the less complex (chaotic) and the higher its deficiency. An infinitely long binary sequence is regarded random if it satisfies the principle of stability of the frequency of 1s for any of its subsequences that are obtained by an admissible selection rule [\cite=Kolmogorov63] [\cite=Kolmogorov98].

In [\cite=Kolmogorov65] it was shown that the stochasticity of a finite binary sequence x may be precisely expressed by the deviation of the frequency of ones from some 0 < p < 1, for any subsequence of x selected by an admissible selection rule R of finite complexity K(R|n). The chaoticity of x is the opposite of its randomness deficiency, i.e., it is large if its Kolmogorov complexity is close to its length n. The works of [\cite=Kolmogorov65] [\cite=Asarin87] [\cite=Asarin88] [\cite=Vyugin99] relate this chaoticity to stochasticity. In [\cite=Asarin87] [\cite=Asarin88] it is shown that chaoticity implies stochasticity. This can be seen from the following relationship (with[formula]):

[formula]

where for a binary sequence s, we denote by [formula] the frequency of 1s in s where #  (s) denotes the number of 1s in s, and [formula] is the length of the subsequence selected by R, c > 0 is some absolute constant. From this we see that as the chaoticity of x grows (randomness deficiency decreases) the stochasticity of the selected subsequence grows (bias from [formula] decreases). The information content of the selection rule, namely K(R|n), has a direct effect on this relationship: the lower K(R|n) the stronger the stability (smaller deviation of the frequency of 1s from [formula]).

Aim of the paper

In this paper we provide first evidence that the basic notion of randomness and its relationship to complexity (as discussed in the previous section) underlie the behavior of physical systems. This supports the ideas introduced in [\cite=Ratsaby_entropy]. We focus on a system composed of a vibrating elastic solid (described by the classical equations of solid mechanics) and its interaction with a random input force. We show that as a result of this interaction, the deformation of the solid over time can be described as an output sequence whose stochastic and algorithmic properties follow those of an output subsequence selected by a selection rule of a finite complexity. Based on a large sample of computer-generated simulations of such solids we provide statistically significant results that show that the complexity of the system inversely affects the complexity of the solid deformations (observed output) and its stochasticity agrees with the theory ([\ref=Ineq]). The next section describes the solid's mechanical equations.

The solid's equations

The solid consists of an elastic homogeneous and one-dimensional beam of length L. Let us denote by x the position on the beam so that 0  ≤  x  ≤  L and by [formula] the unit vector on the x-axis. Denote by [formula] a force applied at time t on position x in the direction of [formula]. We define by[formula] the displacement at time t on x. The classical equation which describes the field of displacements u at a specific position and time when a force f is applied is as follows:

[formula]

where E is Young's modulus (the ratio of stress to corresponding strain when the beam behaves elastically), and ρ is the mass density. We impose the following boundary conditions:

[formula]

i.e., the beam is fixed at its two ends so the only displacements is due to internal elasticity stresses of the material. Let u0(x),u1(x) be two given functions that satisfy u0(0) = u0(L) = 0. As initial conditions we set the following,

[formula]

Equations ([\ref=eq:solid1]-[\ref=eq:solid4]) represent the model that describes the deformations of the elastic solid. In order to simulate the response of the solid to external forces we use the following numerical approximation. This is performed by introducing a regular mesh of the

[formula]

. Specifically, we have the following mesh: x0 = 0, [formula] 1  ≤  i  ≤  N + 1, xN + 1 = L and [formula].

Similarly, if time t belongs to the interval

[formula]

Experimental results

We performed a series of experiments which consisted of several hundreds simulation trials of the response of a vibrating solid (henceforth called a system) to an input force sequence. We used the numerical equations of section [\ref=sec:The-solid's-equations] as the solid's model. As a choice of parameters we took L = 20, T = 70, E = 0.7, ρ = 0.4, N = 30, M = 200.

A system consists of a solid whose length is divided into 31 positions, [formula]. A force sequence [formula] is applied at position 15 while for all remaining positions the applied force is of zero magnitude. The non-zero force sequence [formula] makes the solid vibrate a priori hence we call the system a vibrating solid. This force sequence consists of a series of ternary values - 1,0, + 1 scaled by a constant of 30. The length of the sequence is 200 and the symbols are obtained sequentially by a repeated series of random draws using the random variable F with the following probability distribution: let [formula], then F takes the value 0 with probability 1 - p, the value + 1 with probability [formula], and - 1 with probability [formula]. The complexity of the sequence is controlled by the choice of p. We used a different p for different trials by randomly picking its value and using it as the parameter value p of the distribution of the random variable F.

To the system we apply an input force sequence [formula] at position 1 consisting of 200 randomly drawn binary values + 1 and - 1 each with probability [formula] and scaled by a constant 10. Note that this input force is applied to a vibrating solid (as mentioned above). As the output of the system, we observe the displacement sequences at five positions [formula], [formula], [formula], [formula] and convert their values a from real to ternary V(a) using the following rule: given [formula] then V(a) =  + 1, 0 and - 1 if a > τ, |a|  ≤  τ and a <  - τ, respectively, with τ = 0.1. We then append these five ternary sequences together to form a single ternary output sequence of length 1000 (henceforth this is called the output sequence). We also consider the subsequence of this output sequence which consists only of the values + 1, - 1, i.e., without the zeros (we call this the output subsequence).

As an estimate of the complexity K(x) of a sequence x we use a standard compression algorithm (Gzip, which is a variation of the algorithm of [\cite=LZ77]) to compress x. The length of the resulting compressed version of x is used as an approximation of K(x). Henceforth, when we say system complexity we mean the length of the compressed version of the sequence consisting of all applied forces appended sequentially into one string with [formula] ternary symbols (in our experiments, all but the [formula] force are just all-zeros hence in this 6200-long string approximately only 200 bits contain information). The output complexity is the length of the compressed version of the ternary output sequence.

Let M denote the ratio of the compressed length divided by the uncompressed length of the system and let O denote this ratio for the output sequence. A large M (or O) means that the compressed length is larger hence the complexity of the system (or output sequence) is larger. We sometime simply refer to M and O as the system and output complexity, respectively. Figure [\ref=fig:Output's-comp_vs_M] displays two sets of trials.

In each trial of set (a) a random input force sequence was applied at position 1 (as described above). In each trial of set (b) no input sequence was applied. As is seen, the resulting behavior is clearly different in each of the two sets of trials. With an input present, as the complexity M increases there appears to be a decreasing trend in the value of O and an increase in the spread, i.e., the range of possible values of O. With no input, both O and its spread of values are basically constant with respect to M.

In Figure [\ref=fig:Output-frequeny-of] we plot the frequency of 1s in the output subsequence (this is the number of 1s divided by the number of non-zero symbols in the output sequence).

As can be seen, with an increase in the complexity there appears to be an increase in the spread of possible frequency values. Before we further discuss these results we proceed to perform the statistical tests.

Analysis

In order to test the significance of these results we estimate the output complexity O as a function of the complexity M. Denote by X and Y the random variables corresponding to M and O, respectively. Let the underlying conditional probability distribution function be P(Y|X) with marginals P(X), P(Y). As a sample we use the set of trials of Figure 1(a), denoted by [formula] with cardinality N = 723, and do linear regression in order to estimate Y with dependence on X. Figure [\ref=fig:Estimate-for-Y] shows the resulting estimate,

[formula]

surrounded by the 95% confidence limits for the regression line, i.e., the actual regression line of the population falls within the limits defined by the two curved dashed lines.

The following summarizes the accuracy of this linear regression estimate: R2 = .246187335 is the coeeficient of determination which measures the reduction in total variation of Y due to X and is defined as R2 = 1 - (SSR / SS) with SSR [formula] being the sum of squares of the residuals, [formula] the total variation and [formula] . The square root R is the coeeficient of correlation between the independent variable X and dependent variable Y. The standard error SE = .015128505 where [formula]. Dividing SSR and SS by their degrees of freedom and taking their ratio F = SS / SSR as an overall F test gives F(1,724) = 236.4508 which amounts to a p-value less than 0.000000. Thus with very high confidence the residual variance differs from the total variation hence the linear estimate Ŷ(X) explains well the variation of Y. The distribution of the residuals (shown in Figure [\ref=fig:Distribution-of-the]) is very close to the normal distribution and the Durbin-Watson d value is 1.994 which implies that the assumptions on the residuals being uncorrelated and normaly distributed are met.

Next, from Figure 1(a) it is evident that as the complexity X increases the spread of the output complexity Y increases. To quantify this assertion let us represent this spread by the random variable

[formula]

As we have done above for Y we now estimate Z with dependence on X (the model is shown only the value of X and asked to predict Z). We form the following sample (based on S),

[formula]

where NN(x,k) denotes the set of k nearest sample point xj to x satisfying xj  ≤  x. Figure [\ref=fig:Estimate-of-the_spread] shows the resulting estimate equation (based on k = 7),

[formula]

for the regression line. This verfies the increase in the value of Z (i.e., in the spread of the output complexity Y) as the complexity X increases. The following summarizes the accuracy of this regression estimate: R2 = .098, the F-ratio is F(1,724) = 79.548 with a p-level smaller than .000000. The standard error of the estimate is SE = .015413 with a Durbin-Watson d = 1.938. Thus the estimator Ẑ(X) accurately captures the variability of Z, i.e., the spread of output complexity Y. Figure [\ref=fig:Distribution-of-Zresiduals] displays the distribution of the residuals.

As mentioned above, Figure [\ref=fig:Output's-comp_vs_M](b) shows that when no input is present the behavior of the output complexity is almost unaffected by the system's complexity. To test this, we take the set of trials used in Figure [\ref=fig:Output's-comp_vs_M](b) and study the correlation between the output complexity Y and the system complexity X. As shown in Figure [\ref=fig:The-no-input-scatter] there is hardly any correlation between them and the slope of the regression is almost zero.

We already commented on the increasing spread of possible frequency values of the output subsequence (Figure [\ref=fig:Output-frequeny-of]) as the system's complexity increases (with a random input sequence being applied). Denote by Y the probability of having a + 1 appear in the output subsequence and let X be the system's complexity. Let us define the following random variable

[formula]

to represent the spread in the possible values of the probability of + 1. We form the following sample (based on S),

[formula]

with k = 7. Figure [\ref=fig:Scatter-plot-of-freq-spread] shows (on the top scatter plot with red [formula] symbols) the frequency of 1s in the output subsequence versus the system complexity X. The bottom plot (with blue [formula]) shows the sample ζ' with the w component on the same vertical axis.

We estimate W based on ζ' first transforming the wi values to w2i and then doing linear regression to estimate W2. Figure [\ref=fig:Estimate-of-the-Spread-Freq1s] shows the resulting estimate equation - 0.023 + 1.083  X for W2. It follows that the estimate of W is

[formula]

This verfies the increasing trend in the spread of values of the frequency of 1s as the system's complexity X increases. The following summarizes the accuracy of this linear regression estimate: R2 = .135, the F-ratio is F(1,724) = 113.06 with a p-level smaller than .00000. The standard error of the estimate is SE = .01037 and the Durbin-Watson d = 1.71. The distribution of the residuals is shown in Figure [\ref=fig:Distribution-of-residuals_w].

Some more details on the simulations

Several additional graphs showing additional details of the above experiments are shown below. Figure [\ref=fig:Entropy-H-(red)] shows the observed system description rate M (scatter plot in blue) and the entropy (the minimal expected number of bits per character) used for the system description (red solid curve). They are plotted versus the probability parameter p (in the range [formula] used to generate the random force sequence at position 15 of the solid. It follows from the procedure (described above) of generating the system's vibrating force that the entropy of the random variable F is [formula] As seen from Figure [\ref=fig:Entropy-H-(red)], in order to get a higher system complexity one needs to draw a force sequence with a parameter p closer to [formula]. There is some additional textual information (145 bytes) appended into each of the files that contain the 6200-long ternary string that describes the system. Since M is the ratio of the compressed to uncompressed versions (the actual uncompressed length as reported by the operating system is 6377 bytes) then to get the rate for the number of bits per character used to describe the system (considering just the 145-byte textual information and the 200-byte force sequence at position 15) we multiply M by [formula] and divide by 345.

The next series of figures show examples of the actual solid's response (displacement u is shown on the z-axis) over time (y-axis) along the positions of the solid (x-axis). In all, the input sequence is maximally random with probability [formula] for + 1, - 1. The magnitude of the input force sequence is 10 and the magnitude of the system's vibrating force sequence is 30. The two force sequences are superimposed on the same 3D-plot that displays the displacement response. The output sequence is taken as the concatenation of the string obtained from the displacement at the last five positions (appearing on the plot to be closest to the reader). Figure [\ref=fig:Response-to-a1] shows the response to a system of high complexity. Figure [\ref=fig4] shows a trial without a system force. This represents a low-complexity system. Figure [\ref=fig:Response-to-a2] is the response of a system of a mid-level complexity. Figures [\ref=fig:The-no-input-response3] and [\ref=fig:The-no-input-response4] show the response when no input force is applied.

Conclusions

Based on these results, it is clear that when a random input sequence is applied to the vibrating solid (system) the observed output sequence is not simply a result of the random vibrating force sequence which is part of the system (applied at position 15) but is a direct consequence of the interaction of the system with an external random input force-when no input is present no significant correlation exists between the system and output complexities. The strong negative correlation between these two complexities ([\ref=eq:yhat]) suggests that the system distorts the input randomness and produces a less complex output sequence. This agrees with the model introduced in [\cite=Ratsaby_entropy] which says that a solid effectively acts as a selection rule picking bits from the input sequence to produce a less random output. This is evident in the significant decrease in the output complexity (Figure [\ref=fig:Estimate-for-Y]) and increase in its spread of values (Figure [\ref=fig:Estimate-of-the_spread] ) indicating that the possibility of producing a less-complex output sequence increases as the system's complexity rises.

The selected subsequence consists of [formula] with zeroes deleted. Being less chaotic, its stochastic level decreases. This is evident in the increase in the square of the spread of values of the frequency of 1's (Figure [\ref=fig:Estimate-of-the-Spread-Freq1s]). The higher the system complexity, the higher the spread, i.e., the larger the bias from [formula], the more the chance that the output sequence be less chaotic and random. If we divide the compressed length of the system by the length of the output (binary) subsequence and denote it by X' then re-estimate W2 based on X' we obtain the following estimate for W,

[formula]

The R2 = .0924, SE = .0106, F(1,724) = 73.725 and the p-level less than 0.00000. The Durbin-Watson d = 1.66. This estimate of the spread agrees with the rate predicted by the theory ([\ref=Ineq]). To see this, let x be the input sequence, let the system be the selection rule R with a system complexity K(R|n), let R(x) be the output subsequence (consisting only of binary values [formula]), let ν(R(x)) be the frequency of 1s in this subsequence and take the deficiency of randomness δ(x|n) of the input sequence to be zero (since the input sequence is maximally random). Then the theoretical rate of the maximal possible deviation (spread) between ν(R(x)) and [formula] is [formula]. This is the same rate in which the estimate of spread W grows with respect to the X' in ([\ref=eq:xpr]).

To summarize, the results above imply that a system based on classical equations of mechanics that consists of a vibrating solid subjected to external random input-force acts like an algorithmic selection rule of a finite complexity. It produces an output sequence whose stochastic and chaotic properties are effected by the system's complexity as predicted by the theory of algorithmic randomness. The results confirm the model of [\cite=Ratsaby_entropy].