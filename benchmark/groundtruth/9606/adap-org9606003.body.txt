Self-Annealing Dynamics in a Multistable System

How can one escape from a labyrinth? The question is important not only for a game player but also for a researcher for multistable systems. Evolution of complex systems sometimes obey an optimization process of a kind of "energy" function. Since the landscape of the energy is in general multistable, the harm of trap at local minima prevents the system from reaching a global minimum. A conventional way to escape from local minima is to make thermal fluctuation in such systems, and the relaxation process under thermal fluctuation has been extensively studied.

However, there is a dilemma between a barrier crossing probability in a multistable potential[\cite=RMP] [\cite=Hanggi] and a stationary probability distribution of the system: High temperature fluctuation makes a barrier crossing between basins of multistable potential easy: But, unfortunately, high temperature fluctuation also makes a mean energy over a probability distribution increase. Simulated annealing method[\cite=Kirk], which is a strategy to lead a system to a global minimum by gradually decreasing the temperature of the thermal fluctuation, was introduced to avoid the dilemma and was successfully applied for several fields such as image restoration[\cite=GG], protein folding[\cite=PF2], neural networks[\cite=NN] and so on. However, the method seems somewhat unnatural and inconvenient for physical processes because of the two reasons: 1) one must "control" the temperature of a system gradually, because the convergence to a global minimum is guaranteed when one spends infinite time to decrease the temperature; 2) the system never stops even if the system passes the global minimum state as long as the temperature is finite. This implies that the dilemma cannot be solved essentially even by the "simulated annealing" method.

Although the simulated annealing method is a kind of relaxation process, one should remember the fact that the method is based on the equilibrium statistical mechanics because it uses Boltzmann distribution, which is realized for the system with detailed balance, in its process, Therefore, we conjectured that the dilemma might be solved in a non-equilibrium condition. The conjecture is partially motivated by the Levinthal's paradox that a protein is folded from its initial structure much quicker than the exhaustive sampling[\cite=Levinthal]. We report in this paper a preliminary example of a solution of the dilemma by numerical simulation of a simple model.

One finds that the "energy" of a multistable system is generally composed of plural competitive constraints or interactions each of which is relatively simple, and the competition makes frustration in a system. The global minimum is, thereby, the state where such constraints are mostly satisfied: the frustration is expected to be the minimum there. An interesting example of this competitive dynamics can be found in on-line learning process of neural networks. Radons et al. reported [\cite=Radons] that an effective temperature of parameter fluctuations caused by a probabilistic successive pattern input in a learning process by backpropagation can decrease autonomously at a global minimum under condition that all constraints (patterns) can be perfectly satisfied at a global minimum[\cite=Heskes]. The condition is called as "perfectly trainable", which is approximately satisfied for the network with a sufficiently large number of neurons[\cite=Funahashi]. The autonomous decrease of fluctuation was also found in the learning process of chaotic time series by a conventional feedforward neural network[\cite=Prog] and in the learning by the neural network with coupled oscillators[\cite=Inoue2]. Recent study of on-line learning by neural networks indicates that non-thermal fluctuation due to the successive change of the local potential (error) is important not only for escape from local minima but also for an acceleration of a relaxation process even without local minima[\cite=PRE], which needs a clear understanding of the effect of non-thermal fluctuations due to fluctuating potentials.

The dynamics which autonomously changes the effective temperature is quite interesting from the view point of relaxation process in non-equilibrium condition. However, the discussions above were limited for learning by neural networks, and dynamical analysis of a "perfectly trainable" system has not been carried out due to their high-dimensionality and their complex structures. To investigate the autonomous, annealing-like dynamics clearly, we find a minimal model which satisfies the following conditions: 1) Each partial potential (constraint) term, Vi(x), is expressed in a positive definite, differentiable function so that a zero value state corresponds to a frustration-free state; 2) Global potential, V(x), is a linear sum of the constraints; 3) The dynamics obeys a plain relaxation (gradient descent) process of a dissipative particle under time-dependent potentials; 4) A system has small residual frustration in a global minimum state; 5) A functional form of the partial potential is selected to make the residual frustration of a global minimum small in order to demonstrate a typical self-annealing dynamics; 6) The amplitudes of the partial potentials fluctuate in order to make non-equilibrium fluctuation.

A dynamics which satisfies these conditions is realized:

[formula]

where a global potential is [formula]; a partial potential with index i is Vi(x)  =  (1 -  cos (aix  +  Î´i)) / 2

[formula]