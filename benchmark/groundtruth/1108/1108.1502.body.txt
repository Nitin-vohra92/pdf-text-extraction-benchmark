Lemma Proposition Corollary

Generalized Louvain method for community detection in large networks

Introduction

The investigation of the community structure inside networks has acquired a great relevance during the last years, in particular in the context of Social Network Analysis (SNA). This, also because of the unpredicted success of Online Social Networks (OSNs). In fact, social phenomena such as Facebook and Twitter amongst others, glue together millions of users under a unique network whose features are a goldmine for Social Scientists. Several works are focused on the Social Network analysis of these OSNs; others describe the strategies of analysis themselves.

In this paper we focus on the possible strategies of community detection. As to date, two paradigms exist to discover the community structure of a network. The former is based on the analysis of the global features of the network, for example its topology. These approaches are characterized by high computational complexity and high quality results. The latter paradigm relies on exploiting local information, for example those acquirable by nodes and their neighborhoods. The computational cost of these techniques is lower than those exploiting global features, but the reliability decreases.

In this work, we propose a novel strategy to discover the inner community structure of a network. The main characteristics of our approach are the followings: i) it exploits global information of the network, establishing which are the edges of the network that contribute to the creation of the community structure; ii) to do so, it adopts a novel measure of edge centrality, in order to rank all the edges of the network with respect to their proclivity to propagate information through the network itself; iii) its computational cost is low, making it feasible even for large network analysis; iv) it is able to produce reliable results, even if compared with those calculated by using more complex techniques, when this is possible; in fact, because of the computational constraints, the adoption of some existing techniques is not viable when considering large networks, and their application is only limited to small case-studies.

This paper is organized as follows: in the next Section we provide some background information about the community detection problem. Section [\ref=sec:design-goals] introduces the main objectives of this work and describes an intuitive sketch about the novel strategy of community detection we propose. In Section [\ref=sec:kpath-centrality] the key concept of κ-path edge centrality is recalled, being it a novel and efficient strategy of ranking edges with respect to their centrality in the network. All the pieces are glued together in Section [\ref=sec:community-detection]. We describe our strategy to detect the community structure, inspired by the well-known state-of-the-art LM [\cite=blondel2008fast], which is computationally suitable even when large networks are analyzed. Experiments that have been carried out are discussed in Section [\ref=sec:experimentation]. Finally, Section [\ref=sec:conclusions] concludes, depicting some future directions of research.

Background

Several techniques to investigate the community structure of networks have been proposed in literature during last years. There exist numerous comprehensive surveys to this problem, such as [\cite=porter2009communities] [\cite=fortunato2010community].

In its general formulation, the problem of finding communities in a network is intended as a data clustering problem. In fact, it could be solved assigning each node of the network to a cluster, in a meaningful way. Two approaches have been widely investigated, i) spectral clustering based techniques, and, ii) network modularity optimization strategies. The former relies on the optimization of the process of cutting the graph representing the given network. The latter is based on the maximization of a benefit function, called network modularity. We briefly recall them, separately.

The problem of minimizing the number of cuts in a given graph has been proved to be NP-hard. To do so, different approximate techniques have been proposed. An example is by using the spectral clustering [\cite=ng2001spectral], exploiting the eigenvectors of the Laplacian matrix of the network. We recall that the Laplacian matrix L of a given graph has components Lij  =  kiδ(i,j) - Aij, where ki is the degree of a node i, δ(i,j) is the Kronecker delta (that is, δ(i,j) = 1 if and only if i = j) and Aij is the adjacency matrix representing the graph connections. Another approach relies on the strategy of the ratio cut partitioning [\cite=wei1989towards] [\cite=hagen2002new]. This is a function that, if minimized, allows the identification of large clusters with a minimum number of outgoing interconnections. The principal issue of spectral clustering based techniques is that one has to know in advance the number and the size of communities comprised in the given network. This makes this strategy unfeasible if the purpose is to discover the unknown community structure of a network.

The strategy exploited in this paper adopts the second paradigm, the one relying on the concept of network modularity. It can be explained as follows: let consider a network, represented by means of a graph G = (V,E), partitioned into m communities; assuming ls the number of edges between nodes belonging to the s-th community and ds is the sum of the degrees of the nodes in the s-th community, the network modularity Q is given by

[formula]

Intuitively, high values of Q implies high values of ls for each discovered community; thus, detected communities are dense within their structure and weakly coupled among each other. Equation [\ref=eq:qmod] reveals a possible maximization strategy: in order to increase the value of the first term (namely, the coverage), the highest possible number of edges should fall in each given community, whereas the minimization of the second term is obtained by dividing the network in several communities with small total degrees.

The problem of maximizing the network modularity has been proved to be NP complete [\cite=brandes2007finding]. To this purpose, several heuristic strategies to maximize the network modularity Q have been proposed as to date. Probably, the most popular one is called Girvan-Newman strategy [\cite=girvan2002community] [\cite=newman2004finding]. This approach works in two steps, i) ranking edges by using the betweenness centrality as measure of importance; ii) deleting edges in order of importance, evaluating the increase of the value of Q. In fact, it is possible to maximize the network modularity deleting edges with high value of betweenness centrality, based on the intuition that they connect nodes belonging to different communities. The process iterates until a significant increase of Q is obtained. At each iteration, each connected component of S identifies a community. Unfortunately, the computational cost of this strategy is very high (i.e., O(n3), being n the number of nodes in S). This makes it unsuitable for the analysis of large networks. The largest part of its cost is given by the calculation of the betweenness centrality, that is itself very costly (even if the most efficient algorithm [\cite=brandes2001faster] is adopted).

Several variants of this strategy have been proposed during the years, such as the fast clustering algorithm provided by Clauset, Newman and Moore [\cite=clauset2004finding], that runs in O(n log n) on sparse graphs; the extremal optimization method proposed by Duch and Arenas [\cite=duch2005community], based on a fast agglomerative approach, with O(n2 log n) time complexity; the Newman-Leicht [\cite=newman2007mixture] mixture model based on statistical inferences; other maximization techniques by Newman [\cite=newman2006finding] based on eigenvectors and matrices.

The state-of-the-art technique is called Louvain method (LM) [\cite=blondel2008fast]. This strategy is based on local information and is well-suited for analyzing large weighted networks. It is based on the two simple steps: i) each node is assigned to a community chosen in order to maximize the network modularity Q; the gain derived from moving a node i into a community C can simply be calculated as [\cite=blondel2008fast]

[formula]

where [formula] is the sum of the weights of the edges inside C, [formula] is the sum of the weights of the edges incident to nodes in C, ki is the sum of the weights of the edges incident to node i, kCi is the sum of the weights of the edges from i to nodes in C, m is the sum of the weights of all the edges in the network; ii) the second step simply makes a new network consisting of nodes that are those communities previously found. Then the process iterates until a significant improvement of the network modularity is obtained.

In this paper we present an efficient community detection algorithm which represents a generalization of the LM. In fact, it can be applied even on unweighted networks and, most importantly, it exploits both global and local information. To make this possible, our strategy computes the pairwise distance between nodes of the network. To do so, edges are weighted by using a global feature which represents their aptitude to propagate information through the network. The edge weighting is based on the κ-path edge centrality, a novel measure whose calculation requires a near linear computational cost [\cite=cikm2011]. Thus, the partition of the network is obtained improving the LM. Details of our strategy are explained in the following.

Design Goals

In this Section we briefly and informally discuss the ideas behind our strategy. First of all, we explain the principal motivations that make our approach suitable, in particular but not only, for the analysis of the community structure of Social Networks. To this purpose, we introduce a real-life example from which we infer some features of our approach.

Let consider a social network, in which users are connected among them by friendship relations. In this context, we can assume that one of the principal activities could be exchanging information. Thus, let assume that a "message" (that, could be, for example, a wall post on Facebook or a tweet on Twitter) represents the simplest "piece" of information and that users of this network could exchange messages, by means of their connections. This means that a user could both directly send and receive information only to/from the people in her neighborhood. In fact, this assumption will be fundamental (see further), in order to define the concepts of community and community structure. Intuitively, say that a community is defined as a group of individuals in which the interconnections are denser than outside the group (in fact, this maximizes the benefit function Q).

The aim of our community detection algorithm is to identify the partitioning of the network in communities, such that the network modularity is optimal. To do so, our strategy is to rank links of the network on the basis of their aptitude of favoring the diffusion of information. In detail, the higher the ability of a node to propagate a message, the higher its centrality in the network. This is important because, as already proved by [\cite=girvan2002community] [\cite=newman2004finding], we could ensure that the higher the centrality of a edge, the higher the probability that it connects different communities.

Our algorithm adopts different optimizations in order to efficiently compute the link ranking. Once we define an optimized strategy for ranking links, we can compute the pairwise distances between nodes and finally the partitioning of the network, according to the LM. The evaluation of the goodness of the partitioning in communities is attained by adopting the measure of the network modularity Q.

In the next sections we shall discuss how our algorithm is able to incorporate these requirements. First of all, in Section [\ref=sec:kpath-centrality], we formally provide a definition of centrality of edges in social networks based on the propagation of messages by using simple random walks of length at most κ (called, hereafter, κ- path edge centrality). Then, we provide a description of an efficient implementation of this algorithm, running in O(κ|E|), where |E| is the number of edges in the network. After this, in Section [\ref=sec:community-detection] we discuss the technical details of our community detection algorithm.

κ-Path Edge Centrality

The concept of κ-path edge centrality has been recently defined [\cite=cikm2011] as follows:

(κ-path edge centrality) For each edge e of a graph G  =  (V,E), the κ-path edge centrality Lκ(e) of e is defined as the sum, over all possible source nodes s, of the percentage of times that a message originated from s traverses e, assuming that the message traversals are only along random simple paths of at most κ edges.

The κ-path edge centrality is formalized, for an arbitrary edge e, as follows

[formula]

where s are all the possible source nodes, πκs(e) is the number of κ-paths originating from s and traversing the edge e and πκs is the number of κ-paths originating from s.

Fast κ-path Edge Centrality Algorithm

In this section we recall the functioning of the strategy adopted to efficiently compute the κ-path edge centrality. The proposed algorithm [\cite=cikm2011] is called Weighted Edge Random Walk κ-Path Centrality (or, shortly, WERW-Kpath). It consists of two main steps: i) node and edge weights assignment, and ii) simulation of message propagations using random simple paths of length at most κ. In the following, the two steps are discussed separately.

Step 1

In the first stage, the algorithm assigns a weight to both nodes and edges of the graph G  =  (V,E) representing the given network. Node weights are exploited to choose the source nodes from which the simulation of the message propagations starts; edge weights represent initial values of centrality and they are updated during the execution of the algorithm. At the end of the execution of ρ simulations, where the optimal value ρ  =  |E| - 1 has been proved in [\cite=cikm2011], edge weights are exploited for the edge ranking.

To compute node weights, we recall the notion of local effective density δ(v) of a node v, as follows:

Given a graph G = (V,E) and a node v, its local effective density δ(v) is [formula] where I(v) and O(v) represent, respectively, the number of ingoing and outgoing edges incident on the node v.

This value intuitively represents how much a node contributes to the overall connectivity of the graph. The higher δ(v), the better v is connected in the graph.

As for edge weights, we recall the following definition:

Given a graph G = (V,E) and an edge e, its initial edge weight ω(e)0 is [formula] where |E| is the cardinality of E.

Intuitively, we initially manage a "budget" consisting of |E| points; these points are equally divided among all the nodes; the amount of points received by each edge represents its initial rank.

Step 2

In the second step we simulate ρ simple random walks of length at most κ on the network. In detail, at each iteration, WERW-Kpath (Algorithm [\ref=alg:ERW-Kpath]) performs these operations:

A node v of the graph G is selected with a probability proportional to its local effective density δ(v)

[formula]

where [formula] is a normalization factor.

All the edges in G are marked as not traversed.

The procedure MessagePropagation is invoked.

Let us describe the procedure MessagePropagation (Algorithm [\ref=alg:procedure]). This procedure carries out a loop until both the following conditions hold true:

The length of the path currently generated is no greater than κ. This is managed through a length counter N.

Assuming that the walk has reached the node vn, there must exist at least an outgoing edge from vn which has not been already traversed. In detail, we attached a flag T(e) to each edge e; T(e)  =  1 if the edge e has already been traversed, 0 otherwise. If we call O(vn) the set of outgoing edges from vn, it must hold that [formula].

The former condition allows us to consider only paths up to length κ. The latter condition, instead, avoids that the message get trapped into a cycle.

If the conditions above are satisfied, the MessagePropagation procedure selects an edge en with a probability proportional to the edge weight ω(en), given by

[formula]

where [formula] is a normalization factor, being Ô(vn)  =  {en∈O(vn) | T(en) = 0}.

Let en be the selected edge and let vn + 1 be the node reached from vn by means of en. The MessagePropagation procedure awards a bonus (equal to [formula]) to en, sets T(en)  =  1 and increases the counter N by 1. The message propagation activity continues from vn + 1.

At the end of all the processes of simulation of message propagation, each edge e∈E is assigned a centrality value Lκ(e) (in the interval

[formula]

Community Structure Detection

In the following, we present a novel algorithm to calculate the community structure of a network. It is baptized Fast κ-path Community Detection (or, shortly, FKCD). The strategy relies on three steps: i) ranking edges by using the WERW-Kpath algorithm; ii) calculating the proximity (the inverse of the distance) between each pair of connected nodes; ii) partitioning the network into communities so to optimize the network modularity [\cite=girvan2002community], according to the LM [\cite=blondel2008fast]. The algorithm is discussed as follows.

Fast κ-path Community Detection

First of all, our Fast κ-path Community Detection (henceforth, FKCD) needs a ranking criterion to compute the aptitude of all the edges to propagate information through the network. To do so, FKCD invokes the WERW-Kpath algorithm, previously described. Once all the edges have been labeled with their κ-path edge centrality, a ranking in decreasing order of centrality could be obtained. This is not fundamental, but could be useful in some applications. Similarly, before to proceed, a first network modularity esteem (hereafter, Q) could be calculated. This could help in order to put into evidence how Q increases during next steps. With respect to Q, we recall that its value ranges in the interval

[formula]

Experimental Results

Our experimentation has been conducted both on synthetic and real-world online social networks, whose datasets are available online. All the experiments have been carried out by using a standard Personal Computer equipped with a Intel i5 Processor with 4 GB of RAM.

Synthetic Networks

The method proposed to evaluate the quality of the community structure detected by using the FKCD exploits the technique presented by Lancichinetti et al. [\cite=lancichinetti2008benchmark]. We generated the same synthetic networks reported in [\cite=lancichinetti2008benchmark], adopting the following configuration: i) N = 1000 nodes; ii) the four pairs of networks identified by (γ,β)  =  (2,1),(2,2),(3,1),(3,2), where γ represents the exponent of the power law distribution of node degrees, β the exponent of the power law distribution of the community sizes; iii) for each pair of exponents, three values of average degree 〈k〉  =  15,20,25; iv) for each of the combinations above, we generated six networks by varying the mixing parameter [formula].

Figure [\ref=fig:1k] highlights the quality of the obtained results. The measure adopted is the normalized mutual information [\cite=danon2005comparing]. Values obtained put into evidence that our strategy performs fair good results, avoiding the well-known effect due to the resolution limit of the modularity optimization [\cite=fortunato2007resolution]. Moreover, a classification of results as in Table [\ref=tab:datasets] (discussed later) is omitted because values of Q obtained by using FKCD and the LM in the case of these quite small synthetic networks are very similar.

Real-world Networks

Results obtained by analyzing several real-world networks [\cite=leskovec2006sampling] [\cite=viswanath2009evolution] are summarized in Table [\ref=tab:datasets]. This experimentation has been carried out to qualitatively analyze the performance of our strategy. Obtained results, measured by means of the network modularity calculated by our algorithm (FKCD), are compared against those obtained by using the original LM.

Our analysis puts into evidence the following observations: i) classic not optimized algorithms (for example Girvan-Newman [\cite=girvan2002community]) are unfeasible for large network analysis; ii) results obtained by using LM are slightly higher than those obtained by using FKCD; on the other hand, LM adopts local information in order to optimize the network modularity, while our strategy exploits both local and global information; this results in (possibly) more convenient identified community structures for some applications; iii) the performance of FKCD slightly increase by using longer κ-paths; iv) both the compared efficient strategies are feasible even if analyzing large networks using standard resources of calculus (i.e., a classic personal computer); this aspect is important if we consider that there exist several Social Network Analysis tools (e.g., NodeXL) that require optimized fast algorithms to compute the community structure of networks.

Conclusions

The problem of discovering the community structure in large networks has been widely investigated during last years. Several efficient approaches based on local information have been proposed, and are feasible even when analyzing large networks because of their low computational cost. The main drawback of the existing techniques is that they do not consider global information about the topology of the network. In this work we presented a novel strategy that has two advantages. The former is that it exploits both local and global information. The latter is that, by using some optimization, it efficiently provides good results.

This way, our approach is able to discover the community structure in, possibly large, networks. Our experimental evaluation, carried out over both synthetic and real-world networks, proves the efficiency and the robustness of the proposed strategy. Some future directions of research include the creation of a friendship recommender systems which suggests new possible connections to the users of a Social Network, based on the communities they belong to. Finally, we plan to design an algorithm to estimate the strength of ties between two social network users: for instance, in the case of networks like Facebook, this is equivalent to estimate the friendship degree between a pair of users.