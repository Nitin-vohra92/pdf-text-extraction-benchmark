Corollary Lemma Proposition Conjecture Definition Fact Claim Properties Remark Remark Example

Correlation Angles and Inner Products: Application to a problem from Physics

(Accepted by ISRN Applied Mathematics. August 11, 2011.)

Introduction

In a study of the earth's climate system Douglass [\cite=Douglass2010] considered the correlation among a set of N climate indices. A distance d between two indices i and j was defined as

[formula]

where φij is the Pearson correlation coefficient. It was stated that d satisfies the conditions to be a metric. The measure of correlation, or closeness, among the N indices was taken to be the diameter D.

[formula]

Equation [\ref=diam] was applied to the data from a global set of four climate indices to determine the correlation among them (minimum in D) and to infer 18 changes in the state since 1970. (See section [\ref=appendix].) It was pointed out that the topological diameter D, as a measure of phase locking among the indices, is convenient for computation but was probably not the best measure. It was suggested that a better measure of correlation among the N indices could be based upon the area of the spherical triangles created by the N vectors on the unit sphere.

This paper gives a proof that dij is a metric and generalizes the diameter to higher dimensions. In addition, the data of [\cite=Douglass2010] are analyzed using this generalization to areas (see section [\ref=appendix]) and many new abrupt climate changes are identified.

Probability

Let X and Y be random variables with expected values [formula] and [formula]. With these values we make several standard definitions.

The Variance of X is defined as

[formula]

The Covariance of X and Y is defined as

[formula]

We now list a few basic properties of variance and covariance (found in [\cite=Ross]).

Vector Spaces

The first way most students learn to compare two vectors is through the dot product. The dot product is one example of the more general idea of an inner product. Here we define an inner product and prove that covariance is an inner product.

For any real vector space V an inner product is a map

[formula]

that satisfies the following properties for every u,v,w∈V and [formula]:

〈u + v,w〉  =  〈u,w〉  +  〈v,w〉

〈av,w〉  =  a〈v,w〉

〈v,w〉  =  〈w,v〉

〈v,v〉  ≥  0 and 〈v,v〉  =  0 if and only if v  =  0

We will now construct a vector space for which covariance is an inner product. Let [formula] be a set of n random variables. Also let [formula], the formal [formula]-vector space with basis elements [formula]. We must put one mild hypothesis upon V in order for it to have the desired properties. The hypothesis is that the vectors must be "probabilistically independent". i.e. for any [formula], we have that [formula] if and only if [formula]. It should be noted that this independence is in no way related to the linear independence of the random variables.

Let [formula], the formal [formula]-vector space generated by the random variables [formula] which are probabilistically independent, then covariance is an inner product on V.

We must prove the four properties from definition [\ref=Inner_Product]. i), ii) and iii) follow immediately from proposition [\ref=Basics]. iv) [formula]. The non-negativity is obvious as we are squaring a real number. The condition that [formula] follows from the probablisitic independence of [formula].

The proposition implies that V is an inner-product space (a vector space equipped with an inner-product), and as such it has a norm defined by [formula], where [formula] is the standard deviation of X. Additionally it follows from the Cauchy-Schwartz inequality ([\cite=HoffmanKunze]) that [formula].

Using the inner product on V we are able to define an angle between two vectors. To do this we first define a new map [formula] using the standard definition of correlation

[formula]

By the Cauchy-Schwartz inequality we can easily see that [formula], as such we implicitly define Γ, the angle between X and Y, as follows:

[formula]

Therefore [formula].

[formula] is the "Correlation Angle" of X and Y.

Our definition of Γ is the standard method of defining an angle from the covariance (or any other) inner product. We will show that Γ is a 'metric' on the unit sphere of V.

For any set S a map [formula] is a metric if for any x,y,z∈S the following properties are satisfied.

The map [formula] from definition [\ref=corrangle] is a metric on [formula] the unit sphere of V.

We must prove that Γ satisfies the 3 conditions in definition [\ref=metric].

[formula] so the non-negativity is satisfied trivially. It remains to show that [formula]. This true because if the angle between two vectors is zero, then they are (positive) scalar multiples of each other. Thus since X and Y are unit vectors, if [formula] we must have X  =  Y.

[formula] [formula]

To prove the triangle inequality, a geometric idea in itself, we delve into the geometry being defined. We will complete this part of the proof in section [\ref=Geometry].

Our metric Γ allows us to measure the correlation between two vectors.

For X, Y, Γ and ρ as above:

If Γ  =  0 [formula] then X and Y are maximally positively-correlated.

If Γ  =  π [formula] then they are maximally negatively-correlated.

If Γ  =  π / 2 [formula] then X and Y are uncorrelated.

It should be noted that cases (i) and (ii) are both considered to be "maximally correlated".

A Geometric Interpretation

The vector space V with inner product Covar lends itself nicely to a geometric interpretation. First we must establish a small amount of background.

Consider S, the standard unit sphere in Euclidean n-space ([formula]). Great circles are the intersection of a plane through the origin and S. They share many properties with the standard idea of lines in Euclidean space, including the property that they define the shortest path between any two points. For a thorough treatment of great circles as lines on a sphere see [\cite=Henderson], [\cite=HendersonDiff], [\cite=BON] or [\cite=Morita].

For any two non-zero vectors v1 and v2 in [formula] let θ be the (minimal) angle formed by v1 and v2. The unit vectors 1 and 2, corresponding to v1 and v2, define two points p1 and p2 on S. In order to measure the distance from p1 to p2 along S we take the length of the arc on great circle between the two points. By definition this is the radian measure of θ.

If V, the vector space considered in section 3, is thought of as [formula] with v1 and v2 any two vectors, then we can compute the spherical distance between v1 and v2, namely the distance between p1 and p2 on S. We call this quantity Γ:

[formula]

Thus far we have identified the inner product space [formula] as [formula]. We solidify this intuition with the following proposition. First we define [formula], a real valued symmetric matrix. As in [\cite=HoffmanKunze] we use A to create the inner product on [formula].

The inner product space [formula] w here ·  A is a 'twisted dot product' defined for two vectors [formula] and [formula] as

[formula]

This follows from the standard method of representing an inner-product by a matrix. (See [\cite=HoffmanKunze] chapter 8.1).

Now we return to our proof of [\ref=GammaMetric].

Let X,Y,Z∈V be unit vectors. We have left to show that [formula]. Because X and Z are unit vectors, [formula] is the geodesic distance between X and Z. Since geodesic distance satisfies the triangle inequality, Γ must as well.

Projective Metric

For scientists, ρ  =    ±  1 (equivalently Γ  =  0 or Γ  =  π) are often both considered to be "maximally correlated", for example see [\cite=Douglass2010]. To take this into account we modify our metric on the unit sphere of V. We think of V as a projective space, the space of lines through the origin of V. We denote this space as [formula].

Our original correlation angle Γ is modified to be:

[formula]

[formula] is a metric on [formula].

We must show that the three conditions of [\ref=metric] are met.

[formula] corresponds to a correlation angle of 0 or π. The two vectors are either in the same direction or opposite direction. In either case they determine the same line through the origin and hence correspond to the same point in projective space.

As in [\ref=metric] the symmetry of [formula] follows from the symmetry of ρ.

As before, the triangle inequality follows as [formula] is the geodesic distance for a projective space.

The metric [formula] gives the angular distance between X and Y. If [formula] (what we called a "maximal correlation") then [formula] however if [formula], which we called orthogonality or non-correlation, then [formula].

Let [formula] be the metric [formula], then the pair [formula] is a projective metric space.

This is by construction.

Time Dependence

Until this point we have treated our random variables [formula] as being time-independent. However, random variables often depend on time. Therefore we will now consider each random variable as depending discretely on time. It should be noted that what follows is essentially a replication of what has come before, however X and Y are now treated as vectors instead of singleton points. Vectors, however, are just points of V. The additional theory and notation is simply a means of dealing with the additional information.

To make our n random variables time dependent they will now be given as:

[formula]

We must now redefine the covariance. We do this by looking at a time window starting at time t with a duration of K, where K is called the summation window.

[formula]

Where μ and ν are the sample means in the summation window of Xi and Xj respectively. i.e. [formula].

If we think of [formula] and [formula] as the vectors [formula] (resp. for [formula]) then we get that

[formula]

where"·  " is the standard Euclidean dot product and [formula] is the length K vector [formula] (resp. for [formula]). This is called the "Pearson Covariance".

In other words if we define the vectors [formula] and [formula] then we define the Pearson Correlation as follows.

[formula], where "·  " is the usual Euclidean inner product.

Now we define the Pearson Correlation as

[formula]

Here again [formula] corresponds to the standard Euclidean angle, known as the Pearson Correlation Angle, and the resulting metric is the standard metric studied in classical spherical geometry. (See [\cite=Henderson], [\cite=HendersonDiff], [\cite=BON] or [\cite=Morita]).

Correlation Measures: Mn and Mn,a

To this point we have developed a method that will numerically tell us the correlation between two vectors. In this section we will create two sets of functions that allow us to measure the correlation across a set of vectors. The first set, [formula] is based upon taking the volumes of i-simplices (a 1-simplex is a line, a 2-simplex a triangle, a 3-simplex is a tetrahedron, etc.) The set of Mi,a benefits from computability, but is not as precise as the second set of measures [formula], that measure the volume of i-dimensional convex hulls.

Given a set of vectors [formula], let [formula] be the set of corresponding unit vectors. We will define a way to measure the closeness of the Ui to each other using the metric Γ. To do this we define the diameter of U as

[formula]

If all of the vectors are taken in the standard way to be points on the unit sphere, then the diameter is a measure of the overall spread of the points. If the diameter is small then the vectors are all close together, hence highly correlated. Whereas if the diameter is large at least some of the points are far apart, hence not highly correlated. The benefit of the diameter is that it is an easy quantity to calculate, however it can be somewhat misleading. If, for instance, a large number of points are clustered together and there is one outlying point the diameter can be quite large despite the fact that the points are generally quite correlated.

We now proceed to generalize the correlation measure defined by D. Let T be a collection of t points on the n-sphere, and let D be the set of n-simplices made up of points in T.

[formula]

This maximum is taken over the [formula] different simplices made of points in T.

[formula].

The volume used in [\ref=Mn] is the spherical volume and H is the convex hull of the points of T with respect to the spherical measure. That is, it is the smallest geodesically convex set containing T. (Geodesically convex means that any two points in the set have the minimal geodesic between them completely in the set as well.)

The volume is computed by constructing the convex hull of T, then disregarding all the points of T not contributing to the hull. The hull is then divided into its 'essential' n-simplices and the volumes of these simplices are summed.

Mn and Mn,a are each measures of n-dimensional volume. Mn,a benefits from being easily computable. Mn, though harder to compute, gives a better measure of the overall spread of the vectors. However, in the one dimensional case we have that M1  =  M1,a  =  D, the diameter. The reason for this is that when making the hull to compute M1 all but the two furthermost points will be disregarded. This equality is not true in general, a fact which can be easily observed by plotting four points forming a quadrilateral where M2,a  <  M2. In the general case however we do have the inequality [formula]. This follows since the maximal simplex will necessarily be a subset of the convex hull. Since volume is monotonic we have the inequality.

Assume that s of the t points of T are essential to the convex hull. There is a constant [formula] defining the number of essential simplices that compose the convex hull. i.e.

[formula]

Replacing the volume of each spherical simplex with the maximal one, that is [formula], we get the following inequalities

[formula]

Since B depends only on the number of points in T we see that, for a fixed data set, Mn and Mn,a differ by at most a fixed constant.

To relate Mn and Mn,a to section [\ref=TD] we note that when T time dependent random variables are looked at over a summation window of length K = n + 1 then we get T points on the n-sphere. In this situation we can apply the measures of spread given by [formula] or [formula] or [formula] for k  <  n.

Topology of earth's climate indices and phase-locked states

In this section we apply our new correlation measure to data from Douglass's paper [\cite=Douglass2010]. In [\cite=Douglass2010] the diameter (M1 = M1,a) is used to analyze a set of climate data, in this section we use M2,a to analyze the same data. Comparing the results of the new analysis to Douglass's original analysis shows the increased effectiveness of the new correlation measure.

Various regions of the Earth's climate system are characterized by temperature and pressure indices. Douglass [\cite=Douglass2010], in a study of a global set of four indices, defines a distance

[formula]

between indices that satisfies the properties required to be a metric ([\ref=metric]) where [formula] is the Pearson correlation coefficient. Note that the distance Γ is an angle.

In ([\ref=CorrMeasures]) the correlation among a set of indices can be measured, using Mi,a by taking the volumes of i-simplices. In [\cite=Douglass2010], Douglass uses the diameter of the metric space [formula], defined as

[formula]

In the notation of ([\ref=CorrMeasures]) D  =  M1,a. Geometrically, D selects the largest angle [formula] among the set. The diameter D may be considered a "dissimilarity" index because large D means weak correlation. Thus, the minima in D are associated with high correlation among the elements of the set. In Douglass, [\cite=Douglass2010], two cases were considered: (1) the set of 3 Pacific ocean indices; (2) the global set of 4 indices (6 independent pairs). The D of the global set is shown (in red) in Figure 1.

The maximal area M2,a, the generalized correlation measure, was computed for the same four indices of [\cite=Douglass2010]. The plot for the calculation is shown (blue) in Figure 1ab. Comparison of the two plots shows that the area measure reveals more minima (30) than the diameter (18). The various minima are indicated by arrows in Figure 1ab, and a list of dates is given in Table 1.

Table 1: Date of various minima in plots of diameter D  =  M1,a or area A = M2,a. (Minima are identified with a change in the phase-locked state of the Earth's climate system).

Figure 1(a) 1870-1940. (b)1940-2010 The plots are for two different correlation measures among a set of four global climate indices- the diameter D = M1,a (in red) and the area A = M2,a (in blue) are defined in the text. Minima correspond to high correlation. The diameter D plot shows 18 identified minima while the area A plot shows 30. Comparisons are given in table 1.

Summary

By using covariance on a set of time independent random variables or the covariance defined by the Pearson correlation on a set of time dependent variables we create metrics Γ and [formula] (resp.) on the unit sphere (resp. projective space) of the corresponding formal vector spaces. If V is the n-dimensional formal vector space whose basis is the set of random variables [formula], we use Γ or [formula] to create Mn or Mn,a, two measures of spread on values taken by the Xi. In section [\ref=appendix] we give an explicit example of showing the use of M2,a on a global set of climate indices.

The two measures of spread, differ by at most a fixed multiplicative constant, so for theoretical purposes they are of equivalent use. However when applied they have can have different values. The volume of the convex hull created of [formula], given by Mn is the most precise measure of the correlation of the Xi, however it is computationally difficult. The maximal volume of all possible n-simplices defined by the Xi, given by Mn,a, is a rougher measure of correlation. However Mn,a is a simpler computation than Mn.

In the 2-dimensional example, where all the vectors lie on the 2-sphere one can apply M2.a, M2, or [formula]. But in general M1,a is coarser than M2,a but is significantly easier to compute. For example, in [\cite=Douglass2010] and section [\ref=appendix] the use of M2,a yields much finer and cleaner results than the use of M1,a. More generally in n-dimensions Ml and Ml,a for any l  ≤  n and one sacrifices accuracy for ease.