Bounds on the coefficients of the characteristic and minimal polynomials

Introduction

The Frobenius normal form of a matrix is used to test two matrices for similarity. Although the Frobenius normal form contains more in formation on the matrix than the characteristic polynomial, most efficient algorithms to compute it are based on computations of characteristic polynomial (see for example [\cite=Storjohann:2000:thesis]). Now the Smith normal form of an integer matrix is useful e.g. in the computation of homology groups and its computation can be done via the integer minimal polynomial [\cite=jgd:2001:JSC].

In both cases, the polynomials are computed first modulo several prime numbers and then only reconstructed via Chinese remaindering [\cite=VonzurGathen:1999:MCA]. Thus, precise bounds on the integer coefficients of the integer characteristic or minimal polynomials of an integer matrix are used to know how many primes are sufficient to perform a Chinese remaindering of the modularly computed polynomials. Some bounds on the minimal polynomial coefficients, respectively the characteristic polynomial, have been presented in [\cite=jgd:2001:JSC], respectively in [\cite=jgd:2005:charp]. The aim of this note is to present sharper estimates in both cases.

For both polynomials we present two kind of results: absolute estimates, useful to compare complexity constants, and algorithms which compute more precise estimates based on the properties of the input matrix discovered at runtime. Of course, the goal is to provide such estimates at a cost negligible when compared to that of actually computing the polynomials.

Bound on the minors for the characteristic polynomial

Hadamard's bound on the minors

The first bound of the characteristic polynomial coefficient uses Hadamard's bound, [formula], see e.g. [\cite=VonzurGathen:1999:MCA], to show that the coefficients of the characteristic polynomial could be larger, but only slightly:

Let [formula], with n  ≥  4, whose coefficients are bounded in absolute value by B > 1. The coefficients of the characteristic polynomial CA of A are denoted by cj, j = 0..n and ||CA||∞  =   max {|cj|}. Then

[formula]

Observe that cj, the j-th coefficient of the characteristic polynomial, is an alternate sum of all the (n - j)  ×  (n - j) diagonal minors of A, see e.g. [\cite=Gantmacher:1959:TMone]. It is therefore bounded by [formula]. First note, that from the symmetry of the binomial coefficients we only need to explore the ⌊n / 2⌋ first ones, since [formula] for j < ⌊n / 2⌋.

The lemma is true for j = 0 by Hadamard's bound.

For j = 1 and n  ≥  2, we set [formula]. Now [formula]. Thus, the numerator of the derivative of f(n) has two roots, one below 2 and one between 6 and 7. Also, f(n) is increasing from 2 to the second root and decreasing afterwards. With n  ≥  4, the maximal value of f(n) is therefore at n = 6, for which it is [formula].

For other j's, Stirling's formula has been extended for the binomial coefficient by Stnic in [\cite=Stanica:2001:binomial], and gives [formula],

[formula]

Now first [formula], since the maximal value of the latter is at [formula]. Therefore, [formula].

Then [formula] is decreasing in j for 2  ≤  j < ⌊n / 2⌋ so that its maximum is [formula]. Consider now the rest of the approximation [formula] We have [formula], where [formula]. Well T(n,j) is maximal for [formula]. We end with the fact that for n  ≥  4, [formula] is maximal over [formula] for n = 16 where it is lower than 0.2052. The latter is lower than [formula].

We show the effectiveness of our bound on an example matrix:

[formula]

This matrix has X5 - 5X4 + 40X2 - 80X + 48 for characteristic polynomial and [formula] is greater than Hadamard's bound 55.9, and less than our bound 80.66661.

Note that this numerical bound improves on the one used in [\cite=Giesbrecht:2002:CRF] since [formula]. While yielding the same asymptotic result, their bound would state e.g. that the coefficients of the characteristic polynomial of the example are lower than 21793.

Locating the largest coefficient

The proof of lemma [\ref=lem:hadamard] suggests that the largest coefficient is to be found between the [formula] last ones. In next lemma we take B into account in order to sharpen this localization. This gives a simple search procedure computing a more accurate bound on the fly, as soon as B is known.

Let [formula], with n  ≥  4, whose coefficients are bounded in absolute value by B > 1. The characteristic polynomial of A is CA. Then

[formula]

where δ  ≈  5.418236. Moreover, the cost of computing the associated bound on the size is

[formula]

This localization improves by a factor close to [formula], the localization of the largest coefficient proposed in [\cite=jgd:2005:charp].

Consider [formula] for [formula]. The numerator of the derivative of F with respect to j is

[formula]

where [formula] is the k-th Harmonic number. We have the bounds [formula] from [\cite=Qi:2005:harmonic]. This bounds proves that F(n,j) has at most one extremal value for [formula]. Moreover, [formula] is thus strictly negative, as soon as n  ≥  4. Now let us define G(j) = 2H(n - j) - 2H(j) -  ln (n - j) -  ln (B2) - 1. Using the bounds on the Harmonic numbers, we have that

[formula]

Then, on the one hand, we have that [formula] is increasing for [formula] so that its minimal value is [formula] at j = 2. Finally, [formula] if we let n go to the infinity.

On the other hand, [formula] is also increasing and therefore its maximal value is [formula] at j = n / 2. Finally, [formula], its value at n = 4.

Then, the monotonicity of G and its bounds prove that the maximal value of F(n,j) is found for j* between the solutions ji and js of the two equations below: This proves in turn that

[formula]

where [formula].

Now for the complexity, we use the following recursive scheme to compute the bound:

[formula]

For instance, if we apply this lemma to matrix [\ref=matex] we see that we just have to look at F(n,j) for [formula].

Eigenvalue bound on the minimal polynomial

For the minimal polynomial the Hadamard bound may also be used, but is too pessimistic an estimate, in particular when the degree is small. Indeed, one can use Mignotte's bound on the minimal polynomial, as a factor of the characteristic polynomial. There, [formula], see [\cite=Mignotte:1989:poly]. This yields that the bit size of the largest coefficient of the minimal polynomial is only d bits less than that of the characteristic polynomial.

Therefore, one can rather use a bound on the eigenvalues determined by consideration e.g. of Gershg�rin disks and ovals of Cassini (see [\cite=Varga:2004:GersC] for more details on the regions containing eigenvalues, and [\cite=jgd:2001:JSC] for a blackbox algorithm efficiently computing such a bound). This gives a bound on the coefficients of the minimal polynomial of the form βd where β is a bound on the eigenvalues and d is the degree of the minimal polynomial.

We can then use the following lemma to bound the coefficients of the minimal polynomial:

Let [formula] with its spectral radius bounded by β  ≥  1. Let [formula]. Then

[formula]

This improves the bound given in [\cite=jgd:2001:JSC] by a factor of log (d) when d >  > β.

Expanding the minimal polynomial yields [formula] by e.g. [\cite=Mignotte:1989:poly]. Then, if d  ≤  β, we bound the latter by diβd - i.

Now, when d  >  β, we get the fist bound in two steps: first, for [formula], we bound the binomial factor by di and thus get [formula] since d  >  β ; second, for [formula], we bound the binomial factor by dd - i and thus get [formula].

The second bound, when d  ≥  β is obtained by bounding the binomial coefficients by the middle one, [formula], and using Stnic's bound [\cite=Stanica:2001:binomial] on the latter. This gives that [formula].

For matrices of constant size entries, both β and d are O(n). However, when d and/or β is small relative to n (especially d) this may be a striking improvement over the Hadamard bound since the length of latter would be of order n log (n) rather than d log (β).

This is the case e.g. for the Homology matrices in the experiments of [\cite=jgd:2001:JSC]. Indeed, for those, AAt, the Wishart matrix of A, has very small minimal polynomial degree and has some other useful properties which limit β (e.g. the matrix AAt is diagonally dominant). For example, the most difficult computation of [\cite=jgd:2001:JSC], is that of the 25605  ×  69235 matrix !n4c6.b12! which has a degree 827 minimal polynomial with eigenvalues bounded by 117. The refinement of lemma [\ref=prop:coeffbound] yields there a gain in size on the one of [\cite=jgd:2001:JSC] of roughly 5%. In this case, this represents saving 23 modular projections and an hour of computation.

Conclusion

We have presented in this note bounds on the coefficient of the characteristic and minimal polynomials of a matrix. Moreover, we give algorithms with low complexity computing even sharper estimates on the fly.

The refinements given here are only constant with regards to previous results but yield significant practical speed-ups.