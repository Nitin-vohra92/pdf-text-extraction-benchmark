On Geometric Algebra representation of Binary Spatter Codes

Introduction

Distributed representation is a way of representing information in a pattern of activation over a set of neurons, in which each concept is represented by activation over multiple neurons, and each neuron participates in the representation of multiple concepts [\cite=E1]. Examples of distributed representations include Recursive Auto-Associative Memory (RAAM) [\cite=RAAM], Tensor Product Representations [\cite=Smolensky], Holographic Reduced Representations (HRRs) [\cite=Plate95] [\cite=Plate2003], and Binary Spatter Codes (BSC) [\cite=Kanerva96] [\cite=Kanerva97] [\cite=Kanerva98].

BSC is a powerful and simple method of representing hierarchical structures in connectionist systems and may be regarded as a binary version of HRRs. Yet, BSC has some drawbacks associated with the representation of chunking. This is why different versions of BSC can be found in the literature. In [\cite=Kanerva96] [\cite=Kanerva97] chunking is given by a majority-rule thresholded addition of binary strings, an operation that often discards a lot of important information. In [\cite=Kanerva98] the ordinary addition is employed, and bits are parametrized differently.

The main message we want to convey in this paper is that there exists a very natural representation of BSC at the level of Clifford algebras. Binding of vectors is here performed by means of the Clifford product and chunking is just ordinary addition. Since Cliford algebras possess a geometric interpretation in terms of Geometric Algebra (GA) [\cite=GA1] [\cite=GA2] [\cite=GA3], the cognitive structures processed in BSC or HHRs obtain a geometric content. This is philosophically consistent with many other approaches where cognition is interpreted in geometric terms [\cite=Widdows] [\cite=PG]. Of particular relevance may be the links to neural computation whose GA and HRR versions were formulated by different authors (cf. [\cite=Plate2003] [\cite=Bayro] [\cite=JN].

The present paper can be also seen in a wider context of a "quantum structures" approach to cognitive problems we have outlined elsewhere [\cite=Gabora] [\cite=AC] [\cite=Gabora2] [\cite=Gabora3] [\cite=Bart]. Cartan's representation of GA in terms of tensor products of Pauli matrices introduces formal links to quantum computation (cf. [\cite=Somaroo] [\cite=BDM1] [\cite=BDM2] [\cite=BDM3]). The philosophy we advocate here is also not that far from the approach of Widdows, where both geometric an "quantum" aspects play an important role [\cite=Widdows] [\cite=WiddowsPeters] [\cite=WiddowsHiggins].

It should be stressed that the GA calculus has already proved to be a powerful tool in applied branches of computer science (computer vision [\cite=Lasenby96], robotics [\cite=robot]). GA is a comprehensive language that simplified and integrated many branches of classical and quantum physics [\cite=Hestenes]. One may hope that it will play a similar role in cognitive science.

Binary Spatter Codes

In BSC information is encoded into long unstructured strings of bits that form a holistic record. The record is composed in two steps called binding and chunking.

Binding of a role x with a filler y is performed by means of XOR [formula] (componentwise addition of binary strings mod 2); the role-filler object is [formula]. Chunking means adding the bound structures in a suitable way.

In order to illustrate the original BSC and its algebraic modification let us take the example from [\cite=Kanerva97]. The encoded record is

[formula]

Decoding of the "name" looks as follows

[formula]

We have used here the involutive nature of XOR and the fact that the "noise" can be eliminated by clean-up memory. The latter means that we compare [formula] with records stored in some memory and check, by means of the Hamming distance, which of the stored elements is closest to [formula]. A similar trick could be done be means of circular convolution in HRRs, but then we would have used an approximate inverse name*, and an appropriate measure of distance. Again, the last step is comparison of the noisy object with "pure" objects stored in clean-up memory.

Geometric-algebra representation of Binary Spatter Codes

Euclidean-space GA is constructed as follows. One takes an n-dimensional linear space with orthonormal basis [formula]. Directed subspaces are then associated with the set

[formula]

Here 1 corresponds to scalars, i.e. a 0-dimensional space. Then we have vectors (oriented segments), bivectors (oriented parallelograms), and so on. There exists a natural parametrization: [formula], [formula], [formula], [formula], [formula], [formula], [formula], which shows that there is a one-to-one relation between an n-bit number and an element of GA. An element with k 1s and n - k 0s is called a k-blade.

A geometric product of k 1-blades is a k-blade. For example, e1248 = e1e2e4e8. Moreover, enem =  - emen, if m  ≠  n, and enen = 1, for any n. GA is a Clifford algebra [\cite=BT] enriched by certain geometric interpretations and operations.

Particularly interesting is the form of the geometric product that occurs in the binary parametrization. Let us work out a few examples:

[formula]

The number D is the number of times a 1 from the right string had to "jump" over a 1 from the left one during the process of shifting the right string to the left. Symbolically the operation can be represented as

[formula]

The above observations, generalized to arbitrary strings of bits, yield

[formula]

Indeed, for two arbitrary strings of bits we have

[formula]

where

[formula]

We conclude that the map

[formula]

has GA projective (i.e. up to a sign) representation by means of ([\ref=GAr]). Accordingly, the geometric product is a representation of Kanerva's binding at the level of GA.

Chunking can be represented in GA similarly to what is done in HRRs, that is, by ordinary addition. To see this consider

[formula]

Until now the procedure is similar to what is done in BSC and HRRs.

An analogue of clean-up memory can be constructed in various ways. One possibility is to make sure that fillers, [formula] etc. are orthogonal to the noise term. For example, let us take the fillers of the form [formula], where the first k  ≪  n bits are selected at random, but the remaining n - k bits are all 0. Let the roles be taken, as in Kanerva's BSC, with all the bits generated at random. The term [formula] will with high probability contain at least one Bj = 1, k < j  ≤  n, and thus will be orthogonal to the fillers. The clean-up memory will consist of vectors with Bj = 0, k < j  ≤  n, i.e of the filler form.

Tle final step is performed again in analogy to HRRs. We compute a scalar product between Y and the elements of clean-up memory. Depending on our needs we can play with different scalar products, or with the so-called contractions [\cite=Dorst]. The richness of GA opens here several possibilities.

Cartan representation

In this section we give an explicit matrix representation of GA. We begin with Pauli's matrices

[formula]

GA of a plane is represented as follows: 1 = 2  ×  2 unit matrix, e1  =  σ1, e2  =  σ2, e12  =  σ1σ2 = iσ3. Alternatively, we can write e00 = 1, e10  =  σ1, e01  =  σ2, e11 = iσ3, and

[formula]

This is equivalent to encoding 22 = 4 real numbers into two complex numbers.

In 3-dimensional space we have 1 = 2  ×  2 unit matrix, e1  =  σ1, e2  =  σ2, e3  =  σ3, e12  =  σ1σ2 = iσ3, e13  =  σ1σ3 =  - iσ2, e23  =  σ2σ3 = iσ1, e123  =  σ1σ2σ3 = i.

Now the representation of

[formula]

is equivalent to encoding 23 = 8 real numbers into 4 complex numbers.

An arbitrary n-bit record can be encoded into the matrix algebra known as Cartan's representation of Clifford algebras [\cite=BT]:

[formula]

In practical calculations it is convenient to work with the tensor product implemented by means of the "drag-and-drop" rule: For arbitrary matrices A and B (not necessarily square, and possibly of different dimensions)

[formula]

This representation of [formula] can be used to show that all ek given by Cartan's representation are matrices of zero trace.

Pat Smith revisited

So let us return to the example from Sec. 2. For simplicity take n = 4 so that we can choose the representation

[formula]

[formula]

The fillers have only the first two bits selected at random, the last two are 00. The roles are numbered by randomly selected strings of bits.

The explicit matrix representations are:

[formula]

The whole record

[formula]

The fact that the last two terms are linearly dependent is a consequence of too small dimensionality of our binary strings (four bits, whereas in realistic cases Kanerva suggested 104 bit strings). This is the price we pay for simplicity of the example. Decoding the name involves two steps. First

[formula]

It remains to employ clean-up memory. But this is easy since the noise is perpendicular to ePat. We only have to project on the set spanned by the fillers, and within this set check which element is closest to the cleaned up [formula].

Cartan's represenation allows to define scalar product in GA by means of the trace. We therefore compare scalar products between [formula] and elements of clean-up memory. The only nonzero scalar product is

[formula]

Indeed

[formula]

has zero trace.

Conclusions

BSC represented at the level of GA maintain the essential element of the original construction, i.e. binding by means of XOR. However, instead of the straightforward map

[formula]

we rather have the "exponential map" [formula] satisfying [formula]. Another difference is in mathematical implementation of chunking. Unbinding produces a noise term which, with high probability, is orthogonal to the original filler. In this respect the construction is analogous to error correcting linear codes. As opposed to tensor product representations, and similarly to BSC and HRRs, binding performed by means of geometric product does not increase dimensions.