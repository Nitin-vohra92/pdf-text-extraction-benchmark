A Markov Chain Analysis of a Pattern Matching Coin Game

The Penney Ante Game: Flips and Tricks

The game developed by Walter Penney is not particularly well known and we think that half the fun is to be found in playing the game with your friends. Therefore we would like to take this first foray into the development of the game as an introduction and a lesson. The game is classically not played with suited cards (as is its treatment in [\cite=nishiyama]), but instead with a fair coin. We discuss Penney's probabilistic game in the light of the coin.

Imagine that two players, and , are to play Penney's game. Then we may assume, without loss of generality, that has challenged , and for that reason it falls first to to elect a "binary" (though it is perhaps more natural to consider it either "heads" or "tails") sequence of length three. It's easy to see that there are eight such sequences, and let us suppose that has (lucklessly) chosen [formula] - that is, the sequence of three heads one after the other.

In response, also chooses a sequence. Let us pointedly suppose that chooses the sequence [formula]. Then the game proceeds as follows:

What makes this game particularly interesting is that there exists an optimal strategy that may be taken by the second player (in this case ø) such that they may gain a probabilistic advantage over the first player (here, ). We formalize this notion in the following definition.

We say that a 3-sequence of binary random variables is a strategy. Furthermore, such a strategy s1 is optimal for another strategy s2 iff the probability that the sequence s1 will occur before the sequence s2 (and thereby winning the trick) is larger than [formula]. We denote this probability using the notation,

[formula]

Non-Transitive Games

The word "non-transitive" may at first be rather intimidating, but as it happens almost everyone has been met with a non-transitive game at one point in their lives or another. We begin by defining a non-transitive relationship.

A relationship between strategies s1, s2, and s3 is said to be non-transitive if s1 is optimal for s2 and s2 is optimal for s3, but s1 is not optimal for s3.

This is quite easy to find in everyday life, especially among young children! If one considers carefully, then it should be apparent that the classical game of rock-paper-scissors constitutes a non-transitive game.

As we are playing a slightly different game in rock-paper-scissors, we shall for this section only consider a strategy to be one of the game's namesake possibilities. Then we know that rock is optimal for scissors, and that scissors is optimal for paper. But if rock-paper-scissors were a transitive game, then rock would be optimal for paper. Indeed, this is not the case, and in fact just the opposite since paper is optimal for rock! Therefore, rock-paper-scissors is a non-transitive game.

Similarly, the Penney ante game is also a non-transitive game, which is what makes it interesting. Unlike rock-paper-scissors, however, where rock always beats scissors, it is conceivable in the Penney ante game that a sub-optimal strategy may still win! Thus, optimality must be defined in terms of probabilities rather than in terms of absolute properties.

The Penney ante game is a non-transitive game.

As will follow from exhaustive proof later in the paper, we will have that [formula] has an optimal counterpart in [formula]. Furthermore, [formula] is optimal for [formula]. In a transitive game, this would suggest that [formula] is optimal for [formula], but indeed they are not, for each element in the strategy is simply the "negation" of the corresponding element of the other. Thus, if one strategy were sub-optimal, one could make it optimal by relabeling the sides of the coin.

Interestingly, Penney's game exhibits what we suppose might be called a four-directional non-transitive relationship. Continuing where we left off, we will demonstrate later that the strategy [formula] is optimal for [formula]. But crucially we have at last that [formula] is optimal for [formula]. This is a result precisely opposite of what one would expect in a transitive game.

An Optimality Theorem

Assume that elects the sequence [formula] and that in response chooses the sequence [formula]. Then will win iff [formula] comprises the first sequence to appear.

The direction ⇐ is quite immediate as if the first sequence to appear is [formula] then has won by definition.

The ⇒   direction requires closer examination. Suppose that the first sequence was not [formula]. Then we have the implication that there must therefore be at least one T within the first 3-sequence. Then we have the following four possibilities for the next 2-sequence following the T:

Notice that in each of the four exhaustive conditions above, none allow for the possibility of winning the trick. Therefore, we conclude that cannot win if a T has occurred within the first 3-sequence. Therefore, can only win when the first three sequence does not contain T, or in other words, if the first 3-sequence is [formula].

The probability that wins given that he selects the sequence [formula] and that plays optimally is,

[formula]

Incidentally, the probability that wins under these conditions is [formula].

Denote by B a Bernoulli random variable with parameter [formula]. Then the sequence [formula] is a binary sequence of length three, which is analogous to the sequence chosen by in Penney's game. Then an optimal strategy for to assume is the sequence,

[formula]

Where [formula] is the logical negation such that,

[formula]

The proof is fortunately very straightforward, and it requires only the confirmation that sequence has consistently a higher probability of occurring first than does 's. The eight possible strategies can be enumerated completely.

From it is immediately clear that [formula] is optimal for [formula]. If we assume that takes the strategy [formula], then predicts that the strategy [formula] is optimal. We can confirm this by calculating the probability that [formula] will occur before the sequence [formula].

[formula]

Therefore, we have via complementary events that,

[formula]

This confirms that [formula] is an optimal strategy for [formula]. This concludes the cases for which we provide a proof for the moment.

Let us next examine the case where has elected the 3-sequence [formula] and chooses [formula]. Since both strategies depend on an initial result H, we may assume without loss of generality that the first coin flip in the sequence yields H. This proof is most easily understood via a Markov Chain argument, so we diverge here briefly to discuss Markov Chains and their relationship to Penney's game.

Let ¶ be the transition matrix of a Markov chain. Let the rows and columns of the transition matrix correspond to particular 3-sequences arising in the Penney ante game. Then the probability of transition from the 3-sequence si to the sequence sj is given by the entry ¶i,j.

Let ¶ be the transition matrix of a Markov Chain and let the row-vector 0 denote a probability vector of the state distributions initially. Then the probability of arriving in the 3-sequence si after n iterations of the game is,

[formula]

In fact, the states may be generalized beyond 3-sequences to any number of states existing in an abstract system. It is this property that makes the theorem so useful in applications.

We can now demonstrate how Markov Chains can be leveraged to address two further cases in Penney's game. In particular, [formula] is optimal for both [formula] and [formula].

In the first case, we consider [formula]. Then predicts that should choose the strategy [formula]. In this case, we wish to understand [formula]. Notice that the transition matrix, ¶, for this game may be written,

[formula]

Then it may be demonstrated computationally that we have asymptotically the following behavior of lim n  →    ∞¶n:

[formula]

Let us denote   =   lim n  →    ∞¶n. Notice then that each of initial states are equally likely, each occurring with probability [formula]. Therefore, provides,

[formula]

This shows that [formula] and that therefore, strategy is optimal for under these circumstances.

To demonstrate that [formula] is optimal for [formula], we proceed simply in the same manner. We do not reproduce here the calculations as we did in the previous case, but they are easy to check using a programming language such as MATLAB or Python. Let  be the transition matrix for the Markov Chain corresponding to the game where [formula] is strategy and [formula] is sequence. Then we have that,

[formula]

It follows from here that,

[formula]

In turn, this provides the desired result.

As it happens, it is possible to demonstrate for each of the eight strategies in Penney's game that the corresponding optimal strategy is optimal using a Markov Chain argument. However, in order to demonstrate a broader range of mathematics, we do not take that approach here.

We have already demonstrated proofs that yields an optimal strategy for the cases where chooses either of the 3-sequences [formula] or [formula]. By , we have immediately that gives the correct strategy for the cases where elects either of the strategies [formula] or [formula].

The remainder of the proof is not much work. In order to avoid the tedious repetition inherent in enumerating the remaining four cases, one can get away with simply observing that we could have arbitrarily relabeled the sides of our coin so that our "heads" side becomes our T and the "tails" face represents H. Therefore, we may argue the last four cases via symmetry as follows.

This completes the proof that does indeed produce an optimal strategy for given any of the eight strategies that can elect. provides a visual reference for understanding the relationships between the strategies in the the Penney ante game.

A Markov Chain Analysis of the Penney Ante Game

Let ¶ be the transition matrix of a Markov Chain. We say that a state si is absorbing if ¶i,i  =  1 such that the state may never be left. States that are not absorbing are called transient. A Markov Chain is itself absorbing if it contains at least one such state and if it is possible to transition to one of those states from any of the other states.

Let ¶ be the transition matrix for an absorbing Markov Chain. Then it is possible to "shuffle around" the states of ¶ such that ¶ has the form,

[formula]

Let the matrix have [formula] absorbing states and [formula] transient states. Then  is a [formula] matrix, and  is a [formula] matrix. As usual, [formula] indicates a [formula] identity matrix and [formula] is a [formula] matrix of zeros. Our analysis relies primarily on the matrix .

Let ¶ be the transition matrix for a Markov Chain in canonical form. Then there exists a matrix called the fundamental matrix which is,

[formula]

Furthermore, the entry [formula] is the expected number of times that a Markov process with transition matrix ¶ visits the transient state sj conditioned on the fact that it began in transient state si.

For a proof of this theorem, refer to [\cite=probability].

How Many Flips on Average?

Leveraging the idea that Penney's game may be viewed in the light of Markov Chains, we are to compute the expected number of rounds that will be played before a winner is determined in the case of a single trick. Let [formula] be a vector whose [formula] entry is the expected number of iterations of the Markov process beginning in state si undergoes before it enters an absorbing state. Then we may write that,

[formula]

By we have that  represents the expected number of times that a process beginning in any of the transient states visits each of the other transient states. Thus, taking the summation of the rows of  yields the expected number of times that the process beginning in state si is in any of the other transient states. This is the expected number of iterations before that process is absorbed. Notice that [formula] is precisely the summation of the rows expressed as a matrix multiplication.

We have now established the mathematical foundation that will allow us to present our main result. We calculate the expected number of flips of a coin that will occur before a winner is declared in Penney's game. We assume that given the first player's sequence the second player will choose their strategy according to . This is, of course, dependent on knowing which of the eight possible initial circumstances ended up occurring. We exhibit these results in . We wish to draw attention to interesting symmetry that exists in the tabulation of the results that results from the symmetric nature of the game.

For an instance of Penney's game in which assumes the strategy s1 and takes the optimal strategy as in , then the expected number of coin flips before a winner is declared is,

[formula]

Consider that each of the initial states are equally probable, each occurring with frequency equal to [formula]. Then the average time to absorption for a process beginning in either of s1 or s2 is clearly zero. Additionally, the vector e presents the average time to absorption for each of the six "non-immediate-victory" states. Therefore, if we do not condition on any particular initial sequence at the beginning of the game, we may simply average together all of the expected times to absorption.

However, it is important to note that in this case averaging these expected times to absorption will not yield the expected number of coins flipped before a winner is declared. This is because we are assumed to start with a given 3-sequence in each of these cases, yet it takes three coin flips to arrive there in the first place! Hence, we introduce a supplement of three to each of our expected times to absorption to obtain the expected number of coins we must flip.

This represents an approach that can serve as an alternative to the method using Conway numbers proposed by Nishiyama in [\cite=nishiyama]. We show the expected number of coin tosses for each of the eight possible games in . If we assume that each of the strategies that can assume are equally likely, then we have that the expected number of coins flipped in Penney's ante game is given by,

[formula]

An Alternative Derivation of Optimality

It is possible to derive the probability [formula] for any pair of strategies arising from Penney's game. Here, we present a method that uses the fundamental matrix and another theorem from Markov Chain theory to derive these same probability values. But first, we present a critical result.

Let  be a [formula] matrix such that the value of [formula] is the probability that a Markov process will be absorbed into the absorbing state sj given that it started in the transient state si. Then we may calculate  as,

[formula]

This proof is straightforward and requires only some simple manipulations, particularly switching the order of the summations.

[formula]

The values [formula] and [formula] may be written as follows,

[formula]

Consider that if the game begins in the 3-sequence s1, then the probability of being absorbed into that state is one, yielding a probability of zero for the event that the process is absorbed into s2. The matrix [formula] gives the probability that the process is absorbed into s1 given that it starts in any of the transient states.

Therefore, given that all eight initial states are equally likely, we have that the probability of the process terminating in s1 is the average of the probabilities that it terminates in s1 given an initial state. This yields the equation,

[formula]

To see that the equation for [formula] must hold in we need only confirm that s2|s1 is a complementary event to s1|s2. This is easily seen to be true and so we obtain,

[formula]

This completes the proof.