Algebraic Solutions of Tropical Optimization Problems

Lemma Corollary

Introduction

Tropical (idempotent) mathematics, which is concerned with the theory and applications of semirings with idempotent addition, dates back to the early 1960's, when a few innovative works by Pandit [\cite=Pandit1961Anew], Cuninghame-Green [\cite=Cuninghamegreen1962Describing], Giffler [\cite=Giffler1963Scheduling], Hoffman [\cite=Hoffman1963Onabstract], Vorob'ev [\cite=Vorobjev1963Theextremal] and Romanovskiı [\cite=Romanovskii1964Asymptotic] made their appearance. Since that time the literature on the topic has increased rapidly with several monographs, including those by Carré [\cite=Carre1979Graphs], Cuninghame-Green [\cite=Cuninghamegreen1979Minimax], U. Zimmermann [\cite=Zimmermann1981Linear], Baccelli et al. [\cite=Baccelli1993Synchronization], Kolokoltsov and Maslov [\cite=Kolokoltsov1997Idempotent], Golan [\cite=Golan2003Semirings], Heidergott, Olsder and van der Woude [\cite=Heidergott2006Maxplus], Gondran and Minoux [\cite=Gondran2008Graphs], and Butkovi [\cite=Butkovic2010Maxlinear]; as well as with a great body of contributed papers.

Optimization problems that are set up and solved in the framework of tropical mathematics arose even in the early papers [\cite=Cuninghamegreen1962Describing] [\cite=Hoffman1963Onabstract] and now form an important research and applied field. Tropical optimization problems are formulated to minimize (maximize) a linear or nonlinear function defined on vectors of a finite-dimensional semimodule over an idempotent semifield, and may have constraints in the form of linear equations and inequalities. These problems find applications in job scheduling, location analysis, transportation networks, discrete event systems, and decision making. Some problems in a rather common setting can be solved directly in an exact form under fairly general assumptions. The solutions available for other problems take the form of iterative algorithms, which produce a solution, or indicate that no solution exists.

The aim of this paper is twofold: first, to give a broad overview of known tropical optimization problems and solution methods, including recent results; and second, to derive a direct, complete solution to a new optimization problem with inequality constraints as a clear illustration of an efficient algebraic solution technique based on the approach, which was developed and applied in [\cite=Krivulin2013Amultidimensional] [\cite=Krivulin2014Complete] [\cite=Krivulin2014Aconstrained]. Under this approach, we introduce an additional variable to represent the minimum value of the objective function, and then reduce the problem to the solution of an inequality with the new variable in the role of a parameter. Both the existence conditions for the solution of the inequality and the inequality constraints are exploited to evaluate the parameter, whereas all solutions to the inequality are taken as a complete solution to the problem

The paper is organized as follows. We start with a short, concise introduction in Section [\ref=S-PDR] to basic definitions and notation of idempotent algebra. Section [\ref=S-SLI] includes direct, complete solutions to linear inequalities, which provide the basis for the solving of a new optimization problem. In Section [\ref=S-OKPS], we give an overview of known optimization problems and solution methods. Furthermore, we outline recent results in Section [\ref=S-RR]. Finally, a new tropical optimization problem is formulated and completely solved in Section [\ref=S-NCOP].

Preliminary Definitions and Results

We start with a summary of basic definitions and notation of tropical mathematics to provide an appropriate formal framework for the overview of optimization problems and the derivation of a solution in the subsequent sections. The summary mainly follows the results in [\cite=Krivulin2006Solution] [\cite=Krivulin2009Onsolution] [\cite=Krivulin2012Anew] [\cite=Krivulin2013Amultidimensional], which focus on direct solutions in a compact vector form.

For more details, which are presented in introductory as well as advanced levels, see, e.g., [\cite=Cuninghamegreen1979Minimax] [\cite=Carre1979Graphs] [\cite=Zimmermann1981Linear] [\cite=Baccelli1993Synchronization] [\cite=Kolokoltsov1997Idempotent] [\cite=Golan2003Semirings] [\cite=Heidergott2006Maxplus] [\cite=Akian2007Maxplus] [\cite=Litvinov2007Themaslov] [\cite=Gondran2008Graphs] [\cite=Butkovic2010Maxlinear].

Idempotent Semifield

Consider a system [formula], where [formula] is a nonempty set that contains two distinct elements, zero [formula] and one [formula], and is closed under two binary operations, addition [formula] and multiplication, which satisfy the conditions: [formula] is an idempotent commutative monoid, [formula] is a commutative group, and multiplication distributes over addition. Since any nonzero element has a multiplicative inverse, the system is usually referred to as the idempotent semifield.

Addition is idempotent, which implies that [formula] for all [formula]. We assume the semifield to be linearly ordered by a total order that is consistent with the partial order induced by idempotent addition to define x  ≤  y if and only if [formula]. It follows from the definition that the inequality [formula] is equivalent to the inequalities x  ≤  z and y  ≤  z.

Multiplication is invertible to provide every [formula] with an element x- 1 such that [formula]. The integer powers are defined for any nonzero [formula] and p > 0 as follows: [formula], [formula], x- p = (x- 1)p, and [formula]. Moreover, the semifield is considered radicable (algebraically closed) to extend the power notation to the rational exponents.

Addition and multiplication are isotone in each argument.

From now on, we omit multiplication sign for better readability. The relation symbols and the optimization objectives are thought of in the sense of the above mentioned linear order on [formula].

Typical examples of the idempotent semifield under consideration include the following real semifields: [formula], [formula], [formula], and [formula], where [formula].

Specifically, the semifield [formula] takes -    ∞   to be the zero and 0 to be the one. For every [formula], the multiplicative inverse x- 1 corresponds to the opposite number - x in the conventional algebra. The power xy is defined for all [formula] and corresponds to the arithmetic product xy. The linear order on [formula] coincides with the natural order defined on [formula].

In the semifield [formula], we have [formula], [formula], [formula], and [formula]. Multiplicative inversion and exponentiation accept the usual interpretation. The linear order is opposite to the natural order on [formula].

Matrix Algebra

We now consider matrices over [formula] and denote the set of matrices with m rows and n columns by [formula]. A matrix with all entries equal to zero is the zero matrix denoted [formula]. A matrix is row- (column-) regular if it has no zero rows (columns). A matrix is regular if it is both row and column regular.

Addition and multiplication of conforming matrices [formula], [formula] and [formula], and multiplication by a scalar [formula] follow the standard rules using the entry-wise formulas

[formula]

The matrix operations are isotone in each argument with respect to the matrix relation ≤  , which is considered entry-wise.

The transpose of a matrix [formula] is indicated by [formula].

For every nonzero matrix [formula], we define the multiplicative conjugate transpose to be a matrix [formula] that has the entries a-ij = a- 1ji if [formula], and [formula] otherwise.

Now, examine square matrices in [formula]. A matrix that has all diagonal entries equal to [formula] and all off-diagonal entries equal to [formula] is the identity matrix denoted [formula]. For every matrix [formula] and integer p > 0, the nonnegative matrix powers are given by [formula], [formula].

The trace of a matrix [formula] is given by

[formula]

A matrix that has only one row (column) is a row (column) vector. All vectors are taken as column vectors unless otherwise specified. The set of column vectors with n elements is denoted [formula]. A vector with all zero elements is the zero vector. A vector is regular if it has no zero elements.

Let [formula] is a row-regular matrix and [formula] a regular vector. Then, the vector [formula] is clearly a regular vector. Moreover, if the matrix [formula] is column-regular, then the row vector [formula] is regular as well.

For every nonzero column vector [formula], the multiplicative conjugate transpose is a row vector [formula] that has element x-i = x- 1i if [formula], and [formula] otherwise. Multiplicative conjugate transposition has some useful properties which are not difficult to verify. First, the conjugate transposition is antitone, which means that, for any regular vectors [formula] and [formula] of the same size, the element-wise inequality [formula] implies [formula].

Furthermore, for any nonzero vector [formula], the identity [formula] holds. If the vector [formula] is regular, then the inequality [formula] is valid as well.

A scalar [formula] is an eigenvalue of a matrix [formula] if there exists a nonzero vector [formula] such that

[formula]

A matrix of order n can have one to n eigenvalues. The eigenvalue, which is maximal in the sense of the order defined on [formula], is called the spectral radius and given directly by

[formula]

For any matrix [formula] and vector [formula], we introduce functions, which play the role of tropical analogues of matrix and vector norms,

[formula]

Solutions to Linear Inequalities

In this section, we present direct, complete solutions to linear inequalities, which are of use later to derive new results. First, suppose that, given a matrix [formula] and a regular vector [formula], we need to find all regular vectors [formula] that satisfy the inequality

[formula]

The next result offers a solution given as a consequence of the solution to the corresponding equation [\cite=Krivulin2009Onsolution] [\cite=Krivulin2009Methods], and by independent proof [\cite=Krivulin2013Direct].

For any column-regular matrix [formula] and regular vector [formula], all regular solutions to inequality [\eqref=I-Axd] are defined by the inequality

Furthermore, we consider the problem: given a matrix [formula] and a vector [formula], find all regular vectors [formula] to satisfy the inequality

[formula]

To describe a solution to the problem, we apply a function that assigns to every matrix [formula] a scalar given by

[formula]

Provided that [formula], we use the asterate operator (also known as the Kleene star), which maps [formula] to the matrix

[formula]

A direct, complete solution to inequality [\eqref=I-Axbx] is obtained in [\cite=Krivulin2006Solution] [\cite=Krivulin2009Onsolution] [\cite=Krivulin2013Amultidimensional].

For any matrix [formula] and vector [formula], the following holds:

If [formula], then all regular solutions to inequality [\eqref=I-Axbx] are given by [formula], where [formula] is any regular vector such that [formula].

If [formula], then there is no regular solution.

In the solution to an optimization problem below, Lemma [\ref=L-Axd] is used repeatedly to obtain intermediate results, whereas Theorem [\ref=T-Axbx] provides the basis for the solution, which reduces the problem to an inequality in the form of [\eqref=I-Axbx] and then apply the theorem.

Overview of Known Problems and Solutions

Since the early works by Cuninghame-Green [\cite=Cuninghamegreen1962Describing] and Hoffman [\cite=Hoffman1963Onabstract], multidimensional optimization problems have become an important research domain in tropical mathematics. These problems appeared in different application contexts, including job scheduling [\cite=Cuninghamegreen1962Describing] [\cite=Cuninghamegreen1976Projections] [\cite=Cuninghamegreen1979Minimax] [\cite=Zimmermann1981Linear] [\cite=Zimmermann1984Some] [\cite=Zimmermann2006Interval] [\cite=Butkovic2009Introduction] [\cite=Butkovic2009Onsome] [\cite=Tam2010Optimizing] [\cite=Aminu2012Nonlinear], location analysis [\cite=Cuninghamegreen1991Minimax] [\cite=Zimmermann1992Optimization] [\cite=Cuninghamegreen1994Minimax] [\cite=Krivulin2011Anextremal] [\cite=Krivulin2012Anew], transportation networks [\cite=Zimmermann1981Linear] [\cite=Zimmermann2006Interval], discrete event dynamic systems [\cite=Gaubert1995Resource] [\cite=Deschutter1996Maxalgebraic] [\cite=Deschutter2001Model] [\cite=Krivulin2005Evaluation] and decision making [\cite=Elsner2004Maxalgebra] [\cite=Elsner2010Maxalgebra] [\cite=Gursoy2013Theanalytic].

In this section, we offer a short overview of known tropical optimization problems and briefly discuss existing solution methods. The problems are to minimize or maximize linear and nonlinear functions defined on vectors in a finite-dimensional semimodule over an idempotent semifield, subject to constraints in the form of linear equations and inequalities. The overview covers the problems with those nonlinear objective functions which are, or can be, represented by means of multiplicative conjugate transposition of vectors. As our review of the literature shows, many problems, which are relevant to tropical optimization, have objective functions that admit this form. Note that these problems are usually considered in a different setting; they are formulated and solved either in the framework of ordinary mathematics [\cite=Zimmermann1984Onmaxseparable] [\cite=Zimmermann1984Some] [\cite=Zimmermann1992Optimization] [\cite=Zimmermann2003Disjunctive] [\cite=Zimmermann2006Interval], or in both terms of dual semifields such as [formula] and [formula] in [\cite=Cuninghamegreen1976Projections] [\cite=Cuninghamegreen1979Minimax] [\cite=Butkovic2009Onsome] [\cite=Tam2010Optimizing].

To represent the problems below, we use the boldface capital letters [formula], [formula], and [formula] for known matrices, the boldface lower-case letters [formula], [formula], [formula], and [formula] for known vectors, lower-case letters r and s for scalars. The symbol [formula] stands for the unknown vector. The matrix and vector operations are meant to be performed in terms of an idempotent semifield. The minus sign in the superscript indicates multiplicative conjugate transposition. The relation symbols and problem objectives are in the sense of the order induced by idempotent addition.

Specifically, for the real semifield [formula], matrix addition and multiplication as well as scalar multiplication follow the standard entry-wise formulae, where the operations max  and +   play the respective roles of ordinary addition and multiplication. Multiplicative conjugate transposition of a matrix implies the replacement of each nonzero element of the matrix by its inverse, which coincides with its opposite in the conventional arithmetic, and transposition.

Problems with Linear Objective Functions

One of the early problems in tropical optimization was a formal analogue of linear programming problems, which can be written in the form

Exact solutions to the problem have been obtained under various assumptions about the idempotent semiring, which provides the solution context. Specifically, Hoffman [\cite=Hoffman1963Onabstract] considered a rather general idempotent semiring and proposed a solution, which is based on an abstract extension of the duality principle in linear programming. Another general solution was derived by U. Zimmermann [\cite=Zimmermann1981Linear] by means of a residual-based solution technique. The common approach suggested in [\cite=Hoffman1963Onabstract] was further developed by Superville [\cite=Superville1978Various] to handle the problem in the context of the semifield [formula]. The problem was also examined by Gavalec and K. Zimmermann [\cite=Gavalec2012Duality] within the framework of max-separable functions to obtain solutions for the semifields [formula] and [formula].

Furthermore, K. Zimmermann [\cite=Zimmermann1984Onmaxseparable] [\cite=Zimmermann1984Some] [\cite=Zimmermann1992Optimization] [\cite=Zimmermann2003Disjunctive] [\cite=Zimmermann2006Interval] applied the results of the theory of max-separable functions to solve a problem with more constraints, which takes the form

An exact solution to this problem under general conditions has been obtained, which was, however, given in ordinary terms rather than in terms of tropical mathematics.

Butkovi [\cite=Butkovic1984Onproperties], Butkovi and Aminu [\cite=Butkovic2009Introduction] [\cite=Aminu2012Nonlinear] studied a problem that has a two-sided equality constraint (with the unknown vector on both the left and right sides) in the form

A pseudo-polynomial algorithm, which produces a solution if it exists or indicates that the problem has no solution, has been proposed in [\cite=Butkovic2009Introduction]. The algorithm uses an alternating method developed in [\cite=Cuninghamegreen2003Theequation] to replace the two-sided equation by two opposite inequalities and then alternately solve them to achieve more and more accurate estimates for a solution to the equation. Another heuristic approach, which combines a search scheme to find approximate solutions with iterative procedures to solve low-dimensional problems, were suggested in [\cite=Aminu2012Nonlinear].

Problems with Nonlinear Objective Functions

Multidimensional tropical optimization problems with nonlinear objective functions given by transposition and multiplicative conjugation of vectors form a rich class of various problems, which arise in many applications. We divide these problems into a few groups according to the form of objective functions and the principal interpretation of the problems.

Chebyshev Approximation

Among the first optimization problems with nonlinear objective functions was that in the form

This problem was examined by Cuninghame-Green [\cite=Cuninghamegreen1976Projections] in the context of approximation in the semifield [formula] with the Chebyshev metric. The problem is formulated to find a vector [formula] that provides the best underestimating approximation to a vector [formula] by means of vectors [formula]. A direct solution has been obtained based on the theory of linear operators on vectors over the semifield [formula]. A similar solution was proposed by U. Zimmermann [\cite=Zimmermann1981Linear].

An unconstrained approximation problem in terms of a general idempotent semifield was considered by Krivulin [\cite=Krivulin2009Methods] in the form

[formula]

An exact solution to the problem involves the derivation of a sharp lower bound for the objective function. The form of this bound is exploited to construct a vector at which the objective function attains the bound. The results obtained are then applied to solve the equation [formula] in a closed vector form. As a consequence, direct solutions are given for the following problems of underestimating and overestimating approximation:

There are optimization problems that were originally formulated in a different framework, but can be readily represented in terms of tropical mathematics. Specifically, a constrained problem of Chebyshev approximation in the semifield [formula] was examined and solved in the ordinary setting with a polynomial-time threshold-type algorithm in [\cite=Zimmermann1984Some]. This problem can be written as a tropical optimization problem in the form

[formula]

Problems with Span Seminorm

The problems that were analyzed by Butkovi and Tam [\cite=Butkovic2009Onsome] [\cite=Tam2010Optimizing] in the context of the semifield [formula], have the objective function in the form of the span seminorm, which is defined as the maximum deviation between the elements of a vector. To solve the problems, a technique was applied based on a combined formalism of both dual semifields [formula] and [formula]. A representation of the problems in terms of the semifield [formula] alone is as follows

[formula]

where [formula] is a vector of ones in the sense of [formula].

A Problem of "Linear-Fractional" Programming

A constrained minimization problem, which has a two-sided inequality constraint and is formulated in the semifield [formula] in the form was investigated by Gaubert, Katz and Sergeev [\cite=Gaubert2012Tropical] under the name of the tropical linear-fractional programming problem. The problem was solved using an iterative computational scheme that exploits the relationship established by Akian, Gaubert and Guterman [\cite=Akian2012Tropical] between solutions of two-sided vector equations in the sense of [formula] and mean payoff games.

Extremal Property of Spectral Radius

The problem examined by Cuninghame-Green [\cite=Cuninghamegreen1962Describing] to minimize a function defined on vectors over the semifield [formula] was apparently the first optimization problem appeared in the context of tropical mathematics. With the use of multiplicative conjugate transposition, the problem is given by

[formula]

As one of the main results in [\cite=Cuninghamegreen1962Describing], it has been shown that the minimum value in the problem is equal to the spectral radius λ of the matrix [formula] and this value is attained at any eigenvector that satisfies the equality [formula]. Moreover, explicit expressions have been derived to calculate the spectral radius and an eigenvector in terms of standard arithmetic operations. Similar results were obtained by Engel and Schneider [\cite=Engel1975Diagonal] and by Superville [\cite=Superville1978Various].

Cuninghame-Green [\cite=Cuninghamegreen1979Minimax] extended the above results and described them in general terms of tropical mathematics. To find all vectors that yield the minimum in the problem, a computational approach was proposed, which consisted of solving a linear programming problem. Analogues solutions, which are represented in a compact vector form using multiplicative conjugate transposition, were derived by Krivulin [\cite=Krivulin2005Evaluation] [\cite=Krivulin2006Eigenvalues] [\cite=Krivulin2009Methods].

Finally, Elsner and van den Driessche [\cite=Elsner2004Maxalgebra] [\cite=Elsner2010Maxalgebra] have observed that not only the eigenvectors solve the problem, but all vectors [formula] satisfying the inequality [formula] do that as well. An iterative computational procedure was suggested to find solutions to the inequality.

Recent Results

In this section, we consider several new problems, which are formulated and solved in [\cite=Krivulin2013Amultidimensional] [\cite=Krivulin2013Amaximization] [\cite=Krivulin2013Direct] [\cite=Krivulin2013Explicit] [\cite=Krivulin2013Extremal] [\cite=Krivulin2014Aconstrained] [\cite=Krivulin2014Complete] in terms of a general algebraically complete linearly ordered idempotent semifield. We offer direct, exact solutions which are represented in a compact vector form. For many problems, the results obtained provide complete solutions.

Chebyshev-Like Approximation Problems

We start with constrained optimization problems that have nonlinear objective functions of the form similar to that in approximation problems [\eqref=P-AxppAx] and [\eqref=P-AxppAxgxh]. Applications of these problems include single facility minimax location problems in multidimensional spaces with Chebyshev distance under constraints in the form of linear equations and inequalities (see, e. g., [\cite=Krivulin2012Anew] [\cite=Krivulin2013Direct] [\cite=Krivulin2014Complete]).

To solve the next two problems with simple boundary constraints, we apply an approach which was developed in [\cite=Krivulin2005Evaluation] [\cite=Krivulin2006Eigenvalues] [\cite=Krivulin2009Methods]. The solution is based on the derivation of a sharp lower bound on the objective function and the use of this bound to obtain all vectors that provide the bound.

First, we consider the following problem: given vectors [formula], find regular vectors [formula] that

[formula]

Let [formula] and [formula] be regular vectors, [formula] and [formula] be vectors such that [formula]. Then, the minimum value in problem [\eqref=P-qxxpgxh] is equal to and all regular solutions are given by the condition

Suppose that, given a matrix [formula] and vectors [formula], [formula], the problem is to find regular vectors [formula] that

[formula]

Let [formula] be a regular matrix, [formula] and [formula] be regular vectors. Then, the minimum value in problem [\eqref=P-qAxAxpxg] is equal to

[formula]

and is attained at

We now consider another problem with conditions that include a linear inequality defined by a matrix. Given vectors [formula] and a matrix [formula], find regular vectors [formula] that solve the problem

[formula]

The solution of the problem follows an approach that is based on the general solution to linear inequalities proposed in [\cite=Krivulin2006Solution] [\cite=Krivulin2009Methods] and further refined in [\cite=Krivulin2013Amultidimensional]. We introduce an auxiliary parameter to represent the minimum value of the objective function. The problem is then reduced to the solving of a linear inequality with a matrix that depends on the parameter. We use the existence condition for solutions of the inequality to evaluate the parameter, and take all solutions to the inequality as a complete solution to the initial problem.

Let [formula] be a matrix such that [formula], [formula] be a nonzero vector, [formula] and [formula] regular vectors, and [formula] a vector such that [formula]. Then, the minimum value in problem [\eqref=P-xpqxBxxgxh] is equal to and all solutions are given by

As a consequence, we obtain a complete solution to a problem that was partially solved in [\cite=Krivulin2012Anew]. Consider a variant of problem [\eqref=P-xpqxBxxgxh] in the form

[formula]

Let [formula] be a matrix such that [formula], [formula] be a nonzero vector, and [formula] a regular vector.

Then, the minimum in [\eqref=P-xpqxBxx] is equal to and all solutions are given by

Problems with Span Seminorm

Optimization problems, where the objective function is given by the span seminorm, arose in the context of job scheduling [\cite=Butkovic2009Onsome] [\cite=Tam2010Optimizing]. Minimization of the span seminorm solves scheduling problems in the just-in-time manufacturing. Maximization problems appear when the optimal schedule aims to spread the initiation or completion time of the jobs over the maximum possible time interval.

A solution to problems without constraints is based on the evaluation of lower or upper bounds for the objective function. If a problem has linear equation or inequality constraints, we first obtain a general solution to the equation or inequality, and then substitute it into the objective function to reduce to an unconstrained problem with a known solution.

Minimization Problems

Consider an unconstrained problem that is an extended version of minimization problem at [\eqref=P-minmax1AxAx1]. Given matrices [formula] and vectors [formula], the problem is to find regular vectors [formula] that

[formula]

Let [formula] be a row-regular matrix, [formula] a column-regular matrix, [formula] be a nonzero vector, and [formula] a regular vector.

Then, the minimum value in problem [\eqref=P-minqBxAxp] is equal to and is attained at

We now examine some special cases of problem [\eqref=P-minqBxAxp]. First, assume that [formula] and [formula], and consider the problem

A direct application of Theorem [\ref=T-minqBxAxp] shows that the problem has the minimum [formula], which is attained at any vector [formula] for all [formula].

Under the assumptions that [formula] and [formula], we arrive at problem [\eqref=P-minmax1AxAx1]. Application of theorem [\ref=T-minqBxAxp] provides a new solution to this problem in a compact vector form.

Let [formula] be a regular matrix. Then, the minimum in [\eqref=P-minmax1AxAx1] is equal to and is attained at

Furthermore, we consider the following constrained problem: given matrices [formula], find regular vectors [formula] that

[formula]

Let [formula] be a regular matrix and [formula] be a matrix such that [formula]. Then, the minimum value in problem [\eqref=P-1yy1CxyDxxI] is equal to

[formula]

and is attained at

[formula]

Maximization Problems

We start with the unconstrained problem: given matrices [formula], [formula], and vectors [formula], [formula], find regular vectors [formula] that

[formula]

A complete solution to [\eqref=P-maxqBxAxp] under fairly general conditions is as follows.

Let [formula] be a matrix with regular columns, [formula] a column-regular matrix, [formula] and [formula] be regular vectors.

Then, the minimum value in problem [\eqref=P-maxqBxAxp] is equal to and any solution [formula] has components that are given by where [formula], and the indices k and s are defined by the conditions

[formula]

Now assume that [formula]. Then, we can write

[formula]

Under this assumption, problem [\eqref=P-maxqBxAxp] takes the form

[formula]

By applying Theorem [\ref=T-maxqBxAxp], we obtain the following result.

Let [formula] be a matrix with regular columns and [formula] be a column-regular matrix. Then, the minimum in [\eqref=P-max1BxAx1] is equal to and any solution [formula] has components that are given by where [formula], and the indices k and s are defined by the conditions

[formula]

We now turn to the solution of a constrained problem: given a matrix [formula], we have to solve the problem

[formula]

By Theorem [\eqref=T-Axbx], the inequality constraint has regular solutions if and only if [formula]. Under this condition, all solutions to the inequality are given by [formula], where [formula] is any regular vector. Substitution of the solutions into the objective function reduces problem [\eqref=P-maxqBxAxpCxlex] to the unconstrained problem

This problem has the form of [\eqref=P-maxqBxAxp], and thus is solved by Theorem [\ref=T-maxqBxAxp].

Problems with Evaluation of Spectral Radius

We return to problem [\eqref=P-minxAx] with the minimum value given by the spectral radius. All solutions to this problem are obtained in a closed form in [\cite=Krivulin2013Amultidimensional] as a consequence of the solution to a more general optimization problem. A direct complete solution to problem [\eqref=P-minxAx] is derived in [\cite=Krivulin2013Extremal] in the following form.

Let [formula] be a matrix with spectral radius [formula]. Then, the minimum in [\eqref=P-minxAx] is equal to λ, and all solutions are given by

[formula]

The proof of the statement involves the derivation of a sharp lower bound on the objective function. An equation is written as an equality between the function and the bound to specify all solutions of the problem. We reduce the equation to an inequality and then take all solutions of the inequality as a complete solution of the optimization problem.

Further extensions of problem [\eqref=P-minxAx] with more general form of the objective function and the constraints are examined in [\cite=Krivulin2012Acomplete] [\cite=Krivulin2014Aconstrained]. Below, we offer complete, direct solutions to certain new problems that extend [\eqref=P-minxAx].

An Unconstrained Problem

Given a matrix [formula], vectors [formula], and a scalar [formula], consider the problem of finding regular vectors [formula] that

[formula]

The problem is completely solved by the following result.

Let [formula] be a matrix with spectral radius [formula], [formula] be a regular vector. Then, the minimum value in problem [\eqref=P-xAxxpqxc] is equal to and all solutions are given by

Problems with Constraints

Let us suppose that, given matrices [formula], [formula], and vectors [formula], [formula], we need to find regular vectors [formula] that

[formula]

Let [formula] be a matrix with spectral radius [formula] and [formula] a matrix such that [formula]. Suppose that [formula] is a column-regular matrix and [formula] is a regular vector such that [formula].

Then, the minimum value in problem [\eqref=P-xAxBxgxCxh] is equal to and all solutions are given by

Consider a special case with [formula]. Problem [\eqref=P-xAxBxgxCxh] takes the form

[formula]

Let [formula] be a matrix with spectral radius [formula], and [formula] a matrix such that [formula].

Then, the minimum value in problem [\eqref=P-xAxBxgx] is equal to

[formula]

and all solutions are given by

[formula]

Under the conditions [formula] and [formula] problem [\eqref=P-xAxBxgxCxh] becomes

[formula]

Let [formula] be a matrix with spectral radius [formula], and [formula] a regular vector such that [formula].

Then, the minimum in [\eqref=P-xAxgxh] is equal to

[formula]

and all solutions are given by

[formula]

The next problem combines a special case of the objective function in problem [\eqref=P-xAxxpqxc] with the constraints in problem [\eqref=P-xAxBxgx]. Given matrices [formula] and vectors [formula], the problem is to find regular vectors [formula] that

[formula]

Let [formula] be a matrix with spectral radius [formula], and [formula] a matrix such that [formula].

Then, the minimum value in problem [\eqref=P-xAxxpBxgx] is equal to and all solutions are given by

[formula]

Another extended problem that has an objective function like that in [\eqref=P-xAxxpqxc] and boundary constraints as in [\eqref=P-xAxgxh] is examined in the next section.

New Constrained Optimization Problem

This section includes a direct, complete solution to a new constrained optimization problem. We follow the approach developed in [\cite=Krivulin2013Amultidimensional] [\cite=Krivulin2014Complete] [\cite=Krivulin2014Aconstrained] to introduce an additional variable, which represents the minimum value of the objective function, and then to reduce the problem to the solving of an inequality, where the new variable plays the role of a parameter.

Now suppose that, given a matrix [formula], vectors [formula], and a scalar [formula], we need to find regular vectors [formula] that provide solutions to the problem

[formula]

Let [formula] be a matrix with spectral radius [formula], [formula] and [formula] be regular vectors, and [formula] a vector such that [formula].

Then, the minimum value in problem [\eqref=P-xAxxpqxr-gxh] is equal to

[formula]

and all solutions are given by

[formula]

where [formula] is a vector such that

[formula]

Denote the minimum value of the objective function over all regular vectors [formula] by μ. Then, all regular solutions to problem [\eqref=P-xAxxpqxr-gxh] are given by the system

[formula]

Since μ is assumed to be the minimum, the set of solutions remains unchanged after replacing the first equation by the inequality

[formula]

The first inequality at [\eqref=I-xAxxpqxrmu-gxh] is equivalent to the system of inequalities

[formula]

Note that by Lemma [\ref=L-minxAx], we can write [formula]. Furthermore, after multiplication of the corresponding sides of the second and third inequalities and application of properties of conjugate transposition, we have [formula], and thus [formula]. Together with the forth inequality, we obtain a lower bound for μ in the form

[formula]

Furthermore, applications of Lemma [\ref=I-Axd] to the first three inequalities and multiplication by μ- 1 of the first two give

[formula]

Finally, we combine the first two inequalities with the left boundary constraint [formula] and then the third inequality with the right boundary [formula] to rewrite the system at [\eqref=I-xAxxpqxrmu-gxh] as the double inequality

[formula]

To apply Theorem [\ref=T-Axbx] to the left inequality at [\eqref=I-muAxmupgx-xmuqh], we need to verify that [formula]. Indeed, since μ  ≥  λ, we have

[formula]

It follows from Theorem [\ref=T-Axbx] that the left inequality has regular solutions all given by

[formula]

where [formula] is a regular vector that satisfies the boundary condition

[formula]

Substitution of the solution into the right inequality leads to the inequality

[formula]

which is completely solved with respect to [formula] by Lemma [\ref=I-Axd] in the form

[formula]

By coupling both left and right boundary conditions, we write the double inequality

[formula]

The inequality determines a nonempty set provided the condition

[formula]

Considering properties of conjugate transposition of vectors, it is easy to verify that this inequality is equivalent to that in the form

[formula]

By simple algebra, we reduce the last inequality to the system of inequalities

[formula]

These inequalities can further be rewritten as

[formula]

Considering that [formula] by the conditions of the theorem, the last inequalities are equivalent to the system

[formula]

which can be solved with respect to μ in the form

[formula]

Furthermore, we combine these solution into one inequality

[formula]

By adding the bound at [\eqref=I-mulambdaqpr], we obtain

[formula]

To provide the minimum value of μ, the last inequality must hold as an equality, which completes the proof.