Asymptotic Behavior of the Principal Eigenvalue for a Class of Non-Local Elliptic Operators Related to Brownian Motion with Spatially Dependent Random Jumps

Introduction and Statement of Results

Let D  ⊂  Rd be a bounded domain with C2,α-boundary (α∈(0,1]) and let P(D) denote the space of probability measures on D. Fix a measure μ∈P(D), and consider a Markov process X(t) in D which performs Brownian motion and is killed at the boundary, and which while alive, jumps instantaneously according to a spatially dependent exponential clock with intensity γV to a new point, according to the distribution μ. That is, the probability that the process X(  ·  ) has not jumped by time t, is given by [formula]. From its new position after the jump, the process repeats the above behavior independently of what has transpired previously. Let τD denote the lifetime of the process. We assume that V∈Cα() and that V > 0 in [formula], and we normalize it by

[formula]

We will think of V as being fixed and of γ > 0 and μ as parameters that may be varied. Denote probabilities and expectations for the process starting from x∈D by Pγ,μx and Eγ,μx.

Define the contraction semigroup where C0() is the space of continuous functions on [formula] vanishing on ∂D. The infinitesimal generator of this semigroup is an extension of the operator - Lγ,μ, defined on [formula] by with the Dirichlet boundary condition, where Cμ is the "μ-centering" operator defined by The operator Tγ,μt is compact. These facts were proven in [\cite=P09] in the case of constant V, and can be proved similarly for variable V as defined above. Since Tγ,μt is compact, the resolvent operator for Tγ,μt is also compact, and consequently the spectrum σ(Lγ,μ) of Lγ,μ consists exclusively of eigenvalues. By the Krein-Rutman theorem, one deduces that Lγ,μ possesses a principal eigenvalue, λ0(γ,μ); that is, λ0(γ,μ) is real and simple and satisfies [formula] [\cite=P95]. It is known that λ∈σ(Lγ,μ) if and only if exp ( - λt)∈σ(Tγ,μt) [\cite=Pazy83]. Thus, since ||Tγ,μt|| < 1, it follows that λ0(γ,μ) > 0. We have

[formula]

thus, a standard result [\cite=RS72] allows us to conclude that

[formula]

It is well known that this is equivalent to

[formula]

The Brownian motion with random jumps analyzed here is a paradigm for a phenomenon that occurs in various settings and which is best illustrated perhaps in terms of computer-games or the game "chutes and ladders." The object of the game is to reach the boundary of D in as little time as possible (or alternatively, to avoid reaching the boundary for as much time as possible). The game is played in rounds; however, time is always accumulating. Various obstacles (modelled by the spatially dependent exponential clock with intensity γ) lead to the end of a round, and each new round begins afresh from a new position which may be deterministic or random (modelled by the measure μ). Then λ0(γ,μ) is a measure of the probability of long-term failure (or success, depending on the rules). As γ increases, the obstacles become more dense.

In [\cite=P09], the behavior of λ0(γ,μ) was analyzed for the regimes [formula] and [formula] in the case of constant V. In this paper we consider the regime [formula]. Note that probabilistic intuition suggests the general direction of the result. Since [formula], the Brownian motion doesn't get very far before it jumps and gets redistributed according to μ. In particular then, if supp(μ)  ⊂  D, it will be very difficult for the Brownian motion to exit D, and in light of [\eqref=largetime] one expects that lim γ  →    ∞λ0(γ,μ) = 0. More generally, one expects that the leading order asymptotic behavior for large γ will depend only on the behavior of μ arbitrarily close to the boundary. For the case of constant V, in [\cite=P09] it was shown that if μ is compactly supported in D, then there are constants c1,c2 such that [formula], for large γ. Under the assumption that the measure μ possesses an appropriately smooth density in a neighborhood of the boundary, which we will also call μ, it was proven in [\cite=P09] that

[formula]

Assuming appropriate smoothness of the above density μ, it was also proven there that if [formula] on ∂D, then

[formula]

while if [formula] on ∂D, then

[formula]

The above results show that in the case of constant V, λ0(γ,μ) grows on the order [formula] if the density μ of the jump measure does not vanish identically on ∂D, while for k = 1 or 2, if all the derivatives of μ up to order k - 1 vanish identically on the boundary, and at least one of the derivatives of order k does not vanish identically on ∂D, then λ0(γ,μ) behaves asymptotically on the order [formula]. It is natural to expect that such behavior would continue for all positive integers k.

The case of variable V is not at all a straight forward generalization of the constant case. To see why, consider first of all what occurs if V is allowed to be identically 0 in some sub-domain A  ⊂  D. Then as long as the process remains in A, it never jumps; consequently, starting at x∈A, the probability of not exiting D by time t is greater than the probability of a standard Brownian motion not exiting A by time t. In light of [\eqref=largetime], this means that λ0(γ,μ)  ≤  λA0, where λA0 is the principal eigenvalue for [formula] in A with the Dirichlet boundary condition. In particular, λ0(γ,μ) is bounded and the behavior in [\eqref=P1] cannot occur. Now consider the case that V is positive in D but decreases to 0 at ∂D. If this occurs at an appropriate rate, it should increase the tendency of the process to leave the region, and thus raise the value of λ0(γ,μ). Indeed, in order for the process to exit the region, when the process is very near the boundary it needs to refrain from jumping. Thus, in the case of variable V, the dependence on V of the corresponding constant on the right hand side of [\eqref=P1] should be consistent with the above discussion.

In this paper, for variable, strictly positive V, we prove the analog of [\eqref=P1] and the analog of a generalization of [\eqref=P2], [\eqref=P3] for the case that for some positive integer k, all the derivatives of μ up to order k - 1 vanish identically on ∂D.

Let D  ⊂  Rd, [formula], be a bounded domain with a C2,α-boundary (α∈(0,1]) and let μ∈P(D). Assume that V > 0 on [formula]. Let σ denote Lebesgue measure on ∂D. Let [formula].

i. Assume that for some ε > 0, the restriction of μ to Dε possesses a density which belongs to C1(ε): [formula]. Assume also that V∈C2,α(). Then

[formula]

ii. Let [formula]. Assume that for some ε > 0, the restriction of μ to Dε possesses a density which belongs to Ck + 1(ε): [formula]. Assume also that V∈Ck + 1() if k is odd and that V∈Ck + 1,α() if k is even. Assume that

[formula]

Let n denote the inward unit normal to D at ∂D. If k is odd, then

[formula]

If k is even, then

[formula]

Remark. As V decreases to 0 on some sub-domain A  ⊂    ⊂  D (and increases elsewhere in order to maintain the normalization [formula]), assuming that supp[formula], the constant on the right hand side of [\eqref=1] converges to 0, which is consistent with the discussion in the penultimate paragraph before Theorem [\ref=th]. (If on the other hand [formula] supp[formula], then as V decreases to 0 on A, the constant on the right hand side of [\eqref=1] remains bounded away from 0. This is not inconsistent with the above-mentioned discussion; it shows that the asymptotic behavior as γ  →    ∞   is not uniform over V.)

Assuming that [formula] on ∂D, if V is of the form ε + (1 - ε|D|)V̂, where V̂ is a smooth function which is strictly positive in D and vanishes on ∂D, then as [formula], the right hand side of [\eqref=1] converges to ∞  . This is consistent with the discussion in the penultimate paragraph before Theorem [\ref=1]. It also suggests that for a smooth V which is strictly positive in D and vanishes on ∂D, λ0(γ,μ) will grow on a larger order than [formula]. However, we cannot prove this, and it seems conceivable to us that in fact the order of growth is smaller than [formula]--see section 4.

We will also prove the following result in the case that μ is compactly supported.

Let μ be compactly supported in D. Then there exist constants c1,c2 such that

[formula]

In section 2 we present some preliminary results needed for the proof of Theorem [\ref=th], and we conclude that section with the proof of Proposition [\ref=decay]. Theorem [\ref=th] is proved in section 3. In section 4 we discuss an open problem concerning the behavior of λ0(γ,μ) in the case that V is positive in D but vanishes on the boundary.

Preliminary Results and Proof of Proposition [\ref=decay]

In this section we prove a number of preliminary results, culminating in the proof of Proposition [\ref=decay]. Let Px and Ex denote respectively probabilities and expectations for Brownian motion starting from x.

Let uλ,γ and vλ,γ denote the solutions to the equations

[formula]

[formula]

The principal eigenvalue λ0(γ,μ) is the smallest positive solution λ to the equation

[formula]

In particular

[formula]

Let wγ denote the eigenfunction corresponding to the principal eigenvalue of Lγ,μ, normalized by [formula]. Then wγ satisfies

From the Feynman-Kac formula, one has and then the normalization condition gives

[formula]

Integrating by parts gives Substituting this in [\eqref=int], we obtain

[formula]

By the Feynman-Kac formula again, we have that

[formula]

and

[formula]

Thus, by [\eqref=eq], λ0(γ,μ) is a positive solution to [\eqref=lambda].

Conversely, working backwards, if λ is a solution to [\eqref=lambda] (or equivalently, of [\eqref=eq] with λ0(γ,μ) replaced by λ), then it is an eigenvalue.

The following lemma plays a crucial role in both the proof of Proposition 1 and the proof of Theorem 1.

The principal eigenvalue satisfies

[formula]

Using [\eqref=int] we have or equivalently from ([\ref=vs]) Multiplying above by λ0(γ,μ), ([\ref=lambda2]) gives

[formula]

Let p be an accumulation point of [formula] as γ  →    ∞  . We note that if p =   ∞  , then for certain large γ we would have [formula], where λD0 is the principal eigenvalue for the operator [formula] in D with the Dirichlet boundary condition. Using the representation in ([\ref=us]) and [\cite=P95], this would give [formula], contradicting ([\ref=uineq]).

Now assume that 0 < p <   ∞  . Let {γn} be such that [formula]. As was shown in Lemma 1, λ0(γ,μ) is the smallest positive solution of the equation

[formula]

Both sides of [\eqref=lambdaintermsofE] are continuous in λ, and since the left hand side is zero at λ = 0 and the right hand side is positive at λ = 0, it follows that for λ  <  λ0(γ,μ) the left hand side is smaller the the right hand side. Fix q∈(0, min (p, min V)). Since qγn  ≤  λ0(γn) for sufficiently large n, we have

Or equivalently,

[formula]

Letting n  →    ∞  , the right hand side of ([\ref=contradiction]) goes to zero by the bounded convergence theorem, and this is a contradiction. We have now shown that there are no accumulation points p∈(0,  ∞  ], which proves [\eqref=lim].

We now prove Proposition [\ref=decay].

Proof of Proposition [\ref=decay]. Define By Lemma 1, λ0(γ,μ) is the smallest positive solution to the equation Hγ(λ) = λ. We now show that the smallest positive solution to Hγ(λ) = λ satisfies the upper bound in Proposition [\ref=decay]. Let H+γ(λ) satisfy and let λ+(γ) be the smallest positive solution to H+γ(λ) = λ. If we define then from the definition of Hγ(λ), one has Gγ(0) > 0 and Since λ0(γ,μ) is the first positive zero of Gγ, it follows that λ0(γ,μ)  ≤  λ+(γ). Thus, it suffices to show that λ+(γ) (with an appropriate choice of H+γ). satisfies the upper bound in Proposition [\ref=decay]. Note for use below that the above argument does not even require that H+γ be continuous or monotone, just that there be a smallest positive root to the equation H+γ(λ) = λ.

To find an appropriate H+γ, we write By the bounded convergence theorem, [formula], for [formula] and γ sufficiently large. Also, since μ is compactly supported, there exists a c0 > 0 such that [formula], for [formula] and γ sufficiently large (see [\cite=P09]). Thus, there exists a c1 > 0 such that [formula], for [formula] and γ sufficiently large. For sufficiently large γ, we now define [formula], for [formula], and H+γ(λ) = Hγ(λ), for λ > 1. Then the smallest positive to the equation H+(λ) = λ is [formula]. This gives the upper bound in the proposition.

The lower bound is proved similarly using a function H- satisfying H-  ≤  H. At the point where [\cite=P09] was used above, one uses instead [\cite=P09]. We leave the details to the reader. [formula]

Proof of Theorem [\ref=th]

We will use [\eqref=lambda2] to evaluate the asymptotic behavior of λ0(γ,μ). The behavior of the denominator in [\eqref=lambda2] is easy.

For all μ∈P(D),

[formula]

Thus,

[formula]

For notational convenience we write [formula]. Define [formula], wγ  =  vγ - zγ and [formula]. Then using [\eqref=ve], wγ solves the equation From the Feynman-Kac formula, one has

[formula]

By Lemma [\ref=sublin], γyγ and [formula] are bounded as γ  →    ∞  , and [formula], for large γ. Thus, for some C > 0, we have Thus, lim γ  →    ∞|γwγ(x)| = 0, which along with Lemma [\ref=sublin] gives [\eqref=ptwise].

We now turn to the analysis of the numerator in [\eqref=lambda2]. We will need the following key result, essentially from [\cite=P09].

Let x0∈∂D and let n denote the inward unit normal to D at ∂D. Then

The result was proved in [\cite=P09] for the case that V = 1. From the scaling, it follows that the result continues to hold for V equal to any constant. The method of proof in [\cite=P09] used localization; only the behavior near x0 of the coefficients of the differential equation solved by uλ0(γ,γ),γ are relevant. In addition, by the maximum principle, the solutions uλ,γ,ε to [\eqref=ue] with V(x) replaced by the V - ε are pointwise monotone increasing in ε∈R, and for γ sufficiently large so that λ  -  γV(x) is everywhere non-positive, they are also bounded above by 1. Thus, [formula] is monotone decreasing in ε∈R. From these facts one deduces the lemma.

By assumption, the measure μ can be written as [formula], where μcs is a compactly supported sub-probability measure and [formula] is a sub-probability measure possessing a density which satisfies the smoothness conditions in the statement of the theorem, and which we will also denote by [formula]. Note that [formula] restricted to Dε coincides with the density μ(x) appearing in the statement of the theorem. We write [\eqref=lambda2] as

[formula]

Using [\eqref=us] and Lemma [\ref=sublin] for the first inequality below, and [\cite=P09] and the fact that [formula] is compactly supported for the second one, one has for some c > 0 and large γ,

[formula]

From [\eqref=hittingtime] and Lemma [\ref=vasym], there exists a C > 0 such that for large γ,

[formula]

In the statement of the theorem, note that [\eqref=1] is in fact the same as [\eqref=even] with k = 0. (We simply separated this case out for the sake of exposition.) Thus to prove the theorem, we must show that [\eqref=even] holds for even [formula] and that [\eqref=odd] holds for odd [formula]. In light of [\eqref=mureg], [\eqref=negl] and Lemma [\ref=vasym], the theorem will be proved if we show that

[formula]

and that

[formula]

Although we could give a steam-lined proof that works simultaneously for all even k and another one that works for all odd k, we prefer the following route, in the interest of clarity of exposition. We will first show [\eqref=finalodd] for k = 1 and [\eqref=finaleven] for k = 0. Then we will show how to iterate the method for k = 1 to obtain [\eqref=finalodd] for k = 3 and will note how to continue for general odd k. Then we will show how to iterate the method for k = 0 to obtain [\eqref=finaleven] for k = 2 and will note how to continue for general even k.

We begin with k = 1, which is easier than k = 0. Recalling that n denotes the unit inward normal, and using [\eqref=ue] and the fact that [formula] vanishes on ∂D, integration by parts gives

[formula]

By Lemma [\ref=sublin], as γ  →    ∞  , [formula] converges boundedly pointwise to [formula]. By [\eqref=hittingtime], uλ0(γ,μ),γ converges boundedly pointwise to 0 in D. Also, [formula] converges boundedly pointwise to [formula] on ∂D. Since [formula] vanishes on ∂D, one has [formula] on ∂D. Using these facts and letting γ  →    ∞   in [\eqref=k=1] gives [\eqref=finalodd] for k = 1.

We now turn to the case k = 0. For large γ, let wγ solve the equation

[formula]

We will show below that

[formula]

Thus, it is enough to show [\eqref=finaleven] for k = 0 with [formula] replaced by wγ. Using [\eqref=ue] and [\eqref=aux], and integrating by parts, we have

[formula]

where we have used the fact that

[formula]

Letting γ  →    ∞   in [\eqref=k=0] and using Lemma [\ref=key] and Lemma [\ref=sublin], we obtain

[formula]

which is [\eqref=finaleven] for k = 0 with [formula] replaced by wγ.

To complete the proof of the case k = 0, we now prove [\eqref=diff]. For ε > 0, we have

[formula]

Note that by Lemma [\ref=sublin], [formula] solves ΔVw = 0 in D and [formula] on ∂D. From standard results, it then follows that

[formula]

In the case that, say, [formula] on ∂D, it follows from the maximum principle that wγ is strictly positive in [formula], uniformly over large γ. By the maximum principle and Lemma [\ref=sublin], uλ0(γ,μ),γ is decreasing in γ, for large γ. Using these facts with [\eqref=k=00], it follows that for all choices of μ, one has that [formula] is bounded as γ  →    ∞  . Using this with [\eqref=diffbound], it follows from [\eqref=diffeps] that

[formula]

By [\eqref=hittingtime] and the uniform boundedness in γ of wγ, it follows that

[formula]

Now [\eqref=diff] follows from [\eqref=finaldiff] and [\eqref=inside].

We now consider the cases k = 2 and k = 3, beginning with k = 3. In the case k = 3, μ and all its derivatives up to order 2 vanish on ∂D; in particular, the last term on the right hand side of [\eqref=k=1] is 0. Thus, using [\eqref=ue] again, integrating by parts and using the fact that the second order derivatives of μ vanish on ∂D, we have from [\eqref=k=1]

[formula]

By Lemma [\ref=sublin], as γ  →    ∞  , [formula] converges boundedly pointwise to [formula], and by [\eqref=hittingtime], uλ0(γ,μ),γ converges boundedly pointwise to 0. Also, [formula] converges boundedly pointwise on ∂D to [formula]. Since μ and all of its derivatives up to order 2 vanish on ∂D, one has [formula] on ∂D. Thus, letting γ  →    ∞   in [\eqref=k=3] gives [\eqref=finalodd] for k = 3. Note that in [\eqref=k=3] we needed [formula] and V to be 4 times differentiable. When k = 5, the boundary term on the right hand side of [\eqref=k=3] vanishes, and one again uses [\eqref=ue] to replace uλ0(γ,μ),γ in the first term on the right hand side of [\eqref=k=3] by [formula]. This time the calculations requires that [formula] and V be 6 times differentiable. It should be clear how to continue for all odd k.

We now consider the case k = 2. Since μ and its first order derivatives vanish on ∂D, we have from [\eqref=k=1]

[formula]

As with the case k = 0, we define an auxiliary function wγ, which satisfies this time the equation

[formula]

The same argument used to show [\eqref=diff] shows that

[formula]

From [\eqref=3.9] and [\eqref=diffagain] we have

[formula]

Using [\eqref=ue] and [\eqref=auxagain], and integrating by parts, we have

[formula]

where we have used the fact that

[formula]

Note that since μ and its first derivatives vanish on ∂D, one has [formula] on ∂D. Using this and letting γ  →    ∞  , it follows from [\eqref=reduced], [\eqref=final] and Lemma [\ref=key] that

[formula]

which is [\eqref=finaleven] for k = 2. It should be clear how to continue in the same vein for larger even k.

We now explain the smoothness requirement in the case of k = 2, k = 0 and then for higher order k. First consider k = 2. In order to apply the divergence theorem in [\eqref=final] we needed for wγ to be in [formula]. For this, we claim that it suffices to have [formula] and V∈C3,α(). To see this, recall that the standard theory [\cite=GT] guarantees that if L is a second-order elliptic operator, then the equation Lu = f in D and u = φ on ∂D has a solution [formula] if f and the coefficients of L are in Cα(), φ is continuous and ∂D is a C2,α-boundary. Thus, by the above smoothness assumptions on [formula] and wγ, it follows from [\eqref=auxagain] that [formula]. Now formally differentiate [\eqref=auxagain] with respect to xj, and formally, let [formula]. Using the above smoothness of wγ, and again using the above smoothness assumptions on [formula] and V, one has formally that zγ satisfies an equation of the form L1zγ = f in D and zγ  =  φ on ∂D, where f and the coefficients of the operator L1 belong to Cα(), and φ is continuous. Thus, by the general theory, the above equation has a solution [formula]. One then shows that zγ is in fact [formula], which establishes that wγ is in C1().

For k = 0, the auxiliary function wγ solves [\eqref=aux]. By the line of reasoning in the above paragraph, one needs [formula] and V∈C2,α(). For higher order even k, the auxiliary function wγ that one constructs solves the equation

[formula]

where the operator Δγ,V is defined by [formula]. By the reasoning of the previous paragraph, one needs [formula] and V∈Ck + 1,α().

An Open Problem in a Degenerate Case

Consider the case that V is positive in D but vanishes on ∂D. As was noted in the penultimate paragraph before Theorem [\ref=th], if V decays to 0 at the boundary at an appropriate rate, it should increase the tendency of the process to leave the region, and thus raise the value of λ0(γ,μ). Indeed, in order for the process to exit the region, when the process is very near the boundary it needs to refrain from jumping. And as was noted in the second paragraph of the remark after Theorem [\ref=th], assuming that [formula] on ∂D, if V is of the form ε + (1 - ε|D|)V̂, where V̂ is a smooth function which is strictly positive in D and vanishes on ∂D, then as [formula], the right hand side of [\eqref=1] converges to ∞  . These facts suggest that in the case that V is smooth and vanishes on ∂D, and the density μ does not vanish identically on ∂D, then λ0(γ,μ) should grow on an order larger than [formula] as γ  →    ∞  . On the other hand, if V is compactly supported in D - Dε, then by the reasoning in the penultimate paragraph before Theorem [\ref=th], one has λ0(γ,μ)  ≤  λDε0, where λDε0 is the principal eigenvalue for [formula] in Dε with the Dirichlet boundary condition. Thus, it also seems possible that if V decays to 0 at the boundary sufficiently fast, then in fact λ0(γ,μ) should be of smaller order than [formula] as γ  →    ∞  .

To determine what happens, it should suffice to look at the simple one-dimensional case with D = (0,1). We consider V with a first-order 0 at the boundary. To make things simple, we choose V symmetric: V(x) = 6x(1 - x) (we continue with the normalization [formula]). We take μ to be Lebesgue measure. Thus, we have

[formula]

Unfortunately, we are only able to conclude that there exist c1,c2 > 0 such that

[formula]

We obtain [\eqref=weakest] as follows. By the criticality theory of second order elliptic operators [\cite=P95], which can be applied to Lγ,μ as in [\eqref=special], λ0(γ,μ) can be characterized as the supremum over those λ for which there exists a function u > 0 on D satisfying [formula] in D. (It is enough to work with C1 functions that are piecewise C2.) One can check that if one defines [formula], for [formula], [formula], for [formula], and then extends u to (0,1) by making it symmetric with respect to [formula], then for sufficiently small ε > 0, one has [formula] in D. This gives the lower bound in [\eqref=weakest].

Another way to characterize λ0(γ,μ) is that it is the largest λ such that the generalized maximum principle holds for Lγ,μ  -  λ. That is, the largest λ such that whenever one has Lγ,μv - λv  ≤  0 in D and v(0) = v(1) = 0, then necessarily one has [formula] in D. Choosing u as above, one can show that if ε > 0 is sufficiently small, then one has [formula] in D. Since [formula] in D, the generalized maximum principle does not hold and consequently [formula], giving the upper bound in [\eqref=weakest]. We have experimented with all sorts of much more complicated functions, but have not been able to improve the above bounds.

The upper bound in [\eqref=weakest] can be understood probabilistically by the following heuristic argument, which may be able to be made rigorous. If a Brownian motion is at x, then the probability that it will reach 0 by time s is no more than [formula], for some c > 0. When the process X(  ·  ) is at γ- l, the local jump rate is on the order γ1 - l and thus the expected time to jump is on the order γl - 1. Letting s = γl - 1 and x = γ- l, with [formula], it follows that for large γ, any time the X(  ·  ) process finds itself in

[formula]

is at least (1 - 2γ- l)cγt. So the probability of not exiting by time t is at least on the order (1 - 2γ- l)cγt, which is at least exp ( - c1γ1 - lt) for some c1 > 0. By [\eqref=largetime], we conclude that λ0(γ,μ) grows no faster than γ1 - l for any [formula].