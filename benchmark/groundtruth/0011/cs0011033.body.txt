Web Mining Research: A Survey

Introduction

The World Wide Web (Web) is a popular and interactive medium to disseminate information today. The Web is huge, diverse, and dynamic and thus raises the scalability, multimedia data, and temporal issues respectively. Due to those situations, we are currently drowning in information and facing information overload [\cite=Mae94]. Information users could encounter, among others, the following problems when interacting with the Web:

a. Finding relevant information: People either browse or use the search service when they want to find specific information on the Web. When a user uses search service he or she usually inputs a simple keyword query and the query response is the list of pages ranked based on their similarity to the query. However today's search tools have the following problems [\cite=Cha00]. The first problem is low precision, which is due to the irrelevance of many of the search results. This results in a difficulty finding the relevant information. The second problem is low recall, which is due to the inability to index all the information available on the Web. This results in a difficulty finding the unindexed information that is relevant. See [\cite=LG99] for some other search engine problems.

b. Creating new knowledge out of the information available on the Web: Actually this problem could be regarded as a sub-problem of the problem above. While the problem above is usually a query-triggered process (retrieval oriented), this problem is a data-triggered process that presumes that we already have a collection of Web data and we want to extract potentially useful knowledge out of it (data mining oriented). Recent research [\cite=CD+98] [\cite=MB+99] [\cite=Coh99a] focuses on utilizing the Web as a knowledge base for decision making.

c. Personalization of the information: This problem is often associated with the type and presentation of information, since it is likely that people differ in the contents and presentations they prefer while interacting with the Web.

On the other hand, the information providers could encounter these problems, among others, when trying to achieve their goals on the Web:

d. Learning about consumers or individual users: This is a problem that specifically deals with the problem c above, which is about knowing what the customers do and want. Inside this problem, there are sub-problems such as mass customizing the information to the intended consumers or even to personalize it to individual user, problems related to effective Web site design and management, problems related to marketing, etc.

Web mining techniques could be used to solve the information overload problems above directly or indirectly. However, we do not claim that Web mining techniques are the only tools to solve those problems. Other techniques and works from different research areas, such as database (DB), information retrieval (IR), natural language processing (NLP), and the Web document community, could also be used. By the direct approach we mean that the application of the Web mining techniques directly addresses the above problems. For example, a Newsgroup agent that classifies whether the news is relevant to the user. By the indirect approach we mean that the Web mining techniques are used as a part of a bigger application that addresses the above problems. For example, Web mining techniques could be used to create index terms for the Web search services.

The Web mining research is a converging research area from several research communities, such as database, IR, and AI research communities especially from machine learning and NLP. This paper is an attempt to put the research done in a more structured way from the machine learning point of view. However, the methods of the research that we survey do not necessarily use well-known machine learning algorithms. Since this is a huge, interdisciplinary, and very dynamic research area, there are undoubtedly some omissions in our coverage.

This paper is structured as follows. In section 2 we give an overview of Web mining, describe some confusions in the usage of the term Web mining, provide a classification, and relate this classification to the agent paradigm. In section 3, 4 and 5 we describe some research that represent the range of the research in their respective categories. In section 6 we discuss some related work and finally we conclude in section 7.

Web Mining

Overview

Web mining is the use of data mining techniques to automatically discover and extract information from Web documents and services [\cite=Etz96]. This area of research is so huge today partly due to the interests of various research communities, the tremendous growth of information sources available on the Web and the recent interest in e-commerce. This phenomenon partly creates confusion when we ask what constitutes Web mining and when comparing research in this area. Similar to Etzioni [\cite=Etz96], we suggest decomposing Web mining into these subtasks, namely:

Resource finding: the task of retrieving intended Web documents.

Information selection and pre-processing: automatically selecting and pre-processing specific information from retrieved Web resources.

Generalization: automatically discovers general patterns at individual Web sites as well as across multiple sites.

Analysis: validation and/or interpretation of the mined patterns.

By resource finding we mean the process of retrieving the data that is either online or offline from the text sources available on the Web such as electronic newsletters, electronic newswire, newsgroups, the text contents of HTML documents obtained by removing HTML tags, and also the manual selection of Web resources. We also include text sources that originally were not accessible from the Web but are accessible now, such as online texts made for research purposes only, text databases, etc. The information selection and pre-processing step is any kind of transformation processes of the original data retrieved in the IR process. These transformations could be either a kind of pre-processing that are mentioned above such as removing stop words, stemming, etc. or a pre-processing aimed at obtaining the desired representation such as finding phrases in the training corpus, transforming the representation to relational or first order logic form, etc. In step 3 above, machine learning or data mining techniques are typically used for the generalization. We should also note that humans play an important role in the information or knowledge discovery process on the Web since the Web is an interactive medium. This is especially important for validation and/or interpretation in step 4. Thus, interactive query-triggered knowledge discovery is as important as the more automatic data-triggered knowledge discovery. However, we exclude the knowledge discovery done manually by humans. As we will see later in section 3, the process 1 - 3 - 4 is also used.

Thus, Web mining refers to the overall process of discovering potentially useful and previously unknown information or knowledge from the Web data. It implicitly covers the standard process of knowledge discovery in databases (KDD) [\cite=FSS96b]. We could simply view Web mining as an extension of KDD that is applied on the Web data. From the KDD point of view, the information and knowledge terms are interchangeable [\cite=FSS96a]. There is a close relationship between data mining, machine learning and advanced data analysis [\cite=Mit99]. However, throughout the paper, we discuss the Web mining research where machine learning techniques are used. Although mining is an intriguing word to use, it is not a good metaphor to describe the overall knowledge discovery process [\cite=FSS96a] and what people really do in the field [\cite=Hea99]. Web mining is often associated with IR or IE. However, web mining or information discovery on the Web is not the same as IR or IE.

Web Mining and Information Retrieval

Some have claimed that resource or document discovery (IR) on the Web is an instance of Web (content) mining and others associate Web mining with intelligent IR. Actually IR is the automatic retrieval of all relevant documents while at the same time retrieving as few of the non-relevant as possible [\cite=Van79]. IR has the primary goals of indexing text and searching for useful documents in a collection and nowadays research in IR includes modeling, document classification and categorization, user interfaces, data visualization, filtering, etc. [\cite=YN99]. The task that can be considered to be an instance of Web mining is Web document classification or categorization, which could be used for indexing. Viewed in this respect, Web mining is part of the (Web) IR process. However, we should note that not all of the indexing tasks use data mining techniques.

Web Mining and Information Extraction

IE has the goal of transforming a collection of documents, usually with the help of an IR system, into information that is more readily digested and analyzed [\cite=CL96]. IE aims to extract relevant facts from the documents while IR aims to select relevant documents [\cite=Paz97]. While IE is interested in the structure or representation of a document, IR views the text in a document just as a bag of unordered words [\cite=Wil97]. Thus, in general IE works at a finer granularity level than IR does on the documents. However, the differences between the two become blurred if the interest of IR is in extraction [\cite=Paz99], and when used in the context of vague forms of information in which a full text IR system can provide some IE features [\cite=Wil97].

Building IE systems manually is not feasible and scalable for such a dynamic and diverse medium such as Web contents [\cite=MMK98]. Due to this nature of the Web, most IE systems focus on specific Web sites to extract. Others use machine learning or data mining techniques to learn the extraction patterns or rules for Web documents semi-automatically or automatically [\cite=Kus99]. Within this view, Web mining is part of the (Web) IE process. Other views regarding the relationship between (Web) IE and Web mining also exist. The results of the IE process could be in the form of a structured database or could be a compression or summary of the original text or documents. One could view for the former that IE is a kind of pre-processing stage in the Web mining process, which is the step after the IR process and before the data mining techniques are being performed. In a similar view, IE can also be used to improve the indexing process, which is part of the IR process. Conversely, one could also argue for the latter that IE is an instance of text or Web mining since the summary or the compressed form of a document is a new form of information that does not exist before. However, we advocate the view that Web mining is used to improve Web IE (Web mining is part of IE).

There are basically two types of IE: IE from unstructured texts and IE from semi-structured data [\cite=Mus99]. There are considerable differences between the IE systems that are used for unstructured documents with those that are used for semi-structured or even structured documents. IE tasks from unstructured natural language texts (classical or traditional IE tasks) typically use a rather basic to a slightly deeper linguistic pre-processing before performing data mining. Classical or traditional IE research, with roots on the NLP community, has been studied for quite a long time [\cite=CL96] [\cite=Wil97]. We could say that Advanced Research Projects Agency (ARPA) helped creating the field (classical IE) because the evaluations of IE cannot be separated from the ARPA sponsored Message Understanding Conferences (MUCs) and the TIPSTER IE project [\cite=Wil97] [\cite=AI99]. MUCs and TIPSTER are competitive environments that seek to improve IE and IR technologies [\cite=CL96] [\cite=Car97]. Classical IE usually relies on linguistic pre-processing such as syntactic analysis, semantic analysis, and discourse analysis [\cite=Sod99] [\cite=Mus99] [\cite=Kus99]. Indeed, classical IE could be called a core language technology [\cite=Wil97].

With the increasing popularity of the Web, there is a need for structural IE systems that extract information from semi-structured documents. Structural IE research is different from the classical one as it usually utilizes the meta-information (e.g. HTML tags [\cite=Sod99], simple syntactics [\cite=Kus99], or delimiters [\cite=Mus99] that are available inside the semi-structured data. Structural IE approaches that do not use linguistic constraints are termed wrapper induction [\cite=Mus99]. Some of the structural IE systems are built manually by knowledge engineering approach, for examples see [\cite=CM+94] [\cite=AM97] [\cite=HG+97]. However, more and more structural IE systems for the Web are built (semi-) automatically using machine learning techniques or other algorithms as building the systems manually is no longer appropriate [\cite=Kus99]. Some examples are [\cite=KWD97] [\cite=Fre98] [\cite=HD98] [\cite=MMK98] [\cite=GM99] [\cite=Sod99]. These systems are usually built by using machine learning or data mining techniques, which learn extraction rules from the annotated corpora. For more explanations and the categories of IE we point interested readers to the following survey papers. For classical IE and the issues of IE for unstructured texts we refer to [\cite=CL96] [\cite=Car97] [\cite=AI99] [\cite=Sod99] and for structural IE we refer to [\cite=Sod99] [\cite=Mus99].

Web Mining and Machine Learning Applied on the Web

Web mining is not the same as learning from the Web or machine learning techniques applied on the Web. On the one hand, there are some applications of machine learning applied on the Web that are not instances of Web mining. An example of this is a machine learning technique that is used to spider the Web efficiently for a specific topic [\cite=RM99a] [\cite=MN+99] that emphasize on planning the best path that is going to be traversed next. On the other hand, there are some other methods used for Web mining besides machine learning methods. Some examples are some proprietary algorithms that are used for mining the hubs and authorities [\cite=CD+99], DataGuides [\cite=GW97] [\cite=GW99] and Web schema discovery [\cite=WL97] [\cite=NAM98]. However, there is a close relationship between the two research areas. Machine learning techniques support and help Web mining as they could be applied to the processes in Web mining. For example recent research [\cite=Mla99] shows that applying machine learning techniques could improve the text classification process compared to the traditional IR techniques. In short, Web mining intersects with the application of machine learning on the Web.

Web Mining Categories

In this section we give the overview of each category. More detailed explanations are given in the respective sections. Similar to Madria, et al. [\cite=MB+99] and Borges and Levene [\cite=BL99], we categorize Web mining into three areas of interest based on which part of the Web to mine: Web content mining, Web structure mining, and Web usage mining. Web content mining describes the discovery of useful information from the Web contents/data/documents. However, what consist of the Web contents could encompass a very broad range of data. Previously the Internet consists of different types of services and data sources such as Gopher, FTP and Usenet. Now most of those data are either ported to or accessible from the Web. It is mentioned in [\cite=HC+99] that in the last several years the growth in the amount of government information has been tremendous. We also know the existence of Digital Libraries that are also accessible from the Web. We also see that many companies are transforming their businesses and services electronically. As a consequence many of the company databases that previously resided in the legacy systems are being ported to or made accessible from the Web. Thus the employees, partners, or even customers could access some of the company database directly from Web based interfaces. Another consequence of this transformation is the existence of Web applications so that the users could access the applications through Web interfaces. Many applications and systems are being migrated to the Web and many types of applications are emerging in the Web environment. Of course some of the Web content data are hidden data, which cannot be indexed. These data are either generated dynamically as a result of queries and reside in the DBMSs or are private. In short, the Web already contains many kinds and types of data.

Basically, the Web content consists of several types of data such as textual, image, audio, video, metadata as well as hyperlinks. Recent research on mining multi types of data is termed multimedia data mining [\cite=ZH+98]. Thus we could consider multimedia data mining as an instance of Web content mining. However this line of research still receives less attention than the research on the text or hypertext contents [\cite=ZH+98] [\cite=Mit99]. The Web content data consist of unstructured data such as free texts, semi-structured data such as HTML documents, and a more structured data such as data in the tables or database generated HTML pages. However, much of the Web content data is unstructured text data [\cite=Etz96] [\cite=CC+98] [\cite=AH+99] [\cite=Cha00]. The research around applying data mining techniques to unstructured text is termed knowledge discovery in texts (KDT) [\cite=FD95], or text data mining [\cite=Hea99], or text mining [\cite=Tan99]. Hence we could consider text mining as an instance of Web content mining. We discuss text mining further in the next section. We could differentiate the research done in Web content mining from two different points of view: IR and DB [\cite=CMS97] views. The goal of Web content mining from the IR view is mainly to assist or to improve the information finding or filtering the information to the users usually based on either inferred or solicited user profiles, while the goal of Web content mining from the DB view mainly tries to model the data on the Web and to integrate them so that more sophisticated queries other than the keywords based search could be performed. These viewpoints are further discussed in the next section.

Web structure mining [\cite=CD+99] tries to discover the model underlying the link structures of the Web. The model is based on the topology of the hyperlinks with or without the description of the links. This model can be used to categorize Web pages and is useful to generate information such as the similarity and relationship between different Web sites. Web structure mining could be used to discover authority sites for the subjects (authorities) and overview sites for the subjects that point to many authorities (hubs).

Web usage mining [\cite=CMS97] tries to make sense of the data generated by the Web surfer's sessions or behaviors. While the Web content and structure mining utilize the real or primary data on the Web, Web usage mining mines the secondary data derived from the interactions of the users while interacting with the Web. The Web usage data includes the data from Web server access logs, proxy server logs, browser logs, user profiles, registration data, user sessions or transactions, cookies, user queries, bookmark data, mouse clicks and scrolls, and any other data as the results of interactions. Table 1 gives an overview of the above Web mining categories (the explanations are given in the subsequent sections).

However we should emphasize that the distinctions between the above categories are not clear-cut. Web content mining might utilize text and links and even the profiles that are either inferred or inputted by the users. User profiles are mostly used for the user modeling applications or personal assistants. The same is true for Web structure mining that could use the information about the links in addition to the link structures. Moreover we could infer the traversed links from the documents that were requested during the user session from the logs generated by the server. We could also characterize the categories above from the point of view of the scope of most of the work done in the respective areas: local scope spans an individual Web site while global scope spans the entire Web. The scope of the Web content mining from the IR view and Web structure mining is global while the scope of the Web content mining from the DB view and Web usage mining is local. However this characterization is not clear-cut either.

In practice, the three Web mining tasks above could be used in isolation or combined in an application, especially in Web content and structure mining since the Web documents might also contain links. For example, Chakrabarti et al. [\cite=CD+99] uses as Web content the terms in a document's link neighborhood and as Web structure the links from its neighbors, to classify Web pages. Joachims et al. [\cite=JFM97] use Web content and usage to build a software tour agent for assisting users browsing a Web site.

Web Mining and the Agent Paradigm

Web mining is often viewed from or implemented within an agent paradigm. Thus, Web mining has a close relationship with software agents or intelligent agents. Indeed some of these agents perform data mining tasks to achieve their goals. According to Green, et al. [\cite=GH+97] there are three sub-categories of software agents: user interface agents, distributed agents, and mobile agents. The sub-categories of software agents that are relevant for data mining tasks are user interface agents and distributed agents. User interface agents try to maximize the productivity of current users interaction with the system by adapting behavior. The issue of personalization abounds here. User interface agents that can be classified into the Web mining agent category are information retrieval agents, information filtering agents, and personal assistant agents. Distributed agents technology is concerned with problem solving by a group of agents and relevant agents in this category are distributed agents for knowledge discovery or data mining (for example see [\cite=KHS97]).

There are two frequently used approaches for developing intelligent agents that help users find and retrieve relevant information from the Web [\cite=BS97], namely content-based and collaborative approaches. In the content-based approach, the system searches for items that match based on an analysis of the content using the user preferences. In the collaborative approach, the system tries to find users with similar interests to give recommendations to. The system does this by analyzing the user profiles and sessions or transactions. It assumes that if some users rate an item high, then the other users with similar interests would rate this item high also. So this approach mainly uses the usage data (user ratings). Viewed in this light we could categorize the content-based methods as Web content mining and categorize the collaborative approaches as Web usage mining. However, collaborative approaches might also be used or combined with the Web content.

A similar view related to the Web mining categories above also exists in the software agent community. Delgado [\cite=Del00] classifies the user interface agents by the underlying information filtering technology into content-based filters, reputation based filters, collaborative or social-based filters, event-based filters, and hybrid filters. In event based filtering, the system tracks and follows the events that are inferred from the surfing habits of people in the Web. Some examples of those events are saving a URL into a bookmark folder, mouse clicks and scrolls, link traverse behavior, etc. We could make an association between these agent-based categories with the Web mining categories above. Table 2 shows the association.

Web Content Mining

In this section we list some of the research in the respective categories in separate tables. We should note that the lists are by no means complete. The explanations on the methods surveyed are beyond the scope of this paper. Interested readers can consult the book by Mitchell [\cite=Mit97] and the respective papers for the explanation of the methods. We just intend to give a taste on the variety of some representations, processes, methods, and applications that have been used.

Information Retrieval View

Information Retrieval View for Unstructured Documents

Table 3 summarizes some of the research done for unstructured documents. What we mean by the unstructured documents is free texts such as news stories. Most of the research in table 3 uses bag of words to represent unstructured documents. The bag of words or vector representation [\cite=SM83] takes single words found in the training corpus as features. This representation ignores the sequence in which the words occur and is based on the statistic about single words in isolation. The features could be Boolean (a word either occurs or does not occur in a document), or frequency based (frequency of the word in a document). Variations of the feature selection include removing the case, punctuation, infrequent words, and stop words. The features could be reduced further by applying some other feature selection techniques, such as information gain, mutual information, cross entropy, or odds ratio (see [\cite=MG99] for the details). Other preprocessing includes Latent Semantic Indexing (LSI) [\cite=DD+90] that seeks to transform the original document vectors to a lower dimensional space by analyzing the correlational structure of terms in the document collection such that similar documents that do not share terms are placed in the same topic, and stemming which reduces words to their morphological roots. For example the words "informing", "information", "informer", and "informed" would be stemmed to their common root "inform" and only the latter word is used as the feature instead of the former four. While those pre-processing variations are useful for reducing feature set size, the generality of their effectiveness over different domains for text categorization tasks are doubted [\cite=Ril95].

Other feature representations are also possible such as using information about word positions in the document [\cite=Coh95] [\cite=AH+98] [\cite=FP+99], using n-grams representation (word sequences of length up to n) [\cite=HK97] [\cite=KHS97] (for example "the morphological roots" is a tri-gram), using phrases [\cite=DP+98] [\cite=FP+99] [\cite=SM99] [\cite=YC+99] such as "the quick brown fox that run away", using document concept categories [\cite=FD95], using terms [\cite=FF+98] such as "annual interest rate" or "Wall Street", using hypernyms (linguistic term for the "is a" relationship - a dog is an animal, thus "animal" is a hypernym of "dog") [\cite=SM99], or using named entities [\cite=WB+99] such as people's names, dates, email addresses, locations, organizations, or URLs. The relational representation ([\cite=Coh95] [\cite=JSR99] in table 3) that we mean here is actually first order logic, a language that is more expressive than propositional logic (for instance see [\cite=Mit97]). For example in the bag of words representation features are the frequencies of specific words; using a relational representation one might use relationships between different words and their positions, e.g. "word X is to the left of word Y in the same sentence". Although different types of representations have been used, there is currently no study that shows clear advantages of some representations over several domains for text categorization tasks [\cite=Mla99]. Indeed, Scott and Matwin [\cite=SM99] compare different representations (bag of words, phrase based, and hypernym) but found no significant differences in the performance of different representations.

As we can see from table 3, the commonly used process is 1 - 2 - 3 - 4, while some others do not use any or only use a minimal pre-processing step (process 1 - 3 - 4). The name and explanation of the four steps are described in section 2.1 above. The use of text compression techniques [\cite=WB+99] is rather new for the text classification task. The applications range from text classification or categorization, event detection and tracking, finding extraction patterns or rules, to finding some interesting patterns in the text documents. Event detection and tracking problems are sub-topics of a broader initiative called topic detection and tracking (TDT), which is a new line of research related to research in information retrieval and filtering [\cite=APL98]. TDT is an initiative to investigate the state of the art in finding and following new events in a stream of news stories broadcast [\cite=AC+98].

Recently the usage of the term text mining has been a subject to controversy. There are at least two controversies that we are aware of: one is regarding the usage of the term "mining" itself [\cite=Hea99] and the other one is regarding the meaning of the word "knowledge" in knowledge discovery from text (KDT) [\cite=Kod99]. As far as we know, the term text mining or KDT was first proposed by Feldman and Dagan in [\cite=FD95]. They suggest to structure the text documents by means of information extraction, text categorization, or applying NLP techniques as pre-processing step before performing any kind of KDTs. The reason is mining on the unprepared documents does not provide effectively exploitable results [\cite=RB98] [\cite=FF+98]. Currently the term text mining has been used to describe different applications such as text categorization [\cite=HW99] [\cite=Tan99] [\cite=WA+99], text clustering [\cite=Tan99] [\cite=RM99b], IE [\cite=AH+98], empirical computational linguistic tasks [\cite=Hea99], exploratory data analysis [\cite=Hea99], finding patterns in text databases [\cite=FD95] [\cite=FF+98], finding sequential patterns in texts [\cite=LAS97] [\cite=AH+98] [\cite=AH+99], and association discovery [\cite=Tan99] [\cite=NM00]. So although some of the papers surveyed mention their application as text mining, we use less controversial names for the applications.

Information Retrieval View for Semi-Structured Documents

We can see from table 4 that the process used in the works surveyed above is 1 - 2 - 3 - 4. We can also see that the works surveyed in table 4 use richer representations compared to the works surveyed in table 3. This is due to the additional structural (HTML and hyperlink) information in the hypertext documents. Actually all of the works surveyed utilize the HTML structures inside the documents and some utilize the hyperlink structure between the documents for document representation. The methods that are used are common data mining methods. The applications ranged from hypertext classification or categorization and clustering, learning relations between Web documents, learning extraction patterns or rules, and finding patterns in semi-structured data.

Database View

As mentioned in [\cite=FLM98], the database techniques on the Web are related to the problems of managing and querying the information on the Web. [\cite=FLM98] mentions that there are three classes of tasks related to those problems: modeling and querying the Web, information extraction and integration, and Web site construction and restructuring. Although the first two tasks are related to Web content mining applications, not all the works there are inside the scope of Web content mining. This is due to the absence of the machine learning or data mining techniques in the process. Basically the DB view tries to infer the structure of the Web site or to transform a Web site to become a database so that better information management and querying on the Web become possible. As mentioned previously, the DB view of Web content mining mainly tries to model the data on the Web and to integrate them so that more sophisticated queries other than the keywords based search could be performed. These could be achieved by finding the schema of Web documents, building a Web warehouse or a Web knowledge base or a virtual database. The research done in this area mainly deals with semi-structured data. Semi-structured data from database view often refers to data that has some structure but no rigid schema [\cite=Abi97] [\cite=Bun97].

From table 5, we can see that the DB view uses representations that differ from the IR view that we see in table 3 and table 4. The DB view mainly uses Object Exchange Model (OEM) [\cite=AQ+97] that represents semi-structured data by a labeled graph. The data in the OEM is viewed as a graph, with objects as the vertices and labels on the edges. Each object is identified by an object identifier (oid) and a value that is either atomic, such as integer, string, gif, html, etc. or complex in the form of a set of object references, denoted as a set of (label, oid) pairs. All of the processes that are surveyed above are 1 - 2 - 3 - 4. However, the process used here typically starts from manually selected Web sites for doing Web content mining instead of searching the whole Internet for the specific resources. This is partly due to the applications of the DB view that are quite different from those of the IR view (which mostly are classification tasks). The process 1 and 2 is typically done by site-specific wrappers or parsers for hypertext documents.

Most of the applications that are surveyed above are the task of schema extraction or discovery [\cite=WL99] [\cite=Toi99] or building DataGuides [\cite=GW97] [\cite=NAM97] [\cite=GW99]. Roughly speaking, a schema or DataGuide is a kind of structural summary of semi-structured data. For practical applications and computational reason, this summary is often approximated [\cite=Abi97] [\cite=GW99]. Some applications do not deal with the task of finding the global schema but deal with the task of finding frequent substructures (sub-schema) in semi-structured data. Another application deals with the task of creating multi-layered database (MLDB) [\cite=ZH98] in which each layer is obtained by generalizations on lower layers and use a special purpose query language for Web mining to extract some knowledge from the MLDB of Web documents. This is an example of the query perspective of data mining. There has been some work on query languages for semi-structured data [\cite=AQ+97] [\cite=BD+96] and for the Web [\cite=AM99] [\cite=LSS96] [\cite=MMM96] [\cite=FF+97]. However, we only see the works by Zaïane, et al. [\cite=ZH98] and Singh, et al. [\cite=SC+98] that are inside the scope of Web content mining.

Due to the different representations used in the DB view, most of the methods used for data mining are also different except the ILP methods that could operate on relational or graphical data. These differences are partly due to the inappropriateness of many existing data mining techniques, which operate on flat data, to operate on relational or graphical data. [\cite=GM99] [\cite=NAM97] [\cite=ZH98] use proprietary algorithms for schema discovery and for the construction of MLDB, [\cite=WL99] uses a modified version of association rules, and [\cite=Toi99] uses an upgraded first order logic version of association rules [\cite=DD97].

About Mining Multimedia Data

We should note that we have not actually discussed the issue of mining multimedia data on the Web. Although multimedia data has been the major focus for many researchers [\cite=KB96] [\cite=Sub98] and many techniques for multimedia IR and extraction have been proposed (for example see [\cite=Hau99]), multimedia data mining is still in its infancy [\cite=ZH+98]. Uthurusamy [\cite=Uth96], Shapiro et al. [\cite=SB+96], and Mitchell [\cite=Mit99] assert that working towards a unifying framework for representation, problem solving, and learning from multimedia data is indeed a challenge. Fayyad et al. [\cite=FDW96] describes mining the images of sky objects taken from satellite. Smyth, et al. [\cite=SF+96] describes mining images to identify small volcanoes on Venus. More recent works are [\cite=ZH+98] in the application of Web data warehousing and [\cite=HC+99] in the application of a medical IR system for mining the multimedia data on the Web. For a definition and a short survey on multimedia data mining, we refer to [\cite=ZH+98].

Web Structure Mining

If in the database view of Web content mining we are interested in the structure within Web documents (intra-document structure), in Web structure mining we are interested in the structure of the hyperlinks within the Web itself (inter-document structure). This line of research is inspired by the study of social networks and citation analysis [\cite=KSS97] [\cite=Cha00]. With social network analysis we could discover specific types of pages (such as hubs, authorities, etc.) based on the incoming and outgoing links. Web structure mining utilizes the hyperlinks structure of the Web to apply social network analysis to model the underlying links structure of the Web itself. Research done by Kautz et al. [\cite=KSS97] utilizes the network analysis of people to model the network of AI researchers. They use the name entity data found in close proximity in any public Web pages such as the hyperlinks from home pages, co-authorship and citation of papers, exchange of information between individuals found in net-news archives, and organization charts. In our framework, their research could be classified as a combination of Web structure and content mining.

Some algorithms have been proposed to model the Web topology such as HITS [\cite=Kle98], PageRank [\cite=BP98] and improvements of HITS by adding content information to the links structure [\cite=CD+99] and by using outlier filtering [\cite=BH98]. These models are mainly applied as a method to calculate the quality rank or relevancy of each Web page. Some examples are the Clever system [\cite=CD+99] and Google [\cite=BP98]. Some other applications of the models include Web pages categorization [\cite=CDI98] and discovering micro communities on the Web [\cite=KR+98].

More applications of Web structure mining in the context of Web warehouse are discussed by Madria, et al. [\cite=MB+99]. These include measuring the completeness of the Web sites by measuring the frequency of local links that reside in the same server, measuring the replication of Web documents across the Web warehouse that helps in identifying the mirrored sites for example, and discovering the nature of the hierarchy of hyperlinks in the Web sites of a particular domain to study how the flow of information affects the design of the Web sites.

Web Usage Mining

Web usage mining focuses on techniques that could predict user behavior while the user interacts with the Web. As mentioned before, the mined data in this category are the secondary data on the Web as the result of interactions. These data could range very widely but generally we could classify them into the usage data that reside in the Web clients, proxy servers and servers [\cite=SC+00]. The Web usage mining process could be classified into two commonly used approaches [\cite=BL99]. The first approach maps the usage data of the Web server into relational tables before an adapted data mining technique is performed. The second approach uses the log data directly by utilizing special pre-processing techniques. As is true for typical data mining applications, the issues of data quality and pre-processing are also very important here. The typical problem is distinguishing among unique users, server sessions, episodes, etc. in the presence of caching and proxy servers [\cite=MS00] [\cite=SC+00]. For the details and comparison of some pre-processing methods for Web usage data we refer to [\cite=CMS99].

In general, typical data mining methods (see for example in [\cite=SC+00]) could be used to mine the usage data after the data have been pre-processed to the desired form. However, modifications of the typical data mining methods are also used such as composite association rules [\cite=BL98], an extension of a traditional sequence discovery algorithm (MIDAS [\cite=BB+99]), and hypertext probabilistic grammars [\cite=BL99]. The Web usage data could also be represented with graphs [\cite=BB+99] [\cite=PP+00]. Often the Web usage mining uses some background or domain knowledge such as navigation templates, Web content, site topology, concept hierarchies, and syntactic constraints [\cite=BB+99] [\cite=Spi99].

The applications of Web usage mining could be classified into two main categories: learning a user profile or user modeling in adaptive interfaces (personalized) (for examples see [\cite=Lan99]) and learning user navigation patterns (impersonalized) (for examples see [\cite=Spi99]). Web users would be interested in, among others, techniques that could learn their information needs and preferences, which is user modeling possibly combined with Web content mining. On the other hand, information providers would be interested in, among others, techniques that could improve the effectiveness of the information on their Web sites by adapting the Web site design or by biasing the user's behavior towards satisfying the goals of the site. In other words, they are interested in learning user navigation patterns. Then the learned knowledge could be used for applications such as personalization (at a Web site level), system improvement, site modification, business intelligence, and usage characterization (see [\cite=SC+00] for the detail). It is not in our intention to give a complete survey of Web usage mining research here. Interested readers could consult the overview papers by Srivastava, et al. [\cite=SC+00], Spiliopoulou [\cite=Spi99], and Masand and Spiliopoulou [\cite=MS00], and Robert Cooley's Ph.D. thesis [\cite=Coo00] for mining user patterns and the overview paper by Langley [\cite=Lan99] for mining user profiles.

Related Works

As far as we know, it was Etzioni [\cite=Etz96] who first coined the term Web mining. Etzioni starts by making a hypothesis that the information on the Web is sufficiently structured and outlines the subtasks of Web mining. His paper describes the Web mining processes. There have been some works around the survey of data mining on the Web. The first paper that we know that noticed the confusion in the Web mining research is [\cite=CMS97]. It gives a Web mining taxonomy but restricted to Web content and Web usage mining, and gives a survey on Web usage mining. It divides the Web content mining into the agent based approach and the database approach. We use a similar division but divide it into the IR approach instead of the agent approach. Later, in [\cite=SC+00] they classify Web mining into three categories that are similar to our categories. Compared to their paper, our paper points out three confusions on the usage of the term Web mining, identifies additional user-centered Web mining processes, and provides new perspectives for the Web mining categories. We use the Web mining categories suggested in [\cite=MB+99] and [\cite=BL99]. [\cite=BL99] proposes a new model for mining Web log data, while [\cite=MB+99] discusses the research issues of Web mining in the context of Web warehouse project.

Carbonell et al. [\cite=CC+98] give an overview of the workshop on learning from text and the Web that is related to Web content (from the IR view) and usage mining. They also give an outline of the research directions in that area. Mladenic [\cite=Mla99] surveys the research on text learning and related intelligent agents. She compares two frequently used approaches for developing intelligent agents, namely collaborative and content based. In our categories, these would be Web content (from the IR view) and usage mining. She also surveys research on machine learning applied to text data, which is broader than but similar to our discussion in section 3.1.1 about the IR view of Web content mining from unstructured documents. Carbonell et al. [\cite=CYC00] review the emerging research collaborations between the IR and machine learning communities in a special issue of the Machine Learning journal. They also indicate some fertile research areas for both communities. Garofalakis et al. [\cite=GR+99] review some data mining techniques and the algorithms for Web mining that specifically take into account the hyperlink information. Chakrabarti [\cite=Cha00] provides a survey of data mining for hypertext. His paper mainly surveys the statistical techniques for Web content across the continuum of supervised, semi-supervised and unsupervised learning, and social network analysis techniques for Web structure mining. Levy and Weld [\cite=LW00] wrote a survey in the special issue of Artificial Intelligence on intelligent Internet systems that we think describes a broader domain than Web mining. Vaithyanathan [\cite=Vai99] gives an overview of the papers in the special issue of Artificial Intelligence Review on data mining on the Internet. He mentions similar categories of Web mining as ours, except the database view of Web content mining. Some other related work that we found recently in special issues of some magazines are the following. Yang and Pedersen edited a special issue on intelligent information retrieval [\cite=YP99]. Filman and Pant edited a special issue on searching the Internet [\cite=FP99].

Conclusions

In this paper we survey the research in the area of Web mining. We point out some confusions regarded the usage of the term Web mining. We also suggest three Web mining categories and then situate some of the research with respect to these categories. We also explore the connection between Web mining categories and the related agent paradigm. For the survey, we focus on representation issues, on the process, and on the learning algorithm, and the application of the recent works as the criteria. The Web presents new challenges to the traditional data mining algorithms that work on flat data. We have seen that some of the traditional data mining algorithms have been extended or new algorithms have been used to work on the Web data.

An interesting direction of Web content mining is the recent interest in information integration [\cite=CM+94] [\cite=FK+00], which could be in the form of a Web knowledge base [\cite=CC+98] [\cite=Coh99a] or Web warehouse [\cite=MB+99], or in the form of a mediator (see [\cite=FK+00] for examples). At least this is the area where database and other research communities such as IR, AI, and machine learning met recently. Information integration was mainly concerned with integrating various databases but has changed its focus with the increasing popularity of the Web [\cite=FK+00]. The same is also true for the research in IE, which could be thought as a mediator or wrapper in the information integration area. Information integration also raises some other research questions such as scaling up the number of Web sites that could be integrated, wrapper maintenance, building and maintaining a global schema, etc. [\cite=Coh99b] (see also [\cite=Kus99] for other issues).

Topic detection and tracking (TDT) is also a promising research area for IR and machine learning communities that raises, among others, temporal issue in the data. It would be interesting if the learning algorithm could model this aspect accurately. Some other promising research issues in the area of Web content mining are discussed in [\cite=CC+98]. Finally, another interesting fact is that graph structures occur almost everywhere in Web mining research. There are many opportunities for (existing or new) machine learning algorithms that could work with this representation or that could take advantage of the available structures on the Web.

Acknowledgements

We thank Johannes Fürnkranz, Dunja Mladenic, Nico Jacobs, and Maurice Bruynooghe for reading the draft and the useful comments. We also thank Luc Dehaspe for the interesting discussions. Raymond Kosala is supported by the GOA Project LP+ of the Katholieke Universiteit Leuven. Hendrik Blockeel is a post-doctoral fellow of the Fund for Scientific Research of Flanders.