Available Stabilizing Heaps

University of Iowa herman@cs.uiowa.edu Toshimitsu Masuzawa NAIST, Japan masuzawa@is.aist-nara.ac.jp

Keywords: data structures, fault tolerance, recovery, self-stabilization

Introduction

Increased visibility of systems emphasizes the theme of system availability. When availability is not important, systems may handle failures by stopping normal system activity and restoring damaged data from a recent backup copy. But stopping and restoring from a backup interferes with system availability, and in many instances it is preferable to let system services continue, even if the behavior of the services show temporary inconsistencies. Bookkeeping is intrinsic to system implementation, so data structures are found at the core of system programs. The objective of system availability motivates research of data structures with availability properties.

(Self-) stabilization is the paradigm usually associated with recovery from transient faults of unlimited scope [\cite=D00]. Stabilization is traditionally associated with a distributed system, where each process can perpetually check and repair its variables. Our work departs from this traditional setting: we investigate a sequential, non-distributed data structure, supposing that the data structure is managed only by standard methods. We further suppose that each method invocation starts cleanly (with no transient damage to internal or control variables of that invocation), which resembles other work on fault tolerance [\cite=ER90] [\cite=LP90] [\cite=FMRT96]. The heap proposed here also constrains operation behavior during the period of convergence to a legitimate state -- an issue not usually addressed by stabilization research (papers [\cite=DH97] [\cite=UKMF97] [\cite=H00] are the exception).

Stabilizing Heap Construction

The data structure presented below is a variant of the standard binary heap [\cite=CLR90] with a maximum capacity of K items. Two operations are defined for the heap, (p), which inserts value p into the heap, and deleteMin( ), which returns and removes an item of least value from the heap. We say that an (p) succeeds if it inserts item p into the heap and fails otherwise. The response to an (p) invocation indicates success or failure by returning "ack" for success and "heap full" for failure. Similarly, a deleteMin( ) succeeds if it returns an item and fails by returning a "heap empty" indication.

The heap construction described here is based on a binary, balanced tree of K nodes, rooted at a node named root, and denoted by A. Each node x in tree A has two associated constants x. and x., which refer respectively to the left and right child of x in A. The symbol λ denotes the absence a child: x.  =  λ (x.  =  λ) indicates that x has no left (right) child in A. We suppose that x. and x. cannot be corrupted by a transient fault. (A conventional heap implementation by an array [\cite=CLR90] satisfies this assumption, since there is a static mapping between parent and child.) Each node x has three variable fields, x., x., and x. used for storage and management of heap items in the tree.

The field x. may contain a heap item for node x. We use the symbol ∞  , which is a value outside the domain of possible heap items, to indicate the absence of a heap item at a particular node. For convenience, let λ.  =    ∞   and let y.  ≤    ∞   hold by definition for all y∈A. We define tree TA to be a truncation of tree A that includes only nodes in a path of non-∞   values. Formally, for any node x, let x∈TA iff x.  ≠    ∞   and either x is root  or the child, with respect to A, of some y satisfying y∈TA (the definition is recursive). It follows that TA is empty if .  =    ∞  . A node x∈TA is a leaf of TA iff (x.). = (x.).  =    ∞  . The expression 〈TA〉 denotes the bag (multiset) given by {x.  |  x∈TA}, and |TA| is the number of nodes in tree TA.

Implementation of a binary heap should satisfy the balance property and the heap property. The balance property is that any heap of m items is contained in a tree TA with height O(lgm). The heap property holds at x∈TA iff x.  ≤  y. for any y child of x. The data structure satisfies the heap property iff the heap property holds at every x, x∈TA.

Legitimate State.

The fields of A's nodes determine whether or not the tree is in a legitimate state. The state of A is legitimate iff (i) for every x∈TA, the heap property holds; (ii) the balance property holds; (iii) for every x∈TA, x. is the height of the subtree (in TA) rooted at x; and (iv) for every x∈TA, x. equals the minimum distance from x to a descendant y∈TA such that y has fewer children in TA than A, and if no such descendant y exists, x. can have any value satisfying x.  ≥  K.

Basic Operations.

Because conventional heap operations are well known, we provide only sketches of the operation logic. Two internal routines deepLeaf and findSlot assist in node allocation and tree maintenance. Let deepLeaf(root) be a recursive procedure that locates a node of TA having maximum depth: (x) compares the height fields of x's children, and if one of them, say y, has greater height, then (x) returns (y); and if both children have equal height  fields, then (x) returns (y) for some (possibly nondeterministic choice of) y∈{x.,x.}; (x) returns x if x has no children. A call to () returns the symbol λ if TA is empty.

Let findSlot(root) be a recursive procedure locating a minimum-depth node y in A such that [formula]: if x has one child y in A such that [formula], then (x) returns y; if x has two children in A such that neither is in TA, then (x) returns an arbitrary child of x; and if x has two children in TA, (x) compares the nextslot fields of x's children and returns (y) for the child y that has a smaller nextslot field (if both children have equal nextslot  fields, then y can be any child of x.) An invocation of () may fail to return an element y, and instead will return symbol λ, if no [formula] can be located.

The implementation of (p) consists of assigning y: = (), and if y = λ, then (p) responds with a "heap full" indication; otherwise, the following sequence executes. First, the operation assigns y.,y.,y.: = p,0,t where t = 0 if y has a child in A and otherwise t = K. Second, z.: =   ∞   is assigned for every child z of y in A. Third, the operation calls (y). The upHeapify routine swaps values of items on a path from y to root, until each parent has a value at most that of its child in the path. As upHeapify traverses the path from leaf to root, it also enforces, for each item y on the path, y.: = 1 +  max ((y.).,(y.).) and y.: = 1 +  min ((y.).,(y.).) (with appropriate adjustments to these expressions for cases of single or no children).

The implementation of ( ~ ) consists of y: = (), and if y  ≠  λ, saving . for the response, then assigning .: = y. and y.: =   ∞  , and then calling (). Along the path from y to root, the height and nextslot fields are also recomputed owing to the deletion of y. The downHeapify routine swaps values as needed, along some path from root to a leaf, so that the heap property is restored to TA.

Active Tree.

If A is not in a legitimate state, it is still possible to consider the maximum fragment of A that enjoys the heap property. The active tree SA is defined recursively by: if .  =    ∞   then SA is empty, otherwise ∈SA; and if x∈SA and y is a child of x (with respect to A) such that y.  ≠    ∞   and y.  ≥  x., then y∈SA.

Operation Modifications for Stabilization.

The definition of a legitimate state implies, for every x∈SA and [formula] where y is a child of x in A, that the val field of y is ∞  . In an illegitimate state, this condition need not hold, though SA is defined even for illegitimate states. Our first modification of operations (including internal routines such as deepLeaf and findSlot) is the following: whenever an item x∈SA is encountered, it is first examined to verify that every child y satisfies y.  ≥  x., and if this is not the case, then y.: =   ∞   is immediately assigned. (The only exception to this modification are the heapify routines, which are expected to encounter value reversals along a particular path.) The result of this modification is that operations consider children and leaves with respect to SA rather than TA. Observe that if a sequence of heap operations could somehow encounter all the nodes of TA, then TA = SA would hold as a result. A second modification introduced below does this, enforcing a scan of sufficiently many nodes of TA over any sequence of heap operations so that TA = SA will hold. We call this modification "truncation" since it removes nodes from TA to enforce the heap property. The truncation modification is a convenience for our presentation -- another possibility would be to treat y. as equivalent to ∞   whenever y. < x. for x the parent of y, and adjusting the definition of legitimate state (and TA) accordingly.

The following lemma considers an operation applied to A in an arbitrary (possibly illegitimate) state; for this lemma, T denotes SA prior to the operation and T' denotes SA after the operation.

An operation applied to A in an arbitrary state satisfies: if (p) succeeds, then [formula]; if (p) fails, then 〈T'〉  =  〈T〉; a deleteMin operations fails iff T is empty; if deleteMin returns value q, then q =  min 〈T〉 and [formula]; and any operation completes in O(lgK) time.

Although findSlot(root) does not guarantee to find an available position for an (p) operation for illegitimate A, if findSlot(root) does return r  ≠  λ, then from the logic of findSlot, r is a child of some node of T, and thus T' will contain p as a result of (p). For a deleteMin operation, () returns some leaf of T (not necessarily at greatest depth in T) provided T is nonempty, so deleteMin returns root.val of T. The O(lgK) time bound is satisfied because any path from root to leaf in T has length at most lgK.

The accuracy of height and nextslot fields is critical for maintaining the balance condition and locating an available node for heap insertion. In an illegitimate state, these fields have arbitrary values. Although heap operations recompute height and nextslot fields, such recomputation is limited to paths selected by the operations. The second change we make to operations is to add calls to a new routine verify. Each application of verify works on three objectives: (1) to apply truncation along one path P from root to a leaf of SA, (2) to assign height and nextslot fields from leaf to root in P, and (3) to modify fields so that the next invocation of verify will select a path different from P. To support objective (3), we add a new binary field toggle, with domain [formula], to every node. The path P chosen by verify is obtained by following toggle directions from root until a leaf of SA is reached. Our intent is that O(|SA|) successive invocations of verify will visit all nodes of the active tree.

Figure [\ref=verify] shows routine verify. Objectives (1) and (2) of verify are achieved with straightforward calculations. Although not shown explicitly in the figure, verify first checks values and assigns ∞   if necessary to enforce the heap property, as needed for the truncation procedure. The implementation of objective (3) is more complicated, using subordinate routines nextPath, leftFringe, and swAncestor.

The first few lines of verify in Figure [\ref=verify] assign x. for the case of x having fewer than two children: in case x has only a single child, then x. should be r or [formula] according to the location of its only child. In case x has no children, x. is assigned [formula]. The setup for a new path occurs by call to (x), which only occurs when x is a leaf of the active tree. The idea of (x) is to locate an ancestor w of x with [formula] and change w. to r, thereby setting up the "next path" for verify to examine. The routine leftFringe ensures that whenever such a change of w. from [formula] to r takes place, the toggle fields are such that the leftmost path of the subtree rooted at w. will be selected for this "next path" of verify. All lines but the last of leftFringe consider degenerate cases (single or no children). Not shown in the figure is the swAncestor procedure: (x) returns the nearest ancestor w of x such that w has two children in SA and [formula]; if no such ancestor w exists, then (x) returns λ. Observe that if [formula] does return λ, then (x) sets up the "next path" to be the leftmost path starting from root in SA.

If ⌊(|SA| + 1) / 2⌋ successive invocations of verify(root) are applied to arbitrary A, then as a result TA = SA and properties (i), (iii) and (iv) hold.

Let P denote the path of nodes examined via recursion for a given invocation of (). Observe that () is called within this invocation of verify iff P is the rightmost path within SA (otherwise swAncestor would return a non-λ value). By construction, (x) for x  ≠   sets up the leftmost path in SA to the right of P. Let Tx be a subtree of SA, rooted at x, with m leaves. If m successive verify invocations examine the leaves of Tx, then (i), (iii) and (iv) hold for the nodes of Tx afterwards (this can be shown by induction on subtree height). Let S be a preorder listing of the leaves of SA; S has at most ⌊(|SA| + 1) / 2⌋ items since any binary tree of n items has at most (n + 1) / 2 leaves. It is straightforward to show that any |S| successive invocations of verify(root) visit the leaves of SA in an order corresponding to some rotation of sequence S.

The remaining modification to standard heap operations consists of having each insert and deleteMin operation begin with "verify(root) ; balance(root)". A balance(root) invocation consists of deleting a leaf r found by () from the heap and then reinserting r into the heap. When all height and nextslot fields in the active tree have legitimate values, the effect of balance(root) is to move an item from a position of maximum depth to a position of minimum depth. Since these fields could be illegitimate, care must be taken in the implementation of balance so that deleted leaf r is, in any case, reinserted into the heap (perhaps by reversing the delete of r if reinsertion fails). To see why the balance(root) call is needed, consider an initial active tree with height k that has only one leaf. Without the balance(root) call, if only insert operations are applied to the heap, then O(2k) operations would be required to bring the tree into balance.

Let m = |SA| for an arbitrary initial state of A. After any sequence of at most m + 1 operations, A satisfies properties (i), (iii) and (iv) at all subsequent states.

Each insert and deleteMin operation invokes verify(root), however such operations also change the active tree. With respect to the sequence of verify(root) calls starting from the initial state, each change to the active tree either occurs in a subtree previously visited by verify or occurs in a subtree not yet visited by verify. In the former case, the tree modification satisfies (i), (iii) and (iv) along the path from root  to the modified nodes. In the latter case, a future verify establishes the desired properties. After d operations, the active tree has at most (m + d + 1) / 2 leaves; since each operation invokes verify(root), d operations visit all leaves provided (m + d + 1) / 2  ≤  d, by an argument similar to the proof of Lemma [\ref=verscan]. Therefore m + 1  ≤  d suffices.

Let m = |SA| for an arbitrary initial state of A. After at most O(m) heap operations, all subsequent states of A are legitimate.

Lemma [\ref=metrics] establishes that properties (i), (iii) and (iv) hold after O(m) operations. In the rest of this proof, we assume that properties (i), (iii) and (iv) hold. For the sake of generality we suppose that A is only loosely balanced: assume there exist constants a and b so that for any t, 0 < t  ≤  K, the minimum height ht taken over all subtrees of A with t nodes that contain node root satisfies ht  ≤  a + blgt. From this assumption, it follows that any subtree T of A rooted at root with height exceeding ht is nonoptimal; furthermore, it follows that there is some node w∈A not contained in T, that is a child of some node of T, so that w has depth at most ht.

We define gap(α) for any state α to be a variant function.

[formula]

It is straightforward to show that once gap is zero, any subsequent operation application results in zero gap, and that zero gap implies balance. If the initial gap is some value g > 0, any new item inserted into the heap is placed at minimum depth, any deleteMin  removes a node at maximum depth, so gap does not increase by the insert or delete operations. Moreover, every operation invokes balance(root), which decreases positive gap by at least one, so within g = O(m) operations, property (ii) is established.

Availability and Stabilization

The previous section presents a heap construction that is stabilizing (Lemma [\ref=converge]) and also satisfies certain properties expected of operations even when the data structure's state is illegitimate (Lemma [\ref=avail]). Lemmas [\ref=avail] and [\ref=converge] depend on the definition of SA. Is there a characterization of availability and stabilization independent of implementation specifics such as SA? Such a characterization could be adapted to specify availability and stabilization for general types and implementations of data structures.

Let H be an infinite history of operations on a heap, that is, H is a sequence of insert and deleteMin invocations and corresponding responses. We characterize a heap implementation in terms of properties of all possible operation histories, first for the case of an initially empty heap. Let t denote a point either before any operation or between operations in H. If t is before any operation, define [formula], otherwise let [formula], where It is the bag of items successfully inserted prior to point t, and Dt is the bag of items returned by deleteMin operations prior to point t (recall that success or failure of an operation is judged by the response it returns). We call Ct the heap content at point t. Heap operations satisfy the following constraints: (a) a deleteMin operation immediately following any point t fails iff [formula], and otherwise returns min (Ct); (b) an insert operation immediately following any point t fails iff |Ct| = K, and otherwise returns "ack"; (c) the running time of any operation immediately following t is O(lg|Ct|). From (a)-(c) one can show the usual heap properties, for instance, no deleteMin returns an item not previously inserted.

The above characterization of heap behavior by history depends on [formula] for the initial point t. Availability is a relaxation of this characterization to allow arbitrary initial heap content. Let P denote a history fragment starting from an initially empty heap, that consists of at most K successful insert operations. To specify behavior of H for an arbitrary initial heap, let [formula] (where [formula] denotes catenation). A heap implementation is available if, for each history H of operations, there exists P such that H' satisfies constraint (a), each operation in H' has O(lgK) running time, and any insert operation following any point t fails if |Ct| = K (but is allowed to fail even if |Ct|  ≠  K). The construction of Section [\ref=implementation] satisfies availability, as shown by Lemma [\ref=avail], by choosing P to be a sequence of insert operations for the items of the active tree at the initial state. The simplest heap implementation satisfying availability is one that returns a failing response to every operation (P is empty and the heap content is continuously empty in this case).

Stabilization is also a weakening of (a)-(c). Let Ht denote the suffix of history H following point t. A heap implementation is stabilizing if, for each history H of operations, there exists P (a history fragment of successful insert operations) and a point t such that (a)-(c) hold for [formula]. We call the history prefix C satisfying [formula] the convergence period of H. The construction of Section [\ref=implementation] is stabilizing by choosing P to contain insert  operations for the active tree at some point t that exists by Lemma [\ref=converge]. The definition of stabilization permits operations to arbitrarily succeed or fail during the convergence period, and a deleteMin operation could return a value unrelated to heap content within the convergence period. A plausible stabilizing heap implementation is one that resets the heap content to be empty whenever some inconsistency is detected during the processing of an operation (resetting the heap amounts to establishing a legitimate "initial" state for subsequent operations).

Discussion

The heap construction presented here satisfies desired availability properties: success or failure in an operation response is a reliable indication of the operation's result on the data structure. We have not addressed the issue of relating heap damage to the extent of a fault -- if a fault somehow sets .  =    ∞   then the entire heap contents are lost by our construction. Our intent is to separate concerns by first developing a stabilizing heap, and then later adding logic for limited cases of corrupted items. This is a topic for future work.

Acknowledgment. We thank anonymous referees for helpful comments. We are especially grateful for careful criticisms by Professor Mohamed Gouda, which guided us to improve the presentation.