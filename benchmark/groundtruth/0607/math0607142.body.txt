Eigenvectors and Reconstruction

Introduction

We start by fixing some notations. Let A be a n  ×  n real symmetric matrix. Let Ai be the matrice obtaining by deleting the i-th row and i-th column of A. We say that two symmetric matrices A and B are hypomorphic if Bi can be obtained by permuting the rows and columns of Ai simultaneously. Let Σ be the set of permutations. We write B = Σ(A). If M is a symmetric real matrix, then the eigenvalues of M are real. We write

[formula]

If α is an eigenvalue of M, we denote the corresponding eigenspace by eigenα(M). Let [formula] be the n-dimensional vector [formula]. Put [formula].

Let B and A be two real n  ×  n symmetric matrices. Let Σ be a hypomorphism such that B = Σ(A). Let t be a real number. Then there exists an open interval T such that for t∈T we have

[formula];

[formula] and [formula] are both one dimensional;

[formula]

As proved in  [\cite=he], our result implies Tutte's theorem which says that eigen(A + tJ) = eigen(B + tJ). In this paper, we shall study the eigenvectors of A and B. We first prove that the squares of the entries of simple unit eigenvectors of A can be reconstructed as functions of eiegn(A) and eigen(Ai). This yields a proof of a Theorem of Godsil-McKay. We also study how the eigenvectors of A change after a purturbation of a rank 1 symmetric matrices. Combined with Theorem  [\ref=main], we prove another result of Godsil-McKay which states that the simple eigenvectors that are perpenticular to [formula] are reconstructible. We further show that the orthogonal projection of [formula] onto higher dimensional eigenspaces is reconstructible. Our investigation indicates that the following conjecture could be true.

Let A be a real n  ×  n symmetric matrix. Then there exists a subgroup G(A)  ⊆  O(n) such that a real symmetric matrix B satisfies the properties that eigen(B) = eigen(A) and eigen(Bi) = eigen(Ai) for each i if and only if B  =  UAUt for some U∈G(A).

This conjecture is clearly true if rank(A) = 1. For rank(A) = 1, the group G(A) can be chosen as [formula], all in the form of diagonal matrices. In some other cases, G(A) can be a subgroup of the permutation group Sn.

The group G(A) can be chosen to be a twisted product of a subgroup of Sn with [formula].

Clearly, this conjecture implies the reconstruction conjecture.

Reconstruction of Square Functions

Let A be a n  ×  n real symmetric matrix. Let [formula] be the eigenvalues of A. Suppose λi is a simple eigenvalue of A. Let [formula] be a unit vector in eigenλi(A). Then for every m, p2m,i can be expressed as a function of eigen(A) and eigen(Am).

Proof: Let λi be a simple eigenvalue of A. Let [formula] be a unit vector in eigenλi(A). There exists an orthogonal matrix P such that [formula] and A = PDPt where

[formula]

Then

[formula]

which equals

[formula]

Deleting the m-th row and m-th column, we obtain

[formula]

This is Am  -  λiIn - 1. Notice that P is orthogonal. Taking the determinant, we have

[formula]

It follows that

[formula]

Q.E.D.

Let A and B be two n  ×  n real symmetric matrices. Suppose that eigen(A) = eigen(B) and eigen(Ai) = eigen(Bi). Let λi be a simple eigenvalue of A and B. Let [formula] be a unit vector in eigenλi(A) and [formula] be a unit vector in eigenλi(B). Then

[formula]

Let A and B be two n  ×  n real symmetric matrices. Suppose that A and B are hypomorphic. Let λi be a simple eigenvalue of A and B. Let [formula] be a unit vector in eigenλi(A) and [formula] be a unit vector in eigenλi(B). Then

[formula]

Eigenvalues and Eigenvectors under the perturbation of a rank one symmetric matrix

Let A be a n  ×  n real symmetric matrix. Let x be a n-dimensional row column vector. Let M = xxt. Now consider A + tM. We have

[formula]

Let Ptx = q. So [formula] for each i∈[1,n]. Then

[formula]

Put D(t) = D + tqqt.

[formula]

Proof: det (D - λI + tqqt) can be written as a sum of products of λi  -  λ and qiqj. For each S a subset of

[formula]

det(D+t q q-λ I) = (λ- λ)+ t q (λ -λ).

[formula]

λ > μ > λ > μ > > μ > λ > μ.

[formula]

S= { i > i > > i }

[formula]

λ > μ > λ > μ > > λ > μ

[formula]

eigen(A+ t M )={ λ(A) | i ∉ S } {μ, μ , μ }.

[formula]

p .

[formula]

μ > λ > μ > λ > > μ > λ.

[formula]

P(λ)=1+ .

[formula]

λ > μ > λ > μ > > λ > μ.

[formula]

eigen(A+ t M)= { λ(A) | i ∉ S } {μ, μ , μ }.

[formula]

p= p.

[formula]

(A+ t M ) p = P(D+ t q q) P p =P(D+t q q) ( ),

[formula]

P ( ( )+ t ( ) )= P ( ( )- ( ) )=P ( ).

[formula]

(A+ t M) p= μ P ( )= μ p.

[formula]

p ∈ eigen(A+t M ).

[formula]

Reconstruction of Simple Eigenvectors not perpenticular to [formula]

Now let [formula]. Theorem  [\ref=main0] applies to [formula] and [formula].

Let B and A be two real n  ×  n symmetric matrices. Let Σ be a hypomorphism such that B = Σ(A). Then there exists a subset S  ⊆  [1,n] such that A = PDPt and B = UDUt as in Theorem  [\ref=main0]. For i∈S, we have [formula] or [formula]. In particular, if λi is a simple eigenvalue of A and [formula], then eigenλi(A) = eigenλi(B).

Proof: [formula] By Tutte's theorem, eigen(A) = eigen(B). Let A = PDPt and B = UDUt. Since [formula]. By Lemma  [\ref=det],

[formula]

It follows that for every λi, [formula]. Consequently, the l for A is the same as the l for B. Let S be as in Theorem  [\ref=main0] for both A and B. Without loss of generality, suppose that A = PDPt and B = UDUt as in Theorem  [\ref=main0]. In particular, for every i∈[1,n], we have

[formula]

[formula] Let T be as in Theorem  [\ref=main] for A and B. Without loss of generality, suppose [formula]. Let μl(t) be the μl in Theorem  [\ref=main0] for A and B. Notice that the lowest eigenvectors of [formula] and [formula] are in [formula] and they are not perpenticular to [formula]. By Theorem  [\ref=main0], [formula]. By Theorem  [\ref=main],

[formula]

So

[formula]

Since [formula] and [formula] are orthogonal, by Equation  [\ref=1],

[formula]

It follows that for every t∈T,

[formula]

[formula] Recall that [formula]. Notice that the function [formula] is a continuous and one-to-one mapping from ( -   ∞  ,λn) onto (0,  ∞  ). There exists a nonempty interval T0  ⊆  ( -   ∞  ,λn) such that if ρ∈T0, then [formula]. So every ρ∈T0 is a μl(t) for some t∈(t1,t2). It follow that for every ρ∈T0,

[formula]

Notice that both vectors are nonzero and depend continuously on ρ. Either,

[formula]

or,

[formula]

[formula]. Notice that the functions [formula] are linearly independent. For every i∈S, we have

[formula]

Because [formula] and [formula] are both unit vectors, [formula]. In particular, for every simple λi with [formula] we have eigenλi(A) = eigenλi(B). Q.E.D.

Let B and A be two real n  ×  n symmetric matrices. Let Σ be a hypomorphism such that B = Σ(A). Let λi be an eigenvalue of A such that [formula]. Then the orthogonal projection of [formula] onto eigenλi(A) equals the orthogonal projection of [formula] onto eigenλi(B).

Proof: Notice that the projections are [formula] and [formula]. Whether [formula] or [formula],

[formula]

Q.E.D.

Let A and B be two hypomorphic matrices. Let λi be a simple eigenvalue of A. Then there exists a permutation matrix τ such that τeigenλi(A) = eigenλi(B).

This conjecture is apparently true if eigenλi(A) is not perpenticular to [formula].