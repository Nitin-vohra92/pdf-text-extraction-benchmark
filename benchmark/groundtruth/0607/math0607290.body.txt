Proposition Lemma Corollary Remark Example Definition

Existence and uniqueness of maximizing measures for robust classes of local diffeomorphisms

Introduction

In its most basic form, the variational principle states that the topological entropy of a continuous transformation on a compact space coincides with the supremum of the entropies of the probability measures invariant under the transformation. We call maximizing measure any invariant probability for which the supremum is attained. Existence and uniqueness of such measures has been investigated by many authors, in a wide variety of situations. However, the global picture is still very much incomplete.

In this paper we contribute a simple sufficient condition for existence and uniqueness, applicable to a large class of transformations. Some examples we have in mind are the non-uniformly expanding local diffeomorphisms of Alves, Bonatti, Viana [\cite=ABV00], which exhibit only positive Lyapunov exponents at "most" points. But our hypothesis, formulated in [\eqref=eq.condicao] below, is a condition of the type that Buzzi [\cite=Bu99] [\cite=Bu00] introduced and called entropy-expansivity: we only ask that the derivative do not expand k-dimensional volume too much, for all k less than the dimension of the ambient manifold. We show that this implies existence and, if the transformation is topologically mixing, uniqueness of the maximizing measure.

Statement of main result

Let f:Md  →  Md be a C1 local diffeomorphism on a compact d-dimensional Riemannian manifold. Let p  ≥  1 be the degree of f, that is, the number #  f- 1(x) of preimages of any point x∈M. Define

[formula]

where Λk represents the kth exterior product. We assume that f satisfies

[formula]

We say that f:M  →  M is topologically mixing if given any open set U there exists [formula] such that fN(U) = M. We are going to prove the following

The Ruelle-Perron-Frobenius transfer operator of f:M  →  M is the bounded linear operator L:C(M)  →  C(M) defined on the space C(M) of continuous functions [formula] by

[formula]

Observe that this is a positive operator. Its dual L*:M(M)  →  M(M) acts on the space of Borel measures of M, by

[formula]

preserving the cone of positive measures, and the subset of probability measures.

It is easy to see that the spectra of L and L* are contained in the closed disk of radius p. We call maximal eigenmeasure any probability measure μ that satisfies

[formula]

It is well-known that maximal eigenmeasures do exist. A quick proof goes as follows. Define G:M1  →  M1 on the space of probabilities M1 on M by

[formula]

Then G is continuous relative to the weak* topology on M1. Since M1 is a convex compact space, we may use the Tychonoff-Schauder theorem to conclude that there exists some probability μ such G(μ) = μ. In other words, μ is a maximal eigenmeasure. Observe also that μ is invariant for f. In fact, for every continuous function g we have that [formula] and

[formula]

The paper is organized as follows. In Section [\ref=s.measures] we prove that, under our assumptions, any measure with large entropy has only positive Lyapunov exponents. In Section [\ref=s.generating] we prove that measures with positive Lyapunov exponents admits generating partitions with small diameter. This conclusion uses the notion of hyperbolic times, that we recall in Section [\ref=s.hyperbolic]. On its turn, it is used in Section [\ref=s.rokhlin] to show that the entropy of such measures is given by a simple formula involving the Jacobian. Using this formula, we prove in Section [\ref=s.existence] that the topological entropy is log p and is attained by any maximal eigenmeasure. Finally, in Section [\ref=s.uniqueness] we prove that the maximal measure is unique if the transformation is topologically mixing.

Acknowledgements. We are thankful to Ví tor Araújo for a conversation that helped clarify the arguments in the last section.

Measures with large entropy

By Oseledets [\cite=Os68], if μ is an f-invariant probability measure then for μ-almost every point x∈M there is k = k(x)  ≥  1, a filtration

[formula]

and numbers [formula] such Df(x)Fix  =  Fif(x) and

[formula]

for every [formula] and [formula]. The numbers λ̂i(x) are called Lyapunov exponents of f at the point x. The multiplicity of λi(x) is dim Fix  -   dim Fi + 1x. We also write the Lyapunov exponents as

[formula]

where each number is repeated according to the corresponding multiplicity. Then the integrated Lyapunov exponents are the averages

[formula]

Given a vector space V and a number k  ≥  1, the kth exterior power of V is the vector space of all alternate k-linear forms defined on the dual of V. We always take V to be finite-dimensional, and then the exterior product ΛkV admits an alternative description, as the linear space spanned by the wedge products [formula] of vectors [formula] in V. Assuming V comes with an inner product, we can endow ΛkV with a inner product such that [formula] is just the volume of the k-dimensional parallelepiped determined by the vectors [formula] in V.

A linear isomorphism A:V  →  W induces another, ΛkA:ΛkV  →  ΛkW, through

[formula]

When V = W, the eigenvalues of ΛkA are just the products of k distinct eigenvalues of A (where an eigenvalue with multiplicity m is counted as m "distinct" eigenvalues). Correspondingly, there is a simple relation between the Lyapunov spectra of ΛkDf and Df: the Lyapunov exponents of ΛkDf are the sums of k distinct Lyapunov exponents of Df, with the same convention as before concerning multiplicities. Thus,

[formula]

for any [formula], and our hypothesis [\eqref=eq.condicao] implies that these sums are strictly smaller than log p, for all k < d.

If μ is an invariant probability with some integrated Lyapunov exponent less than

[formula]

then hμ(f) <  log p.

Let μ be an invariant probability, and suppose [formula]. As we have just seen, [\eqref=eq.condicao] implies that [formula] for all 1  ≤  k < d. Then, using the Ruelle inequality [\cite=Rue78],

[formula]

This proves the lemma.

Hyperbolic times

For the next step we need the notion of hyperbolic times, introduced by Alves et al [\cite=Al00] [\cite=ABV00]. Given c > 0, we say that [formula] is a c-hyperbolic time for x∈M if

[formula]

In what follows we fix c = c(f) / 10 and speak, simply, of hyperbolic times. We say that f has positive density of hyperbolic times for x if the set Hx of integers which are hyperbolic times of f for x satisfies

[formula]

We quote a few basic properties from [\cite=ABV00] (alternatively, see [\cite=Ol03]):

If a point x satisfies

[formula]

then f has positive density of hyperbolic times for x.

In fact, the density, that is, the lim inf  in [\eqref=eq.density], is bounded below by some positive constant that depends only on f (and our choice of c).

There exists δ0 > 0, depending only on f and c, such that given any hyperbolic time n  ≥  1 for a point x∈M, and given any 1  ≤  j  ≤  n, the inverse branch f- jx,n of fj that sends fn(x) to fn - j(x) is defined on the whole ball of radius δ0 around fn(x), and satisfies

[formula]

for every z, w in that ball.

In view of Lemma [\ref=l.entropiagrande], the next lemma applies to any invariant measure μ with hμ(f)  ≥   log p.

Given an invariant ergodic measure μ whose Lyapunov exponents are all bigger than 8c, there exists [formula] such that fN has positive density of hyperbolic times for μ-almost every point.

Since all Lyapunov exponents of μ are greater than 8c, for almost every x∈M there exists n0(x)  ≥  1 such that

[formula]

In other words,

[formula]

Define αn  =  μ({x:n0(x) > n}). Since f is a local diffeomorphism, we may also fix a constant K > 0 such [formula] for all x∈M. Then

[formula]

Since αn goes to zero when n goes to infinity, by choosing N big enough we ensure that

[formula]

Then, since μ is ergodic,

[formula]

This means that we may apply Lemma [\ref=l.integral] to conclude.

According to the remark following Lemma [\ref=l.integral], we even have that the density of hyperbolic times is bounded below by some positive constant that depends only on fN (and our choice of c).

Let B  ⊂  M, θ > 0, and g:M  →  M be a local diffeomorphism such that g has density > 2θ of hyperbolic times for every x∈B. Then, given any probability measure ν on B and any m  ≥  1, there exists n  >  m such that

[formula]

Define H to be the set of pairs [formula] such that n is a hyperbolic time for x. For each k  ≥  1, let χk be the normalized counting measure on the time interval

[formula]

χH({x}×) > 2 θ

[formula]

νH(B×{n})) > θ

[formula]

Generating partitions

In all that follows the constant δ0 > 0 is fixed as given by Lemma [\ref=l.contracao]. Given a partition α of M, we define

[formula]

If μ is an invariant measure such that all its Lyapunov exponents are bigger than 8c, and α is a partition with diameter less than δ0, for μ-almost every x∈M, the diameter of αn(x) goes to zero when n goes to ∞  . In particular, α is an f-generating partition with respect to μ.

By Lemma [\ref=l.iterados] there exists N  ≥  1 such that fN has positive density of hyperbolic times for μ-almost every point. Define

[formula]

By Lemma [\ref=l.contracao], if k is a hyperbolic time of fN for x then [formula]. In particular, since the sets γk(x) are non-increasing with k, the diameter of γk(x) goes to zero when k  →    ∞  . Since αkN(x)  ⊂  γk(x) and the sequence [formula] is non-increasing, this immediatelly gives that the diameter of αn(x) goes to zero when n goes to infinity, for μ-almost every x∈M.

The rest of the argument is very standard. It goes as follows. To prove that α is a generating partition for f with respect to μ, it suffices to show that, given any measurable set E and any ε > 0, there exists n  ≥  1 and elements Ain, [formula] of αn such that

[formula]

Consider compact sets K1  ⊂  A and K2  ⊂  Ac such that μ(K1ΔA) and μ(K2ΔAc) are both less than ε / 4. Fix n  ≥  1 large enough so that [formula] is smaller than the distance from K1 to K2 outside a set of points x with measure less than ε / 4. Let Ain, [formula] be the sets αn(x) that intersect K1. Then, they are all disjoint from K2, and so [formula] is bounded above by

[formula]

This completes the proof.

Rokhlin's formula

The Jacobian of a measure μ with respect to f is the (essentially unique) function Jμf satisfying

[formula]

for any measurable set A such that f|A is injective.

In other words, the Jacobian is defined by [formula]. Jacobians for every measure do exist in this context, because f is finite-to-one (countable-to-one would suffice). Using the definition, one can verify that [formula] is a Jacobian for each fn. In the case of μ is an invariant measure, we observe that from the definition follows that Jμf  ≥  1 in μ-almost everywhere.

Let f:M  →  M be a measurable transformation, μ be an invariant probability. Suppose there exists a finite or countable partition α of M such that

f is locally injective, meaning that it is injective on every atom of α;

α is f-generating with respect to μ, in the sense that [formula] for μ-almost every x.

If μ is an invariant measure satisfying (a) and (b) as above, then

[formula]

where Jμf denotes any Jacobian of f relative to μ.

Let [formula]. Denote [formula] and [formula] for each n  ≥  1. Notice that β∞(x) = f- 1(α∞(f(x))). The hypothesis that α is generating implies that α∞(x) = {x}, and so

[formula]

The conditional expectation of a function [formula] relative to a partition γ is the essentially unique γ-measurable function Eμ(φ|γ) such that

[formula]

for every γ-measurable set B.

[formula] for μ-almost every x.

It is clear that the function on the right hand side is β∞-measurable. Let B be any β∞-measurable set, that is, any measurable set that consists of entire atoms of β∞. By [\eqref=eq.sat], there exists a measurable set C such that B = f- 1(C). Then, since μ is invariant,

[formula]

where [formula] and yA = (f|A)- 1(z). Since every f|A is injective, we may use the definition of the Jacobian to rewrite the latter expression as

[formula]

This proves [\eqref=eq.expect1] and the lemma.

For [formula], define the conditional entropy (Definition 4.8 in [\cite=Wa82])

[formula]

[formula] for [formula].

[formula].

For [formula], the partition βn is countable, and so

[formula]

for every A∈α. It follows that

[formula]

This gives the first statement. Next, Lemma [\ref=l.Emu] says that

[formula]

Notice that if z∈f(A) then ψA(z) = 1 / Jμf(yA), where yA = (f|A)- 1(z), and if z∉f(A) then ψA(z) = 0. Therefore,

[formula]

Using the definition of Jacobian, and the assumption that f is injective on A, this gives

[formula]

as claimed.

Since the partition α is generating, hμ(f)  =  hμ(f,α). Then,

[formula]

by Theorem 4.14 of [\cite=Wa82]. Combined with the second part of Lemma [\ref=l.entropia], this gives [formula], as claimed.

Existence

Here we prove that every maximal eigenmeasure is a maximizing measure. The first step is

If μ is a maximal eigenmeasure then Jμf is constant equal to p.

Let A be any measurable set such that f|A is injective. Take a sequence {gn}∈C(M) such that gn  →  χA at μ-almost every point and sup |gn|  ≤  2 for all n. By definition,

[formula]

The last expression converges to χf(A)(x) at μ-almost every point. Hence, by the dominated convergence theorem,

[formula]

Since the left hand side also converges to [formula], we conclude that

[formula]

which proves the lemma.

If μ is a maximal eigenmeasure then hμ(f)  ≥   log p.

We define the dynamical ball Bε(n,x) by

[formula]

If ε small enough so that fn|Bε(n,x) is injective, then:

[formula]

In particular, we may conclude that

[formula]

for every n and ε small. By the Brin-Katok local entropy formula (see [\cite=Man87])

[formula]

This proves the lemma.

Every maximal eigenmeasure μ has entropy equal to log p.

By Lemma [\ref=l.eigenentropy], the entropy is at least log p. Then, we may apply Lemma [\ref=l.entropiagrande] to conclude that all Lyapunov exponents of μ are positive. It follows, by Lemma [\ref=l.partition], that μ admits generating partitions with small diameter. Hence, we may apply Proposition [\ref=p.rokhlinformula] and Lemma [\ref=l.jacobian], to find that [formula].

The topological entropy htop(f)  =   log p. Moreover, if η is any ergodic maximizing measure then the Jacobian Jηf is constant equal to p.

Consider any probability η such hη(f)  ≥   log p. By Lemma [\ref=l.entropiagrande] all Lyapunov exponents of η are bigger than c(f). Then, by Lemma [\ref=l.partition], there exist generating partitions with arbitrarily small diameter. This ensures we may apply Proposition [\ref=p.rokhlinformula] to η. We get that

[formula]

Let us write gη  =  1 / (Jηf). The assumption that η is invariant means that

[formula]

for η-almost every x∈M. From the previous equality, we find

[formula]

where the first equality uses gη = 1 / Jηf. Using the Jensen inequality:

[formula]

at η-almost every point. Since the integral is non-negative, by [\eqref=eq.quaseentropia], the equality must hold η-almost everywhere, and hη(f)  -   log p  =  0. Since η is arbitrary, this proves that log p  =  htop(f).

From the last part of Lemma [\ref=l.calculus], we get that the values of log p -  1  /  gη(y) are the same for all y∈f- 1(x). In other words, for η-almost every x∈M there exists a number c(x) such that p -  1  /  gη(y)  =  c(x) for every y∈f- 1(x). Then

[formula]

for η-almost every x. This means, precisely, that Jηf(y)  =  p for every y on the pre-image of a full η-measure set.

Uniqueness

In this section we assume f is topologically mixing, and conclude that the maximizing measure is unique and supported on the whole ambient M. It suffices to consider ergodic measures, because the ergodic components of maximizing measures are also maximizing measures.

Any ergodic maximizing measure μ is supported on the whole M.

Suppose μ(U) = 0 for some non-empty open set U. By the mixing assumption, there exists N  ≥  1 such fN(U) = M. Partitioning U into subsets U1, , Uk such that every fN|Uj is injective, we get that

[formula]

for [formula]. Recall Lemma [\ref=l.grau]. This implies that μ(M) = μ((fN(U)) = 0, which is a contradiction.

This has the following useful consequence: given any δ > 0 there exist b = b(δ) > 0 such that

[formula]

Indeed, if there were points such that the balls of radius δ around them have arbitrarily small measures then, considering an accumulation point, one would get a ball with zero measure, and that would contradict Lemma [\ref=l.support].

Now let μ1 and μ2 be any two ergodic maximizing measures. Our goal is to prove that the two measures coincide. As a first step we prove that they are equivalent. For this, we fix any (finite) partition P of M into subsets P such that P has non-empty interior, and the boundary ∂P has zero measure for both μ1 and μ2. Fixing δ > 0 small so that every P∈P contains some ball of radius δ, and applying [\eqref=eq.bedelta] to both measures, we conclude that there exists B > 0 such that

[formula]

Now let g be an inverse branch of any iterate fn, n  ≥  1. Using Lemma [\ref=l.grau], we get that μi(P) = pnμi(g(P)) for i = 1,2. It follows that [\eqref=eq.equivalencia1] remains valid for the images g(P):

[formula]

for every P∈P and every inverse branch g of fn, for any n  ≥  1. We denote by Q the family of all such images g(P).

Given any measurable set E  ⊂  M and any ε > 0 there exists a family E of pairwise disjoint elements of Q such that

[formula]

By Lemma [\ref=l.entropiagrande], all Lyapunov exponents of μi are larger than c(f). Hence, by Lemma [\ref=l.iterados] and the remark following it, there exists N  ≥  1 and θ > 0 such that μi-almost every point has density >  2θ of hyperbolic times.

Let U1 be an open set and K1 be a compact set such that K1  ⊂  E  ⊂  U1 and [formula] for i = 1,2 and μi(K1)  ≥  (1 / 2)μ(E). Using Lemma [\ref=l.fubini] with B = K1 and ν  =  μi  /  μi(K1), we may find n1  ≥  1 such that e- cn1  <  d(K1,Uc1) and the subset L1 of points x∈K1 for which n1 is a hyperbolic time satisfies μi(L1)  ≥  θμi(K1)  ≥  (θ / 2)μi(E). Let E1 the family of all g(P) that intersect L1, with P∈P and g an inverse branch of fn1. Notice that the elements of E1 are pairwise disjoint, because the elements of P are pairwise disjoint. Moreover, by Lemma [\ref=l.contracao], their diameter is less than e- cn1. Thus, the union E1 of all the elements of E1 is contained in U1. By construction, it satisfies

[formula]

Next, consider the open set [formula] and let [formula] be a compact set such that [formula]. Observe [formula] because the boundaries of the atoms of P have zero measure and that is preserved by the inverse branches, since μi is invariant. Reasoning as before, we may find n2 > n1 such that e- cn2  <  d(K2,Uc2) and a set L2  ⊂  K2 such that μi(L2)  ≥  θμi(K2) and n2 is a hyperbolic time for every x∈L2. Denote by E2 the family of inverse images g(P) that intersect L2, with P∈P and g an inverse branch of fn2. As before, the elements of E2 are pairwise disjoint, and their diameters are smaller than e- cn2. The latter ensures that their union E2 is contained in U2. Consequently, the elements of the union [formula] are also pairwise disjoint. Moreover,

[formula]

Repeating this procedure, we construct families Ek, k  ≥  1 of elements of Q such that their elements are all pairwise disjoint and contained in U1, and

[formula]

for all k  ≥  1, where [formula]. Thus, [formula] for i = 1,2, and [\eqref=eq.interests] implies that

[formula]

This completes the proof of the lemma, with [formula].

The lemma remains true if one asks that [formula] for both i = 1,2. This follows from a variation of the previous construction, considering each one of the two measures alternately: for each k  ≥  1 consider [formula]; then ask that [formula], and choose nk such that μi(Lk)  ≥  θμ(Kk). The same kind of argument applies with any number of probability measures [formula]. These extensions will not be used here.

Combining [\eqref=eq.equivalencia2] with Lemma [\ref=l.exaustao], we get that, for any measurable set E  ⊂  M,

[formula]

As ε > 0 is arbitrary, we get that μ1(E)  ≤  Bμ2(E). A symmetric argument gives that μ2(E)  ≤  Bμ1(E) for any measurable set E. This implies that μ1  =  hμ2 where the Radon-Nikodym derivative h satisfies B- 1  ≤  h  ≤  B. Since μ1 and μ2 are invariant measures,

[formula]

As the Radon-Nikodym derivative is essentially unique, we get that [formula] at μ2-almost every point. By ergodicity, it follows that h is constant almost everywhere. Since the μi are both probabilities, we get that h = 1 and so μ1  =  μ2. This proves uniqueness of the maximizing measure.

Krerley Oliveira ( krerleymat.ufal.br ) Departamento de Matemática - UFAL, Campus A.C. Simões, s/n 57072-090 Maceió, Alagoas - Brazil

Marcelo Viana ( viana.br ) IMPA, Est. D. Castorina 110 22460-320 Rio de Janeiro, RJ, Brazil