The effect of Planck scale space time fluctuations on Lorentz invariance at extreme speeds

Richard Lieu

Department of Physics, University of Alabama, Huntsville, AL 35899, U.S.A.

Abstract

The starting point of this work is the axiomatic existence of a smallest measurable interval, viz. the Planck time tP, set by quantum fluctuations in the vacuum metric tensor. By the Relativity Principle, the same limit must then apply to the accuracy of all clocks which register time of events in their own frames. Further, it implies that the ordinary meaning of distance also ceases in the same manner beyond a scale lP  =  ctP. We demonstrate that quantum space-time, if real, may be made manifest by observing very energetic collisions, defined as interactions which occurred with the center-of-mass frame Σ' (of the participating bodies) moving at a high speed v relative to our laboratory frame Σ. In such situations, the initial conditions of the interaction are determined from direct measurements of the ultra-energetic particles or photons by instruments aboard Σ: they gather a raw dataset S which are subject to the limiting uncertainties ~  (tP,lP). Yet a meaningful (i.e. experimentally verified) version of the interaction is one where the interaction is viewed from frame Σ'. Since no instruments aboard Σ' have taken any data, the way we proceeded is by a Lorentz transformation of S from Σ to Σ'. Beware however that the resulting S' no longer consists of raw data, i.e. Lorentz distortions of probability distributions render the uncertainties non-Planckian - in fact, it will be shown that as v  →  c they are ≫   (tP,lP), and are no longer negligible. Examples will given to indicate how a proper interpretation of the most current high energy cosmic and gamma-ray data necessitates incorporation of the said effect.

At present no one knows the design of the most precise clock. There is nonetheless a broad agreement that the unsurpassable limit is ~   tP (see, e.g. Wilczek 2001), because to achieve such an accuracy a large amount of energy (hence mass) has to be confined within a small region of space - the result is a black hole. We shall therefore begin with a standard deviation σt, which is ~  tP, and postulate that all clocks which keep time aboard their respective inertial platforms carry the same intrinsic uncertainty of σt (cf Principle of Relativity). The measurement of space by an inertial observer must then be subject to an error σx  =  cσt, since by special relativity this simply involves light beams and synchronized clocks. Scale sizes like tP and lP, though extremely small, may soon be probed by interferometric experiments (Camelia 2001, Abramovici 1996). Here we propose another way of testing the discreteness of time, by observing the behavior of ultra-energetic particles and photons.

Let us now consider the effect of frame transformation on space-time data. Suppose two inertial observers Σ and Σ' construct their own frames of reference having spatial axes oriented in the same way, and that Σ' moves relative to Σ with a speed v along the + x direction. Suppose further that Σ and Σ' used instruments aboard their own platforms to locate an event, with the results (x,y,z,t) and (x',y',z',t') respectively, which we shall henceforth refer to as raw data (to distinguish them, in particular, from data which emerge from frame transformations). According to our postulate, intrinsically both sets of coordinates are equally inaccurate to within ±  cσt for x, y, z (and x', y', z') and ±  σt for t (and t'). This indicates the absence of a preferred frame, and remains valid so long as the two observers measure the event by their own clocks and light beams. The symmetry will be broken, however, if e.g. Σ' fails to take his own data, but monitors the event solely from the data taken by Σ. In that case, the original raw data of Σ would appear meaningless to Σ' until they are processed by the Lorentz transformation L which necessarily alters the uncertainties.

For a quantitative estimation of the effect, we note that according to L:

[formula]

where [formula]. Obviously, then, y' and z' remain uncertain by cσt. To calculate the uncertainies of x' and t' one must add those of x and t in quadrature, because these two coordinates were directly and separately measured by Σ their errors are independent (and, for the same reason, of magnitude cσt and σt respectively). Thus we have:

[formula]

In general, Eq. (2) indicates that σx'  ≥  σx, σt'  ≥  σt. Further, σx' and σt' are no longer independent errors. Unlike σx and σt, they cannot be added in quadrature.

It should be emphasized that, among the consequences which may ensue from Eq. (2), violation of the Principle of Relativity is not one of them. The coordinates x' and t' carry correlated errors larger than the intrinsic values because they are not raw data. Had Σ' performed his own measurements, the results would fundamentally have been limited by the quantum space-time fluctuations (σt,cσt) in exactly the same way as those of Σ. Any such data taken directly by Σ', when compared with the transformed data of Σ (which by Eq (2) carry larger errors) could lead to disagreement. Conversely, if Σ' were to transform by L- 1 his own data to the Σ frame, the results would likewise be subject to the same error amplification and correlation as depicted in Eq (2), and could disagree with the measurements done by Σ himself. Moreover, the symmetry imposed by the Principle of Relativity tells us that the two observers could continue to argue about 'who is correct'. Neither in fact is on a privileged platform. Rather, the source of the discrepancy lies with the fact that when raw data are processed L they inevitably emerge with larger than intrinsic (Planckian) uncertainties. This is a feature of L which we have hitherto ignored.

The significance of Eq (2) depends on the situation it applies to. As an example, let Σ measure the decay time of a fast-moving particle, which we assume to be at rest relative to Σ'. The result, denoted by τ, is simply obtained by taking the difference between two time coordinates, each of which is subject independently to the same random uncertainty σt, i.e. τ  =  t2  -  t1 and [formula]. Likewise, if Σ' were to measure this particle directly his result τ' will also be accurate to [formula]. Now suppose no data were ever gathered aboard Σ', and the only information available concerning the rest lifetime τ' of the particle is the measurement of Σ after Lorentz transformation to the Σ' frame. From Eq (2) we see that L enlarges intrinsic uncertainties by the factor [formula] when v  →  c. This means, had Σ' done his own measurement and compared it with the transformed data of Σ there may, in the case γ  ≫  1, be substantial discrepancies on the value of the rest life τ'. One could insist upon a shorter lifetime than the other, which renders it inevitable that they could disagree with each other in a random manner on whether the decay has taken place or not (the 'time sequencing' problem which will not be discussed in detail here). The transformed data of Σ carry a relative (percentage) uncertainty of 2γσt  /  τ', which exceeds that for the raw data of Σ' and Σ by a factor of [formula] and [formula] respectively. The reliance of Σ' on the measurement of Σ can no longer be justified when this relative error 2γσt  /  τ' is ≥  1, which happens for sufficiently large γ.

In the present work we pursue to some depth the impact of the above development on another common usage of L. Often the physics of ultra-energetic quanta cannot at all be perceived in our laboratory frame Σ - we must transform its parameters which we measured aboard Σ to another frame Σ' before any sensible conclusions on the nature and fate of the subject can be drawn. As an example, consider a 1020 cosmic ray proton in the vicinity of a 3K microwave background photon. While we may have data about the two bodies taken by laboratory detectors working in the Σ frame, no experiments done aboard Σ have ever directly witnessed how they may interact. However, from the viewpoint of the proton rest frame Σ' a 3K photon appears, according to our laboratory data of the two particles after transformation by L, as having sufficient energy to cross the photo-pion production threshold. This reveals a familiar occurence in our own environment (viz. pions from photon-proton interactions) which, by the Principle of Relativity, must happen aboard Σ' as well. Thus we conclude that aboard Σ one necessarily encounters pions, and the required energy is now drawn from the fast proton. The logic of the above reasoning is sound except for one point: it presumes that L remains highly accurate when the relative motion between Σ and Σ' involves a Lorentz factor as large as γ  ~  1011.

In order to address this point, we must realize that once time and space fluctuate intrinsically the components of all four-vectors will behave similarly. The following example shows how to quantitatively secure the connection. Consider a plane light wave. If by some means the wave frequency ν is very precisely known in the regime ν  >  1 / σt we will be able to use the wave as a 'super-clock' to overcome quantum limitations - which by assumption is impossible. An equivalent manner of expression would state that any value of ν can only be determined to an accuracy σν  /  ν  ~  νσt.

A more rigorous approach to the problem, with something similar to the above as an outcome, is afforded by the following abstraction of the measurement procedure. Let the wave phase be written as φ  =  (ωt  -  kx cos θ) / c where θ is the angle which the wavevector [formula] makes w.r.t. + x. All the basic information about the wave have to do with one cycle of oscillation when:

[formula]

Denoting any possible variations in the Δ's by the δ's, we have:

[formula]

Eq (4) embodies the manner by which space-time fluctuations lead to limitations in our knowledge of the wave properties. To elucidate this, we examine the simplest case θ  =  0, and note that the angular frequency is by definition ω  =  2π  /  Δt where Δt refers to the time interval (cf. the aforementioned τ) satisfying Eq (3) in the limit of vanishing space interval, Δx  =  0, during which Eq (4) reduces to δω  /  ω  =    -  δt / Δt  +   cos θ(δx / cΔt). The limiting ω uncertainty is obtained, by treating (δt,δx) as independent random errors of magnitude [formula], to be:

[formula]

or simply σν  /  ν  ~  νσt, as before.

Likewise, the quantity k cos θ, defined as =  2π  /  Δx where Δx refers to the value satisfying Eq. (3) in the case Δt = 0. Thus, using again Eq (4) and arguments similar to those which follow this equation lead to the result:

[formula]

where in deriving Eq (6) it is also assumed that a real (on-shell) photon satisfying ω / k  =  c is detected in our laboratory.

Once the original data of Σ are Lorentz transformed to the Σ' frame the frequency will assume a value ω' given by:

[formula]

From the foregoing treatment it is plain that our laboratory 'energy-momentum' measurements of ω and (k cos θ), like those of t and x, must be regarded as independent. Thus when ω' is inferred from ω and k cos θ by means of Eq (7), the result carries an error σω' of magnitude:

[formula]

where the final form of Eq (8) was obtained with the help of Eqs (5) and (6). Then it follows from Eq (7) that:

[formula]

We now apply our results to the special case of θ  =  0 (Σ' moving relative to Σ in the same direction as the photon wavevector) and v  →  c (γ  ≫  1) Eqs (7) and (9) simplify to:

[formula]

As can be seen in Eq (10), there is an accuracy deterioration when the measurement of Σ is referred to a frame Σ' where the frequency ω' is ≪  ω. More precisely, upon comparison of Eq (10) with Eq (5) it is apparent that σω'  /  ω' exceeds the relative error σω  /  ω intrinsic to raw data of Σ by a factor [formula]. It is also important to assess the ultimate quality of any measurement directly performed aboard Σ'. Had such been available, one would have repeated the reasoning which led to Eq (5), with (ω',θ' = 0) now replacing (ω,θ  =  0), to conclude upon a relative error ~  ω'σt  /  π  =  ωσt / (2πγ), which is less than that of the transformed data of Σ, Eq (10), by the factor [formula]. This means what we believe as the frequency seen by observer Σ' could differ very substantially from the actual value witnessed by that observer. In fact, Eq (10) indicates that the point at which we cannot meaningfully predict ω' using our laboratory measurement of ω occurs when:

[formula]

A similar calculation reveals that in the limit of Eq (11) the 'momentum' parameter k' cos θ' will also undergo large excursions (yet correlated with those of ω').

Further, the argument can be repeated, with similar conclusions, to a situation where the energy of an ultra-relativistic particle is measured in the laboratory frame Σ and transformed to the particle rest frame Σ'. For the purpose of calculating intrinsic uncertainties, the laboratory 4-momentum [formula] of such a particle may be treated in the same way as that of the photon [formula], with an on-shell relation of [formula]. Then the transformed energy E' carries a relative uncertainty σE' / E' which likewise exceeds that of the original measurement of Σ, viz. σE / E, by [formula] times. Again, analogous to Eq (11), our own data become irrelevant towards predicting actual rest frame experiences when:

[formula]

When the limit given by Eq (12) is reached the particle energy E' fluctuates substantially about mc2. Here and beyond, a key identifying characteristic of the particle, viz. its rest mass, ceases to be meaningful, nor can one assign a special status to the rest frame.

We now consider two applications. In each case presented, we point out the interesting phenomenon of an observational anomaly occurring at a parameter regime where the effect discussed in this paper is non-negigible. We then provide a qualitative yet compelling argument to explain why the anomaly may be a manifestation of quantum space-time. To proceed, a value for the basic parameter σt is necessary. As discussed earlier, it makes sense to adopt the Planck time tP  ≈  5.4  ×  10- 44 s as a conservative estimate.

Our first example concerns the laboratory frame detection of ~   25 TeV (ω  ~  4  ×  1028 Hz) gamma rays from the blazar Mkn 501 (Aharonian et al 1999). This is an unexpected result: the gamma radiation should have severely been attentuated by photons from the isotropic infra-red background which exists along the intervening line-of-sight, because of pair production in the center-of-mass frame Σ' where both photon populations appear to be >   1 MeV in energy and undergoing essentially head-on collisions.

Note however a caveat in the logic: while all the relevant data are collected only aboard the Σ frame the interaction between 25 TeV and infra-red photons has never directly been studied experimentally in any detail from this frame. Rather, we simply relied on L to avail ourselves a view of the situation from frame Σ' where the physics of the interaction becomes well established but the input parameters for the two colliding photons assume values as derived from the transformed data of Σ. To scrutinize the performance of L, let us focus on the ω  →  ω' operation. Since the two frames are connected by a Lorentz factor of γ  >  107, subsitution of the above value of ω and σt  ≈  tP into Eq (11) reveals that σω'  /  ω'  >  0.2, i.e. intrinsic uncertainties in the transformed energy of the original gamma rays have become significant. Thus, with respect to Σ', those 1 MeV photons from the blazar may assume quite different energies than our prediction based upon the laboratory data and L. Owing to the sensitivity of the pair production rate to input energies ( particularly the presence of a low energy threshold, below which the reaction cannot proceed) we can no longer insist that the process has necessarily played the expected role in attenuating the source radiation. In fact it is obvious that when ω  ~   25 TeV the photon can be transmitted without undergoing pair production (because its actual energy in frame Σ' turns out to be sub-threshold). Moreover the probability of such an occurence increases as as ω exceeds 25 TeV.

In our second example attention is drawn to an expected cutoff in the cosmic ray (CR) spectrum at energies above E  =  1020 eV, as when this laboratory frame energy measurement is transformed along with the cosmic microwave background measurements to Σ', the rest frame of the particle (presumed to be a proton), the familar scene of photo-pion production becomes apparent (Greisen 1966). In reality, no such cutoff was observed (e.g. Takeda et al 1998). Note, however, that the relevant Lorentz factor here is γ  ~  1011, and if we substitute such a value of γ and the above value of E into Eq (12) we will arrive at σE' / E'  ~  1014. Such an absurd uncertainty renders obsolete any theoretical expectations of the fate of the particle which is based upon a Lorentz transformation to the rest frame (another manner of expression is to say that because the rest frame cannot at all be identified the incident photon energy in this frame is unknown). Certainly 50 % of the particles can avoid an interaction: for these particles the energy of the microwave photon relative to Σ' is below the pion production threshold. Moreover, the colossal value of σE' prevents any modification of our conclusion even when multiple in-situ interactions and the improbable scenario of σt  <  tP are invoked.

For very high energy cosmic rays we wish to inquire the value of the 'critical energy' Ec beyond which the notion of a unique rest frame is no longer tenable. By means of Eq (12), one readily deduces that Ec  ≈  2  ×  1015 eV for protons, and ≈  3  ×  1013 eV for electrons.

An earlier work (Lieu 2001) presented a plausibility argument for the existence of space and time units which vary randomly both in magnitude and direction, by showing that such a model can interpret relativity as the macroscopic (aggregate) behavior of a microscopic ensemble. The above discussion provides a direct means of testing (a) the existence of Planck scale space-time fluctuations and (b) the validity of the Principle of Relativity as applied to ultra-relativistic speeds. If both hypotheses are upheld the reaction rates for the two processes considered should exhibit an anomaly in the forementioned situations. The gamma ray and cosmic ray data gathered to date suggest that the said anomaly is indeed in place.

It is also worth mentioning that the phenomenon discussed has implications on the theory of General Relativity. Since in the framework of this theory gravity is a sequence of local Lorentz frames Σ' moving at varying speeds relative to the laboratory frame Σ, our everyday perception of physical laws are to be applied to Σ' and then transformed to Σ - a transformation which again exaggerates the space-time uncertainties beyond their Planck scale values. Effectively this means that space and time in a gravitation field must fluctuate more severely than the levels given by lP and tP. Obviously the consequences in the case of strong fields are very interesting.

Author thanks W.I. Axford and Y. Takahashi for helpful discussions.

References

Abramovici, A. et al, Phys. Lett. A, 218, 157 (1996). Aharonian, F.A. et al, Astron. Astrophys., 349, 11A (1999). Camelia, G.A., Nature, 410, 1065 (2001). Greisen, K., Phys. Rev. Lett., 16, 748 (1966). Lieu, R., Foundations of Physics, 31, 1233 (2001). Takeda, M. et al, Phys. Rev. Lett., 81, 1163 (1998). Wilczek, F., Physics Today, 54, 13 (2001).