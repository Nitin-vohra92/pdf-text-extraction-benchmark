On Regularization Parameter Estimation under Covariate Shift

Introduction

In supervised learning, there is a (mostly implicit) assumption that the training data is an unbiased sampling of the underlying distribution of interest. However, that may not be the case. In a variety of problems there is often an unknown bias in the sampling procedure. These arise due to environmental effects, such as temperature in different genome sequencing centers [\cite=shah2009ontology] [\cite=mei2011gene] [\cite=xu2011survey], or due to the use of particular measuring instruments, such as types of cameras in computer vision [\cite=saenko2010adapting] [\cite=hoffman2013efficient]. This means the training dataset (source domain) and the test dataset (target domain) are technically generated by different distributions and generalization might no longer be possible. The challenge lies in using the labeled source data and the unlabeled target data to classify new target data; a problem setting often referred to as domain adaptation, transfer learning or sample selection bias [\cite=cortes2008sample] [\cite=quionero2009dataset] [\cite=ben2010theory] [\cite=margolis2011literature] [\cite=moreno2012unifying]. Most research focuses on classifiers that incorporate information on the difference between the data in both domains, but unfortunately most of these approaches overlook the role of the regularization parameter.

Regularization is used to combat overfitting of complex models and is a vital component in most classifiers to ensure they generalize to unseen data. It consists of a trade-off between how well the classifier can discriminate training samples and how complex it must become to do so. This balance is described by the regularization parameter which is usually estimated by holding out a small subset of unseen labeled data and evaluating the trained classifier (cross-validation). However, since there are no labeled target samples available, it is not possible to construct a target validation set. If one were to alternatively construct a validation set from source data, the estimator converges in distribution to the source risk and not the target risk [\cite=sugiyama2007covariate].

In this paper, we study how the generalization performance of a classifier behaves as a function of the regularization parameter and the domain dissimilarity. There are many factors that influence the value of the optimal regularization parameter, such as the moments of the class-conditional distributions in each domain (differences in variance, skewness, etc.), concept drift (different class priors in each domain), types of adapting classifiers (some require less regularization than others) and high-dimensional distribution estimation errors, but in this paper we focus on differences in variance between domains. The first correction that comes to mind consists of scaling the source validation risk with importance weights and although this remedies the problem somewhat, we show that the optimal regularization parameter for the target domain remains underestimated.

Outline

The paper is outlined as follows: section [\ref=first] reviews the regularized empirical risk minimization framework and identifies the problem with selecting the optimal regularization parameter. Section [\ref=second] illustrates the covariate shift setting and how the problem might be resolved there. Section [\ref=fourth] considers several importance weight estimators with diverse properties while sections [\ref=fifth] and [\ref=sixth] present experimental evaluations of their estimates.

Estimation Problem

Preliminaries

For a classification problem with a sample space Ω and an event space F, the domains are biased samplings resulting in probability spaces with different probability measures [formula] and [formula]. Denote X as the random variable associated with the source domain, [formula], Z as the random variable associated with the target domain [formula] and the classes as elements of Y  =  { - 1, + 1}. Source data X with labels y consists of n samples from pX,Y, denoted as {(xi,yi)}ni = 1, and target data Z with labels u consists of m samples from pZ,Y, denoted as {(zj,uj)}mj = 1. A classifier is a function that takes as input data and outputs a class prediction, h:Ω  →  Y.

Regularized Risk Minimization

The risk minimization framework allows one to construct classifiers through searching a class of hypothetical functions H (e.g., linear) and selecting the one that minimizes the expected loss [formula]. The source and target risk are defined respectively as:

[formula]

Note that by virtue of the shared sample space Ω of the source and target domains, the differentials x and z are interchangeable, and that, for any h, they differ only through the joint probabilities pX,Y and pZ,Y. The goal is to find a hypothesis h, based on a source sample, that will minimize the target risk.

Unfortunately, minimizing the empirical source risk with respect to h often leads to a solution that does not generalize well to other samples (overfitting), let alone samples from another distribution. In order to restrict the classifiers ability to match the training sample as well as possible, a complexity term, in the form of the Lp-norm of the hypothesis, is added to the empirical risk during training:

[formula]

where [formula] denotes the set of indices used to select the training samples {(xt,yt)}  ⊂  {(X,y)}, |.| denotes the cardinality and [formula] denotes the Lp-norm. For the remainder of the paper, we will be working with the L2-norm.

The regularization parameter λ trades off the average loss and the L2-norm. It is usually estimated by defining a set of values Λ, training a classifier for each and selecting λ∈Λ that minimizes the empirical risk evaluated on a disjoint validation dataset. The set of regularized classifiers can be denoted as:

[formula]

where hλ∈hΛ refers to the classifier that is trained using λ∈Λ. The regularization parameter space Λ is often taken to be an exponentially increasing set of nonnegative values; for example {0,0.01,0.1,1,10,100,1000}. Note that regularization is added during training, but not during evaluation.

If we choose a quadratic loss function, [formula], with a linear hypothesis class, then the solution to minimizing equation [\ref=rrX] with respect to h is [formula].

Evaluation

Evaluation of a classifier consists of its risk on a novel dataset. We will be studying two novel sets, the first being held out source data, because that is usually the only validation data available, and the second being target data, which is the actual measure of interest but is usually not available due to the lack of target labels. Taking the quadratic loss again, the resulting risk is also known as the Mean Squared Error. If we expand the square and plug in the held out source validation data {(XV,yV)}, indexed by [formula] disjoint from the training set [formula], and the labeled target samples {(Z,u)}, the Mean Squared Errors are:

[formula]

Cross-validation consists of holding out each source sample at least once, training a classifier on the remainder and evaluating on the held out validation set. One round of cross-validation is performed for each hλ∈hΛ and the minimizer of the set with respect to the Mean Squared Error corresponds to the estimated regularization parameter.

Problem

For any h, the empirical source validation risk R̂X(h) converges to the true source risk RX(h) by independently sampling validation sets infinitely many times:

[formula]

which is unfortunately not equal to the true target risk RZ(h). Furthermore, the larger the difference between pX,Y and pZ,Y, the larger the difference between the minimizers of RX(hλ) and RZ(hλ) with respect to λ and the larger the error in estimating the optimal regularization parameter.

Covariate Shift

A natural approach to designing a corrected cross-validation procedure, would be to employ some functional relation between the source and target risks. Fortunately, such a relation exists for a subset of the class of domain adaptation problems: if one makes the covariate shift assumption that the class posterior distributions are equivalent in both domains, pY  |  Z  =  pY  |  X, then the target risk can be rewritten into a weighted source risk:

[formula]

and the functional relation thus consists of weighting the source samples appropriately. It can be shown that under the additional assumption of a small domain discrepancy, this problem setting is learnable [\cite=ben2010impossibility].

Generating a covariate shift setting

Since we are restricting the analysis to covariate shift settings, we need to generate such a problem. First, we choose a set of source class-conditional distributions pX  |  Y(x  |  y), a set of priors pY(y) and compute the class posterior distributions pY  |  X(y  |  x) through Bayes' rule. Then, by choosing a different target distribution pZ(z), multiplying by the derived class posterior distributions pY  |  Z(y  |  z) = pY  |  X(y  |  x) and inverting the Bayes' rule, the class-conditional target distributions pZ  |  Y(z  |  y) are obtained. Figure [\ref=cv_problem] (top) visualizes an example of this problem for Gaussian class-conditional distributions. We plotted the labeled source distributions in red and blue with the unlabeled target distributions in black. The class posteriors of this problem are plotted in Figure [\ref=cv_problem] (bottom), and are equivalent. An artificial dataset can be generated by sampling from these distributions, either through inverse transform sampling or rejection sampling.

If we fix the source class-conditional distributions to be Gaussian distributions, with the blue class as N( - 1,1) and the red class as N(1,1), then we can generate 5 problem settings by choosing 5 different target distributions. Figure [\ref=cvshift_scale_mse] (top) shows 5 Gaussian target distributions with equal means but with different variances σ2Z∈{0.5,1,2,3,4}. If we train a classifier based on the source class-conditional distributions and evaluate it using the target MSE, then it becomes apparent that the difference between the minimizer of the source risk and the target risk starts to increase as the difference between the distributions start to increase. Figure [\ref=cvshift_scale_mse] (bottom) plots the MSE as a function of hΛ for the 5 covariate shift problems, with the minimum for each marked with a black square. Note that for σ2Z  =  1 the distributions are equivalent and its minimizer is equivalent to the minimizer of the source risk. The curves show a gradual increase in the minimizers as the variance increases.

Difference in MSE curves

If we minimize the MSE curves of both the source validation risk and the target risk with respect to the trained regularized classifier hλ, we obtain:

[formula]

where the subscripts λ̂V and λ̂Z denote the optimal regularization parameter according to the source validation and the target risk, respectively. Studying these two forms, we see that these estimates of λ differ mainly through their data inner products (i.e., the uncentered, unnormalized covariance matrices). To illustrate this point, we can decompose the data through a singular value decomposition, allowing us to express the minimizers as:

[formula]

where the diagonal matrices DV and DZ consist of the normalized singular values DV,ii  =  αV,i  /  α2V,i and DZ,ii  =  αZ,i  /  α2Z,i. Apart from a change of basis from VV to VZ and UV to UZ, the difference lies in the scale of the eigenvalues.

If we were to apply a scaling operation to the validation risk, then the difference between these curves can be minimized. Finding the optimal regularization parameter for the target domain will then be equivalent to finding the optimal regularization parameter for the scaled validation risk.

Importance Weighted Validation

Sugiyama et al. (2007) employ just such a scaling transformation in the form of importance weighting the validation risk, with the weights as estimates of the ratio of data marginals pZ(x)  /  pX(x) [\cite=sugiyama2007covariate]. These weights scale the risk of each individual validation sample separately. This leads to an importance weighted source validation risk as follows:

[formula]

where W is a matrix with the importance weights w(xv) as its diagonals. This formulation has the following minimizer:

[formula]

This ratio of probabilities can have a very large variance, depending on how likely it is to evaluate it for either extremely large target probabilities or extremely small source probabilities. Furthermore, in the small sample size setting, estimation errors increase the likelihood of encountering a numerical explosion, such as when 10 samples are drawn that lie so close together that the estimated target distribution resembles a Dirac distribution. Lastly, the cross-validation estimator has its own variance [\cite=markatou2005analysis] which is now directly affected by the variance of the importance weight estimator. For a better understanding of the behavior of an importance weighted cross-validation estimator, we performed a number of experiments with a large diversity of weight estimators in the following section.

Experiments

We conducted an experiment on an artificial problem setting and one on a typical real-world domain adaption problem where there is no knowledge on whether the covariate shift assumption holds. Our goal is to evaluate the ability of a number of both parametric and nonparametric importance weight estimators to correctly estimate the optimal regularization parameter in the target domain. These experiments illustrate that a large diversity of existing estimators tends to underestimate the optimal target parameter.

Importance weight estimators

We selected four importance weight estimators with a diverse set of behaviors.

Ratio of Gaussians ( rG)

A baseline method of estimating the marginal data ratio through modeling each sample set with a separate Gaussian distribution [\cite=shimodaira2000improving]:

[formula]

where N denotes the Gaussian distribution function, the [formula]'s denote the estimated means of the subscripted sample set and the [formula]'s denote the estimated variance of the subscripted sample sets. Note that the data marginals in our problem are actually Gaussian and that this is thus the correctly specified model.

Kullback-Leibler Importance Estimation Procedure ( kliep)

This popular method is based on minimizing the Kullback-Leibler divergence between the reweighted source samples and the target samples [\cite=sugiyama2008direct]:

[formula]

where the constraint avoids numerical explosions. For K we chose a Gaussian kernel, with the kernel width σ estimated through a separate 3-fold cross-validation [\cite=sugiyama2008direct].

Kernel Mean Matching ( kmm)

Another popular weight estimator that is motivated by assigning weights that minimize the Maximum Mean Discrepancy (MMD) between the reweighted source and the target samples [\cite=huang2006correcting]. The MMD is the distance between the means of two sets of samples under a worst-case transformation (one that pushes them as far away as possible):

[formula]

where the constraints ensure that the weights are non-negative, bounded above and roughly sum to the sample set size. For the kernel, we selected a radial basis function with Silverman's rule of thumb for bandwidth selection. Huang et al. recommend setting epsilon to [formula] ensuring that the allowed deviation from the sample size depends on both the upper bound for each weight and the sample set size itself.

Nearest Neighbour ( nn)

Lastly, we have a nonparametric estimator based on a Voronoi tessellation of the space [\cite=loog2012nearest]. The procedure consists of assigning a weight to each source sample based on the number of target samples that are nearest neighbors of it and is proportional, up to the ratio of sample sizes, to the ratio of marginal distributions. It is expressed as:

[formula]

where Ci refers to the Voronoi cell of sample xi. The tessellation can be smoothed by adding a value of 1 to each cell, a technique also known as Laplace smoothing.

Artificial data

Our first experiment consists of an evaluation of different importance weight estimators and their resulting minimizers of hΛ. The set hΛ was constructed through linear least squares classifiers [formula], with a range for Λ from -100 to 500. For the source data, we drew 100 samples from two Gaussian class-conditional distribution with means μX∈{ - 1,1} and unit variances σ2X  =  1. The target class-conditional distributions have the same mean μZ∈{ - 1,1}, but with a different set of variances σ2Z∈{0.1,0.5,1,2,3,4}. The ratio of the marginal distributions is sensitive in regions of low probability of the source distribution; really small probabilities in the denominator explode the weight value. Therefore, we expect the minimizers of the importance weight estimators to be close to the target minimizer for smaller target variances σ2Z  <  σ2X. Consequently, we expect erratic behavior for target variance larger than the source variance σ2Z  >  σ2X. Table [\ref=diff_Ll] displays the minimizers of hΛ for the source validation risk, for the different importance weight estimators, for the actual ratio of marginals pZ(x)  /  pX(x), and for the empirical target risk. They are the means and standard errors over 100 repeats.

It seems that all importance weight estimators as well as the true ratio of marginals underestimate the target risk minimizer. Furthermore, it seems that [formula] leads to increasingly smaller minimizers for an increasing target variance. Even though [formula] is increasing, it still underestimates the true value the most. [formula] is the most accurate one, but that will probably not be the case if the marginal distributions are not Gaussian anymore (i.e., model misspecification). [formula] is the other most accurate one and lies closest to true importance weights. Considering that it does not rely on an assumption of normality, it might be the preferred estimator in a more general setting.

Heart disease

The artificial data represents a case where we know exactly what the dissimilarity is between domains and whether assumptions are valid. However, it is also interesting to evaluate on data where we do not have this knowledge. For this we have selected a UCI dataset [\cite=Lichman:2013] on medical data where the domain dissimilarity is caused by a geographically biased sampling of patients. The goal is to classify the presence of a heart disease based on symptoms. The four domains correspond to hospitals in 'Cleveland', 'Virginia', 'Hungary' and 'Switzerland', containing 303, 200, 294 and 123 samples each respectively. There are a total of 14 symptoms, but 2 contained so much missing data (>  99%) that these were removed from the set. All other missing data was imputed with 0 values after z-scoring, i.e. subtracting the mean of each feature and normalizing by its standard deviation. Table [\ref=hdis_Ll] displays the minimizers found by the importance weight estimators compared with those found by the unweighted source validation risk hλ̂V and the empirical target risk hλ̂Z, for all combinations of treating one hospital as the source domain and another as the target. Shown are the means and standard errors over 10 repetitions.

The results show that also for real datasets all importance weight estimators underestimate the optimal target regularization parameter. Note that the standard errors are 0 for all hλ̂Z that have value 500, which is because 500 is the right boundary of the set Λ. Extending the range further would produce even larger values for the optimal target regularization parameter. It seems that [formula] is the best performing estimator here. [formula] also produces reasonable results, but that would probably not be the case if we had not z-scored each feature first. That ensures an overlap of the regions with high probability mass in each domain. The other estimators seem to find weight values close to 1, as they are not very different from the unweighted source validation risk.

Discussion

Considering the significance of regularization to generalization, it would be interesting to further study factors that influence the difference between the risk minimizers in each domain. At the moment we assume that no concept drift has occurred (a difference between class priors in each domain), but if this assumption is violated then the difference in scale depends on the two dominant classes in each domain. The minimizers of the MSE would be dominated by the proportions of samples that belong to one class, which can get very complicated in the multi-class setting. Furthermore, it would be interesting to describe the minimizers in terms of general measures of domain dissimilarity, such as the discrepancy distance [\cite=mansour2009domain] or the H-divergence [\cite=ben2010theory].

The main difficulty in estimating the appropriate weights lies in the fact that it is hard to estimate exactly how the two domains differ from each other. Most adaptation approaches are sensitive to only a particular type of relation between domains or rely on assumptions that can not be checked in advance. Furthermore, estimation errors tend to propagate. For instance, if the distributions of each domain's data marginals are poorly estimated, then the importance weights explode, leading to a more erroneous estimate of the optimal target regularization parameter. In domain adaptation settings with so many sources of uncertainty, it seems that simple methods work best.

Conclusion

We have shown an empirical analysis of regularization parameter estimation in the context of differing variances in covariate shift problems. It seems that the generalization performance of an unadapted source classifier can be improved by importance weighting the source validation risk. However, most popular weight estimators underestimate the optimal target regularization parameter.

Acknowledgment

This work was supported by the Netherlands Organization for Scientific Research (NWO; grant 612.001.301).