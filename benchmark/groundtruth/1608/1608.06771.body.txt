Remark Lemma Corollary Assumption

A priori stopping rule for an iterative Bregman method for optimal control problems

Introduction

We consider an optimization problem of the following form:

[formula]

which can be interpreted both as an optimal control problem or as an inverse problem. Here [formula], n  ≥  1 is a bounded, measurable set, Y a Hilbert space and z∈Y a given function. The operator S:L2(Ω)  →  Y is supposed to be linear and continuous. The inequality constraints are prescribed on the set Ω. We assume ua,ub∈L∞(Ω). A common example of such an operator S is the solution operator of a linear partial differential equation. In many situations the operator S is compact or has non-closed range, which makes [\eqref=eq:main_problem] ill-posed. We want to see [\eqref=eq:main_problem] as an optimal control problem. The unknown u is the control and the constraints are limitations arising from the underlying physical problem. The given function z is the desired state, and we search for a control u satisfying the constraints, such that Su is as close to z as possible. In many situations z cannot be reached due to the presence of the control constraints. Though solutions of [\eqref=eq:main_problem] exist, uniqueness of solutions can only be proven under additional assumptions, e.g. injectivity of S. Furthermore solutions may be unstable with respect to perturbations, which is critical if only approximations zδ  ≈  z of the exact data z exist. In order to overcome these difficulties, several regularization methods were developed. The most common is the Tikhonov regularization with some positive regularization parameter α  >  0. The regularized problem is given by: where zδ with [formula] is the perturbed state to the noise level δ  ≥  0. Here one is interested in the convergence of the solution for (α,δ)  →  0 under some suitable conditions. For this problem convergence results were developed in [\cite=wachsmuth2011]. In the context of inverse problems, we refer to [\cite=engl1996]. However, for α tending to zero, the Tikhonov regularized problem becomes increasingly ill-conditioned.

In order to overcome this difficulty, we started in [\cite=wachsmuth2016] to investigate the Bregman iterative regularization technique. There, the iterate uk + 1 is given by the solution of where Dλ(u,v): = J(u)  -  J(v)  -  (u - v,λ) is called the (generalized) Bregman distance associated with a regularization function J with subgradient λ∈∂J(v). This iteration method was first used first in [\cite=burger2007] [\cite=osher2005], it was applied to an image restoration problem with J being the total variation. We choose to incorporate the control constraint into the regularization functional, resulting in

[formula]

where [formula], and I is the indicator function of convex analysis. While at first sight the incorporation of [formula] into the Bregman regularization functional together with the explicit control constraint u∈Uad seems to be redundant, this choice allows to prove strong convergence under a suitable regularity assumption, which allows bang-bang structure and non-attainability (see [\cite=wachsmuth2016]). We recall the most important results in section [\ref=sec:bregman], including our regularity assumption.

The convergence and regularization error estimates are formulated assuming that the value z is known exactly. If only approximations zδ  ≈  z are available, the next iterate uδk + 1 is given by the solution of Again we assume that the noise level δ is known and zδ satisfies [formula]. In general we cannot expect convergence of the sequence (uδk)k. Our aim is to identify an optimal parameter k(δ), at which it is reasonable to stop the iteration.

In section [\ref=sec:noise_error] we derive an estimate for the noise error [formula] which is used to construct an a priori stopping rule. Furthermore convergence of uδk(δ) is investigated as δ  →  0. In Section [\ref=sec:numerics] we show how to use and how to implement a semi-smooth Newton solver into our iterative method using finite elements. Finally numerical results will be presented in section [\ref=sec:numerical_results].

Notation.

For elements q∈L2(Ω), we denote the L2-Norm by [formula]. Furthermore c is a generic constant, which may change from line to line, but is independent from the important variables, e.g. k.

Bregman iteration

In order to prove convergence and convergence rates of our numerical method we need to assume some regularity of the solution. A common assumption on a solution [formula] is the following source condition, which is an abstract smoothness condition, see, e.g., [\cite=burger2007] [\cite=chaventkunisch94] [\cite=itojin11] [\cite=neubauer1988] [\cite=wachsmuth2011] [\cite=wachsmuth2011b]. We say [formula] satisfies the source condition [\ref=ass:SC] if the following assumption holds.

The source condition is equivalent to the existence of Lagrange multipliers for the problem

[formula]

where [formula] is the uniquely defined optimal state of [\eqref=eq:main_problem]. Note that the existence of Lagrange multipliers is not guaranteed in general, as in may situations the operator S is compact or has non-closed range. If z is not attainable, i.e. [formula], a solution [formula] may be bang-bang, i.e., [formula] is a linear combination of characteristic functions, hence discontinuous in general with [formula]. But in many examples the range of [formula] contains H1(Ω) or C(). Hence the source condition [\ref=ass:SC] is too restrictive for this case. We will resort to the following condition. We say [formula] satisfies the source condition [\ref=ass:ActiveSet] if the following assumption holds. Recall that the adjoint state is defined by [formula].

Assumption [\ref=ass:ActiveSet] is a generalization of assumption [\ref=ass:SC], since for I  =  Ω both assumptions coincide. We decided to differentiate between them, because assumption [\ref=ass:SC] omits more regularity, allowing us to establish improved results. This source condition is used in e.g. [\cite=wachsmuth2011] [\cite=wachsmuth2011b] [\cite=wachsmuth2013] [\cite=wachsmuth2016].

In [\cite=wachsmuth2016] we applied the Bregman iteration with the regularization functional

[formula]

where IC denotes the indicator function of the set C. The Bregman distance for J at u,v∈L2(Ω) and λ∈∂J(v) is defined as

[formula]

Here ∂J(v) denotes the subdifferential of J at v. The functional J is convex and nonnegative, the Bregman distance is also nonnegative and convex with respect to u. Our method is now given by:

Here (αk)k is a non-negative, uniformly bounded sequence of real numbers. Algorithm [\ref=alg:MinEx] is well-posed, see [\cite=wachsmuth2016]. We define the abbreviation

[formula]

The following theorem provides some regularization error estimates for the control uk under some suitable regularity assumptions. For the proof and for some general convergence results of algorithm [\ref=alg:MinEx] we refer to [\cite=wachsmuth2016].

Let (uk)k be the sequence generated by algorithm [\ref=alg:MinEx]. Assume that Assumption [\ref=ass:SC] holds for [formula]. Then

[formula]

If we assume that instead Assumption [\ref=ass:ActiveSet] holds, then

[formula]

Note that by the uniform boundedness of the sequence (αk)k and by [\cite=wachsmuth2016] we obtain

[formula]

Noise error estimate and stopping rule

Assume that we do not know the exact data z, but rather a disturbed approximation zδ, which satisfies

[formula]

The number δ  ≥  0 can be considered as an estimate for the noise level. Let [formula] be a solution of [\eqref=eq:main_problem] with the exact data z. We cannot expect [formula] if δ  >  0, even if some regularity assumption holds for [formula]. Here (uδk)k denotes the sequence generated by algorithm [\ref=alg:MinEx] for zδ.

As pointed out in [\cite=frick2010] [\cite=frick2011] [\cite=frick2012] the Bregman iteration algorithm [\ref=alg:MinEx] can be interpreted as an augmented Lagrange method applied to the minimum norm problem:

[formula]

Furthermore we want to point out, that the authors in [\cite=frick2010] derived a stopping rule kM(δ) based on Morozov's principle. One major assumption to enforce convergence of the iterates read (see [\cite=frick2010]):

[formula]

Then each weak cluster point of the sequence (uδkM(δ))δ  →  0 is a solution of the original problem. The proof relies heavily on the attainability of z, and the source condition [\eqref=ass:SC]. We cannot use this result due to non-attainability and the more general regularity assumption [\eqref=ass:ActiveSet].

Noise estimate

We establish the following noise estimate, which will be used later to construct the stopping rule.

Let (uk)k and (uδk)k denote the sequences generated by Algorithm [\ref=alg:MinEx] for data z and zδ, respectively. Then it holds

[formula]

We start by using the first order optimality conditions, both for uk and uδk (compare to [\cite=wachsmuth2016])

[formula]

By adding we obtain

[formula]

An estimate yields for the first term

[formula]

while for the second term we estimate

[formula]

By defining the quantity

[formula]

and using the equality

[formula]

we obtain

[formula]

Putting everything together yields

[formula]

With

[formula]

we obtain

[formula]

By dividing everything by α2k + 1 and performing a summation over k yield the result

[formula]

The first iteration step is precisely a Tikhonov regularization with regularization parameter α1, so we should recover the same noise estimates. This is the case, since for k = 1 we obtain

[formula]

which is the same estimate obtained for Tikhonov with regularization parameter α1, see [\cite=wachsmuth2011].

A slight modification of the proof above yields

[formula]

from which we recover the estimates

[formula]

which resembles the estimates obtained for the Tikhonov regularization but with a constant c  ≥  1, see also [\cite=wachsmuth2011].

A priori stopping rule

We will now combine the error estimates with respect to the noise level and regularization. This will give an a priori stopping rule with best possible convergence order. We assume that assumption [\ref=ass:ActiveSet] holds for [formula]. The two estimates are given by (see lemma [\ref=lem:noise_error] for the noise error and theorem [\ref=thm:SC_strong_conv] for the regularization error):

[formula]

where the sum of quadratic noise error enk and the sum of quadratic regularization error erk is defined by:

[formula]

Our stopping rule is now given by: Find maximal k(δ), such that the noise error eni is below the regularization error eri for all i  ≤  k(δ). Hence the optimal parameter k(δ) is defined by

[formula]

Here τ  >  0 is a constant. For the case en1  >  τer1 we define k(δ)  =  0, which reflects the case that the noise error is dominating after the first iteration. This happens only if δ is too big and we will show that k(δ)  ≠  0 for δ small enough. Note that k(δ) depends also on τ and (αk)k, but we are suppressing the dependence due to clarity of the notation.

Let δ  >  0. The value k(δ) defined above is well-defined and unique. Furthermore k(δ)  →    ∞   as δ  →  0.

For the case en1  >  τer1, there is nothing to show. Now assume that en1  ≤  τer1 holds. We now show that there exists a [formula] such that enk̄  >  τerk̄. Assume that such a value does not exists, hence we get enk  ≤  τerk for all [formula]. Multiplying this inequality with γ- 1k yields for k  →    ∞   (see [\cite=wachsmuth2016])

[formula]

Hence the sequence (γ- 1kenk)k tends to zero. Recall that there exists a constant C  >  0 such that αj  ≤  C. Define the following quantities

[formula]

leading to 0  <  βj  ≤  1. Now compute

[formula]

We now have a contradiction since

[formula]

Therefore, we know the existence of k̄ with enk̄  >  τerk̄, and we can deduce the existence of a maximal [formula] with [formula]. Setting [formula] yields the well-posedness of k(δ). To show the second part we assume that this is wrong, hence there exists a [formula] such that for all δ  >  0 we have k(δ)  <  k̄. Without loss of generality we assume k(δ)  ≥  1 and k(δ) + 1 = k̄. By definition of k(δ) we now obtain

[formula]

This gives a contradiction for δ small enough.

If we chose k(δ) based on the principle above, we can establish the following convergence result for uδk(δ) as δ  →  0.

Let k(δ) be given by the a priori stopping rule presented above. Then

[formula]

as δ  →  0.

We use triangle inequality to obtain

[formula]

which yields

[formula]

and since k(δ)  →    ∞   as δ  →  0 we obtain the result (see [\cite=wachsmuth2016]).

The results can be improved if we assume that Assumption [\ref=ass:SC] is satisfied. In this case we set erk: = 1, see theorem [\ref=thm:SC_strong_conv]. Note that all of the results above stay true in this case. The modification of the proofs is simple.

Numerical implementation

This section is devoted to the numerical implementation of the Bregman iteration using finite elements.

Semi-Smooth Newton Method for the subproblem

In our algorithm we need to solve the subproblem

[formula]

with λ∈L2(Ω), which has a unique solution, characterized by the projection formula

[formula]

with [formula]. Several different techniques are available to solve [\eqref=eq:sub]. The simplest is a projected gradient (see [\cite=troelsch2010]) method with the decent direction [formula]. The implementation is rather simple but comes at very slow convergence speed and high numerical costs. Nevertheless the gradient method can be used to globalize the Newton method presented below.

In order to solve [\eqref=eq:sub] we want to apply a Newton method to [\eqref=eq:fixed]. In this section we follow the idea presented in [\cite=hinze2009b], where a semi-smooth Newton solver was applied for a Neumann-type elliptic optimal control problem. We adapt this technique for distributed control problems. This technique can also be applied for optimal boundary control problems, see [\cite=beuchler2012]. Denote by uk the iterates given by the Newton method. Define the function

[formula]

and apply a Newton step

[formula]

where G(uk):L2(Ω)  →  L2(Ω) is the Newton derivative of F at uk. For a convergence analysis of this Newton method we refer to [\cite=hinze2009b]. A suitable function G is given by the following lemma. The result can also be found in [\cite=beuchler2012] or in [\cite=hinze2009].

A suitable function G is given by

[formula]

and

[formula]

We see that uk + 1 satisfies the relation

[formula]

Define the sets

[formula]

and the operator

[formula]

We have uk + 1  =  ua on Aa(uk) and uk + 1  =  ub on Ab(uk). On the set I(uk) we obtain

[formula]

This can be rewritten in a linear equation for EI(uk)uk + 1.

The function uk + 1I: = EI(uk)uk + 1 satisfies

[formula]

with [formula].

Our Newton solver now solves the equation above for uk + 1I, which allows us to construct our new iterate uk + 1.

Algorithmic aspects and implementation

We now focus on the special case where y = Su is given by the elliptic equation The discretized version is now given by the solution (uh,yh,ph) of the coupled problem

[formula]

with the test function space [formula], the bilinear form

[formula]

and λh∈Vh. For a given uh there exists a unique yh(uh) and hence a unique ph(uh), so we reduce the coupled system [\eqref=eq:num_coupled] to one equation for the optimal control uh, e.g.

[formula]

Note that lemma [\ref=lemma:Control_lin_sys] also holds for uh. We are interested in the solution uk + 1h,I from equation [\eqref=equ:Control_lin_sys]. But uk + 1h,I is not a finite element function in general, since it is the truncation of a finite element function uk + 1h,I  =  EI(ukh)ũk + 1h, which can be computed by solving

[formula]

In the following we denote by [formula] the coefficient vector of a function uh∈Vh, where m denotes the degrees of freedom (DOF). By testing [\eqref=eq:discr_uk1newton] with a test function we obtain the following lemma.

The coefficient vector [formula] satisfies

[formula]

where

[formula]

Note that we now have the relation

[formula]

We can use this relation to get a system for the coefficient vector of the function pk + 1h.

The coefficient vector of the adjoint state pk + 1h satisfies

[formula]

Note that only the adjoint state pk + 1h is used to update the active and inactive sets, hence kinks and discontinuities will not be accumulated.

As mentioned in [\cite=beuchler2012] the operator on the left-hand side of [\eqref=equ:Control_lin_sys] is positive definite on L2(I(uk)), hence the matrix on the left-hand side of [\eqref=equ:Control_Matrix_Sys] is positive definite on the span of all basis functions whose support has non-empty intersection with the inactive set I(ukh). This makes the equation accessible with a conjugate gradient method.

With these results we can implement our Newton method and solve the subproblem without actually computing ukh, we only work with adjoint state and the active/inactive sets.

Using the Newton-solver in the Bregman iteration

The fact that we are not computing the control (which is not a FEM function) and work instead with the adjoint state (which is a FEM function) can be extended to the implementation of the Bregman iterative method. Denote k the number of iterations and let λkh∈Vh be the computed subgradient. Let pk + 1h∈Vh be the adjoint state computed while solving the subproblem. To start the next iteration all we have to do is to update the subgradient

[formula]

to start the next iteration. Again note that we do not need to compute the control. The control can be computed (for plotting e.g.) using the optimality condition [formula] if needed.

Numerical examples

In the following we present some numerical examples for the problem

[formula]

to illustrate our stopping rule. Our implementation is done in FEniCs ([\cite=fenics]) and we use Lagrange polynomials of order 1. In one space dimensions we use an equidistant mesh, and in two space dimensions we use a regular triangulation. Here the degrees of freedom of our discretization will be denoted by DOF. Let zh∈Vh be given and [formula] its coefficient vector. Let nh∈Vh be such that each component of [formula] is a random number in the interval

[formula]

z := z + δ ,

[formula]

Example 1

One can see, that with the choice of Ω  =  ( - 1,1), ua  =  0, [formula] and

[formula]

the functions [formula] are a solution to [\eqref=eq:test_problem]. Furthermore Assumption [\ref=ass:ActiveSet] is satisfied with I  =  (0,1) and [formula], hence the solution is bang-bang on A  =  ( - 1,0] and satisfies a source condition on I. We apply algorithm [\ref=alg:MinEx] with constant αk  =  1 and different noise level δ and compute [formula]. Furthermore we compute the stopping rule with τ  =  5  ·  103 and DOF = 105. The results can be found in figure [\ref=fig:case12].

Example 2

With the choice of Ω  =  ( - 1,1), ua  =   - 1, ub  =  1 and

[formula]

the functions [formula] are a solution to [\eqref=eq:test_problem]. Here the solution satisfies Assumption [\ref=ass:ActiveSet] with A = Ω and κ  =  1. Again we apply algorithm [\ref=alg:MinEx] with constant αk  =  1 and different noise level δ. The stopping rule k(δ) is computed with τ  =  106 and DOF = 105. The results can be found in figure [\ref=fig:case12].

Example 3

With the choice of Ω  =  (0,1), ua  =   - 1, ub  =  1 and

[formula]

the functions [formula] are a solution to [\eqref=eq:test_problem]. Here the solution satisfies Assumption [\ref=ass:ActiveSet] with A = Ω and [formula]. Again we apply algorithm [\ref=alg:MinEx] with constant αk  =  1 and different noise level δ. The stopping rule k(δ) is computed with τ  =  5  ·  105 and DOF = 105. The results can be found in figure [\ref=fig:case34].

Example 4

With the choice of Ω  =  (0,1)2, ua  =   - 1, ub  =  1 and

[formula]

the functions [formula] are a solution to [\eqref=eq:test_problem]. Here the solution satisfies Assumption [\ref=ass:ActiveSet] with A = Ω. Numerical estimates indicate κ  =  1. Again we apply algorithm [\ref=alg:MinEx] with constant αk  =  0.1 and different noise level δ. The stopping rule k(δ) is computed with τ  =  107 and DOF = 106. The results can be found in figure [\ref=fig:case34].

Let us remark that such an a priori stopping rule is barely possible in practice, as the constant κ appearing in Assumption [\ref=ass:ActiveSet] is not known a priori, as it depends on the unknown solution of the unregularized problem and the possible unaccessible noiseless data. Furthermore the choice of τ is not clear a priori. Nevertheless we can use the a priori rule as an benchmark to compare the convergence order of an a posteriori stopping rule.

In theorem [\ref=thm:asymptotic_convergence] we proved asymptotic convergence of our stopping rule independent from τ. This can also be observed numerically. We computed [formula] for different values of τ and δ for example 3 with constant αk = 0.1. The results can be found in figure [\ref=fig:asymptotic].

Let us remark that it is an open question to construct an a posteriori stopping rule in our case. It is not clear how to extend the a posteriori estimates presented in [\cite=wachsmuth2011] into our iterative method. Furthermore we cannot apply more general a posteriori stopping rules, as presented in [\cite=schock2005] as they rely on estimates of [formula], which are not available in our case.