Identifying stochastic oscillations in single cell live imaging time series using Gaussian processes

Introduction

Oscillatory dynamics are widespread in biology over a range of time scales, from the circannual migration patterns of animals [\citep=Gwinner2003] to the cytosolic calcium oscillations on the order of seconds [\citep=Dupont2011]. In between these extremes lie a plethora of oscillatory phenomena [\citep=Goldbeter2012], from NF-KB oscillations in inflammation [\citep=Nelson2004], the cell cycle [\citep=Ferrell2011] [\citep=Tyson2008], circadian rhythms [\citep=Zhang2014] and p53 oscillations in response to DNA damage [\citep=Geva-Zatorsky2006]. Biological oscillations have attracted intense research focus due to the functional benefits conferred by oscillatory dynamics for cellular functions. The most intuitive advantage of oscillations is to function as clocks to measure time within a cycle. For example, the circadian clock is used to anticipate conditions and synchronise physiological responses to daily environmental changes [\citep=Rensing2001]. Biological oscillators can be coupled to an output with much slower dynamics, such that every oscillation increases the output in a step-like manner [\citep=Levine2014] [\citep=Goodfellow2014]. They can also be used to measure distance, such as in the segmentation clock where oscillations in gene expression are used to control the formation of somites along the elongating vertebrate body axis, which are the precursors of the segmented vertebral column [\citep=Oates2012]. In addition to measuring time and space, oscillations have attracted interest due to the unique properties of oscillatory signal processing. Oscillations are defined by both amplitude and frequency, and manipulation of either can be used to transmit and process information [\citep=Berridge1997] [\citep=Micali2015]. They may also confer robustness of information transmission in the face of extrinsic noise caused by variability in cellular states [\citep=Selimkhanov2014].

As new potential oscillators are discovered it is essential to have tools that can objectively classify a biological time series as rhythmic or arrhythmic. This is particularly challenging in data from individual cells because mRNA and protein oscillations may be stochastic due to the finite number of interacting molecules in the gene regulatory networks that control their production and degradation. Live imaging shows that oscillations in single cells may display variable inter-peak distances and gradual shifts in phase over time (quasiperiodicity), such that the signal will not match a perfectly periodic sine wave. In addition, recent evidence suggests that gene transcription per se is a discontinuous process, where bursting episodes of transcription are interspersed with silent periods [\citep=Suter2011]. Thus, intrinsic noise inherent to single cell dynamics makes it important to distinguish aperiodic (but pulsatile) from periodic (but stochastic) oscillatory phenomena.

Many methods for analysing biological time series are designed for estimating the period of known oscillators, such as encountered, for example, in circadian time series [\citep=Zielinski2014]. A common and well-known method is the Fourier transform, which finds periodic contributions within the time series by matching (convolving) the signal with sine waves. One such example is the Fast Fourier Transform Nonlinear-Least-Squares algorithm (FFT-NNLS), which uses a Fourier transform to provide an initial guess of the period before fitting the signal as a sum of sinusoidal functions with a non-linear least squares procedure [\citep=Plautz1997]. The Fast Fourier Transform can be inaccurate for period determination due to poor resolution in the frequency domain, and other analysis pipelines, such as spectrum re-sampling, use bootstrap methods within the spectrum to refine the period estimate and obtain confidence intervals [\citep=Costa2013].

In addition to the Fourier transform, time series analysis using wavelets is also commonly used to estimate the amplitude and period of oscillations [\citep=Webb2016]. Fourier based techniques assume that the time series is stationary, so the statistical properties such as mean, variance, autocorrelation, period etc. remain constant over time. Wavelet analysis does not assume stationarity, and is therefore able to detect amplitude and period changes over time. However, the Fourier transform, the wavelet transformation and related period estimation techniques [\citep=Zielinski2014] do not form a statistical test to classify whether a time series is periodic.

Algorithms for assessing statistical confidence that the time series is periodic [\citep=Wu2014] include methods such as JTK and RAIN [\citep=Hughes2010] [\citep=Thaben2014], but both of these methods require prior knowledge of the expected period. While they may be useful for the circadian clock, where the period is known to be approximately 24 hours, they do not form a general test that can be applied to any biological system. The Lomb-Scargle periodogram is a method that can be used in objectively classifying data as oscillatory or not. It is related to the Fourier transform but it provides a statistical confidence of the significance of periodicity and does not require a previously known period [\citep=Glynn2006]. The Lomb-Scargle periodogram performs well when benchmarked against other popular competing schemes [\citep=Zhao2008].

A limitation of the Lomb-Scargle periodogram in applications to single cell time series is that the assumed model of oscillatory and non-oscillatory dynamics may be unrealistic. The Lomb-Scargle periodogram and similar methods are typically benchmarked by generating a sine wave or other perfectly periodic waveform and adding white noise to simulate measurement error [\citep=Zhao2008] [\citep=Zielinski2014] [\citep=Wu2014]. The competing methods are then tested by comparing their performance in detecting the periodicity in the simulated signals. However, the choice of waveforms is ad hoc, and there is no theoretical justification as to why a biological oscillator would produce a time series of that form. Additionally, existing methods commonly assume that non-oscillatory expression is described by white noise and use this to form a null hypothesis for statistical testing [\citep=Glynn2006]. The key assumption of white noise is that consecutive time series measurements are random and completely uncorrelated. However, all components of gene expression have a finite time scale of degradation such that if, for example, a protein is in high abundance at one time point, it is likely to be high at the next. This is poorly modelled by white noise, where by definition consecutive time points have no correlation. In summary, current statistical methods for detecting periodicity are not suitable for stochastic data emerging from recent single cell studies.

Another approach that is complementary to data driven approaches has been to employ "bottom-up" dynamical modelling, which takes a hypothesis of interactions within a gene regulatory network and predicts how the products of gene expression (mRNA, protein etc.) will evolve in time. Stochastic dynamical modelling accounts for the natural randomness inherent to single cells due to low copy number of interacting molecular components [\citep=Schwanhausser2011]. Even though stochastic models are also subject to assumptions they none-the-less form a mechanistic expectation of dynamics at a single cell level. There are a range of techniques to analyse a given time series that are based on stochastic modelling [\citep=Bronstein2015], from inferring parameters of a model of a transcription network (e.g. transcription rate) [\citep=Heron2007] to inferring a sequence of promoter states and potential refractory periods in transcriptional activity [\citep=Hey2015] [\citep=Zechner2014]. Although these methods model the time series at a more mechanistic level, they once again do not output a confidence estimate as to whether the time series is periodic.

Here we combine stochastic modelling to form a mechanistic expectation of single cell dynamics with a statistical method to determine confidence that a given time series is periodic. We present a new computational tool based on Gaussian processes to classify cells as oscillatory or non-oscillatory in stochastic single cell live imaging data, which was developed by making a fundamental connection between microscopic stochastic models of gene regulation and the powerful techniques of Bayesian non-parametric regression. The new method has two critical improvements for the analysis of single cell data: firstly, it can deal with a “drifting phase” which is often present in single cell gene regulation data, such that the exact peak-to-peak time of oscillations varies and the time series is therefore poorly described as a perfectly periodic signal. This peak-to-peak variation is naturally embedded in the newly presented analysis pipeline through use of a quasi-periodic covariance function. Secondly, our non-oscillatory model accepts that a time series can be randomly fluctuating and that consecutive time points can be correlated due to the finite degradation timescales of mRNA and protein. This is more likely to be a realistic model of non-oscillatory gene expression than white noise.

We demonstrate that our approach is much more effective than the Lomb-Scargle periodogram at classifying cells as oscillatory or non-oscillatory in synthetic data generated from a stochastic model of a single cell system. We then apply our method to experimental data, and show that significantly more cells are classified as oscillating in time series from the Hes1 genetic oscillator than an MMLV control, which is representative of fluctuating, non-oscillatory gene expression. Our analysis pipeline calculates the proportion of oscillating cells within a population and also parameters quantifying dynamic behaviour, such as period of oscillations. The coherence of oscillations can also be quantified through the quality Q-factor. It can be applied to single cell live imaging data from any gene system, and can be used to both make comparisons between genes and to characterise changes in dynamics caused by perturbations and genetic mutations.

Methods

In this section we show how single cell gene expression dynamics can be approximated as a Gaussian process and how this can be used as a non-parametric model to detect periodicity in single cell imaging gene expression data using reporters such as fluorescence or bioluminescence. We firstly define the dynamics of gene regulation in terms of underlying reactions, before applying the linear noise approximation (LNA) to derive two general models of single cell dynamics: 1) intrinsically noisy oscillations, 2) random aperiodic fluctuations, which forms the null model of non-oscillatory behaviour. These define a mechanistic model-based representation of single cell dynamics as a Gaussian process. In a Gaussian process model, measurements at different times follow a multivariate normal (Gaussian) distribution, which is defined by a mean function and a covariance function. The covariance function determines how correlated a pair of measurements is as a function of their separation in time. The LNA provides a theoretical model of the mean and covariance for both the oscillatory and non-oscillatory cases. Bayesian nonparametric regression then allows us to define the likelihood that a given time series has been generated from either an oscillatory or non-oscillatory model. The likelihood ratio between these models is then used for model selection between the oscillatory and non-oscillatory models to provide a confidence estimate that a time series is periodic. Finally, a classification threshold in the likelihood ratio is chosen in order to control the false discovery rate (FDR). Code to implement the method and reproduce all of the figures is available at https://github.com/ManchesterBioinference/GPosc.

Approximating gene expression dynamics as a Gaussian process

Firstly, we describe how a stochastic model of gene expression can be used to define a model of single cell oscillations or random aperiodic fluctuations. The biochemical reactions controlling gene expression are the result of probabilistic encounters between discrete numbers of molecules. The exact order and timing of reactions are random, and this is mathematically described with the chemical master equation (CME). The CME formulates the stochastic kinetics in terms of underlying reactions, and captures the probability of having a certain number of molecules as a function of time. The CME is formulated from the underlying microscopic reactions of the system, where R chemical reactions change the molecule number of N chemical species

[formula]

where j is the index of the reaction number, Xi is the chemical species i, sij and rij are the stoichiometric coefficients and f(X)j is the rate of reaction j, which depends on both the network of interactions and the kinetics of the reaction. The probabilistic evolution of the system is described with the CME, and approximate solutions can be found using van Kampen's system-size expansion [\citep=VanKampen1997]. The system-size expansion decomposes the time evolution of each chemical species into a deterministic and stochastic contribution, where the relative amplitude of stochastic fluctuations decrease with the inverse of the square root of the system size (i.e. relative fluctuations decrease with higher molecule number)

[formula]

where x(t) is the deterministic solution and ε(t) describes the stochastic fluctuations around the deterministic solution. While ni represents the discrete copy number of reactants, εi can be modelled as a continuous random variable for large ni and Ω. The ansatz (equation ([\ref=ansatz])) can be used to derive the linear noise approximation (LNA, see Elf and Ehrenberg [\citep=Elf2003] for details). When the deterministic equations reach a fixed-point, the LNA recovers a system of linear Langevin equations for the dynamics of the stochastic fluctuations

[formula]

[formula]

[formula]

where J represents the Jacobian of the deterministic dynamics evaluated at steady state, D represents the diffusion matrix, and ζ(t) is Gaussian white noise with 〈ζi(t)ζj(t')〉  =  δijδ(t - t'). Equation ([\ref=langevin]) describes the dynamics of noisy fluctuations around a deterministic steady-state. It defines a Gaussian process, where the fluctuations ε are distributed as a multivariate normal distribution. A multivariate normal distribution is fully described by its mean and covariance. As the deterministic equations are at a steady state, the mean of the process is zero. The covariance function K(τ) can be solved analytically, as the linear Langevin equation derived through the LNA is a multivariate Ornstein Uhlenbeck (OU) process [\citep=Gardiner2009],

[formula]

where τ  =  |t  -  t'| is the time difference between two points. The quantity σ satisfies

[formula]

Modelling single cell oscillations and aperiodic random fluctuations

Equation ([\ref=langevin]) defines a general representation of single cell gene expression dynamics approximated as a Gaussian process, and from this general representation we now define models of single cell oscillations and aperiodic random fluctuations. The Jacobian contains information on all of the parameters of the model, and is dependent on the network interactions, which may not be known. To simplify the covariance function, the Jacobian can be diagonalised by the transformation UJU- 1  =  diag(λ1,λ2,...,λN), and the covariance matrix is transformed to [formula]. The covariance function for eigenmode i is then

[formula]

The eigenvalue λi can either be real or complex, and we therefore define two covariance functions, labelled "OU" and "OUosc"

[formula]

The OU covariance function represents a process with aperiodic stochastic fluctuations and no peak in the power spectrum [\citep=Gardiner2009]. The OU covariance function has two parameters: σOU, quantifying the variance of the generated signal, and α, which describes how rapidly the time series fluctuates. Illustrative examples are provided below. The OUosc covariance function defines a quasi-periodic oscillatory process which captures the peak-to-peak variability inherent to stochastic biochemical oscillators. The OUosc covariance function likewise contains both σOUosc and α parameters quantifying the variance and time scale of fluctuations, respectively, but it also contains a cos (βτ) term. The covariance function displays damped oscillations at frequency β, and the system therefore undergoes stochastic oscillations at this period. Crucially, the OUosc covariance function is still damped, and therefore peaks in the time series will only be locally correlated in time. For a given position of a peak in the time series, the timing of the next peak will be reasonably known, but subsequent peaks become increasingly difficult to predict, dependent on the length scale of the dampening α. This leads to the phase drift and peak-to-peak variability within single cell oscillators.

To visualise the time series generated by Gaussian processes with OU and OUosc covariance functions, Fig [\ref=Examples] shows realisations with different parameter values. The amplitude (variance) of fluctuations is controlled by σ, and this is kept at 1 for all examples. For the non-oscillatory OU covariance function, the α parameter controls how long fluctuations are correlated in time. When α is high the covariance function is heavily damped and successive time points have low correlation (Fig [\ref=Examples]A). As the correlation is low, future time points are highly unpredictable and hence the time series rapidly fluctuates. In contrast, when the damping parameter α is low, time points are correlated over longer time scales as shown in Fig [\ref=Examples]B. For the OUosc function, the β parameter controls the frequency of oscillations while α similarly controls the rate of decay of the covariance function. Together, these parameters regulate the peak-to-peak variability and coherence of oscillations. The quality of oscillations can be quantified by the oscillation Q-factor, which quantifies the ratio of the timescale of damping to the frequency of oscillations [\citep=DEysmond2013]

[formula]

When the decay of the covariance is slow relative to the frequency of oscillations, oscillations are correlated for many cycles and there is low peak-to-peak variability, as shown in Fig [\ref=Examples]C. The oscillations are of high quality (high Q-factor), and they reasonably match a sine wave at exactly the oscillatory frequency. However, when the quality is low (low Q-factor), the peak-to-peak variability becomes significant, and the signal is poorly described by a perfectly periodic sine wave (Fig [\ref=Examples]D).

Gaussian process regression to classify cells as periodic or aperiodic

Having derived mechanistic models of single cell oscillations and aperiodic fluctuations, our goal is to assess whether a given time series is better described by a non-oscillatory OU or an oscillatory OUosc model. Firstly, we show that we can quantify how well a given time series is described by either model through the likelihood of the data under a Gaussian process model. This then allows us to define the log likelihood ratio (LLR) of the two models, which is used for model selection between the non-oscillatory OU and the oscillatory OUosc model and provides a level of confidence that a time series is periodic. Stochastic modelling and the LNA is a forward modelling approach in that we can generate time series data from a given model. The objective of data analysis is to perform this process in reverse, and infer the most likely model from given data. As the LNA describes a Gaussian process, the tools of Bayesian non-parametric regression can be used to describe the likelihood of a data set for a given model [\citep=Rasmussen2006]. Simulating a Gaussian process time series with either the OU or OUosc covariance function and measuring the value at times [formula] will generate a random vector [formula]. Due to the randomness of the process, however, this represents just one sample from an infinite number of trajectories that could be created. Gaussian process regression is so powerful because it is analytically tractable to state the likelihood of the data for a given model, even though there are infinite possible trajectories that the stochastic model could take. By integrating (marginalising) over all possible trajectories, the marginal likelihood of the data set [formula] for a given model is

[formula]

where θ are the hyperparameters of the models, which in the current context is α, β and σ. The covariance matrix K has elements from the KOU or KOUosc covariance function evaluated at the time points where the data are collected. The first term describes how well the model fits the data, whereas the second term penalises model complexity of the covariance function. If the covariance function is rapidly damped (high α), then it describes a process with extremely short timescales. As the process fluctuates rapidly, it will be able to fit the data well regardless of whether it is a true representation of the dynamics, and this second term corrects for this overfitting. The third term is a normalisation constant. If the data are subject to measurement error, each observation y can be related to the underlying function of the cellular behaviour [formula] through a Gaussian noise model

[formula]

where σ2n represents the standard deviation of the measurement noise. The noise can be combined with the covariance function

[formula]

The task is then to find the maximal likelihood of the data for both the OU and OUosc covariance functions, which is found by varying the hyperparameters to find an optimum. The partial derivative of the marginal likelihood with respect to hyperparameters is

[formula]

The maximum marginal likelihood is found when the derivative of the marginal likelihood with respect to hyperparameters becomes zero. The marginal likelihood was maximised for both OU and OUosc models using the MATLAB GPML toolbox [\citep=Rasmussen2010], and the maximum likelihood of the two models can then be compared. The difference in the log-likelihood of the two models is known as the log-likelihood ratio, and the LLR between the OU and OUosc models then provides a statistic to determine whether the data is oscillating as opposed to aperiodic random fluctuations.

Detrending to identify oscillations embedded in long term trends

As well as oscillatory activity, gene expression may exhibit long term trends. Without accounting for trends in the data, oscillations can become harder to detect because the signal is dominated by an aperiodic long term trend. The OUosc model describes oscillations with variability in amplitude and period, but the mean of the covariance function is zero. Over long time scales it is clear that the average of the signal generated by the OUosc model remains constant ([\ref=LongTimeSeriesExample2] Fig), and consequently experimental data with long term trends may be poorly described by the OUosc alone and oscillations that co-exist with long term trends could be missed.

We therefore require a method to detrend the data and allow the detection of oscillations superposed on long term trends. Typically, detrending data involves fitting and removing a polynomial [\citep=Westermark2009] [\citep=Plautz1997]. Here we detrend using Gaussian processes, which has the advantage that we do not have to specify an exact functional form of the trend. We use the squared exponential (SE) covariance function, because it describes a general smooth process

[formula]

where τ  =  |t - t'| as before. Fig [\ref=Detrending] illustrates how the addition of long term trends can interfere with the detection of oscillatory dynamics. Fig [\ref=Detrending]A shows an example of a time series from an OUosc model, and the calculated LLR of 39.6 is strongly in favour of oscillations. Random functions drawn from the SE covariance function are then displayed in Fig [\ref=Detrending]B, where the length scale of the trend is set by the parameter αSE. Crucially, when the long term trend is added to the original oscillatory signal, the calculated LLR markedly drops to 1.12, favouring the OU model (Fig [\ref=Detrending]C). The essence of the detrending approach is to run this process in reverse, by first fitting a SE trend model to the data (Fig [\ref=Detrending]C green line). By applying our detrending method and removing the fitted trend, the LLR of 41.8 once again indicates the presence of oscillations, as shown in Fig [\ref=Detrending]D. When fitting the trend it is important to remove long term trends while preserving the oscillatory signal, and if the trend line is allowed to be too flexible it will fit both. To avoid this problem one can set an upper bound on αSE, such that there is a minimum length scale that the trend will remove. The importance of this upper bound is discussed in the results section.

Choosing a LLR threshold to classify cells and control false discoveries

In order to classify a cell as oscillatory or non-oscillatory, a threshold in the LLR must be reasonably chosen. We now describe our procedure for choosing the LLR threshold to define a cut-off between where we classify a cell as oscillatory or non-oscillatory.

An objective metric on which to base the LLR threshold is the false discovery rate (FDR). The FDR seeks to control the proportion of cells passing the oscillatory test that are actually non-oscillatory, but it differs from the false positive rate (FPR) often used in statistical testing. Given a particular LLR threshold, the FPR is the proportion of cells called significant (oscillatory) when they are actually null (non-oscillatory). The FPR is typically controlled by setting a significance level on the p-value, which is the probability of the observed test statistic under the null hypothesis (in our case the LLR). In contrast, the FDR quantifies the expected proportion of cells falsely called significant as a percentage of the total number of cells passing the threshold. So if, for example, out of 100 non-oscillatory cells the LLR threshold is chosen such that 5 are deemed significant, then the FPR is 5%, but the FDR is 100%, because all 5 of the cells called significant are actually false. The FDR therefore provides a better representation of the balance between the number of true positives and false positives in classifying cells.

Analogous to the p-value to control the FPR, the q-value is the minimum FDR attained at or above a given score. For a particular LLR threshold, the associated q-value is the expected number of false positives as a proportion of all cells that exceed the threshold. To control the FDR and calculate q-values, we follow the procedure proposed by Storey and Tibshirani [\citep=Storey2003]. The original protocol uses the statistical properties of p-values, specifically that under the null hypothesis the p-values are uniformly distributed between 0 and 1. As we calculate a LLR instead of a p-value, we find this distribution through a bootstrap approach by simulating many cells with the null OU model and calculating the LLRs. In order to choose parameters to simulate cells, we use the parameters fitted to the data. Sampling from the null models to compute the test statistic is known as a Cox test [\citep=Goldman1993] [\citep=Cox1962]. The procedure of calculating q-values is as follows:

1) For each cell in the data set, fit an oscillatory (OUosc) and non-oscillatory (OU) Gaussian process model to the detrended data, and calculate the LLR difference between the fits of the two models. The LLR is normalised by dividing by the length of the data and multiplying by 100 (to make units more rounded). Let LLRd1  ≤  LLRd2  ≤  ...  ≤  LLRdm represent the ordered LLR values of the time series from the data.

2) Create a synthetic data set to approximate the LLR distribution expected from the null (OU) model. Generate 2000 synthetic cells by sampling equally from the parameters fitted by the trend and OU non-oscillatory model for each cell. If the data set consists of 100 cells, then the fitted trend and OU parameters of each cell would be used to create 20 synthetic cells, for example. Let LLRs1  ≤  LLRs2  ≤  ...  ≤  LLRsm represent the ordered LLR values of the synthetic time series.

3) For a range of λ, (e.g. 20 linearly spaced points between minimum and maximum LLRs), estimate proportion of cells in the data set that are non-oscillatory

[formula]

where # denotes the number of cells. π0 must be estimated by tuning the parameter λ. Allowing [formula] to be a cubic polynomial of π0(λ) on λ, set the estimate of π0 to be

[formula]

4) Calculate

[formula]

For i  =  m - 1,m - 2,...,1 calculate

[formula]

Synthetic data for evaluating classification performance

In order to assess the performance of the method to discriminate periodic and aperiodic signals, we generated synthetic data from a stochastic model consisting of reactions between discrete numbers of molecules. We use a model of the Hes1 genetic oscillator [\citep=Monk2003] [\citep=Galla2009], which consists of negative autoregulation with delay. The network topology is illustrated in Fig 3, and it is comprised of the following four reactions

[formula]

The first two reactions correspond to mRNA and protein degradation, respectively, where μm and μp are parameters describing their degradation rates. The third reaction describes the production of Hes1 protein through translation, and is dependent on both the number of mRNA molecules and the translation rate parameter αp. The final term represents the production of Hes1 mRNA through the process of transcription. The negative repression of transcription by Hes1 protein is modelled with the Hill function f(np)  =  αm / (1 + (np  /  ΩP0)h), where P0 and h are constants representing the strength of negative repression and Ω represents the system size. This reaction contains the total delay within the system, such that when the reaction is triggered at t, an mRNA molecule is not produced until t + τ. The parameters of the model control whether the system undergoes oscillations or aperiodic fluctuations [\citep=Galla2009]. Data was simulated in an oscillatory and non-oscillatory parameter regime using the delayed version of Gillespie's stochastic simulation algorithm [\citep=Cai2007] [\citep=Gillespie1977]. To compare with a pre-existing method, we also applied the Lomb-Scargle periodogram to the data using the "plomb’’ function within MATLAB.

Experimental procedures

Cell-lines

Cells were grown in DMEM (ThermoFisher Scientific, UK) with 10% FBS (ThermoFisher Scientific, UK). Generation of stable Hes1 reporter or control reporter cell-lines was performed by transfection of pcDNA4-Hes1::ubq-luciferase WT 3UTR or pbabepuro::ubq-luciferase respectively into C17.2 cells using Lipofectamine 2000 (ThermoFisher Scientific, UK) and addition of 1 mg/ml Zeocin (ThermoFisher Scientific, UK) or puromycin (Sigma, UK) 5ug/ml after 48 hours. Cells were maintained in antibiotic selection for 2 weeks and individual resistant colonies picked to generate single cell clones. C17.2 Hes1::ubq-luciferase clones were tested for luciferase expression and response to transient NICD over-expression in a FLUOstar Omega plate reader (BMG LabTech, UK). A representative clone was used for subsequent imaging.

Bioluminescence imaging

C17.2 reporter cells were plated on 35mm glass-based dishes (Greiner-Bio One, UK) and were allowed to adhere before serum withdrawal for 3 hours and subsequent imaging in the presence of 10% serum and 1mM D-luciferin (Promega, UK). Plates were placed on an inverted Zeiss microscope stage and maintained at 37oC in 5% CO2. Luminescent images were obtained using a 10x 0.3NA air objective and collected with a cooled charge-coupled device camera (Orca II ER, Hamamatsu Photonics). A 30 minute exposure and 2x2 binning was used.

Image analysis

Bioluminescent movies were analysed in Imaris (Bitplane, UK). Images were first subject to a 3x3 median filter to remove bright spot artefacts from cosmic rays. Individual cells and background regions were tracked manually using the "spots" function and single cell bioluminescence values over time were extracted.

Results

In order to characterise the performance of the new method based on Gaussian processes we compare it with the Lomb-Scargle periodogram on synthetic data. We subsequently apply the method to live cell imaging from C17.2 neural progenitor cells to assess ability to discriminate the activity from two different types of promoter.

Performance on synthetic data

Having defined a stochastic model to generate synthetic data, we now proceed to evaluate the performance of the new Gaussian process method versus the Lomb-Scargle periodogram [\citep=Glynn2006] in classifying cells as oscillatory or non-oscillatory. As the data is generated from a computational model it is known whether each time series is from an periodic or aperiodic parameter regime and hence we can quantify the statistical performance of the two methods.

In order to ascertain that the model is in an oscillatory or non-oscillatory regime, we calculate the average power spectra for cells simulated with the two different parameter sets (parameters given in Fig [\ref=LS]). The power spectrum is the Fourier transform squared, and while is does not individually classify cells, it shows the average behaviour of a large population. For the non-oscillatory regime the average power spectrum of 1000 cells shows no peak (Fig [\ref=LS]A), indicating that the cells undergo random fluctuations with no characteristic periodicity. The average power spectrum from the oscillatory regime shows a clear peak at a frequency of 0.5 hours- 1, corresponding to a period of 2 hours (Fig [\ref=LS]B).

We simulated data from 1000 cells for the Hes1 model in both the oscillatory and non-oscillatory parameter regime, and the protein levels were measured every 30 minutes for 25 hours, which is approximately the same as available for experimental data [\citep=Goodfellow2014]. Measurement noise with a standard deviation of 10% of the signal was then added to each time point. An example time series from the non-oscillatory regime is shown in Fig [\ref=LS]C, and the calculated LLR for the cell was 6.5. Fig [\ref=LS]D shows an example from the oscillatory regime, with an associated LLR of 44.6.

The Lomb-Scargle periodogram of the non-oscillating cell is highly noisy and contains strong contributions at multiple frequencies (Fig [\ref=LS]E). The signal exceeds the threshold for a significant p-value threshold of 0.05, and is therefore classified as oscillating. This particular cell would represent a false positive at this particular p-value threshold of 0.05. The Lomb-Scargle periodogram of the oscillating cell is shown in Fig [\ref=LS]F, where the signal passes the 0.05 p-value significance threshold, and is classified as oscillating.

We use the Receiver Operating Characteristic (ROC) curve to systematically compare the performance of both methods [\citep=Broadhurst2006], which plots the true positive rate against the false positive rate of classifying oscillating cells for the synthetic data set. Both methods require a threshold to classify a cell as oscillatory (either LLR for Gaussian process or p-value for Lomb-Scargle), and varying the threshold controls the number of false positives to true positives. The ROC illustrates the performance of both methods as the threshold is varied, where a greater area under the curve indicates a better ratio of true positives to false positives.

For the first synthetic data set used to generate a ROC curve, the protein levels were measured every 30 minutes for 25 hours and measurement noise with a variance of 10% of the signal was then added to each time point (representative time series of non-oscillating and oscillating cell shown in Fig [\ref=ROC]A and B, respectively). The area enclosed by the ROC curve of the new method is greater than the Lomb-Scargle periodogram (Fig [\ref=ROC]C), and this shows that it is able to distinguish oscillating and non-oscillating cells with higher performance for the synthetic data set. When the level of experimental noise is increased to 50% of the signal, the time series look noisier (Fig [\ref=ROC]D and E). The area under the ROC curve is reduced for both methods, although the Gaussian process method still performs better (Fig [\ref=ROC]F). For the final data set we consider experimental noise of 10% of the signal and a reduced length of 10 hours (Fig [\ref=ROC]G and H). The area under the curve is smaller for both methods, which demonstrates that the performance of detecting periodic signals is poorer when the time series is short although the Gaussian process again still performs better (Fig [\ref=ROC]I).

In order to investigate the effect of detrending on the performance of classification and period estimation, we added a long term trend at a length scale of αSE  =   exp ( - 4) to oscillatory and non-oscillatory synthetic data (representative time series of oscillating cell shown in Fig [\ref=UpperBound]A). Each cell was then detrended using an upper bound on the detrending parameter αSE of exp ( - 6), exp ( - 4) and exp ( - 2). The higher the upper bound, the more flexible the fitted trend is to the data (Fig [\ref=UpperBound]B, D and F). We sought to characterise the effects of detrending on the performance of FDR estimation. When the detrending parameter is lower than the true trend and does not provide enough flexibility (exp ( - 6)), (20/1000) non-oscillating cells passed the test while (817/1000) oscillating cells passed, giving an achieved FDR of 2.4% and true positive rate (TPR) of 82%. When the correct length scale of exp ( - 4) is used, (59/1000) non-oscillating cells passed the test while (955/1000) oscillating cells passed, giving an achieved FDR of 5.8% and TPR of 96%. Finally, when the detrending parameter provides too much flexibility (exp ( - 2)), (68/1000) non-oscillating cells passed the test while (958/1000) oscillating cells passed, giving an achieved FDR of 6.6% and statistical power of 96%. Note that the reason why the achieved FDR exceeds the expected value of 5% is that the synthetic bootstrap data does not perfectly represent the Gillespie data used to simulate cells, and this leads to an LLR distribution of non-oscillating cells in the Gillespie simulations that is broader than the synthetic bootstrap distribution ([\ref=SuppFigGillespieWithTrendOffset] Fig). The first challenge is to perfectly disentangle trends from the underlying signal, and the variance of the trend may be underestimated. The second is that Gillespie simulations are only approximated by Gaussian processes, and even without any trend added the LLR distribution do not perfectly match ([\ref=SuppFigGillespieNoTrend] Fig). However, even when non-oscillating data are generated by an OU Gaussian process the average LLR score is still lower in the synthetic bootstrap ([\ref=SuppFigOUnotrend] Fig). This may be because the time scale of fluctuations is typically underestimated i.e. fluctuations are inferred to be more rapid than they really are. This issue of biased parameter estimation is mitigated when the time series is longer and the averages are better matched. The average estimated period of the oscillating cells is also affected by the detrending length scale, where the period decreases from 2.66 to 2.41 hours as αSE is increased from exp ( - 6) to exp ( - 2) (Fig [\ref=UpperBound]C, E and G).

In conclusion, the method of classifying cells based on Gaussian processes is much more effective than the Lomb-Scargle periodogram on data simulated with a stochastic model over a range of noise levels and time lengths. Our estimated FDR provides a useful threshold for controlling false discoveries but we find that the achieved FDR is typically a little higher than the expected FDR due to approximations used in our parametric bootstrap approach.

Application to bioluminescence imaging data

Having demonstrated the utility and accuracy of our method on synthetic data, we then applied the method to an experimental data set consisting of live single cell bioluminescence imaging. A firefly luciferase reporter was driven either by the 2.7 Kb region of the Hes1 promoter or by a constitutive murine leukaemia virus (MMLV) (5' LTR) promoter, and bioluminescence of single cells was measured by exposing the camera to signal over 30 minutes, to give time points every 30 minutes, where the length of time series ranged from 26 to 72 hours. The Hes1 promoter has been previously reported to drive oscillatory expression due to negative feedback of the Hes1 protein on its own promoter [\citep=Masamizu2006] [\citep=Shimojo2008], although the proportion of oscillating cells within an experimental population of cells remains unknown. Examples of the time series generated by a sequence of bioluminescent images from both promoters are shown in Fig [\ref=Images]. As can be seen in the traces of single cells in Fig. [\ref=Images], both the oscillatory ([\ref=Images]A-C) and the constitutive reporter ([\ref=Images]D-F) show dynamic expression with many peaks and troughs. Intuition is insufficient to classify these cells, and an objective statistical measure must be used.

All cells from both the Hes1 (19 cells) and MMLV promoter (25 cells) were analysed by calculating the LLR between OU and OUosc models. The LLRs of the Hes1 promoter cells ranged from 0 to 40, with a reasonably uniform distribution over the entire range (Fig [\ref=LLRdists]A). The distribution of the LLRs for the MMLV promoter cells were more peaked towards lower values, with fewer cells having a high LLR (Fig [\ref=LLRdists]B). The FDR is then required to decide the LLR cut-off threshold and quantify the numbers of oscillating cells in each population.

Using the parameters of the trend and OU model fitted to both the cells with Hes1 and MMLV promoter, we simulated 2000 synthetic cells from the OU model and calculated the LLR. This defined our null distribution of LLRs, representing the distribution expected from a population of non-oscillating cells (Fig [\ref=LLRdists]C). The LLR distribution from the null distribution was more similar to the MMLV promoter than the Hes1 promoter (compare Fig [\ref=LLRdists]B with C), indicating that the proportion of non-oscillating cells in the MMLV promoter data set was higher. By comparing the null distribution with the pooled experimental data from the Hes1 and MMLV promoter we obtained an estimate of the the FDR at various LLR thresholds, and we control the FDR at 5%. At an FDR of 5%, 10/19 of the cells from the Hes1 promoter exceed the LLR threshold and are classified as oscillatory, whereas 0/25 cells from the MMLV promoter pass. This shows that the method is able to classify a higher proportion of cells as oscillatory from single cell gene expression data of a promoter with known oscillatory behaviour relative to a promoter with constitutive expression. If the FDR is made less stringent and controlled at 10%, 12/19 Hes1 and 0/25 MMLV cells pass the test.

Note that the detrending parameter has an effect on the overall ranking of cells. The analysis of the data was performed with a detrending parameter of -  αSE  =   exp ( - 4.5), which corresponds to a time scale of 6.7 hours. The ranked list of LLRs is shown in Table [\ref=table:MyTableLabel], with detrending parameters of -  αSE  =   exp ( - 4.5), exp ( - 4) and exp ( - 5).

Discussion

Oscillations are important for a wide range of biological processes, but current methods for discovering oscillatory gene expression are best suited for regular oscillators and assume white noise as a null hypothesis of non-oscillatory gene expression. We have introduced a new approach to analysing biological time series data well suited for cases where the underlying dynamics of gene expression is inherently noisy at a single cell level. By modelling gene expression as a Gaussian process, two competing models of single cell dynamics were proposed. An OU model describes random aperiodic fluctuations, but in contrast to white noise the fluctuations are correlated over time, and this may form a more appropriate model of non-oscillating single cells for statistical testing. The OUosc model describes quasi-periodic oscillations with a gradually drifting phase causing "dephasing" whereby an initially synchronous population of cells lose phase with one another; such dephasing has been observed in the Hes1 system [\citep=Hirata2002]. This general class of quasi-periodic covariance function, which is the product of a decaying and oscillatory function, has been described before [\citep=Solin2014] but has not to our knowledge been derived from a mechanistic model of a chemical reaction system. Gaussian processes have previously been used to detect periodicity in biological time course data [\citep=Durrande2016] but not in the context of quasi-periodic stochastic signals.

An alternative but related method was proposed by Westermark et al. [\citep=Westermark2009], which attempted to discriminate whether single cell circadian imaging data is best described by self-sustained limit cycle oscillations or by noise-induced oscillations. Whilst both methods assume that the dynamics are noisy, the data fitting procedure used by Westermark et al is markedly different, as their model is fitted directly to the empirical autocorrelation of the data. This allows one to describe how well each model fits the data in isolation, but cannot make comparisons between models to ask which is more likely given the data. Here we employed Gaussian processes to find the likelihood of the data for two competing models (OU and OUosc), and this allowed us to make direct comparisons between the two using a statistical test on the LLR between the two models.

As a practical application of their algorithm, Westermark et al. fitted circadian time series of cells with gene knock-outs and subsequently compare the parameters of the fitted models. If a genetic perturbation causes a systematic change to the dynamics, mutants may carry signatures in their time series that can be discovered by clustering in parameter space. This clustering of time series with parameters can also be performed with our method, as the period and quality parameters are estimated for each cell. Additionally, our method can also be used to quantify the percentage of cells with oscillatory versus non-oscillatory activity for various mutants. This allows quantitative assessment of the degree of disruption to oscillatory dynamics caused by a genetic mutation, which has a wide range of applications for both circadian and ultradian fields.

Our analysis method could form a starting point from which extensions can be designed to customise it for different experimental purposes. Firstly, our method could be extended to form a statistical test for whether two oscillating time series are coupled or synchronised. For example, dual-colour imaging in a single cell can be used to image the expression of two genes simultaneously. Using the same Gaussian process framework, one model could propose that the oscillations are independent while another could describe them as coupled oscillators (with a possible phase-shift between them). Through calculating a LLR between the competing models, a confidence measure could similarly be defined that the two oscillators are coupled.

Secondly, our method currently assumes that gene expression is either oscillatory or non-oscillatory for the entire duration of the time series. During development, however, stem cells may make dynamic transitions from oscillatory to non-oscillatory gene expression as they differentiate into more specialised cells [\citep=Imayoshi2013] [\citep=Goodfellow2014]. A "changepoint" model can be proposed in order to account for this behaviour, where the covariance function can switch between OU and OUosc at a given time point. Gaussian processes have previously been used for changepoint detection (e.g. [\citep=Saatci2010]).

Finally, the method could be adapted to infer spatial organisation and pattern formation. The starting point of the method was a chemical reaction system in a well-mixed compartment, where space was neglected. In spatial systems, the combination of reaction and diffusion can lead to the formation of Turing Patterns [\citep=Turing1952], such as digit patterning during limb development [\citep=Badugu2012]. The LNA can be applied to derive equations for stochastic Turing patterns [\citep=Biancalani2010], where intrinsic noise can induce pattern formation for parameters where the deterministic system reaches a homogeneous state. A similar method to the one presented here could therefore be applied to spatial systems to provide a confidence measure that a system is spatially organised in patterns as opposed to randomly structured [\citep=Solin2013].

By quantifying the proportion of oscillating cells in a statistically objective manner, we hope that our method will provide a useful tool to single cell gene expression community and that the method is expanded upon for future applications.

Acknowledgements

We are grateful to Prof. Mike White and Dr. David Spiller for their invaluable help with imaging.

Supplementary figures