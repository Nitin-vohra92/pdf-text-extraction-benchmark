Recurrent Fully Convolutional Neural Networks for Multi-slice MRI Cardiac Segmentation

Introduction

Cardiovascular disease is one of the major causes of death in the world. Physicians use imaging technologies such as magnetic resonance imaging (MRI) to estimate structural (e.g. volume) and functional (e.g. ejection fraction) cardiac parameters for both diagnosis and disease management. Fully-automated estimation of such parameters can facilitate early diagnosis of the disease and has the potential to remove the more mechanistic aspects of a radiologist's assessment. As such, lately there has been increasing interest in machine learning algorithms for fully automatic left-ventricle (LV) segmentation [\cite=avendi2016] [\cite=ngo2014] [\cite=hu2013] [\cite=huang2011] [\cite=jolly2009]. This is a challenging task due to the variability of LV shape across slices, cardiac phases, patients and scanning machines as well as weak boundaries of LV due to the presence of blood flow, papillary muscles and trabeculations. A review of LV segmentation methods in short-axis cardiac MR images can be found in [\cite=petitjean2011].

The main image analysis approaches to LV segmentation can be grouped into three broad categories: active contour models, machine learning models, and hybrid versions that combine elements of the two approaches. Active contour models with either explicit [\cite=kass1988] or implicit [\cite=li2010] contour representations minimize an energy function composed of internal and external constraints. The internal constraints represent continuity and smoothness of the contour and external constraints represent appearance and shape of the target object. However, designing appropriate energy functions that can handle all sources of variability is challenging. Also, the quality of the segmentations produced by these methods typically depends on the region-of-interest (ROI) used to initialise the algorithms. Machine learning approaches have been proposed to circumvent some of these issues [\cite=huang2004] [\cite=ngo2013] [\cite=ngo2014] [\cite=avendi2016] at the expense of collecting large training datasets with a sufficient number of examples. Investigating hybrid methods that combine some elements of both approaches is an active research area [\cite=georgescu2005]. Current state-of-the-art LV segmentation approaches rely on deep artificial neural networks [\cite=ngo2013] [\cite=ngo2014] [\cite=avendi2016]. Typically, these solutions consists of three distinct stages carried out sequentially. Initially, the LV is localised within each two-dimensional slice; then the LV is segmented, and finally the segmentation is further refined to improve its quality. For instance, a pipeline consisting of Deep Belief Networks (DBNs) for both localisation and segmentation, followed by a level-set methodology, has shown to generate high-quality segmentations [\cite=ngo2014]. In more recent work, a different pipeline has been proposed that consists of convolutional neural networks for initial LV detection, followed by a segmentation step deploying stacked autoencoders, and a fine-tuning strategy also based on level-sets methodology [\cite=avendi2016]. The latter approach has been proved to produce state-of-the-art results on the MICCAI 2009 LV segmentation challenge [\cite=radau2009]. Both approaches share a number of common features. First, the segmentation is carried out using two-dimensional patches that are independently extracted from each MRI slice. Second, they use a separate architecture for the two tasks, localization and segmentation. Third, different neural network architectures are trained for cardiac MR slices containing the base and apex of the heart, due to the observed heterogeneity in local shape variability.

In this work we investigate a neural network architecture, trained end-to-end, that learns to detect and segment the LV jointly from the the entire stack of short-axis images rather than operating on individual slices. Recently, fully convolutional networks (FCN) have been proposed for the segmentation of 2D images [\cite=long2015]. They take arbitrarily sized input images, and use feature pooling coupled with an upsampling step to produce same size outputs delivering the segmentation. Compared to more traditional sliding-window approaches, FCNs are more efficient. They have received increasing interest lately as they unify object localization and segmentation in a single process by extracting both global and local context effectively [\cite=long2015] [\cite=ronneberger2015]. Applications of FCNs to medical imaging segmentation problems have also started to appear, for instance for the identification of neuronal structures in electron microscopic recordings [\cite=ronneberger2015]. In independent work, Valipour et al. [\cite=valipour2016] have recently adapted recurrent fully convolutional networks for video segmentation.

Here we propose an extension of FCNs, called Recurrent Fully-Convolutional Networks (RFCN), to directly address the segmentation problem in multi-slice MR images. We are motivated by the desire to exploit the spatial dependences that are observed across adjacent slices and learn image features that capture the global anatomical structure of the heart from the full image stack. We investigate whether exploiting this information is beneficial for accurate anatomical segmentation, especially for cardiac regions with weak boundaries, e.g. poor structural contrast due to the presence of blood flow, papillary muscles and trabeculations.

Datasets

Our experiments are based on two independent datasets consisting of short-axis cardiac MR images for which the endocardium has been manually segmented by expert radiologists in each axial slice. Further details are provided below.

MICCAI dataset

The MICCAI 2009 LV Segmentation Challenge [\cite=radau2009] dataset was made publicly available by the Sunnybrook Health Sciences Center (Canada) and has been extensively used to compare a number of LV segmentation algorithms [\cite=jolly2009] [\cite=huang2011] [\cite=hu2013] [\cite=ngo2013] [\cite=ngo2014] [\cite=avendi2016]. It consists of 45 CINE MRI images from a number of different pathologies. The individual exams have been pre-grouped into training, validation and online testing subsets. Each subset contains 15 cases of which 4 heart failure with infarction (HF-I), 4 heart failure without infarction (HF), 4 LV hypertrophy (HYP) and 3 healthy subjects. However, the clinical information has not been used by any of the algorithms discussed here and in our experiments. All the images were obtained during breath-hold sessions lasting 10 - 15 seconds with a temporal resolution of 20 cardiac phases over the heart cycle. A typical phase, end diastole (ED) or end systole (ES), contains 6 - 12 short-axis slices obtained from the base to apex. In all the images, the slice thickness is 8mm, the inter-slice gap is 8mm, the field of view is 320mm ×   320mm and the pixel size is 256 ×  256. In all 45 samples, LV endocardial contours were drawn by an experienced cardiologist by taking 2D slices at both the end-systolic and end-diastolic phases, and then independently confirmed by a second reader. The manual segmentations were used as ground truth for the evaluation of the proposed models. Each set consists of 30 sequences (15 samples for each one of the two cardiac phases) with an average sequence length 8.94 slices.

PRETERM dataset

A second and larger dataset was used for an independent evaluation of all the cardiac segmentation algorithms. The dataset consists of 234 subjects used to study perinatal factors modifying the left ventricular parameter [\cite=lewandowski2013]. All the individuals are between 20 to 39 years of age. Of these, 102 were followed prospectively since preterm birth, and are characterised by an average gestational age of 30.3  ±  2.5 weeks and a birth weight of 1.3  ±  0.3 kg. The remaining 132 subjects were born at term to uncomplicated pregnancies. Short-axis CINE MRI stacks were acquired with a 1.5-T Siemens Sonata scanner. All images have a 7mm slice thickness and 3mm inter-slice gap, the in-plane resolution is 1.43  ±  0.29 mm (min. 0.57, max 2.17). All cardiovascular MRI was prospectively ECG gated and acquired during end-expiration breath holding. LV slices and endocardial masks were resampled into a homogeneous in-plane resolution of 2mm, which yield slice pixel size of 212  ×  212. Left ventricular short-axis endocardial borders were manually contoured by an expert reader at ES and ED using Siemens analytic software (Argus, Siemens Medical Solutions, Germany). The dataset was randomly divided into training, validation and testing sets of sizes 194,20 and 20, respectively.

Recurrent fully-convolutional networks

The proposed recurrent fully-convolutional network (RFCN) is an extension of the architecture originally introduced in [\cite=long2015] for predicting pixel-wise, dense outputs from arbitrarily-sized inputs. The main idea underlying FCNs is to extend a contracting path, in which a sequence of pooling operators progressively reduces the size of the network, by adding successive layers where pooling operators are replaced by upsampling operators. In this respect, our architecture is similar to U-net [\cite=ronneberger2015] where the expanding path is characterised by a large number of feature channels allowing the network to propagate context information to higher resolution layers.

Our purpose is to model the full stack of short-axis images extracted from cardiac MRI and improve the segmentation of the left ventricle in each slice by leveraging inter-slice spatial dependences. The input is the entire sequence of S slices obtained at a particular cardiac phase (ED or ES) and the output is the sequence of corresponding (manually produced) left-ventricular masks. Each input and output image is assumed to have equal size. A schematic illustration is given in Figure [\ref=fig:rfcn_inputs]. As can be seen there, slices around the base of the heart (at the top) cover larger LV regions and show relatively clear boundaries whereas slices around the apex (at the bottom) cover smaller LV regions and present more blurred boundaries. Learning the typical shape deformations that are observed as we move from the base towards the apex is expected to improve the overall quality of the segmentation in challenging regions around the apex.

Three main building blocks characterise the proposed RFCN as illustrated in Figure [\ref=fig:rfcn_model]: a feature-extraction (contracting) path, a global-feature component and an upsampling (expanding) path. The feature-extraction component, which is independently applied to each image in the stack, deploys successive convolution and max-pooling operations to learn higher level features and remove local redundancy. In our architecture, this component consists of a repeated block of two (3  ×  3) convolutional layers (with stride of 1) followed by a rectified linear unit (ReLU) and a (2  ×  2) max pooling layer (with stride of 2). We doubled the number of feature channels c after each max pooling layer to maintain enough context, i.e each block takes an input of size (c  ×  h  ×  w) and generates output feature maps of size (2c  ×  h / 2  ×  w / 2).

At the end of this contracting path the network has extracted the most compressed features carrying global context. The global feature component starts here with a (3  ×  3) convolutional layer (with stride of 1) followed by a ReLU. We denote [formula] the output of this layer where s indicates the slice index, i.e. [formula]. This output consists of (256  ×  30  ×  30) feature maps. In an attempt to extract global features that capture the spatial changes observed when moving from the base to the apex of the heart, we introduce a recurrent mechanism mapping [formula] into a new set of features, [formula], where φ(  ·  ) is a non-linear function, and the size of [formula] is the same as the size of [formula]. Another (3  ×  3) convolutional layer (with stride of 1) followed by a ReLU is then applied to complete the global-feature extraction block. Given that training recurrent architectures is particularly difficult due to the well-document vanishing gradient problem, several options were considered for the implementation of recurrent function φ, including a Long Short-Term Memory (LSTM) [\cite=hochreiter1997] and Gated Recurrent Units (GRUs) module [\cite=cho2014]. GRUs in particular have been shown to achieve a performance comparable to LSTM on a number of tasks involving sequential data whilst requiring fewer parameters and less memory [\cite=chung2014]. Here we have chosen to use a convolutional variant of GRU so that the local correlation of the input images are preserved whilst achieving a notable reduction in the number of parameters compared to its non-convolutional counter part.

For every slice, the dense feature maps that have been learned by the convolutional GRU module are then upsampled to compensate for the input size reduction caused by the max-pooling operations. The upsampled features are concatenated with a high resolution parallel layer aligned to the feature-extraction component, similarly to the U-net architecture [\cite=ronneberger2015]. Our upsampling component consists of a repeated block of a convolutional layer (with a fractional stride of 1 / 2), a feature map concatenation module and two 3  ×  3 convolutional layers (with stride of 1) followed by ReLU. The feature map concatenation module combines the outputs of the upsample layer and parallel feature-extraction block. Each block of the upsampling component takes a three-dimensional input c  ×  h  ×  w and output c / 2  ×  2h  ×  2w dimensional tensor. A convolutional operation with fractional stride is employed to compensate the reduction in input size due to the max pooling operation. Even though the upsampling procedure smooths out the boundaries of the object to be segmented, the concatenation of up-sampled feature maps with high-resolution feature maps helps mitigate this smoothing problem by providing better local and boundary information. The final segmentation is obtained by using a 1  ×  1 convolutional layer, which maps the output of the upsampling component onto the two classes, i.e. LV and background. The probability for each class is given by a softmax function across all pixel locations.

Other architectures and model training

Recently, deep belief networks (DBNs) have been proposed for automatic LV detection and segmentation using short-axis MR images [\cite=ngo2013] [\cite=ngo2014]. A DBN was first used to detect the region of interest containing the LV. Anatomical segmentation was then carried out using distance-regularised level sets, which were modified to leverage prior shape information inferred by a separate DBN. In these models, as in FCNs, each slice in the short-axis stack is segmented independently of all the others. The main building block of a DBN model is a restricted Boltzmann machine (RBM), typically trained using the contrast divergence algorithm [\cite=hinton2006]. In some of our experiments, we have assessed the performance of DBNs for LV segmentation comparably to FCNs and the proposed RFCNs.

In order to further investigate whether modelling the dependence across slices typically yields improved performance, and motivated by the existing body of work on DBNs, we have also assessed the performance of a recurrent version of restricted Boltzmann machines (RRBM), originally proposed to learn human body motion [\cite=sutskever2009], but never used for LV segmentation. RRBMs are stacked together to form what we call a recurrent deep belief network (RDBN). Similarly to the proposed RFCN, RDBN takes the entire sequence of short-axis slices as input and leverages the spatial correlations through additional bias units. For further information, we refer the reader to the original work [\cite=sutskever2009].

The two convolutional architectures, FCN and RFCN, were trained by minimizing the cross-entropy objective function. FCN was trained using a stochastic gradient descent algorithm with momentum whereas RFCN was trained using a stochastic gradient descent algorithm with RMSProp [\cite=tieleman2012]. Back-propagation was used to compute the gradient of the cross-entropy objective function with respect to all parameters of the model, including the GRU component in the case of RFCN. We also learned [formula] as required by the first slice of the sequence. In each block, batch normalization [\cite=ioffe2015] was added after each convolutional layer, i.e. just before the max-pooling and upsampling layers. All reported results refer to the best out of 5 experiments in which the models were initialised with random parameters. RFCN was initialised using weights obtained from FCN, which reduces the training time and provided the good initial weights. Both the DBN and RDBN architectures were trained using the contrast divergence algorithm [\cite=hinton2006]. Dropout [\cite=hinton2012] was found to improve their overall performance. For all these models, best results were achieved using a learning rate of 0.01 with constant decay of 3% after each epoch, a momentum of 0.9 and weight decay of 0.00005. At the training phase, both the MICCAI and PRETERM datasets were augmented by generating additional artificial training images to prevent model overfitting. During training, we performed translation (±  16 pixels) and rotation ([formula]) data augmentation, which was found to yield better performance.

Experimental results

This section presents an empirical evaluation of several LV endocardium segmentation algorithms using three performance metrics: good contours (GC) [\cite=avendi2016], Dice index, and average perpendicular distance (APD) between manually drawn and predicted contours [\cite=radau2009]. In order to make our experimental results comparable with published studies on MICCAI dataset, all models were validated using the online set, and we report on results obtained on the validation set. Table [\ref=tbl:results] summarises the experimental results. On the MICCAI dataset, the DBN-based results presented in [\cite=ngo2014] include a Dice index of 0.88, a GC of 95.71% and an APD of 2.34 mm whereas the pipeline described in [\cite=avendi2016] results in a Dice index of 0.90, a GC of 90% and an APD of 2.84 mm (before further post-processing). A comparable Dice index is obtained by both FCN and RFCN, which yield higher GC and smaller ADP. Here RFCN outperforms FCN with a substantially improved ADP of 2.05 mm.

The PRETERM dataset was modelled using the the same architectures, without further customisation. The results of this application are also summarised in Table [\ref=tbl:results]. For this dataset, we compared the performance of four different architectures: FCN, RFCN, DBN and RDBN. The latter two models were given as input a region of interest containing the LV thus conferring them an advantage compared to FCN and RFCN. On this dataset we were not able to test the recently proposed pipeline described in [\cite=avendi2016], which relies on multiple stages. As in the MICCAI dataset, the fully convolutional architectures have achieved superior performance. RFCN has outperformed all other architectures in terms of Dice index and APD, which was found to be as small as 1.56 mm. In comparison, DBN with known LV location yields an APD of 2.05 mm. RDBN yields higher GC and lower APD compared to DBN thus providing additional evidence that performance gains can be obtained by modelling intra-slice dependences.

In order to shed insights into the regional improvements introduced by RFCN, the Dice index was computed separately for different local regions of the LV, and the results are summarised in Table [\ref=tbl:results_break_down]. Here, Base-1, Base-2 and Base-3 indicates that 1, 2 and 3 slices were taken starting from the base of the heart and moving towards the middle, and analogously for the apex. All the remaining slices contributed towards the Central class. In all cases, the Dice index is calculated using all the samples at once to reflect overall pixels accuracy. In both datasets, RFCN outperforms FCN around the central slices and around the apex, as expected. However, in the MICCAI dataset, FCN yields better performance around the base of the heart. On the PRETERM dataset, both DBN and RDBN gave the worst performance, compared to FCN and RFCN, despite using focused region of interests instead of full-sized images. Here again it can be observed that RDBN improves upon DBN across all cardiac locations.

Conclusions

In this paper we have investigated whether a single neural network architecture, trained end-to-end, can deliver a fully-automated and accurate segmentation of the left ventricle using a stack of MR short-axis images. The proposed architecture, RFCN, learns image features that are important for the localisation of the LV in a sequential manner, going from the base to the apex of the heart, through a recurrent modification of fully convolutional networks.

Experimental findings obtained from two independent applications demonstrate that propagating information from adjacent slices can help extract improved context information with positive effect on the resulting segmentation quality. The hypothetical value of the large inter-slice correlation has been further tested by introducing a recurrent version of deep belief networks, and verified with our results showing that RDBNs generally outperform DBNs on the segmentation task, assuming the LV has already been localised. As expected, notable improvements can be seen in the delineation of cardiac contours around the apex, which are notoriously more difficult to identify.

One surprising finding was to note that performance of RFCN in apical slices was better for MICCAI than for PRETERM cohort (0.85 vs. 0.76 Dice index in the most apical slice, see Table 2), when one could expect the opposite: a regular and homogeneous cohort, PRETERM, should lead to a better performance when leveraging the inter-slice spatial dependence. This aspect will warrant further investigations.

Compared to other models, RFCN has the advantage of carrying out both LV detection and segmentation in a single architecture with clear computational benefits and the potential for real-time application. In future work, we are planning to investigate alternatives operations that can capture inter-slice correlations, such as 3D convolutions, and further extend RFCN by incorporating a bi-directional mechanism for the inclusion of an inverse path (from the apex to the base of the heart) as well as a temporal extension to handle all cardiac phases at once.

Acknowledgements

The authors would like to thank Paul Leeson and Adam Lewandowski from Oxford University for their assistance with the PRETERM dataset.