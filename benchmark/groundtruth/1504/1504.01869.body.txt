On Multi-Step MLE-Process for Ergodic Diffusion

Key words: Parameter estimation, ergodic diffusion process, one-step and two-step MLE-processes

Introduction

We consider the problem of parameter estimation by the continuous time observations [formula] of the diffusion process

[formula]

We suppose that the process [formula] has ergodic properties with the density of invariant distribution [formula]. The functions [formula] and [formula] are known, smooth and the parameter ϑ∈Θ  ⊂  Rd. It is known that the maximum likelihood estimator (MLE) T constructed by the observations XT (under regularity conditions) is consistent, asymptotically normal and asymptotically efficient (see, e.g., [\cite=Kut77] or [\cite=Kut04]).

We consider here slightly different statement of the problem. Suppose that we are interested by an estimator-process [formula], where t,T depends on the observations [formula] only. The need of such on-line estimators naturally arises in many problems, for example in adaptive control. We used such estimators in the construction of the approximation of the solution of backward stochastic differential equation [\cite=KZ14], [\cite=Kut14], where the estimator-processes were of the one-step MLE-type. Note that there is a large literature on stochastic approximation, which provides satisfactory solutions (see, e.g.; [\cite=KY], and references therein). For continuous time systems such problems were studied for example in [\cite=H67] and [\cite=NH73]. In the last work there was proposed a recurrent asymptotically efficient estimation in the case of observations

[formula]

Another recurrent estimator-process for diffusion processes was studied in [\cite=LSZ94]. We have to mention that the estimator-process proposed in our work is not recurrent in this sense. The right-hand side of the equation for it does not depend on the preceding values of this estimator (see [\eqref=01] below).

For diffusion processes observed in discrete times the adaptive estimation of the parameters of the trend and diffusion coefficients were studied in many works, see, e.g., [\cite=Y92], [\cite=Kes97], [\cite=UY12],[\cite=UY14] and the references therein. Note that in the works [\cite=UY12] and [\cite=UY14] the proposed multi-step adaptive procedures of parameter estimation allows to improve the initial bad rates of convergence up to asymptotically efficient (good) rates.

The studied in the present work estimator-processes are based on the one-step MLE structure. Recall that the one-step MLE was introduced by Le Cam [\cite=LC56] in 1956. The definition and properties of it in i.i.d. case can be found, for example, in [\cite=LR05]. Let us remind it's construction. Suppose that the observed i.i.d. random variables [formula] have smooth density function [formula] with unknown parameter ϑ∈Θ  ⊂  Rd and we have to estimate ϑ. Suppose as well that we are given an estimator n which is consistent and asymptotically normal [formula] with a bad d  ×  d limit covariance matrix [formula], i.e., the matrix [formula] is positive definite. We say "bad" because [formula] is not equal to the the inverse Fisher information matrix [formula], which is limit covariance of asymptotically efficient estimators. The one-step MLE is defined as follows

[formula]

Here and in the sequel dot means derivation w.r.t. ϑ. The estimator [formula] has already the good limit covariance matrix

[formula]

Therefore this procedure allows us to improve any estimator with good rate [formula] but bad limit covariance up to asymptotically efficient.

The one-step MLE [formula] for ergodic diffusion process can be defined by a similar way. Suppose that we have a preliminary estimator T (say, minimum distance estimator or estimator of the method of moments), which is consistent and asymptotically normal :

[formula]

The limit variance [formula], where [formula] is the Fisher information matrix

[formula]

Here and in the sequel A* means transposition of A.

Following the same "one-step" idea we can improve this estimator up to asymptotically efficient as follows

[formula]

whehe [formula] is the one-step MLE. Of course, the special attention have to be paid for the definition of the stochastic integral because the estimator T depends on the whole observations XT. This estimator is consistent, asymptotically normal

[formula]

and asymptotically efficient (see, e.g., [\cite=Kut04]). Note that the preliminary estimator here has a good [formula] rate of convergence.

Recently Kamatani and Uchida [\cite=KU14] considered the problem of parameter estimation by the discrete time observations [formula] of ergodic diffusion process

[formula]

Here [formula] is unknown parameter. They proposed a modification of Newton-Raphson (N-R) procedure, with the initial estimators of bad (non-optimal) rate of convergence and showed that the multi-step N-R procedure allows to obtain the asymptotically efficient estimators with the good rates. The asymptotic is hn  →  0 and nhn  →    ∞  .

In our work we consider a similar construction but based on the modification of one-step MLE procedure. We propose estimator-processes [formula] and [formula], where δ < 1 and [formula] and [formula] have one-step MLE-type structure. As preliminary estimator Tδ we take an estimator constructed by the first observations XTδ on the time interval [formula]. Therefore the preliminary estimator has a bad rate of convergence due to the length of the learning interval.

Then we propose one-step (for [formula]) and two-step (for [formula]) MLE-processes. For example, the one-step MLE-process is

[formula]

where Tδ  ≤  t  ≤  T. It is shown that this estimator-process is consistent, asymptotically normal and asymptotically efficient. Note that the calculation of this estimator-process is much more simple than the calculation of the MLE t,T for all t∈[Tδ,T].

Auxiliary results

We are given a probability space [formula] with filtration [formula] satisfying the usual conditions and the Wiener process [formula]. Suppose that for all [formula], (Θ is an open bounded set) the stochastic process [formula] satisfies the stochastic differential equation

[formula]

where [formula] is the initial value. The functions [formula] and [formula] are such that this equation has a unique strong solution on any fixed interval [formula] and that the measures [formula] induced in the measurable space [formula] of its realizations are equivalent (see conditions for example here [\cite=LS05]). Moreover we suppose that the process Xt,t  ≥  0 has ergodic properties with the density of invariant distribution

[formula]

where [formula] is the normalizing constant [\cite=Kh12]. The random variable with such density we denote as ξ and suppose that X0 has the same density function. This condition makes the stochastic process stationary.

The sufficient condition for the existence of ergodic properties we take as in [\cite=Kut04]. Define the class of functions

[formula]

where the constants C > 0,q > 0 do not depend on ϑ in the case of the function [formula] and its derivatives and can be different for different functions.

Condition [formula]. The functions [formula] and

[formula]

The smoothness condition: the function [formula] has two continuous partial derivatives w.r.t. ϑ and these derivatives belong to P.

These derivatives we denote as : [formula] (vector) and [formula] (d  ×  d matrix).

The identifiability condition: for any ν > 0

[formula]

Here the r.v. ξ0 has the density function [formula].

The Fisher information matrix [formula] is uniformly non degenerate (below λ∈Rd)

[formula]

The set of all these conditions we call Regularity conditions.

We have to estimate ϑ by the observations [formula] for all t∈(0,T] and to describe the properties of the estimator-process [formula] [formula], where [formula]. We would like to obtain an estimator-process which has asymptotically optimal in some sense properties.

It will be convenient to change the variables t = τT,τ∈(0,1] and to study the random processes τ,T,0 < τ  ≤  1, where [formula]. For simplicity of exposition we will write τ,T as τ.

Introduce the likelihood ratio-process [formula], where

[formula]

Note that for any τ∈(0,1] the family of measures [formula] is locally asymptotically normal (LAN) in Θ, i.e.; the likelihood ratio-process

[formula]

with u such that [formula], admits the representation

[formula]

Here [formula], rT  →  0 and the score-function (vector-process)

[formula]

Therefore we have the following Hajek-Le Cam-type low bound for polynomial loss function (p > 0): for all estimator-processes τ,0 < τ  ≤  1 and all ϑ0∈Θ and τ∈(0,1]

[formula]

where the vector [formula], [formula] is unit d  ×  d matrix (see, e.g., [\cite=IH81] or [\cite=Kut04]).

Therefore the estimator process τ,0 < τ  ≤  1 we call asymptotically efficient if for all ϑ0∈Θ and all τ∈(0,1] we have the equality

[formula]

One solution of this problem is to introduce the MLE process τ,0 < τ  ≤  1 defined by the equation

[formula]

It is known that the estimators τ,τ∈(0,1] under regularity conditions are consistent and asymptotically normal (ϑ0 is the true value)

[formula]

Moreover we have the uniform on ϑ convergence of moments

[formula]

Therefore the MLE-process τ,0 < τ  ≤  1 is asymptotically efficient (see [\cite=Kut04]).

Unfortunately except the linear case [formula] the calculation for all τ∈(0,1] of the MLE-process as solution of the equation [\eqref=2-3] is computationally very difficult problem and we have to seek another estimator-process which is computantionally much more simple. The goal of this work is to describe such class of estimator-processes. The construction of the proposed estimator-processes is based on the development of the well-known one-step MLE device.

Main result

We consider the problem of estimation ϑ by observations Xt for [formula]. The corresponding estimators we study after the change of variables t = τT. Therefore we are interested by the construction of the estimator-process [formula], where τδ = T- 1 + δ. We show that if [formula], then the one-step MLE-process is asymptotically normal and asymptotically efficient. If [formula], then we propose two-step MLE-process with the same asymptotic properties.

One-step MLE ([formula])

Introduce the learning interval 0  ≤  t  ≤  Tδ, where [formula] and denote by τδ an estimator of parameter ϑ which is uniformly on compacts [formula] asymptotically normal

[formula]

where τδ = T- 1 + δ  →  0 and the matrix [formula] of limit covariance is bounded. Moreover we suppose that we have the convergence of all polynomial moments too: for all p > 0

[formula]

where the constant C > 0 does not depend on T. The regularity conditions providing these properties of the MLE, minimum distance estimators (MDE), bayesian estimators (BE) and the estimators of the method of moments (EMM) can be found, for example, in [\cite=Kut04], Chapter 2. Therefore as preliminary estimator we can take one of them.

The one-step MLE-process we construct as follows:

[formula]

where

[formula]

Introduce the random process

[formula]

where τ*∈(0,1) and measurable space [formula] of continuous on [formula] functions. Here [formula] is the corresponding borelian σ-algebra. Denote by [formula] a d-dimensional standard Wiener process.

Suppose that the regularity conditions hold. Then the one-step MLE-process [formula] has the following properties:

It is uniformly consistent: for any ν > 0

[formula]

For any τ*∈(0,1) the random process [formula] converges in distribution in [formula] to the vector-process [formula].

It is asymptotically efficient in the sense [\eqref=2-2] for any p > 0.

Note that for a fixed τ we have the asymptotic normality

[formula]

Proof. We denote by C the generic constant. The uniform consistency [\eqref=2-9] is verified as follows

[formula]

We have

[formula]

where [formula] and therefore

[formula]

where we used the condition [formula] and the consistency of τδ. Recall that by condition [formula] the invariant density has all polynomial moments and therefore we obtain the convergence to zero of all moments for these normalized integrals.

Further, we have for any λ∈Rd and m > 0

[formula]

where we used the Burkholder-Davis-Gundy (BDG) inequality (see, e.g., [\cite=KS], Theorem 3.28). Therefore the consistency [\eqref=2-8] is proved.

To prove the weak convergence of [formula] we write the representation

[formula]

where

[formula]

Then we verify that

We have the uniform convergence

[formula]

We have the convergence of finite-dimensional distributions: for any [formula] and [formula]

[formula]

There exists a constant C > 0 such that

[formula]

We consider T > T* where [formula], i.e., τδ  <  τ*. We can write

[formula]

where we denoted [formula] and

[formula]

Here [formula] is a difference of the corresponding expressions with τδ and ϑ0.

Then we remark that by the central limit theorem for ordinary integrals (see e.g.,[\cite=Man68] or [\cite=Kut04], Proposition 1.23) we have

[formula]

with some finite limit variance D2.

Hence

[formula]

because [formula] and [formula] are bounded in probability. To verify that this convergence is uniform in [formula] we give some details. Let us denote

[formula]

Here [formula]. Then [formula] and by Itô formula we can write

[formula]

Further by BDG inequality: for any ν > 0 and m > 0

[formula]

The existence of the related moments is verified following the same steps as in [\cite=Kut04], p.31-33. To show that [formula] we verify several estimates like

[formula]

and (below [formula])

[formula]

Note that the convergence [\eqref=2-15] is uniform w.r.t. [formula] because by BDG inequality: for any ν > 0 and any m > 0

[formula]

with some constant Km > 0.

The convergence [\eqref=2-11] follows from the central limit theorem for the vector-stochastic integrals (see, e.g., [\cite=Kut04], Proposition 1.21). Further for τ1  <  τ2 we have

[formula]

where the constant C > 0 does not depend on ϑ0 and T.

More detailed analysis based on the same estimates shows that we have the convergence of moments uniform on compacts

[formula]

From this convergence and the continuity of the matrix [formula] follows the asymptotic efficiency [\eqref=2-2] of the one-step MLE.

Two-step MLE ([formula])

The learning time interval can be shorter. Let us take the first estimator τδ constructed by the observations [formula] with [formula]. We suppose that this estimator is consistent, asymptotically normal and the moments converge too:

[formula]

for any p > 0. Here [formula] is some matrix and C > 0 does not depend on T. As before it can be the MLE, MDE, BE or the EMM.

Introduce the second preliminary estimator, which is estimator-process

[formula]

where

[formula]

The two-step MLE-process we define as follows

[formula]

where

[formula]

Note that [formula].

Suppose that the conditions of regularity hold. Then the two-step MLE-process [formula] is uniformly consistent, asymptotically normal

[formula]

and asymptotically efficient. The random process

[formula]

for any [formula] converges in distribution to the d-dimensional standard Wiener process [formula].

Proof. The proof will be given in two steps. First we show that the estimator-process τ is such that

[formula]

with [formula] and then we can use the proof of the Theorem [\ref=T1], where the mentioned properties are already established.

Let us take such [formula] that γ < 2δ. We have

[formula]

Here [formula]. We can write

[formula]

Recall that the components of the vector [formula], of the matrix [formula] and of the function [formula] have polynomial majorants and the invariant density has exponentially decreasing tails. Therefore it can be shown that the moments converge too. Moreover for any p > 0

[formula]

We have the similar relations for the two-step MLE-process too. Indeed

[formula]

where [formula]. Then the corresponding relations are

[formula]

Therefore

[formula]

The weak convergence [formula] now follows from the proof of the Theorem [\ref=T1].

Example

Suppose that the observed process is

[formula]

where [formula]. It is easy to see that the conditions of regularity are fulfilled and the process is ergodic with the density of invariant distribution

[formula]

Note that the MLE of the parameter ϑ can not be written in explicit form. Let us take [formula]. We have for the empirical mean (estimator of the method of moments) the consistency

[formula]

and asymptotic normality

[formula]

where

[formula]

Here the random variable ξ0 has the density function [formula]. The Fisher information I does not depend on ϑ and the one-step MLE-process is

[formula]

This estimator by Theorem [\ref=T1] is uniformly consistent, asymptotically normal

[formula]

and asymptotically efficient.

If the learning interval is [formula], then the preliminary estimator T3 / 8 has the rate of convergence T3 / 16. We take the second estimator-process as

[formula]

For this estimator the relation

[formula]

holds. Therefore by Theorem [\ref=T2] the two-step MLE-process

[formula]

is asymptotically normal

[formula]

The similar estimator-processes can be constructed and in the case of two-dimensional parameter [formula] and the observations

[formula]

where β > 0. Indeed suppose that [formula]. the preliminary estimator [formula] can be

[formula]

The invariant density is

[formula]

and the Fisher matrix [formula] is diagonal. Therefore the one and two-step MLE-processes can easily by written.

Discussions

Note that the process of construction of multi-step estimators can be continued. For example, if the initial rate is Tδ with [formula], then we can use once more one-step device to improve the rate of preliminary estimator up to [formula], where γ satisfies the condition γ < 2δ and so on. Therefore the asymptotically efficient estimator-process will be three-step MLE.

We used two estimators τδ and τ because the estimator τ depends on the whole trajectory XτT and the stochastic integral

[formula]

is not well defined. Another possibility to avoid this problem is to replace the stochastic integral by ordinary integrals and to use one estimator only as follows.

Suppose that the functions [formula] and [formula] are continuously differentiable w.r.t. x and the derivatives belong to the class P. Introduce the vector-process

[formula]

We have (by the Itô formula)

[formula]

The two-step MLE-process in this case is

[formula]

It can be shown that this estimator is asymptotically equivalent to [formula] and has the same asymptotic properties as those described in the Theorem [\ref=T2].

The calculation of the Fisher information matrix for some models can be a difficult problem. In such cases we can replace the Fisher information matrix [formula] by its empirical version

[formula]

The proposed in this work construction can be easily generalized to many other statistical models. At particularly, it "works" in the case of small noise asymptotic

[formula]

where T is fixed and the asymptotics corresponds to ε  →  0. We introduce a learning time interval [formula], where τε  =  εδ  →  0 and for some values of δ > 0 we show that the one-step MLE-process

[formula]

is asymptotically efficient estimator for all [formula] with any 0 < τ*  ≤  T [\cite=Kut15]. Note that for this model the construction of the consistent preliminary estimator τε of d-dimensional parameter ϑ is possible if the observed process Xt is k dimensional and k  ≥  d.

This multi-step MLE-processes can be realized and in the case of estimation of parameter ϑ by the discrete time observations [formula] [formula] of the diffusion process

[formula]

Here we suppose that the time of observation T is fixed and n  →    ∞  . The corresponding multi-step pseudo MLE-process is asymptotically efficient [\cite=GK15].

For the nonlinear autoregresive model

[formula]

the similar multi-step MLE-process provides asymptotically efficient estimator process too [\cite=KM15].

The construction of the multi-step MLE-processes can be done in the case of inhomogeneous Poisson processes, i.i.d. observations and so on.

In the work [\cite=Kut15] we apply the one-step MLE in the construction of the goodness-of-fit tests based on score-function-processes.

Note as well that the one-step MLE-process device allowed us to construct asymptotically efficient estimator of the paramezters of hidden telegraph signal [\cite=KhK15].

Aknowlledgement. This work was done under partial financial support of the grant of RSF number 14-49-00079.