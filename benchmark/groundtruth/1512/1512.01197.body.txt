The topology of large Open Connectome networks for the human brain

Introduction

Drawing parallels between neurological and socio-technological networks, neuroscientists have hypothesized that in the brain we have small-world networks [\cite=H2000] [\cite=SpHo06] with scale-free degree distribution [\cite=Egui-SF] [\cite=Heu-SF]. Small-world networks are at the same time highly clustered on a local scale, yet possess some long-distance connections that link different clusters of nodes together. This topology is efficient for signal processing [\cite=LF2000], but doubts have remained if the small-world assumption is generally true for the brain [\cite=CCH15]. Despite some evidence that networks obtained from spatially coarse-grained parcellations of the brain are small worlds [\cite=Salvador_etal05], at a cellular level the brain may be a large-world network after all [\cite=GMS12].

Like the small-world property, the hypothesis that the brain has a scale-free degree distribution became popular around the turn of the millennium. The degree ki of node i is defined as the number of edges adjacent to i. Because the degree is a basic measure of a node's centrality, the probability Pr (k) that a node has degree k has played a key role in network science for a long time [\cite=Solla76]. Especially physicists have popularized power law fits to observed degree distributions [\cite=BarabasiAlbert99] [\cite=Caldarelli07]. When such a fit is statistically justified, the network is called formally "scale-free". Power laws play a crucial role in statistical physics, where they arise at transitions between an ordered and unordered phase because of the absence of a characteristic length scale [\cite=Obook]. There are theoretical and empirical arguments that the brain operates near such a critical point [\cite=BP03] [\cite=Expert_etal11] [\cite=ShewPlenz13] [\cite=Haimovici_etal13]. For this reason it is plausible to assume that the connectome's degree distribution is also scale-free. But, similar to the small-world assumption, more sophisticated statistical analyses justify skepticism about the scale-free hypothesis [\cite=Humphries_etal06] [\cite=Ferrarini_etal11] [\cite=Le13] [\cite=Ruiz14].

In this article we answer whether the structural connectome at an intermediate spatial resolution can be viewed as a scale-free, small-world network. We analyze large data sets collected by the Open Connectome project (OCP) [\cite=OCP] that describe structural (rather than functional) brain connectivity. The particular data sets chosen by us were processed by members of the OCP from the raw diffusion tensor imaging data in Ref. [\cite=DTI]. Earlier studies of the structural network have analyzed much smaller data. For example the network obtained by Sporns et al., using diffusion imaging techniques [\cite=29] [\cite=30], consists of a highly coarse-grained mapping of anatomical connections in the human brain, comprising N  =  998 brain areas and the fiber tract densities between them. The entire brain is made up of ~  9  ×  1010 neurons [\cite=Lent_etal11], but current imaging techniques cannot resolve such microscopic detail. The networks investigated in this article have up to ~  106 nodes, which puts them on a scale that is halfway between the earlier coarse-grained view and the complete neural network.

One important measure which could not have been estimated previously because of too coarse-grained data is the topological (graph) dimension D. It is defined by

[formula]

where Nr is the number of node pairs that are at a topological (also called "chemical") distance r from each other (i.e. a signal must traverse at least r edges to travel from one node to the other). The topological dimension characterizes how quickly the whole network can be accessed from any of its nodes: the larger D, the more rapidly the number of r-th nearest neighbors expands as r increases. Different small-world networks can possess different D, for example due to their distinct clustering behavior [\cite=CCH15]. Therefore, the level of small-worldness (quantified for example by the coefficient defined in Ref. [\cite=HumphriesGurney08]) and the topological dimension contain different information.

Distinguishing between a finite and infinite topological dimension is particularly important theoretically. It has been conjectured that heterogenities can cause strong rare-region effects and generic, slow dynamics in a so-called Griffiths phase [\cite=Griff], provided D is finite [\cite=Ma2010]. Criticality or even a discontinuous phase transition is smeared over an extended parameter space. As a consequence, a signalling network can exhibit behavior akin to criticality, although it does not operate precisely on a unique critical point that sharply divides an ordered from a disordered phase. This phenomenon is pronounced for the Contact Process [\cite=harris74], a common model for the spread of activity in a network. Subsequent studies found numerical evidence for Griffiths effects in more general spreading models in complex networks [\cite=BAGPcikk] [\cite=wbacikk] [\cite=basiscikk], although the scaling region shrinks and disappears in the thermodynamic limit if D  →    ∞  . Recently Griffiths phases were also reported in synthetic brain networks [\cite=MM] [\cite=VMM] [\cite=HMNcikk] with large-world topologies. Real connectomes have finite size, so they must possess finite D. If in real connectomes D remains small, these models hint at an alternative explanation why the brain appears to be in a critical state: instead of the self-tuning mechanisms that have been frequently postulated [\cite=Bak] [\cite=HesseGross14], the brain may be in a Griffiths phase, where criticality exists without fine-tuning. Models with self-tuning require two competing timescales: a slow "energy" accumulation on the nodes and a fast redistribution by avalanches when the energy reaches the firing threshold. It is unclear if such a separation of timescales is realistic. Even if the brain were in a self-organized critical state with clearly separated timescales, Griffiths effects can play an important role due to the heterogeneous behavior of the system, frequently overlooked when modelling the brain.

Open Connectome brain network data

The data sets analyzed in this article were generated by members of the OCP with the MIGRAINE method described in Ref. [\cite=MIG]. The raw input data consist of both diffusion and structural magnetic resonance imgaging scans with a resolution of [formula] (i.e. the size of a single voxel). MIGRAINE combines various pieces of software into a "pipeline" to transform this input to a graph with 105-106 nodes.

As an intermediate step, the processing software first generates a small graph of 70 nodes [\cite=Gray]. For this purpose the image is downsampled into 70 regions taken from the Desikan gyral label atlas [\cite=Desikan_etal06]. During this step the software also identifies the fibers in the brain with deterministic tractography using the Fiber Assignment by Continuous Tracking (FACT) algorithm [\cite=Mori_etal99]. As stopping thresholds a gradient direction of 70 degrees and a stopping intensity of 0.2 were used.

These fibers are then reanalyzed in the next step of data processing. The Magnetic Resonance One-Click Pipeline outlined in Ref. [\cite=OCCres] generates a big graph where each voxel corresponds to one vertex. First a "mask" is defined, for example the 70 regions included in the small graph. Then all data outside the mask are discarded and an edge is assigned to each remaining voxel pair that is connected by at least one fiber staying within the boundaries of the mask. This procedure will naturally produce hierarchical modular graphs with (at least) two quite different scales.

At this point each scan has been turned into a network with ~  107 vertices and ~  1010 edges. However, many of these voxels must be considered as noise. To clean up the data, all vertices outside the largest connected component are removed. According to Ref. [\cite=MIG], the remaining graph "keeps essentially all white matter voxels, consisting of ≈  105 vertices and ≈  108 edges."

One important point to note is that two voxels A and C are linked by an edge even if there are other voxels [formula] between A and C on the same fiber. For example, if one traverses voxels A, B, C on a fiber, the edges (A,B), (A,C) and (B,C) are all part of the graph. Furthermore the edges are undirected so that (B,A), (C,A) and (C,B) are also part of the graph because the FACT algorithm cannot provide information about the direction of an edge. To save space the OCP data files store only one of the directions (i.e. the upper triangle of the adjacency matrix) so that the opposite direction must be inferred from the data and inserted into the graph.

There were 3 different sets of big human brain graphs available from the OCP website [\cite=OCP] with the abbreviations KKI (Kennedy Krieger Institute), MRN (Mind Research Network) and NKI (Nathan Kline Institute). The raw data are described in Ref. [\cite=DTI] [\cite=Jung_etal10] [\cite=Nooner_etal12], respectively. We analyzed the KKI graphs with numbers 10 to 19 in more detail. Some graph invariants (e.g. degrees, clustering coefficients) were calculated and analyzed in Ref. [\cite=OCCres], but for the present study we have recalculated all invariants directly from the graph data available from the OCP website.

Degree distribution

Model selection

We want to assess how well different probability distributions fit the degrees of the OCP graphs. A first rough-and-ready visual attempt supports the hypothesis that the tails might be stretched exponentials, for example for the networks KKI-10 and KKI-18 in Fig. [\ref=eloLpfit]. However, such visual techniques have no inferential power. Even if the fitted parameters come from ordinary least-squares regression toolboxes, the fitted parameters in general do not converge to the true values even if the number of data points is large. Moreover, least-squares regression lacks a statistically principled criterion for comparing different models with each other.

A statistically sound framework for model selection is information theory. Here we adopt the information-theoretic methodology proposed in Ref. [\cite=HandcockJones04], where different functions were fitted to degree distributions in sexual contact networks. The key idea is that a good model should perform well in terms of two opposing objectives. On one hand the model should have enough flexibility so that it is able to fit the observed distribution. On the other hand it should have only a minimal number of parameters. In general, the more parameters we have at our disposal, the better we can fit the observation.

The goodness of fit can be quantified by the likelihood function which, under the assumption of independent observations, has the form

[formula]

Here [formula] is the set of parameters in the model, N the number of observations, and [formula] are the observed degrees. Alternatively we can write the likelihood as

[formula]

where [formula] and [formula] are the minimum and maximum observed degrees and ni is the number of times we observe the degree ki. In the graphs KKI-10 through KKI-19, [formula] is always equal to 1; [formula] ranges from 5154 to 11  241. In the extreme case of allowing as many parameters as there are observed degrees we can achieve a maximal likelihood of e- nH, where [formula] is the Shannon entropy of the data. However, such a highly parameterized model is no longer informative, because it fits only the particular connectome used as input and sheds little light on general features that different connectomes might have in common.

Statisticians have proposed several "information criteria" to address this problem of over-fitting (e.g. Bayesian, deviance or Hannan-Quinn information criteria). These are objective functions that rate the quality of a model based on a combination of the likelihood L and the number of parameters K. In this study we apply the Akaike information criterion with a correction term for finite sample size [\cite=BurnhamAnderson98],

[formula]

where [formula] is the set of parameters that maximizes L; as before, N is the number of observations. The last term in Eq. [\ref=AICc] is a second-order bias correction which, although not in Akaike's original formula [\cite=Akaike74], gives more accurate results if N  ≈  K [\cite=HurvichTsai89].

Differences in [formula] allow us to quantitatively compare different models. If we denote the [formula] value of model j by [formula] and the minimum over all models by [formula], then the difference

[formula]

estimates the relative expected Kullback-Leibler distance between model j and the estimated best model [\cite=BurnhamAnderson01]. As a rule of thumb, models with [formula] have substantial empirical support; models with Δj > 10 on the other hand are unlikely candidates to explain the data [\cite=BurnhamAnderson98].

Reference [\cite=BurnhamAnderson98] lists many theoretical reasons in favor of model selection based on [formula]. The Bayesian information criterion (BIC), although almost equally popular, has been reported to yield poor results when used to fit power-law tails in probability distributions [\cite=Clauset_etal09] because it tends to underestimate the number of parameters. The Akaike information criterion penalizes less severely for additional parameters: in the limit N  ≫  K the penalty is asymptotically equal to the term 2K in Eq. [\ref=AICc], whereas the equivalent term in the BIC grows as K ln (N). We carried out Monte Carlo simulations on synthetically generated probability distributions of the type described in the next section (see Appendix). We found that model selection by [formula] came close to the true number of parameters. Although the BIC showed acceptable performance, we confirmed that it indeed favors a too small number of parameters. We therefore advocate the use of [formula] rather than BIC for fitting degree distributions.

Candidate models

The first step of [formula]-based model selection is the definition of several candidate models that might generate the observed distribution. We denote as before by Pr (k) the probability that a node has degree k. The distinctive feature of different candidate models is the asymptotic decay of Pr (k) for k  ≫  1. Only in this limit we can hope to find scale-free behavior if it indeed exists. Of course, all real networks are finite so that, strictly speaking, we cannot take the limit k  →    ∞  . If we restrict ourselves to only a few high-degree nodes, we have too few data points for a meaningful fit. On the other hand, if we include too many low-degree nodes, then we may misjudge the correct asymptotic behavior of Pr (k).

We therefore assume for all candidate models that there is an optimal cutoff point kc that separates nodes with degree ≤  kc from the region where a hypothesized asymptotic function F(k) can fit the data [\cite=HandcockJones04],

[formula]

Each parameter Ak is chosen so that Pr (k) = Ak for [formula]. Different families of candidate models can be defined by different functions F(k). We list all the functions F investigated in this study in Table [\ref=candidates]. The exponential function (EXP) is the candidate that decays most rapidly in the right tail. The power law (POW) has two parameters: an exponent β > 0 and a constant α > 0 that shifts the function to the left or right. The tail k  ≫  α has the conventional power law form [formula]. The discrete log-normal (LGN) and Weibull (WBL) distributions are represented by the usual distribution functions of their continuous namesakes. We also include two three-parameter models: a truncated power law (TPW) and the generalized Weibull distribution (GWB). In comparison to POW, TPW includes an additional exponential factor which is often used to mimic finite-size cutoffs in the right tail. GWB is a standard three-parameter generalization of WBL with an additional parameter γ, called location parameter, that shifts the distribution to the right or left [\cite=TeimouriGupta13].

We can distinguish the members of each candidate model family by the choice of kc, the values of [formula] and α, β, γ. Model selection by [formula] gives a natural criterion for the optimal parameters matching an observed distribution. It is a simple exercise to prove that L is maximized if Ak equals the observed relative frequency of nodes with degree k,

[formula]

For a fixed value of kc, standard numerical algorithms can optimize the remaining parameters α, β and γ in Table [\ref=candidates] to maximize L. After calculating these maximum-likelihood estimators for every kc between 0 and [formula], we search for the value of kc that minimizes [formula] of Eq. [\ref=AICc]. The number K of parameters that we have to insert into this equation is

K  =  kc + 1 for EXP,

K  =  kc + 2 for POW, LGN and WBL,

K  =  kc + 3 for TPW and GWB.

Results of model selection

For each candidate model and each [formula] we compute the [formula]. We then determine the smallest [formula] from the entire set and calculate for each model j the difference Δj defined in Eq. [\ref=Delta_j]. In Fig. [\ref=ccdf_fit] we show for the example of the network KKI-18 the best-fitting distribution within each candidate model family. We have chosen a logarithmic scale for the ordinate to highlight the differences in the right tail. While the exponential and simple Weibull distributions decrease too rapidly, the power law and log-normal distributions decay too slowly. The truncated power law and generalized Weibull distributions are better in mimicking the overall shape of the distribution.

We find that, broadly speaking, this observation is typical of the ten investigated connectomes. As we see from Table [\ref=AIC_table], in 9 out of the 10 investigated networks we can achieve Δj < 10 with the GWB distribution. In 6 out of 10 cases, there is a similar level of evidence for the TPW model which was hypothesized for functional brain networks in Ref. [\cite=4] [\cite=63] [\cite=64]. For all other candidate distributions there is either none or very sporadic statistical support.

A closer look at the fitted GWB values (Table [\ref=tabgwb]) shows that, with the exception of KKI-16 where GWB is rejected by the [formula], the β exponents lie within one order of magnitude suggesting a common trend if not even universality. This order of magnitude also agrees with the least-squares fit in Fig. [\ref=eloLpfit].

Dimension measurements

To measure the dimension of the network we first computed the distances from a seed node to all other nodes by running the breadth-first search algorithm. Iterating over every possible seed, we counted the number of nodes Nr with chemical distance r or less from the seeds and calculated the averages over the trials. As Fig. [\ref=dim-KKI] shows, an initial power law crosses over to saturation due to the finite network sizes. We determined the dimension of the network, as defined by the scaling law ([\ref=topD]), by attempting a power-law fit to the data N(r) for the initial ascent. This method resulted in dimensions between D = 3 and D = 4.

To see the corrections to scaling we determined the effective exponents of D as the discretized, logarithmic derivative of ([\ref=topD])

[formula]

As the inset of Fig. [\ref=dim-KKI] shows, [formula] tends to values below 4 even in the infinite size limit, but the narrow scaling region breaks down for r  >  5. Furthermore, the extrapolated values for D of the connectomes exhibit an increasing tendency with N as we will now explain in detail.

For better understanding we have also performed the analysis for other graphs besides KKI, possessing graph sizes in different ranges of N. The finite size scaling results are summarized in Fig. [\ref=dim-par], where we also extrapolate to N  →    ∞  . As one can see, the dimension values follow the same trend for KKI-, MRN- and NKI-graphs without any clear sign of saturation. A power-law fit to the data with the form A + BNC is also shown, suggesting that D diverges for infinite N. It is tempting to extrapolate with this function to larger sizes or even to the infinite size limit. However, since we can rule out that the degree distributions are scale-free, we cannot assume that such extrapolated graphs faithfully represent connectomes of finer resolution. For exmaple, using this power-law extrapolation we would overestimate kmax of them.

Thus the present data does not permit claiming any particular numeric value for the dimension D of the true (i.e. microscopically resolved) brain connectome.

Small-world coefficient

Small-worldness can be characterized by different definitions. One of them is the so-called small-world coefficient σ, which is defined as the normalized clustering coefficient (C / Cr) divided by the normalized average shortest path length (L / Lr),

[formula]

where the normalization divides the observed quantity (C or L) by the expectation value (Cr or Lr) for an Erds-Rényi random graph with the same number of nodes and edges [\cite=HumphriesGurney08].

There are two different definitions of a clustering coefficient in the literature. The Watts-Strogatz clustering coefficient [\cite=WS98] of a network of N nodes is

[formula]

where ni denotes the number of direct links interconnecting the ki nearest neighbors of node i. An alternative is the "global" clustering coefficient [\cite=globalC] also called "fraction of transitive triplets" in the social networks literature [\cite=Jackson08],

[formula]

Both definitions are in common use, but values for CW and CΔ can differ substantially because Eq. [\ref=Cws] gives greater weight to low-degree nodes.

The average shortest path length is [\cite=Heuvel_etal09]

[formula]

where d(i,j) is the chemical distance between vertices i and j. L is only properly defined if the network is connected because otherwise the chemical distance between some voxels is infinite.

We have calculated C and L for the largest connected components of several KKI networks directly from the edge lists on the OCP website [\cite=OCP]. The CΔ values are about half of those for CW (see Table [\ref=tab1]). A finite size scaling analysis shows that the values of L, CΔ and CW decay by increasing the size N (see Fig. [\ref=tab3]). For the average shortest path-length this decay is rather fast; a least-squares regression with the form a + b(1 / N)c results in c≃0.29 and [formula]. The constant is near zero within the precision of data, so in the infinite size limit we see small-world behavior. The clustering coefficients are almost constant; the power-law fit provides a very small slope: c≃0.046 in agreement with the behavior of modular graphs [\cite=RB03]. The decreasing trends for L, CW and CΔ as functions of N are statistically significant at the 5% significance level; the p-values for t-tests of zero slope for the log-transformed data are 0.03, 0.002 and 0.04 respectively. Again, finite size scaling has to be interpreted with caution given that the topology is not scale-free.

To calculate σ we determined the clustering coefficient of the corresponding random networks Cr  =  〈k〉  /  N, where 〈k〉 is the mean degree. We have computed the average path length of the corresponding Erds-Rényi networks with the formula of Ref. [\cite=Fron]

[formula]

where Nl is the size of the largest component.

Using these data we have calculated the small-world coefficients of the KKI graphs. As the last two columns of Table [\ref=tab1] show, σW,σΔ  ≫  1 for all cases, suggesting small-world behavior according to this definition. These values do not show any tendency with respect to N: the t-tests for zero slope have p-values 0.45 and 0.72 for σW and σΔ, respectively.

Conclusions

Let us return to our introductory question: are the structural connectome graphs from the OCP database scale-free, small-world networks? As far as the adjective "scale-free" is concerned, the answer is clearly no. We have applied model selection based on the Akaike information criterion to 10 graphs comparing 6 different degree distribution models. The observed distributions are best fitted by the generalized Weibull function with a stretched exponential tail [formula]. Most of the exponents β are between 0.2 and 0.5, which may hint at a universal trend. In some cases a truncated power law is a plausible alternative. However, the truncation occurs at a degree much smaller than the number of nodes in the network so that one cannot regard these distributions as scale-free.

Unlike the term "scale-free", the adjective "small-world" does apply to the OCP connectomes in the sense that the small-world coefficients are much larger than 1. We have performed a finite size scaling analysis using several graphs and found no dependence between the number of nodes N and the small-world coefficients. The average path length, however, decreases as N increases. The resolution to this apparent paradox is that the average degree 〈k〉 increases with N so that there is an increasing number of shortcuts through the network. On the other hand, we obtained small topological dimensions characteristic of large-world networks. The dimensions show a tendency to grow as the sizes of the studied graphs increase. The limit N  →    ∞   here is taken by increasing N for a fixed voxel size. The absence of a scale-free degree distribution suggests that this limit may not be equivalent to fixing the brain volume and instead resolving the details of the connectome at an infinitely small scale. For this reason, it is difficult to judge whether Griffiths effects can be found in the brain, but the small topological dimensions that we have observed warrant further investigation.

Our analysis has been based on unweighted graphs. More realistically, however, the connectome is a weighted, modular network. Links between modules are known to be much weaker than the intra-module connections. Thus, future studies should take into account that signals in the brain propagate on a weighted, heterogeneous network where generic slow dynamics is a distinct possibility. The methods presented here to characterize degree distributions and topological dimensions can be generalized to the weighted case. We hope that, as more precise and finely resolved connectome data will become available, future research will be able to assess whether Griffiths phases can indeed occur in the brain.

Justification of [formula] as model selection criterion

Among the various criteria for model selection that have been proposed in the literature, the Akaike and Bayesian information criteria (commonly abbreviated as AIC and BIC, respectively) are those that are most frequently employed in the analysis of empirical data. Both criteria have the general form

[formula]

where L is the likelihood function, [formula] the model parameters that maximize L, and K is the number of parameters. The difference between AIC and BIC is the prefactor a in the last term,

[formula]

where N is the number of data points. For [formula], the BIC gives thus a larger penalty than the AIC for every additional parameter in the model.

BIC-based model selection is known to be consistent in the sense that it almost surely selects the true model if it is among the candidates and N is infinitely large [\cite=Kim_etal12]. AIC-based model selection is generally not consistent, but unlike the BIC it is, in statistical parlance, efficient: in the limit N  →    ∞   the AIC selects a candidate model with the smallest Kullback-Leibler divergence from the true model, even if the true model is not among the candidates [\cite=Vrieze12] [\cite=Aho_etal14]. The true model is in most biological applications indeed unlikely to be included in the candidate set because it usually contains a large number of unknown parameters, which may furthermore increase with N. The consistency of the BIC and the efficiency of the AIC are asymptotic statements valid for N  →    ∞  . While it is insightful to know under which conditions the AIC or BIC are asymptotically optimal, these properties are ultimately of theoretical rather than practical relevance for finite data sets. The best guidance which criterion to choose comes from simulation studies involving finite data.

With a random number generator we have created finite data that pose a similar challenge to the model selection algorithm as the observed degree distributions. The data are N = 106 random numbers, independently sampled from the distribution

[formula]

where [formula] is the generated random integer and the prefactor on the second line is [formula]. The tail of this distribution is a power law. If k were real-valued rather than an integer, the right-hand side of Eq. ([\ref=Pr_power_test]) would be differentiable everywhere. We have chosen this distribution for two reasons. First, we want to test whether it is possible to determine with information criteria that the true model is a power-law (POW in Table [\ref=candidates]). Second, we want to find out which criterion is better at determining the precise crossover point kc in the presence of random fluctuations. The motivation is that, if the brain were indeed scale-free, we would correctly identify the power-law model and its parameterization. We fixed α = 10, β = 2.5 and allowed kc to vary.

For our first exploratory Monte Carlo simulations, we compared whether AIC- or BIC-based model selection is more successful at determining the true kc from the POW candidate models

[formula]

where α, β and [formula] are adjustable parameters. The crossover point kc is not itself a parameter in Eq. ([\ref=Pr_power_cand]), but rather an index for different candidate models. We summarize the results in Fig. [\ref=kc_mc]. The AIC reconstructs the crossover point almost accurately in the entire range 0  ≤  kc  ≤  150. The BIC underestimates kc, especially when kc is large. The reason lies in the BIC's steeper penalty for additional parameters in Eq. ([\ref=penalty]). Another obstacle for the BIC is that the true model (i.e. the distribution of Eq. [\ref=Pr_power_test] with the three parameters α, β and kc) is generally not one of the candidates of Eq. ([\ref=Pr_power_cand]) because those contain more parameters than necessary, in particular one parameter Ai for every 0 < i  ≤  kc. The AIC, by contrast, correctly chooses a candidate that still describes the input best among the wrong (i.e. overparameterized) models: for k > kc the distribution decays [formula] whereas there is no power law in the region 0 < k  ≤  kc.

Having found that the AIC is better suited for model selection in the present context, we investigate next whether the AIC reliably identifies the correct model among those listed in Table [\ref=candidates]. We generate 10 independent sets of N = 106 random numbers each. These are drawn from the distribution of Eq. ([\ref=Pr_power_test]) with α = 10, β = 2.5, and now we also fix kc = 100. For 8 out of these 10 sets, the power law had the smallest AIC. In the remaining two, the power law's AIC differed from the minimum only by [formula] in one case and [formula] in the other case. As we have explained after Eq. [\ref=Delta_j], such small [formula] are still interpreted as substantial empirical support for the power law. We conclude that, if the connectome's degree distribution were scale-free, the AIC would have correctly identified a power law as a plausible candidate model.

There is one fine detail to note when the dimension K of the model approaches the sample size N. In such cases the AIC is a negatively biased estimate of the Kullback-Leibler information [\cite=HurvichTsai89]. An approximate correction for this bias is the additional penalty term [formula] in Eq. [\ref=AICc]. This modified version of the AIC is commonly abbreviated as [formula]. Although the difference is small in the present context, Ref. [\cite=HurvichTsai89] and [\cite=BurnhamAnderson01] suggest that [formula] should routinely be used instead of the AIC. We have followed their advice throughout this article.

Acknowledgments

We thank the staff of the Open Connectome project for help and discussions. Support from the Hungarian research fund OTKA (Grant No. K109577) and the European Commission (project number FP7-PEOPLE-2012-IEF 6-4564/2013) is gratefully acknowledged.