Degeneracy, degree, and heavy tails in quantum annealing

Introduction

The recent development of quantum annealing (QA) processors has spurred research into how to construct input instances--Ising spin instances--that might confirm or refute any purported computational advantage conferred by such hardware [\cite=McGeoch2013] [\cite=Roennow2014] [\cite=Venturelli2015a] [\cite=Boixo2015] [\cite=Denchev2015] [\cite=henfl] [\cite=flsat] [\cite=Katzgraber2014] [\cite=Katzgraber2015] [\cite=Martin2015]. These recent works have proposed various important considerations such as error sensitivity, thermal hardness [\cite=Martin2015], ground state degeneracy, consistency of energy scale across a random ensemble [\cite=henfl] [\cite=flsat], potential barrier shape [\cite=Boixo2015] [\cite=Denchev2015], and the existence of classical phase transitions [\cite=Katzgraber2014]. In parallel to this line of research is the consideration of suitable performance metrics for exact and approximate optimization [\cite=ttt] [\cite=Katzgraber2015] [\cite=Steiger2015].

Several previous efforts to quantify the performance of D-Wave hardware relative to physically motivated software solvers have focused on the median case performance for a given input class [\cite=Roennow2014] [\cite=henfl]. However, Ref. [\cite=Steiger2015] cautions that the median case does not give a complete picture of a given solver's performance. Simulated quantum annealing (SQA) [\cite=Santoro2002] [\cite=boixo2014evidence], which has been advanced as an effective model for D-Wave hardware, shows dramatically varying performance over particular random ensembles of low precision problems: the total time required to solve all instances is dominated by a few instances at the tail of the distribution. In contrast, simulated annealing (SA) does not show nearly as strong of a variation in performance when run on the very same instances. The presence of so-called heavy tails in the distribution of the time to solution, as seen in both SQA simulations [\cite=Steiger2015] and D-Wave hardware results [\cite=boixo2014evidence] [\cite=Roennow2014], points to an intrinsic physical mechanism that could explain the difference in performance between classical physics-based approaches such as SA and the quantum physics-based approaches such as SQA and D-Wave hardware.

In this paper we examine the hypothesis that local degeneracy--the abundance of large isoenergetic clusters of spin states--plays a crucial role in the appearance of heavy tails. We compare the performance of a D-Wave 2X quantum anealing processor (DW2X) [\cite=ttt] with SA on random ±  1 Ising spin glass instances with high local degeneracy and low local degeneracy, where local degeneracy is controlled via parity of qubit connectivity rather than selection of coupling strengths [\cite=Katzgraber2015] [\cite=Zhu2015]. Our results indicate that heavy tails are a consequence of degeneracy in the final target Hamiltonian and a particular implementation of (S)QA wherein all qubits follow an identical annealing schedule. Under these circumstances, small gap perturbative anticrossings develop in the system eigenspectrum late in the anneal, at which point tunneling is suppressed. These circumstances arise when random low-precision Ising spin glass instances are imposed on the full DW2X qubit connectivity graph. However, they do not arise when the connectivity of that graph is varied as described herein, and they become less common when more realistic [\cite=Rieffel2015] [\cite=Venturelli2015] [\cite=Babbush2014] [\cite=Perdomo-Ortiz2015a] or combinatorially interesting problem classes are subject to (S)QA [\cite=Venturelli2015a] [\cite=Zdeborova2008].

Quantum annealing processor

Hamiltonians in the Ising model

Quantum annealing in the Ising model aims to find low-energy states in a system of n interacting spins via evolution of the time-dependent Hamiltonian

[formula]

where σxi and σzi are Pauli matrices acting on spin i, 0  ≤  s  ≤  1 is the annealing parameter t / tanneal, B(0)  ≪  A(0), A(1)  ≪  B(1), and HI is the Ising problem Hamiltonian [\cite=Johnson2011]. We refer to the Ising Hamiltonian as HI = (h,J), where the local biases h and pairwise couplings J encode the energy function from which we wish to draw low-energy states. In the classical limit σzi can be replaced with a binary spin si∈{ - 1,1}.

Floppy qubits and degeneracy in J =   ±  1 Chimera-structured Ising instances

Qubits in a D-Wave processor are connected as a Chimera graph [\cite=bunyk2014architectural] (see Fig. [\ref=fig:chimeradegrees]), in which most qubits are coupled to six others, provided that only a few qubits and couplers are inoperable. For a classical n-qubit state [formula], each qubit si experiences an effective field

[formula]

In the case [formula], we say that qubit si is floppy in [formula]; equivalently, changing si does not change the energy of the state. Floppy qubits and the resulting degeneracy have a well-understood contribution to perturbative crossings [\cite=Dickson2011] [\cite=Dickson2013], and they have been studied from the perspective of differentiating heuristics that operate over time-dependent quantum versus thermal annealing potential [\cite=Boixo2013] [\cite=Albash2015]. In short, floppy qubits lead to wide, degenerate valleys in the state space which are favored in the time-dependent quantum potential early in the anneal. We now illustrate the effect of floppy qubits on degeneracy in the random Ising instances often used to study D-Wave processors [\cite=McGeoch2013] [\cite=boixo2014evidence] [\cite=Roennow2014] [\cite=Steiger2015] [\cite=ttt].

Let (h,J) be a random Ising spin glass instance with [formula] and with each operable coupler Jij taking a value in { - 1,1} uniformly at random. A qubit si coupled to d others (i.e. of degree d), has [formula] when d is even and Pr [null] = 0 when d is odd (Fig. [\ref=fig:floppy]). Qubits of degree 2, 4, and 6 have respective probabilities 50%, 38%, and 31% of being floppy in a random spin configuration. This probability approaches zero for large degree. To put these probabilities in perspective, in a 512-qubit C8 instance there are 384 degree 6 qubits, of which we expect 120 to be floppy in a random state. This results in large isoenergetic clusters: due to the bipartite structure of Chimera, we expect every qubit in such a state to be in an isoenergetic hypercube of size 260. Degeneracy will be less severe in local minima.

For positive integer k we denote by Uk the class of instances in which each coupler is set to a value in [formula] chosen uniformly at random. Refs. [\cite=Katzgraber2015] [\cite=Zhu2015] avoided the local degeneracy seen in Uk instances by drawing coupling strengths from Sidon sets; for example S28 instances draw couplings from {  ±  28,  ±  19,  ±  13,  ±  8}. However, these instances must be normalized, and suffer a 28-fold inflation of relative noise, control error and temperature relative to the classical gap when run on DW2 [\cite=flsat]. These instances are therefore unlikely to reveal any performance advantage for current physical QA processors. It will be demonstrated that even a 5-fold normalization of a low-degeneracy instance significantly degrades DW2X performance (see Fig. [\ref=fig:tails1]).

In this work we employed an alternative construction that suppresses or enhances local degeneracy while maintaining a large classical gap. First we simply disabled, by setting to zero, a subset of couplers that heuristically minimizes or maximizes the number of qubits with even degree. We then imposed a U1 instance on the remaining couplers. More specifically, we chose a target degree d∈{3,4,5,6} and attempted to make as many qubits as possible with this degree, while retaining the underlying gridlike structure of the graph by leaving inter-cell couplers mostly intact . We denote by Udk the class of instances in which a Uk instance is imposed on a subgraph with target degree d; note that Uk  =  U6k. Ideal subgraph examples are shown in Fig. [\ref=fig:chimeradegrees]. The study of DW2X and SA performance on random instances with controlled degree (and consequently floppiness) illuminates the role of local degeneracy in the emergence of heavy tails.

Results

The testbed consisted of random U1 and U4 Ising instances on Chimera subgrids of varying size, from 3  ×  3 unit cells (C3) to 10  ×  10 unit cells (C10). These problems contain between 72 and 765 operable qubits. For each problem size, range k, and target degree d, we constructed 1000 Udk instances, each on a newly generated subgraph with target degree d. We used the same processor and qubit configuration as Ref. [\cite=ttt]. Further details are given in the appendix.

The smoking gun: Heavy tails for U41 instances, but not U31 instances

Ref. [\cite=Steiger2015] ran SQA and SA on the same 200-qubit (C5) U61 instances, each containing 120 degree 6 (and therefore potentially floppy) qubits, and investigated the ground state probability p of each solver on a given instance. While they consider τ  =  1 / p, we consider the number of repetitions R needed to achieve 99% probability of finding a ground state [\cite=boixo2014evidence]:

[formula]

The two solvers exhibit similar success probability in the median case, but for the hardest instances SA has success probability orders of magnitude larger than SQA [\cite=Steiger2015]. If these "heavy tails" appear for QA across broad selections of input classes, it would call into question the potential utility of the general QA implementation given in Eq. [\ref=eq:ham]. Fig. [\ref=fig:smokinggun] shows that on our inputs, DW2X shows a heavy tail on U41 instances but not on U31 instances. This difference is not observed in SA results, which indicates that degree and degeneracy play a different role in QA than in SA.

Performance scaling on bimodal spin glasses

Fig. [\ref=fig:c4] shows performance of DW2X and SA at the C4 and C8 scales, which were the respective sizes of of D-Wave One and D-Wave Two processors [\cite=boixo2014evidence] [\cite=Roennow2014]. Again, performance of DW2X relative to SA improves enormously in high percentiles for U31 instances, where removal of couplers minimizes degeneracy, versus U41 instances. Fig. [\ref=fig:scaling1] shows performance scaling on U31, U41, U51, and U61 instances. These results suggest that several threads of research that probed for computational advantage in U61 problems [\cite=Katzgraber2015] [\cite=Martin2015] [\cite=Roennow2014] might be more successfully directed towards U31 problems. Neither SA nor DW2X performance responds monotonically to increasing degree. Thus the difficulty of a Ud1 testbed as seen by QA or SA is not trivially related to the number of couplings it contains--additional couplings do not necessarily make a problem more or less difficult.

Mean-field spectra of U1 instances

Heavy tails in problem sets with high local degeneracy might be explained by perturbative crossings late in the anneal for hard instances [\cite=Dickson2011] [\cite=Dickson2013], when a superposition of many excited classical states ceases to be an instantaneous quantum ground state [\cite=Amin2008] [\cite=Amin2009a] [\cite=Altshuler2010] [\cite=Young2010]. This crossing results in a minimum eigengap late in the anneal, when the tunneling rate is small. As a result the annealer tends to get stuck in a local minimum, leading to low success probability.

Here we illustrate the relationship between gap position and local degeneracy. For 127-qubit U1 instances we cannot determine the gap position using exact or even approximate diagonalization, as the instances have too many low-energy states. As an alternative we resort to the mean-field spin vector Hamiltonian [\cite=Smolin2013] derived in Ref. [\cite=Albash2015b] as the semiclassical limit of the spin-coherent states path integral [\cite=Shin2014] [\cite=Muthukrishnan2015]. Qubits are represented by rotors on the unit circle, while σx, σy, and σz are replaced with sin θ, 0, and cos θ respectively:

[formula]

Ref. [\cite=Muthukrishnan2015] showed that for certain inputs, the minimum gap location given by HSV(s) closely matches the location given by exact diagonalization. Here we aim to associate ground and excited states of the classical Hamiltonian with global and local minima of the time-dependent semiclassical Hamiltonian HSV(s), estimating the gap location as the last moment at which the global minimum of HSV(s) corresponds to a classical excited state.

We can represent a classical Ising state as a rotor state [formula], and for annealing parameter s we can map [formula] to a locally-optimal rotor state [formula] according to HSV(s) (details are given in the appendix). Early in the anneal, every [formula] will map to an instantaneous ground state in the direction of the transverse field. Late in the anneal, the transverse field will have little effect, so only classical ground states will map to instantaneous ground states.

Computing [formula] for a range of s and for [formula] representing many classical ground and excited states gives a heuristic idea of when instantaneous and final ground states coincide according to the mean-field Hamiltonian. We define the mean-field crossing time s*SV as the maximum value of the annealing parameter s for which no [formula] with [formula] minimizing HSV(s) corresponds to a classical ground state. We use s*SV as a mean-field approximation of the location of the minimum gap of the quantum Hamiltonian HS.

Figure [\ref=fig:svgaps] shows distributions of s*SV for instances of different degrees. There is a strong correlation between a late crossing and low DW2X success probability. Typically, a very late s*SV implies a crossing between a semiclassical superposition of many low-energy excited states and a relatively small number of ground states [\cite=Dickson2013].

Tails and energy scale

SA, DW2X, and other physically-motivated solvers are sensitive to multiplication of the problem Hamiltonian HI by a scaling factor α. Reducing α in SA is equivalent to increasing temperature, but in DW2X there are additional considerations of noise, error, and transverse field.

When multi-qubit tunneling is the dominant mechanism of solution for DW2X (likely not the case for Udk instances [\cite=Katzgraber2014] [\cite=Shin2014] [\cite=Albash2015b]), performance is best when α is maximized and relative temperature is minimized [\cite=Boixo2015] [\cite=Denchev2015]. In contrast, Fig. [\ref=fig:tails1] shows that heavy tails become less prevalent in DW2X results for U41 input as we reduce α. This may be due to thermal excitation prior to diabatic Landau-Zener transition [\cite=Zener1932] through a perturbative crossing, as hypothesized in Ref. [\cite=Dickson2013]. Reducing α degrades DW2X performance on easy U41 and all U31 instances, which agrees with the evidence in Fig. [\ref=fig:svgaps] that these instances are not governed by late perturbative crossings.

Performance of DW2X on U34 and U44 instances is almost identical; in both regimes a qubit is floppy in a random state with probability only 7%, far lower than in U41 instances. Thus these instances are less degenerate, but are also run with couplings normalized by a factor of [formula], to within the range

[formula]

Error sensitivity

Heavy tails in QA are most severe when energy scale is highest, i.e. when relative noise and error should be minimal. The existence of heavy tails for SQA with no Hamiltonian misspecification [\cite=Steiger2015] indicates that this phenomenon--and more generally, poor QA results on certain low-precision instances--cannot be solely attributed to control error. To explore the contribution of classical control error to heavy tails, we ran our 127-qubit U31 and U41 instances 100 times each using 10 repetitions over random spin reversal transformation (otherwise known as gauge transformations [\cite=Roennow2014] [\cite=King2014]). Fig. [\ref=fig:gauge1] shows that heavy tails appear for U41 across all quantiles (of 100 experiments), and do not appear at all for U31 instances.

Clearly R (Eq. [\ref=eq:R]) varies more for hard problems than for easy problems. More striking is how this distribution of performance quantiles is almost identical for U31 and U41 instances when normalized by the median Rmedian (of 100 experiments) and plotted versus Rmedian rather than the percentile. This indicates that heavy tails are not caused by error sensitivity, but rather that error sensitivity is closely related to hardness of the instance in terms of the quantum potential, rather than some classical measure of hardness derived from Boltzmann sampling, matrix condition number, or mixing time of a thermal process as studied in Ref. [\cite=Martin2015].

Discussion

Does local degeneracy challenge the viability of the QA platform?

How important is local degeneracy in interesting problem classes? Low-precision Chimera-structured problems have been used to benchmark D-Wave processors as a matter of simplicity and supposed resistance to control error. The extreme local degeneracy in these instances arises from the fact that the Chimera qubit interaction graph is dominated by qubits of degree six, which is even. When we disable couplers to suppress even-degree qubits, the tails associated with local degeneracy disappear. This cannot be attributed to reduction of classical hardness: Figs. [\ref=fig:c4] and [\ref=fig:scaling1] show that for SA, U41 instances are easier than U31 and U51 instances, while for DW2X the opposite is true. This further indicates that the number of couplings has limited value as a measure of hardness in a random Ising problem.

Heavy tails are not present to the same extent in higher-precision instances, as we see in DW2X U4 performance results. However, we cannot dismiss the practical importance of low-precision problems, as there are hard low-precision combinatorial problems in the Ising model that are of more general interest than Chimera-structured U1 instances. Fully connected ±  1 Sherrington-Kirkpatrick instances [\cite=Sherrington1975] [\cite=Venturelli2015a] are well understood and of interest beyond quantum annealing, but for a large instance each qubit is coupled to many others, and is therefore unlikely to be floppy regardless of the parity of its degree since [formula] scales as d- 1 / 2 (see Section [\ref=sec:floppy]). Any given small set of qubits is also unlikely to be floppy. More recently there has been interest in locked constraint satisfaction problems [\cite=Zdeborova2008] [\cite=Zdeborova2008b] [\cite=Zdeborova2011], which are hard by design and have low-precision expressions in the Ising model [\cite=Douglass2015], for example 2-in-4-SAT and 3-in-6-SAT. Locked constraint satisfaction problems explicitly avoid local degeneracy, and ground states are expected to be pairwise distant in Hamming space. These constraint satisfaction problems tell us that hard, interesting problems in the Ising model do not need to have high precision or high degeneracy.

Probing for speedup in highly degenerate instances

Previous work has advocated searching for quantum speedup in hard U61 problems [\cite=Boixo2013] [\cite=Roennow2014] [\cite=Steiger2015] [\cite=Martin2015]. The relationship between degree and degeneracy provides two limitations of this choice, in addition to the limited ability of U1 instances to showcase exploitation of quantum tunneling [\cite=Katzgraber2014]. First, U61 problems have enormous local degeneracy, resulting in perturbative crossings late in the anneal for a subset--a heavy tail--of instances. Those instances in the 99th percentile for QA time to solution will be exactly those instances that experience very late crossings, and therefore exhibit weakest performance of QA rather than the strongest (cf. [\cite=Boixo2015] [\cite=Denchev2015]). Second, U1 instances have been assumed to be robust to control error, but we have shown that robustness should be evaluated in terms of the quantum potential rather than the classical potential. Instances experiencing late crossings will be sensitive to error regardless of precision required to represent each term in the classical Hamiltonian. When probing for quantum speedup in the hardest of a set of random problems, degeneracy should be minimized in order to avoid disproportionate focus on instances susceptible to failure through late perturbative crossings.

While highly degenerate U1 instances may have limited potential to exhibit quantum speedup, their simple structure and susceptibility to perturbative crossings may prove useful in the development of methods for avoiding perturbative crossings that might appear in more subtle ways.

Mitigation of perturbative crossings

Difficulties associated with QA and local degeneracy will likely be impossible to avoid altogether as we relax the definitions of local and degeneracy. If high-precision instances do not have floppy qubits, they will at least sometimes have nearly floppy qubits, and it is unreasonable to expect that the time-dependent QA eigenspectrum will accurately reflect classical energy levels throughout the anneal. In this case, can we deal with degeneracy and near-degeneracy? Ref. [\cite=Dickson2011] proposes a method to eliminate perturbative crossings by manipulating the relative degeneracy of ground and excited states by addition of ancillary qubits. These perturbative crossings, which arise in the presence of degenerate clusters of excited classical states [\cite=Altshuler2010] [\cite=Amin2009a], might be circumvented by algorithmic [\cite=Dickson2012] or random [\cite=Farhi2011] choice of the initial Hamiltonian and qubit annealing trajectories.

Conclusions

The heavy tails observed in SQA performance on U61 instances [\cite=Steiger2015] also appear in physical QA [\cite=boixo2014evidence] [\cite=Roennow2014]. We have shown that among U1 and U4 instances, only those with high local degeneracy (U41 and U61) exhibit heavy tails in QA. Moving from the U61 instances normally studied in the literature to U31 instances yields enormous improvement of QA performance relative to SA.

Mean-field simulations indicate that the heavy tails in highly degenerate instances are caused by Landau-Zener transitions through perturbative crossings late in the anneal. These transitions appear in problems with large clusters of first excited states [\cite=Amin2008] [\cite=Amin2009a] [\cite=Altshuler2010], and may be circumvented (or enhanced [\cite=Dickson2013] [\cite=Boixo2013]) using structural [\cite=Dickson2011] and algorithmic [\cite=Dickson2012] modifications to the naive quantum annealing algorithm in which every qubit follows the same annealing trajectory.

Acknowledgments

The authors are grateful to Richard Harris for helpful advice regarding this manuscript, and to Damian Steiger for useful discussions about degeneracy and heavy tails.

Experimental details

Quantum annealing processor

The quantum annealing processor used in this work, and in Refs. [\cite=ttt] [\cite=Douglass2015], was a D-Wave Two X processor operating at 12mK. Fig. [\ref=fig:schedule] shows the annealing schedule of the transverse and Ising Hamiltonians (see Eq. [\ref=eq:ham]). All experiments were run using an anneal time of [formula], and samples were drawn in batches of 1000 using random spin reversal transformations except where otherwise specified. Experiments were terminated after finding 100 ground state samples or drawing 105 samples, except where indicated otherwise (e.g. Fig. [\ref=fig:gauge1]).

Simulated annealing

Simulated annealing was run with a linear schedule in β running from β0 = 0.01 to βf = 5, with the input Hamiltonian J scaled such that max ij|Jij| = 1. For performance scaling experiments shown in Fig. [\ref=fig:scaling1] performance was measured at optimal anneal length (number of Monte Carlo sweeps) chosen from the set [formula], similar to Ref. [\cite=flsat]. In order to estimate the time required in Fig. [\ref=fig:scaling1] we used the single-thread speed of 6.65 spin updates per nanosecond claimed in Ref. [\cite=Isakov2015]. Samples were drawn in batches of 100, and experiments were terminated after finding 100 ground states or drawing 104 samples.

Mean-field crossing time

In the context of HSV (Eq. [\ref=eq:sssvham]) we consider the effective field [formula] on qubit i in the state [formula] to be

[formula]

For a given annealing parameter s, consider the locally optimal value of θi minimizing HSV subject to (θj|j  ≠  i), i.e.

[formula]

given that A(s) and B(s) are positive. Since modifying θi can alter some θ*j, we calculate the associated local minimum [formula] using an iterative method that replaces θi with (θi  +  θ*i) / 2 for every spin θi in turn, and iterates until convergence.

Fig. [\ref=fig:svspec] gives an example mean-field spectrum of a U51 instance. Early in the anneal, A(s)  ≫  B(s) and all classical states map to instantaneous ground states in the direction of the transverse field. Late in the anneal, classical states assume instantaneous mean-field energies that reflect their energies in the final classical Hamiltonian. From s*SV = 0.359 onwards, the instantaneous ground state is the associated mean-field local minimum of a classical ground state.

Testbed construction

Every Udk is constructed over a subgraph G' of the available qubit connectivity graph G. For each instance, we construct G' iteratively at random by removing one edge at a time. An edge uv can be chosen

u has maximum degree in G'

There is no edge u'v' in G' such that d(u')  ≥  d(u) and d(v') > d(v).

If u and v are in different unit cells (see [\cite=bunyk2014architectural]) then d(u) = d(v) and there is no edge u'v' for which both d(u') = d(v') = d(u) and u' and v' are in the same unit cell.

d(v)  ≥  3.

Removing uv does not disconnect the graph.

Given the set of removable edges at a given point in the construction, we choose an edge uniformly at random to remove, and restart the process if we are unable to proceed (i.e. reduce the maximum degree of G' to d). Table [\ref=tab:degreedist] shows the distributions of degrees for Ud1 instances of varying size. The distributions are similar for Ud4 instances, as the construction of the graph G' is identical.

Additional data

Fig. [\ref=fig:scaling1] shows performance scaling of SA and DW2X on Ud1 instances of varying size for d∈{3,4,5,6}. CL instances use up to 8L2 qubits in an L  ×  L subgrid of unit cells in the Chimera graph [\cite=ttt]. At the C8 scale, which is the size of the previous generation of D-Wave Two processor, DW2X solves U31 problems at the 95th percentile around 1000 times faster than U41 problems at the 95th percentile.

Fig. [\ref=fig:gauge2] shows error sensitivity data corresponding to Fig. [\ref=fig:gauge1] when problems are run at energy scale α∈{0.2,0.6} rather than full energy scale α = 1.0. For each energy scale, U31 and U41 instances of similar hardness Rmedian show very similar error sensitivity (R / Rmedian).