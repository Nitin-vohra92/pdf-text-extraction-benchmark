Subgraph Similarity Search in Large Graphs

Introduction

Similarity based graph searching has attracted considerable attention in the context of social networks, road networks, collaboration networks, software testing, computational biology, molecular chemistry etc. In these domains, underlying graphs are large with tens of thousands of vertices and millions of edges. Subgraph searching is fundamental to the applications, where occurrence of the query graph in the large target graph has to be identified. Searching for exact occurrence of an induced subgraph isomorphic to the query graph is known as the subgraph isomorphism problem, which is known to be NP-complete for undirected unlabeled graphs.

Presence of noise in the underlying graphs and need for searching 'similar' subgraph patterns are characteristic to these applications. For instance, in computational biology, the data is noisy due to possible errors in data collection and different thresholds for experiments. In object-oriented programming, querying typical object usage patterns against the target object dependency graph of a program run can identify deviating locations indicating potential bugs [\cite=nguyen2009graph]. In molecular chemistry, identifying similar molecular structures is a fundamental problem. Searching for similar subgraphs plays a crucial role in mining and analysis of social networks. Subgraph similarity searching is therefore more natural in these settings in contrast to exact search. In subgraph similarity search problem, induced subgraph of the target graph that is 'most similar' to the query graph has to be identified, where similarity is defined using some distance function. Quality of the solution and computational efficiency are two major challenges in these search problems. In this work, we assume that both the underlying graph and query graph are unlabeled and undirected.

Most applications work with a distance metric to define similarity between two entities (graphs in our case). Popular distance metrics include Euclidean distance, Hamming distance, Edit distance, Kernel functions [\cite=haussler1999convolution] [\cite=desobry2005class] [\cite=kondor2003kernel] [\cite=vishwanathan2004fast] etc. We use graph kernel functions to define graph similarity.

Kernels are symmetric functions that map pairs of entities from a domain to real values which indicate their similarity. Kernels that are positive definite not only define similarity between pairs of entities but also allow implicit mapping of objects to a high-dimensional feature space and operating on this space without requiring to compute explicit mapping of objects in the feature space. Kernels implicitly yield inner products between the feature vectors without explicit computation of the same in feature space. This is usually computationally cheaper than explicit computation. This approach is usually referred to as the kernel trick or kernel method. Kernel methods have been widely applied to sequence data, graphs, text, images, videos etc., as many of the standard machine learning algorithms including support vector machine (SVM) and principle component analysis (PCA) can directly work with kernels.

Kernels have been successfully applied in the past in the context of graphs [\cite=hido2009linear] [\cite=hammond2011wavelets] [\cite=shervashidze2009fast]. There are several existing graph kernels based on various graph properties, such as random walks in the graphs [\cite=gartner2003graph] [\cite=kashima2002kernels], cyclic patterns [\cite=horvath2004cyclic], graph edit distance [\cite=neuhaus2005edit], shortest paths [\cite=borgwardt2005shortest] [\cite=bunescu2005shortest], frequency of occurrences of special subgraphs [\cite=frohlich2005optimal] [\cite=ramon2003expressivity] [\cite=menchetti2005weighted] and so on.

Graphlet kernels are defined based on occurrence frequencies of small induced subgraphs called graphlets in the given graphs [\cite=shervashidze2009efficient]. Graphlet kernels have been shown to provide good SVM classification accuracy in comparison to random walk kernel and shortest path kernel on different data sets including protein and enzyme data [\cite=shervashidze2009efficient]. Graphlet kernels are also of theoretical interest. It is known that under certain restricted settings, if two graphs have distance zero with respect to their graphlet kernel value then they are isomorphic [\cite=shervashidze2009efficient]. Improving the efficiency of computing graphlet kernel is also studied in [\cite=shervashidze2009efficient]. Graphlet kernel computation can also be scaled to parallel and distributed setting in a fairly straight forward manner. In our work, we use graphlet kernels to define graph similarity.

Related Work

Similarity based graph searching has been studied in the past under various settings. In many of the previous works, it is assumed that the graphs are labeled. In one class of problems, a large database of graphs is given and the goal is to find the most similar match in the database with respect to the given query graph [\cite=shasha2002algorithmics] [\cite=yan2004graph] [\cite=zhang2009gaddi] [\cite=mongiovi2010sigma] [\cite=zhang2010sapper] [\cite=wang2009g]. In the second class, given a target graph and a query graph, subgraph of the target graph that is most similar to the query graph needs to be identified [\cite=khan2011neighborhood] [\cite=khan2013neighborhood] [\cite=sun2012efficient] [\cite=yuan2015]. Different notions of similarity were also explored in the past for these classes of problems.

In [\cite=tian2008tale], approximate matching of query graph in a database of graphs is studied. The graphs are assumed to be labeled. Structural information of the graph is stored in a hybrid index structure based on B-tree index. Important vertices of a query graph are matched first and then the match is extended progressively. In [\cite=zheng2013graph], graph similarity search on labeled graphs from a large database of graphs under minimum edit distance is studied. In [\cite=khan2011neighborhood], algorithm for computing top-k approximate subgraph matches for a given query graph in a large labeled target graph is given. In this work, the target graph is converted into a set of multidimensional vectors based on the labels in the vertex neighborhoods. Only matches above a user defined threshold are computed. With higher threshold values, the match is a trivial vertex to vertex label matching. In [\cite=khan2013neighborhood], label matching is performed while simultaneously preserving pairwise vertex proximity. Their query time is proportional to the product of number of vertices of the query and target graph. Subgraph matching in a large target graph for graphs deployed on a distributed memory store was studied in [\cite=sun2012efficient]. In [\cite=yuan2015], efficient distributed subgraph similarity search to retrieve matches whose number of missing edges is below a given threshold is studied. It looks for exact matching and not similarity matching. Though different techniques were studied in the past for the problem of similarity searching in various settings, to the best of our knowledge, little work has been done on subgraph similarity search on large unlabeled graphs. In many of the previous works, either the vertices are assumed to be labeled or the graphs they work with are small with hundreds of vertices.

Our Contribution

We consider undirected graphs with no vertex or edge labels. We use graphlet kernel to define similarity between graphs. We give a subgraph similarity matching algorithm that takes as input a large target graph and a query graph and identifies an induced subgraph of the target graph that is most similar to the query graph with respect to the graphlet kernel value.

In our algorithm, we first compute vertex labels for vertices in both query and target graph. These labels are vectors in some fixed dimension and are computed based on local neighborhood structure of vertices in the graph. Since our vertex labels are vectors, unlike many of the other labeling techniques, our labeling allows us to define the notion of similarity between vertex labels of two vertices to capture the topological similarity of their corresponding neighborhoods in the graph. We build a nearest neighbor data structure for vertices of the target graph based on their vertex labels. Computing vertex label for target graph vertices and building the nearest neighbor data structure are done in the preprocessing phase. Using nearest neighbor queries on this data structure, vertices of the target graph that are most similar to the vertices of the query graph are identified. Using this smaller set of candidate vertices of target graph, a seed match is computed for the query graph. Using this seed match as the basis, our algorithm computes the final match for the full query graph.

We study the performance of our algorithm on several real life data sets including facebook network, google plus network, youtube network, road network, amazon network provided by the Stanford Large Network Dataset Collection (SNAP) [\cite=snapnets] and DBLP network [\cite=DBLP]. We conduct number of experimental studies to measure the search quality and run time efficiency. For instance, while searching these networks with their communities as query graphs, the computed match and the query graph has similarity score close to 1, where 1 is the maximum possible similarity score. In about 30% of the cases, our algorithm is able to identify the exact match and in about 80% of the cases, vertices of exact match are present in the pruned set computed by the algorithm. We validate our results by showing that similarity scores between random subgraphs and similarity scores between random communities in these networks are significantly lower. We also query communities across networks and in noisy networks and obtain matches with significantly high similarity scores. We use our algorithm to search for dense subgraphs and identify subgraphs with significantly high density.

Computationally expensive parts of our algorithm can be easily scaled to standard parallel and distributed computing frameworks such as map-reduce. Most of the networks in our experiments have millions of edges and thousands of vertices. Our multithreaded implementation of the search algorithm takes close to one second on these networks on a 32 core machine for the search phase. This excludes time taken by the one time pre-processing phase.

Preliminaries

Graph is an ordered pair G = (V,E) comprising a set V of vertices and a set E of edges. To avoid ambiguity, we also use V(G) and E(G) to denote the vertex and edge set. We consider only undirected graphs with no vertex or edge labels. A subgraph H of G is a graph whose vertices are a subset of V, and whose edges are a subset of E and is denoted as H  ⊆  G. An induced subgraph G' is a graph whose vertex set V' is a subset of V and whose edge set is the set of all edges present in G between vertices in V'.

Graphlet Kernel

Graphlets are fixed size non isomorphic induced subgraphs of a large graph. Typical graphlet sizes considered in applications are 3,4 and 5. For example, Figure [\ref=graphlets] shows all possible non isomorphic size 4 graphlets. There are 11 of them of which 6 are connected. We denote by Dl, the set of all size l graphlets that are connected. The set D4 is shown in Figure [\ref=connectedgraphlets].

If graphs G and G' are isomorphic then clearly their corresponding graphlet vectors fG and fG' are identical. But the reverse need not be true in general. But, it is conjectured that given two graphs G and G' of n vertices and their corresponding graphlet vectors fG and fG' with respect to n - 1 sized graphlets Dn - 1, graph G is isomorphic to G' if fG is identical to fG' [\cite=shervashidze2009efficient]. The conjecture has been verified for n  ≤  11 [\cite=shervashidze2009efficient]. Kernels based on similarity of graphlet vectors provide a natural way to express similarity of underlying graphs.

Graphlet vectors are in fact an explicit embedding of graphs into a vector space whose dimension is |Dl| if size l graphlets are used. Graphlet kernels have been shown to give better classification accuracies in comparison to other graph kernels like random walk kernel and shortest path kernel for certain applications [\cite=shervashidze2009efficient]. Values of K(G,G')∈[0,1] and larger values of K(G,G') indicate higher similarity between G and G'.

Graphlet vector based vertex labeling

Computing vertex labels that capture topological neighborhood information of corresponding vertices in the graph and comparing vertex neighborhoods using their labels is crucial in our matching algorithm. Our vertex labels are graphlet vectors of their corresponding neighborhood subgraphs.

Given a fixed positive integer t and graph G, let N(v) denote the depth t neighbors of vertex v in G. That is, N(v) is the subset of all vertices in G (including v) that are reachable from v in t or less edges. Let Hv denote the subgraph induced by vertices N(v) in G. We denote by fv, the graphlet vector corresponding to the graph Hv, with respect to size l graphlets for some fixed l. We note that for defining the graphlet vector fv for a vertex, there are two implicit parameters l and t. To avoid overloading the notation, we assume them to be some fixed constants and specify them explicitly when required. Values of l and t are parameters to our final algorithm.

For each vertex v of the graph, its vertex label is given by the vector fv. Given vertex labels fu and fv for vertices u and v, we denote by s(u,v) the similarity between labels of fu and fv, given by their dot product as

[formula]

Values of s(u,v)∈[0,1] and larger values of s(u,v) indicate higher topological similarity between neighborhoods of vertices u and v. Computing the vertex labels of the target graph is done in the preprocessing phase. Implementation details of the vertex labeling algorithm are discussed in the next section.

Our Algorithm

Our subgraph similarity search algorithm has two major phases: one time pre-processing phase and the query graph matching phase. Each of these phases comprise sub-phases as given below. Details of each of these subphases is discussed in the subsequent sections.

Pre-processing Phase: This phase has two subphases:

In this phase, vertex labels fv of all the vertices of the target graph G are computed.

k-d tree based nearest neighbor data structure on the vertices of G using their label vectors fv is built.

Matching Phase: This phase is further divided into four subphases:

Selection Phase: In this phase, vertex labels fv for vertices of the query graph Q are computed first. Each vertex u of the query graph then selects a subset of vertices from the target graph G closest to u based on their Euclidean distance.

Seed Match Generation Phase: In this phase, a one to one mapping of a subset of query graph vertices to target graph vertices is obtained with highest overall similarity score. Subgraph induced by the mapped vertices in the target graph is called the seed match. The seed match is obtained by solving a maximum weighted bipartite matching problem.

Match Growing Phase: The above seed match is used as a basis to compute the final match for Q.

Match Completion Phase: This phase tries to match those vertices in Q that are still left unmatched in the previous phase.

Pre-processing Phase

Computation of vertex labels fv

In this phase, vertex label fv for each vertex v of the target graph G is computed first. To compute fv, we require parameter values t and l. These two values are assumed to be provided as parameters to the search algorithm. For each vertex v, a breadth first traversal of depth t is performed starting from v to obtain the depth t neighborhood N(v) of v. The graph Hv induced by the vertex set N(v) is then used to compute the graphlet vector fv as given in [\cite=przulj2005supplementary]. The pseudo code is given in Algorithm 1.

Major time taken by the pre-processing phase is for computing the graphlet vector for Hv. In [\cite=shervashidze2009efficient], methods to improve its efficiency including sampling techniques are discussed. We do not make use of sampling technique in our implementation. We remark that finding the graphlet frequencies can easily be scaled to parallel computing frameworks or distributed computing frameworks such as map-reduce.

Nearest neighbor data structure on fv

After computing vertex labels for G, a nearest neighbor data structure on the vertices of G based on their label vectors fv is built. We use k-d trees for nearest neighbor data structure [\cite=heineman2008algorithms]. k-d trees are known to be efficient when dimension of vectors is less than 20 [\cite=heineman2008algorithms]. Since the typical graphlet size l that we work with are 3,4 and 5, the dimension of fv (which is |Dl|) does not exceed 10.

Matching Phase

In the following we describe the three subphases of matching phase.

Selection Phase

The vertex labels fv for all vertices of the query graph Q are computed first using Algorithm 1. Let Rv denote the set of k vertices in G that are closest to v with respect to the Euclidean distance between their label vectors. In our experiments, we usually fix k as 10. For each vertex v of Q, we compute Rv by querying the k-d tree built in the pre-processing phase. Let R denote the union of Rv for each vertex v of the nq vertices of Q. For the subsequent seed match generation phase, we will only consider the vertex subset R of G. Clearly size of R is at most k.nq which is typically much smaller than the number of vertices in G.

Seed Match Generation Phase

In this phase, we obtain a one to one mapping of a subset of vertices of the query graph Q to the target graph G with highest overall similarity score. We call the subgraph induced by the mapped vertices in G as the seed match. To do this, we define a bipartite graph (V(Q),R) with weighted edges, where one part is the vertex set V(Q) of the query graph Q and the other part is the pruned vertex set R of G obtained in the previous step. The edges of the bipartite graph and their weights are defined as follows. Each vertex v in the part V(Q) is connected to every vertex w in Rv  ⊆  R, where Rv is the set of k nearest neighbors of v in G as computed in the previous step.

The weight λ(v,w) for the edge (v,w) is defined in the following manner. Let 0  <  α  <  1 be a fixed scale factor which is provided as a parameter to the search algorithm. We recall that vertex v belongs to query graph Q and vertex w belongs to target graph G and s(v,w) given by equation ([\ref=simscore]) denote the similarity between their label vectors fv and fw. Let Vw denote the neighbors of vertex w in graph G including w. Let Q' denote the subset of V(Q) excluding v such that each vertex in Q' is connected to at least one vertex in Vw in the bipartite graph (V(Q),R). In particular, for each vertex u∈Q', let s(u) denote the maximum s(u,z) value among all its neighbors z in Vw in the bipartite graph. Now the weight λ(v,w) for the edge (v,w) of the bipartite graph is given by

[formula]

We now solve maximum weighted bipartite matching on this graph to obtain a one to one mapping between a subset of vertices of Q and the vertices of G. Defining edge weights λ(v,w) to edge (v,w) in the bipartite graph in the above fashion not only takes into account the similarity value s(v,w), but also the strength of similarity of neighbors of w in G to remaining vertices in the query graph Q. By assigning edge weights as above, we try to ensure that among two vertices in G with equal similarity values to a vertex in Q, the vertex whose neighbors in G also have high similarity to vertices in Q is preferred over the other in the final maximum weighted bipartite matching solution.

Let M denote the solution obtained for the bipartite matching. Let QM and GM respectively denote the subgraphs induced by the subset of matched vertices from graphs Q and G under the matching M. The connectivity of QM and GM may differ. For instance, the number of connected components in GM and QM could differ. Therefore, we do not include all the vertices of GM in the seed match. Instead, we use the largest connected component of GM as a seed solution. That is, let SG  ⊂  V(G) denote the subset of vertices in GM corresponding to a maximum cardinality connected component. Let SQ denote their corresponding mapped vertices in QM. We call SG as a seed match. The pseudo code for seed match computation is given in Algorithm 2.

Match Growing Phase

After computing the seed match SG in G and its mapped vertices SQ in Q, we use this seed match as the basis to compute the final match. The final solution is computed in an incremental fashion starting with empty match. In each iteration, we include a new pair of vertices (v,w) to the solution, where v and w belongs to G and Q respectively. In order to do this, we maintain a list of candidate pairs and in each iteration, we include a pair with maximum similarity value s(v,w) to the final solution. We use a max heap to maintain the candidate list. The candidate list is initialized with the mapped pairs between SG and SQ as obtained in the previous phase. Thus, the heap is initialized by inserting each of these mapped pairs (v,w) with corresponding weight s(v,w).

We recall that the mapped pairs obtained from previous phase have stronger similarity with respect to the modified weight function λ(v,w). Higher value of λ(v,w) indicates that not only s(v,w) is high but also their neighbors share high s() value. Hence they are more preferred in the solution over other pairs with similar s() value. By initializing the candidate list with these preferred pairs, the matching algorithm tries to ensure that the incremental solution starts with these pairs first and other potential pairs are considered later. Also, because of the heap data structure, remaining pairs are considered in the decreasing order of their similarity value. Moreover, as will be discussed later, the incremental matching tries to ensure that the partial match in G constructed so far is connected. For this, new pairs that are added to the candidate list are chosen from the neighborhood of the partial match between G and Q.

The incremental matching might still match vertex pairs with low s() value if they are available in the candidate list. Candidate pairs with low s() values should be treated separately as there could be genuine pairs with low s() value. For instance, consider boundary vertices of an optimal subgraph match in G. Boundary vertices are also connected to vertices outside the matched subgraph. Hence, their local neighborhood structure is different from their counterpart in the query graph. In other words, their corresponding graphlet vectors can be very dissimilar and their similarity value s() can be very low even though they are expected to be matched in the final solution. In order to find such genuine pairs, we omit pairs with similarity value below some fixed threshold h1 in this phase and such pairs are handled in the next phase.

In each iteration of the incremental matching, a pair (v,w) with maximum s(v,w) value is removed from the candidate heap and added to the final match. After this, the candidate list is modified as follows. We recall that v and w belong to G and Q respectively. We call a vertex unmatched if it is not yet present in the final match. The algorithm maintains two invariants: (a) the pairs present in the candidate list are one to one mappings and (b) a query vertex that enters the candidate list will stay in the candidate list (possibly with multiple changes to paired partner vertex) until it is included in the final match. Let Uv denote the unmatched neighbors of v in G that are also not present in the candidate list. Let Uw denote the unmatched neighbors w in Q. For each query vertex y in Uw, let x be a vertex in Uv with maximum similarity value s(x,y). We add (x,y) to the candidate list if y is absent in the list and s(x,y)  ≥  h1. If y is already present in the candidate list, then replace the current pair for y with (x,y) if s(x,y) has a higher value. The incremental algorithm is given in Algorithm 3. The candidate list modification is described in Algorithm 4.

Match Completion Phase

In this phase, vertices of the query graph Q that are left unmatched in the previous phase due to similarity values below the threshold h1 are handled. Typically, boundary vertices of the final matched subgraph in G remain unmatched in the previous phase. As discussed earlier, this is because, such boundary vertices in G and their matched partners in Q have low s() value as their local neighborhood topologies vastly differ. Hence using neighborhood similarity for such pairs is ineffective. To handle them, we try to match unmatched query vertices with unmatched neighbors of the current match F in G. Since the similarity function s() is ineffective here, we use a different similarity function to compare potential pairs. Let X denote the set of unmatched neighbors of the current match F in G. Let Y denote the set of unmatched query vertices. Let v∈X and let w∈Y. We define the similarity c(v,w) as follows. Let Zv denote the matched neighbors of v in target graph G and let Zw denote the matched neighbors of w in query graph Q. Let Z'v denote the matched partners of Zv in Q. We now define c(v,w) using the standard Jaccard similarity coefficient as

[formula]

We use a fixed threshold h2 that is provided as parameter to the algorithm. We now define a bipartite graph (X,Y) with edge weights as follows. For each (v,w)∈X  ×  Y, insert an edge (v,w) with weight c(v,w) in the bipartite graph if c(v,w)  ≥  h2. Compute maximum weighted bipartite graph matching on this bipartite graph and include the matched pairs in the final solution F. In our experiments, size of Y (number of unmatched query graph vertices) is very small. The pseudo code is given in Algorithm 5.

We remark that our searching algorithm finds the matched subset of vertices in G and also their corresponding mapped vertices in the query graph Q.

Experimental Results

In this section, we conduct experiments on various real life graph data sets [\cite=snapnets] including social networks, collaboration networks, road networks, youtube network, amazon network and on synthetic graph data sets.

Experimental Data sets

Social Networks: We conduct experiments on facebook and google plus undirected graphs provided by Stanford Large Network Dataset Collection (SNAP) [\cite=snapnets]. Facebook graph contains around 4K vertices and 88K edges. In this graph vertices represent anonymized users and an undirected edge connects two friends. google plus graph contains 107K vertices and 13M edges. google plus graph also represents users as vertices and an edge exists between two friends. The data set also contains list of user circles (user communities), where user circle is specified by its corresponding set of vertices. We use these user circles as query graphs and they are queried against the entire facebook network. We also query facebook circles against google plus network to find similar circles across networks. We also experiment querying facebook circles against facebook network after introducing random noise to the facebook network.

DBLP Collaboration Network: We use the DBLP collaboration network downloadable from [\cite=DBLP]. This network has around 317K vertices and 1M edges. The vertices of this graph are authors who publish in any conference or journal and an edge exists between any two co-authors. All the authors who contribute to a common conference or a journal form a community. The data set provides a list of such communities by specifying its corresponding set of vertices. We use such communities as query graphs.

Youtube Network: Youtube network is downloaded from [\cite=snapnets]. Network has about 1M vertices and 2M edges. Vertices in this network represent users and an edge exists between two users who are friends. In youtube, users can create groups in which other users can join. The data set provides a list of user groups by specifying its corresponding set of vertices. We consider these user-defined groups as our query graphs.

Road Network: We use the road network of California obtained from [\cite=snapnets] in our experiments. This network has around 2M vertices and 3M edges. Vertices of this network are road endpoints or road intersections and the edges are the roads connecting these intersections. We use randomly chosen subgraphs from this network as query graphs.

Amazon Network: Amazon network is a product co-purchasing network downloaded from [\cite=snapnets]. This network has around 334K vertices and 925K edges. Each vertex represents a product and an edge exists between the products that are frequently co-purchased [\cite=snapnets]. All the products under a certain category form a product community. The data set provides a list of product communities by specifying its corresponding set of vertices. We use product communities as query graphs and we query them against the amazon network.

The statistics of the data sets used are listed in Table [\ref=datastats].

Experimental Setup

All the experiments are carried out on a 32 core 2.60GHz Intel(R) Xeon(R) server with 32GB RAM. The server has Ubuntu 14.04 LTS. Our implementation uses Java 7.

The computationally most expensive part of our algorithm is the computation of vector labels for all vertices of a graph. The preprocessing phase that computes label vectors for each vertex of the graph is multi-threaded and thus executes on all 32 cores. Similarly, in the matching phase, computing label vectors for all vertices of the query graph is also multi-threaded and uses all 32 cores. Remaining phases use only a single core.

Results

To evaluate the accuracy of the result obtained by our similarity search algorithm, we compute the graphlet kernel value K(Q,G*) between the query graph Q and the subgraph G* of G induced by the vertices V* of the final match F in G. We use this value to show the similarity between the query graph and our obtained match and we refer to this value as similarity score in our experiments. We recall that similarity score lies in the range

[formula]

Scalability

Computationally most expensive parts of our algorithm are the vertex label computation for vertices of query and target graphs. Since this is a one time preprocessing for the target graph, it can be easily scaled to a distributed framework using the standard map-reduce paradigm. Vertex label computation for each vertex can be a separate map/reduce job. Vertex label computation for query graph is performed for every search. This can also be parallelized using the standard OpenMP/MPI framework as each vertex label computation can be done in parallel. As shown in the experimental results, remaining phases take much lesser time even with serial implementation. Parts of them can also be parallelized to further improve the search efficiency.