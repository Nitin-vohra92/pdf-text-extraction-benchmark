Lemma Corollary

Lemma Proposition

Stability of Feynman-Kac formulae with path-dependent potentials

, Pierre Del Moral

and S. Rubenthaler

Introduction

The most common application of the theory of Feynman-Kac formulae [\citep=delMoral:book] is nonlinear filtering of a hidden Markov chain (Λn), based on observed process (Yn). In such settings, the potential function at time n typically depends only on the current state Λn. The uniform stability of the corresponding particle approximations can be obtained under appropriate conditions, see Section 7.4.3 of the aforementioned book and references therein. For a good overview of the theoretical and methodological aspects of particle approximation algorithms, also known as particle filtering algorithms, see also [\citet=DouFreiGor], [\citet=Kun:SSHMM], and [\citet=CapMouRyd].

They are however several applications of practical interest where the potential function depends on the complete state trajectory [formula]. The corresponding particle filtering algorithms still have a fixed computational cost per iteration, because the potential can be computed using recursive formulae. An important example is the class of conditional linear Gaussian dynamic models, where the conditioning is on some unobserved Markov chain Λn. The corresponding particle algorithm is known as the mixture Kalman filter ([\citealp=ChenLiu], see also Example 7 in [\citealp=DouGodAnd], and [\citealp=AndDou], for a related algorithm): the potential function at time n is then a Gaussian density, the parameters of which are computed recursively using the Kalman-Bucy filter [\citep=KalBuc]. Another example is the mixture GARCH model considered in [\citet=Chopin:change].

It is worth noting that these models such that the potential functions are path-dependent can often be reformulated as a standard hidden Markov model, with a potential function depending on the last state only, by adding components to the hidden Markov chain. For instance, the mixture Kalman filter may be interpreted as a standard particle filtering algorithm, provided the hidden Markov process is augmented with the associated Kalman filter parameters (filtering expectation and error covariance matrix) that are computed iteratively in the algorithm. However, this representation is unwieldy, and the augmented Markov process does not fulfil the usual mixing conditions found in the literature on the stability of particle approximations. This is the main reason why our study is based on path-dependent potential functions. Quite interestingly, we shall see that the opposite perspective is more fruitful. Specifically, our stability results obtained for path-dependent potential functions can also be applied to standard state-space models, leading to stability results under conditions different from those previously given in the literature.

In this paper, we study the asymptotic stability of particle algorithms based on path-dependent potential functions. We work under the assumption that the dependence of potential n on state n - p vanishes exponentially in p. This assumption is met in practical settings because of the recursive nature of the potential functions. Our proofs are based on the following construction: the true filter is compared with an approximate filter associated to 'truncated' potentials, that is potentials that depend only on λn - p + 1:n, the vector of the last p states, for some well-chosen integer p. Then, we compare the truncated filter with its particle approximation, using the fact the 'truncated' filter corresponds to a standard Feynman-Kac model with a Markov chain of fixed dimension. Finally, we use a coupling construction to compare the particle approximations of the true filter and the truncated filter. In this way, we obtain estimates of the stability of the particle algorithm of interest. We apply our results to the two aforementioned classes of models, and obtain practical conditions under which the corresponding particle algorithms are stable uniformly in time.

The paper is organised as follows. Section [\ref=sec:model] introduces the model and the notations. Section [\ref=sec:local] evaluates the local error induced by the truncation. Section [\ref=sec:mix-truncated] studies the mixing properties of the truncated filter. Section [\ref=sec:Propagation] studies the propagation of the truncation error. Section [\ref=sec:Coupling] develops a coupling argument for the two particle systems. Section [\ref=sec:Main] states the main theorem of the paper, which provides a bound for the particle error and derives time-uniform estimates for the long-term propagation of the error in the particle approximation of the true model. Section [\ref=sec:applis] applies these results to two particle algorithms of practical interest, namely, the mixture Kalman filter, and the mixture GARCH filter, and shows how these results can be adapted to standard state-space models, such that the potential function depends only on the last state.

Model and notations

We consider a hidden Markov model, with latent (non-observed) state process [formula], and observed process [formula], taking values respectively in a complete separable metric space E and in [formula]. The state process is an inhomogeneous Markov chain, with initial probability distribution ζ, and transition kernel Qn. The observed process Yn admits Ψn(yn|y1:n - 1;λ0:n) as a conditional probability density (with respect to an appropriate dominating measure) given Λ0:n  =  λ0:n and Y1:n - 1 = y1:n - 1, where the short-hand v0:n for any symbol v stands for the vector [formula]. As explained in the Introduction, this quantity depends on the entire path λ0:n, rather than the last state λn. Following common practice, we drop dependencies on the yn's in the notations, as the observed sequence y0:n may be considered as fixed, and use the short-hand Ψn(λ0:n) = Ψn(yn|y0:n - 1;λ0:n). The model admits a Feynman-Kac representation which we describe fully in ([\ref=Eq:FKrep]). We consider the following assumptions.

The constants an and φn depend implicitly on the realisation y1:n of the observed process. Hypotheses 1 and 3 are standard in the filtering literature; see e.g. [\citet=delMoral:book]. Hypothesis 2 formalises the fact that potential functions are computed using iterative formulae, and therefore should forget past states at an exponential rate. One may take [formula] for instance, where z is an arbitrary element of E. We shall work out, in several models of interest, practical conditions under which Hypothesis 2 is fulfilled in Section [\ref=sec:applis].

We introduce the following notations for the forward kernels, for [formula]:

[formula]

where δλ0:n - 1 is the Dirac measure centred at λ0:n - 1. The above kernels implicitly defines operators on measures and on test functions, i.e.,

[formula]

for any μ∈M+(En + 1), any test function f:En + 1  →  [0,1], where M+(Ek) denotes the set of nonnegative measures w.r.t. Ek, and P(Ek) the set of probability measures w.r.t. Ek.

We associate to γn a "normalised" operator Rn, such that, for any μ∈M+(En), Rnμ is defined as:

[formula]

for any [formula]. Both the γn's and the Rn's may be iterated using the following short-hands, for 1  ≤  k  ≤  n:

[formula]

We have the following Feynman-Kac representation:

[formula]

[formula], [formula], where, as mentioned above, ζ the law of Λ0.

Finally, we denote the total variation norm on nonnegative measures by [formula], the supremum norm on bounded functions by ||  ·  ||∞, and the Hilbert metric by h(μ,μ') for any pair μ,μ'∈M+(Ek), [formula]; see e.g. [\citet=atar1997esn] or [\citet=legland2004sau], Definition 3.3. We recall that the Hilbert metric is scale invariant, and is related to the total variation norm in the following way, see e.g. Lemma 3.4 in [\citet=legland2004sau]:

[formula]

provided K is a ε-mixing kernel. We can also derive the following properties from the definition of h ([formula], [formula]):

[formula]

with an equality in the latter equation if ψ is positive.

Local error induced by truncation

Until further notice, p is a fixed integer such that [formula] and such that Hypothesis 2 holds. Since our proofs involve a comparison between the true filter and a 'truncated' filter, we introduce the projection operator Hpn which, for n  ≥  p, associates to any measure μ(dλ0:n)∈M+(En + 1) its marginal w.r.t. its last p components, i.e. :

[formula]

for any [formula]; for p > n, let Hpn(μ) = μ. We also define the following 'truncated' forward kernels, for n  ≥  p:

[formula]

and the associated normalised operators, for μ∈M+(Ep), [formula]:

[formula]

and set γ̃pn  =  γn, pn = Rn for n < p. From now on, we will refer to the filter associated to these 'truncated' operators as the truncated filter.

We now evaluate the local error induced by the truncation.

For all 1  ≤  k < n, and for all μ∈M+(Ek),

[formula]

Let [formula]. One has

[formula]

where

[formula]

and

[formula]

hence

[formula]

according to Hypothesis 2. And, since, for all a, b, c, [formula] such that [formula] and [formula],

[formula]

one may conclude directly by taking a = γ̃k + 1:nHpkγkμ(f), b = γ̃k:nHpk - 1γk - 1μ(1), c = γ̃pk + 1:nHpkμ(f), and d = γ̃pk:nHpk - 1μ(1).

For [formula], if there exists a (possibly random) probability kernel [formula] such that, for all [formula],

[formula]

for some [formula], then, for all [formula] and [formula],

[formula]

where the expectation is with respect to the distribution of k.

Using the same ideas as above, one has, for [formula],

[formula]

In order to use inequality ([\ref=eq:abcd]), compute

[formula]

where [formula] is defined as

[formula]

and conclude by noting that

[formula]

since pkμ is a probability measure.

Mixing and contraction properties of the truncated filter

The truncated filter may be interpreted as a standard filter based on Markov chain Λ̃pn  =  Λ(n - p + 1)+:n. This insight allows us to establish the contraction properties of the truncated filter.

One has:

[formula]

and

[formula]

where

[formula]

for all [formula], and all μ ,[formula].

Note k,n must be interpreted as a mixing coefficient, and k,p as a Birkhoff contraction coefficient.

Using Hypothesis 3, one has:

[formula]

where p stands for the following reference measure:

[formula]

One shows similarly that

[formula]

Hence kernel Qk + pγ̃k + 1:k + p - 1μ is mixing, with mixing coefficient k + 1,p.

Following Lemma 3.4 in [\citet=legland2004sau],

[formula]

using the scale invariance property of the Hilbert metric. Similarly, according to Lemma 3.9 in the same paper:

[formula]

Propagation of truncation error

We establish first the two following lemmas.

Let [formula] be a sequence of (possibly random) probability kernels such that for all [formula] and [formula],

[formula]

where the expectation is w.r.t. the randomness of n, then, for all [formula] and all ζ∈P(E), one has

[formula]

where [formula], and with the convention that empty products equal one.

The following difference can be decomposed into a telescopic sum:

[formula]

We fix the integers i, n, and consider some arbitrary test function f. For i  ≥  n - 2p, one may apply Lemma [\ref=lem:32]:

[formula]

since [formula], [formula] and [formula] for all n.

For i < n - 2p, let k = ⌊(n - i) / p⌋, then, using Lemma [\ref=lem:melange], Equations ([\ref=Eq:borne1]) to [\eqref=Eq:inv1] one has

[formula]

where ν  =  pi1:i - 1ζ, ν' = i1:i - 1ζ. Applying (7) p. 160 of [\citet=legland2004sau], one gets

[formula]

where, using the same calculations as in Lemma [\ref=lem:melange],

[formula]

and

[formula]

which ends the proof.

For all [formula] and all ζ∈P(E), one has

[formula]

with the convention that empty sums equal zero, and empty products equal one.

One has:

[formula]

For i  ≤  n - p, let k = ⌊(n - i) / p⌋, then according to Lemma [\ref=lem:melange]:

[formula]

and ones concludes using Lemma [\ref=lem:loc2]. For i > n - p, one can apply Lemma [\ref=lem:loc2] directly.

Coupling of particle approximations

We now introduce two interactive particle systems: the first particle system approximates the true filter, and is equivalent to the type of particle algorithms studied in this paper, and the second particle system approximates the truncated filter, and corresponds to an artificial algorithm that would not be implemented in practice. We work out a way of coupling both particle systems in order to evaluate the distance between the two (in a sense that is made clear below).

We define, for [formula],

[formula]

[formula]

We define [formula], [formula] measurable [formula], [formula], [formula] measurable [formula],

[formula]

For any measurable space (E',Ω') and any measure μ'∈P(E'), we can take [formula] i.i.d. of law μ' and define the random empirical measure, for N  ≥  1,

[formula]

Notice that, as the [formula] are only given in law, we only define SN(μ) in law. We define the random operators RNn, p,Nn ([formula]) by: [formula], RNnμ is a random weighted empirical measure such that

[formula]

Similarly, [formula], p,Nnμ' is a random weighted empirical measure such that

[formula]

As pointed above, RNnμ and p,Nnμ' are only defined in law. Since ζ denotes the probability density of the first state Λ0, the particle system with N particles approximating the true filter at time n is defined by

[formula]

and the particle system with N particles approximating the truncated filter at time n is defined by

[formula]

There exists a coupling such that, for all [formula] and μ∈P(Ek):

[formula]

As HpkRNkμ and p,NkHpkμ are defined to be random variables with such and such law, the term "coupling" means that we can define a random variable (HkRNkμ,p,NkHkμ) with the desired marginals.

To prove the above result, we produce a coupling between the two random measures p,NkHpk - 1μ and HpkRNkμ. Let

[formula]

so that, for μ∈P(Ek), and using [\eqref=eq:inlaw], one has

[formula]

in the sense that both sides define the same distribution. Let [formula] i.i.d. ~  μk, where χi is a vector λ0:k,i, for [formula], and i denotes its projection on the p last components, i  =  λ(k - p + 1)+:k,i, then

[formula]

and

[formula]

For any f such that [formula] (using a classical result on empirical measures):

[formula]

using Hypothesis 2, from which we deduce the result.

Main result

We are now able to derive estimates of the error

[formula]

induced by the particle approximation of the true filter, for the marginal filtering distribution of the p last states, provided p  ≤  n. The expectation [formula] is with respect to the randomness of the N particles, and the functions f are [formula]. Note that Epn,N(y1:n) is by construction an increasing function of p.

For any ζ∈P(E), and any test function w.r.t. [formula],

[formula]

where

[formula]

We first study the following local error, for μ∈P(En),

[formula]

where the difference of operators can de decomposed into:

[formula]

To bound the first term, one may use (25) p. 162 of [\citet=legland2004sau], for ν = Hpn - 1μ and Hypothesis 3:

[formula]

and, for the second term, one may apply Lemma [\ref=lem:coupling]:

[formula]

so that

[formula]

for [formula]. This local error is propagated using Lemma [\ref=lem:tele1]:

[formula]

To conclude, one may decompose the global error as follows:

[formula]

where the second term is bounded above, and the first term is directly bounded using Lemma [\ref=lem:tele2].

Since p is an arbitrary parameter, one may minimise the error bound with respect to p. For instance, one has the following result for time-uniform estimates. As noted above, the error Epn,N(y1:n) is an increasing function of p, so the bound below applies a fortiori to E1n,N(y1:n), the particle error corresponding to the marginal filtering distribution of the last state Λn.

If there exists constants c, ε, φ > 0 such that, almost surely, anbn  ≤  c, εn  ≥  ε, and φn  ≤  φ, then, provided τc3 < 1, the particle error is bounded almost surely as follows:

[formula]

for N large enough, where

[formula]

and

[formula]

Under these conditions, the RHS of ([\ref=eq:error_bound]) is smaller than or equal to:

[formula]

for p large enough, since [formula] for a∈(0,1), x∈(0,1), so, provided c3τ < 1, one may take p as in [\eqref=eq:pfN], which gives:

[formula]

and conclude.

[formula]

Obviously, this is a qualitative result, in that there are many practical models where such time-uniform, deterministic bounds are not available. For specific models, one may be able instead to use ([\ref=eq:error_bound]) in order to establish the asymptotic stability of the expected particle error, where the expectation is with respect to observed process (Yn). We provide an example of this approach in Section [\ref=sec:applis].

Applications to practical models

In this section, we apply our general result to three practical models. We keep the same settings and notations, i.e. the observed process (Yn) admits some probability distribution conditional on the path Λ0:n  =  λ0:n of a Markov chain (Λn), with initial distribution ζ and Markov transition Qn, which fulfil Hypothesis 1, see Section [\ref=sec:model]. We derive conditions on the model parameters that ensure asymptotic stability of the particle error; in particular, these conditions imply that Hypotheses 2 and 3 are verified.

We state the following trivial result for further reference. Let (f,g) a pair of probability densities (f,g) on E, then:

[formula]

for [formula].

GARCH Mixture model

We assume that the observed process is such that

[formula]

where the Zn's are i.i.d. N(0,1) random variables, and the variance function σ2n is defined recursively, for [formula]:

[formula]

and [formula] where α, β and γ are [formula] functions. Conditional on Λ0:n, (Yn) is a GARCH (generalised autoregressive conditional heteroskedasticity) process [\citep=bollerslev1986gac]; see [\citet=Chopin:change] for a finance application of such a GARCH mixture model.

The potential functions equal

[formula]

for λ0:n∈En + 1, and (Λn) is a Markov process, with Markov kernels Qn, which satisfy Hypothesis 1.

The functions α, β and γ are assumed to be bounded as follows:

[formula]

[formula]

We first consider the case where β(λ) = 0 for all λ∈E. As mentioned in the introduction, this simplified model can be interpreted as a standard hidden Markov model, with observed process (Yn), and Markov chain [formula]. However, since σ2n(Λ0:n) is a deterministic function of σ2n - 1(Λ0:n - 1) and λn, it does not have mixing or similar properties that are usually required to obtain estimates of the particle error. Instead, analysing this model as a Feynman-Kac flow with iterative, path-dependent potential functions make it possible to derive such estimates.

For the simplified model described above (with β = 0), the expected particle error of the corresponding particle approximation is uniformly stable in time, i.e. there exists constants C, D, such that

[formula]

where p is given by ([\ref=eq:pfN]), provided ι < 2 and τc3 < 1, where τ  =  γmax, [formula], and

[formula]

From ([\ref=eq:sigman]), one sees the process σ2n is bounded, σ2min  ≤  σ2n(λ0:n)  ≤  σ2max for all λ0:n∈En + 1, where

[formula]

so, for a given sequence observations y1:n, Hypothesis 3 is verified with:

[formula]

provided the truncated potential is taken as:

[formula]

where z is an arbitrary element of E. For Hypothesis 2, one has, for any λ0:n,λ0:n'∈E(n + 1) such that λ(n - p + 1)+:n  =  λ(n - p + 1)+:n' :

[formula]

where σ2n is contracting, in the sense that, for n  ≥  p,

[formula]

Thus, using ([\ref=ineq:logdens]), and the fact that (ex - 1) / x is an increasing function, Hypothesis 2 is verified with τ  =  γmax and

[formula]

for any q  ≤  p. Finally, to compute the expectation with respect to process [formula] of the error bound ([\ref=eq:error_bound]), one may use repetitively the following results:

[formula]

for a < 1 / 2σ2max, using standard calculations and the fact that Yn, conditional on Y1:n - 1 and Λ0:n  =  λ0:n is [formula]. This implies in particular that:

[formula]

where the constant c is well-defined since σ2max  /  σ2min < 2, then by Jensen inequality,

[formula]

and similarly,

[formula]

where φ is properly defined for q large enough. Using the above results recursively on the sum on the RHS of ([\ref=eq:error_bound]), one obtains the same expression as in ([\ref=eq:error_cor]) for the error bound than in Corollary [\ref=cor:time-unif] for time-uniform estimates (with the values of c, φ, τ as defined above), and concludes similarly.

If β is allowed to take positive values, stability results may be obtained under more restrictive conditions. In particular, one may impose that γ is a constant function.

For the general mixture GARCH model defined above, the expected particle error is uniformly stable in time, i.e. there exist constants C, D, such that

[formula]

provided γ is a constant function, γ(λ) = γ, τc3 < 1, ϑ < 2, where τ  =  γ, [formula], p is given by ([\ref=eq:pfN]), and

[formula]

We follow the same lines as above, except that the bounds of the process σ2n(λ0:n) must be replaced by:

[formula]

which, by construction, are such that

[formula]

Hence, one has again

[formula]

and the rest of the calculation is identical to those of previous Lemma, with τ  =  γ.

Mixture Kalman model

We focus on an univariate linear Gaussian model, i.e. conditional on Markov process (Λn), one has X0 = 0 almost surely, and, for [formula],

[formula]

where the Vn's and the Wn's are independent N(0,1) variables, and h, v, w are real-valued functions. Using the recursions of the Kalman-Bucy Filter [\citep=KalBuc], one is able to marginalise out the process Xn, and compute recursively the probability density of Yn, conditional on Λ0:n  =  λ0:n, in the following way:

[formula]

where, the following quantities are defined recursively: for [formula],

[formula]

and m0(λ0) = c0(λ0) = 0.

We make the following assumptions:

Functions v and w are bounded as follows: for all λ∈E,

[formula]

Function h is bounded as follows: for all λ∈E,

[formula]

We first prove the following intermediate results.

The sequence σ2n is bounded and uniformly contracting, i.e. for all [formula] for all λ0:n, λ'0:n, such that λn - p + 1:n  =  λn - p + 1:n', one has

[formula]

where 2  =    +  , 2 = (2 + 1)  +  , Cσ  =  2  /  τσ, and

[formula]

From ([\ref=eq:cn]), one deduces that

[formula]

thus

[formula]

and, from ([\ref=eq:sign]), that

[formula]

In addition, ([\ref=eq:invcn]) implies that

[formula]

where

[formula]

It is easy to show that, for a fixed λ, the derivative of [formula] with respect to c is bounded from above by τσ as defined above. Thus, [formula] is a contracting function, and, by induction, for n  ≥  p,

[formula]

where τσ and Cσ were defined above.

The sequence μn is bounded and contracting in the sense that there exists Cμ > 0 such that, for all [formula] for all n  ≥  p, and λ0:n, λ'0:n, such that λn - p + 1:n  =  λ'n - p + 1:n, one has

[formula]

where

[formula]

Note first that

[formula]

so one shows recursively, using ([\ref=eq:mun]) and ([\ref=eq:mn]), that:

[formula]

and that, for λ0:n, λ'0:n such that λn - p + 1:n  =  λ'n - p + 1:n,

[formula]

where an - i, an - i' are short-hands for an - i(λ0:n - i), an - i(λ0:n - i'). The sequence an itself in contracting, since, from ([\ref=eq:an]), one has, for i < p:

[formula]

so ([\ref=eq:diffmun]) and the fact that [formula] provided x,x',y,y'∈[0,1] leads to

[formula]

for [formula], and a well chosen value of Cμ.

We are now able to state the main result.

For the model above, the particle error is bounded uniformly in time, i.e. there exist C, D, such that

[formula]

almost surely, for p given by ([\ref=eq:pfN]), provided the realizations yn are bounded, i.e. [formula] for all [formula], and that τc3 < 1, with [formula] and

[formula]

This proposition is a direct application of Corrolary [\ref=cor:time-unif], so we need only to prove that Hypotheses 2 and 3 are fulfilled. For Hypothesis 2, one may take

[formula]

so that anbn  ≤  c for c defined above. For Hypothesis 3, one has:

[formula]

where the first term is such that

[formula]

according to Lemma [\ref=lem:sig], and the second term is such that

[formula]

and one concludes using ([\ref=ineq:logdens]) and taking

[formula]

Obviously, the boundness condition on the realizations yn is not entirely satisfactory, as the generating process of (Yn) is such that Yn should leave any interval eventually. However, Yn is marginally a Gaussian variable with variance uniformly bounded in time (since  < 1), so this remains a reasonable approximation if Cy is large enough. Generalizing the above result to more general conditions is left for future research.

Application to standard state-space models

Consider a 'standard' state-space model, based on a linear auto-regressive state process (Xn):

[formula]

for [formula], ρ∈( - 1,1) and X0  =  Λ0, and an observed process (Yn), with conditional density, with respect to an appropriate dominating measure, and conditional on Xn = xn, given by the potential function ΨXn(xn).

In this section, we show how to apply our stability results to such a standard state-space model, where the potential function depends only on the current state Xn. We rewrite the model as a state space model with hidden Markov chain (Λn), and observed process (Yn) corresponding to potential function

[formula]

where the argument xn in the right hand side has been substituted with the appropriate function of λ0:n, as derived from ([\ref=eq:autoreg]).

Clearly, the reformulated model satisfies Hypothesis 1: the (Λn) are i.i.d., hence they form a Markov chain with mixing coefficient εn = 1. If we assume that the Ψn(λ0:n) are such that Hypotheses 2 and 3 hold as well, then we can apply directly Theorem [\ref=prop:maj]. However, the path-dependent formulation of this model is artificial, and, in practice, we are interested in filtering the process Xn, conditional on the Yn's, rather than filtering the Λn's, again conditional on the Yn's. More precisely, we wish to approximate the conditional expectation of

[formula]

for some bounded function g, and, provided g is also Lipschitz, with constant K, and that the λn's lie in interval , for some [formula], one has:

[formula]

where [formula]. Therefore, we must consider an additional term in the particle error attached to the filtering of (Xn), which stems from the difference between the filtering distribution of Xn and that of Λn - p + 1:n, for some integer p. Consider the following estimate of the particle error for functions of Xn:

[formula]

where Lip(K) denotes the set of Lipschitz functions with Lipschitz constant K, and fg is the function [formula] such that

[formula]

i.e., loosely speaking, fg(λ0:n) = g(xn), where xn must be substituted by its expression as a function of λ0:n.

For the state-space model described above, one has, for any n  ≥  p,

[formula]

Taking into account this additional error term, we can derive time-uniform estimates of the stability of the particle algorithm. For the sake of space, we focus on the following simple example: Yn∈{ - 1,1}, Yn = 1 with probability 1 / (1 + eXn), Yn =  - 1 otherwise. The potential function (for the model in its standard formulation) equals:

[formula]

We recall that the support of the (Λn) is

[formula]

Conclusion

To extend our results to a broader class of models, three directions may be worth investigating. First, it may be possible to bound directly the particle error, without resorting to a comparison with an artificial, truncated potential function. It seems difficult however to avoid some form of truncation, as the path process Λ0:n itself does not benefit to any sort of mixing property, while fixed segments Λn - p + 1:n do. Second, one may try to loosen Hypothesis 1 (Markov kernel is mixing) and Hypothesis 3 (potential function is bounded), using for instance [\citet=OudRub]'s approach. Third, it seems possible to adapt our general result on the particle error bound to several models not considered in this paper, in particular standard models with potential functions depending on the last state only, by using and extending the approach developed in the previous Section.

Acknowledgements

Part of this work was performed while the authors were invited by the SAMSI institute during the 2008-2009 Program on Sequential Monte Carlo Methods.