Instruction Sequence Processing Operators

Introduction

We take the view that a sequential program is in essence a sequence of instructions, and that the execution of an instruction sequence involves the processing of instructions by an execution environment offering a family of services and may yield a Boolean value at termination. Interaction with services concerning the processing of instructions is deemed to form part of the behaviour exhibited by the instruction sequence under execution. We introduce a composition operator for families of services and three operators that have a direct bearing on the processing of instructions. Although all terms that can be build by means of these operators denote something, some of them are not really intended to denote anything. Therefore, we propose to comply with conventions that exclude the use of such terms.

A slightly different view on the execution of an instruction sequence was taken in [\cite=BP02a]. This resulted in different operators: a composition operator for services instead of service families and two kinds of operators, called use operators and apply operators, that have a direct bearing on the processing of instructions but do not cover the possibility that some value is yielded at termination. In subsequent work, the composition operator for services was not used. Moreover, we experienced the lack of a way to deal with the possibility that some value is yielded at termination of the execution of an instruction sequence. This lack is particularly felt with instruction sequences that implement some test. This state of affairs forms the greater part of our motivation for devising the four operators presented in this paper.

The work presented in this paper belongs to a line of research in which program algebra [\cite=BL02a] is the setting used for investigating issues in which sequential programs are involved. The starting-point of program algebra is the perception of a program as a single-pass instruction sequence, i.e. a finite or infinite sequence of instructions of which each instruction is executed at most once and can be dropped after it has been executed or jumped over. This perception is simple, appealing, and links up with practice. Moreover, basic thread algebra [\cite=BL02a] is the setting used for modelling the behaviours exhibited by instruction sequences under execution. In [\cite=BL02a], basic thread algebra is introduced under the name basic polarized process algebra. The three operators that are related to the processing of instructions will be introduced as operators extending basic thread algebra. Because these operators are primarily intended to be used in the setting of program algebra to describe and analyse instruction sequence processing, they are loosely referred to by the term instruction sequence processing operators.

Both thread and service are abstract behavioural concepts. A state space is not inherent in the concept of a service. This is sometimes experienced as a limitation in case the services that are involved in the processing of instructions can be viewed as the behaviours of a machine in its different states. For that reason, we introduce the related but more concrete concept of a functional unit, in which a state space is inherent. The case where the state space is the set of natural numbers is arguably the simplest significant case. Another interesting case is the one where the state space consists of objects that represent the possible contents of the tapes of Turing machines with a particular tape alphabet. Using the instruction sequence processing operators proposed in this paper, we investigate both cases. One of the main result of the investigation is the existence of a universal computable functional unit for natural numbers. Results like this one are outside the scope of the concept of a service. The other main results of the investigation concern the autosolvability requirement inherent in Turing's result regarding the undecidability of the halting problem.

The halting problem is frequently paraphrased as follows: the halting problem is the problem to determine, given a program and an input to the program, whether execution of the program on that input will eventually terminate. However, Turing's result regarding the undecidability of the halting problem is a result about Turing machines rather than programs. It says that there does not exist a single Turing machine that, given the description of an arbitrary Turing machine and input, will determine whether the computation of that Turing machine applied to that input eventually halts (see e.g. [\cite=Tur37a]). In [\cite=BP04a], Turing's result regarding the undecidability of the halting problem is positioned as a result about programs rather than machines. In the case of the unsolvability result regarding the halting problem for programs presented in [\cite=BP04a], the mere requirement that a program of a certain kind must solve the halting problem for all programs of that kind leads to a contradiction. This requirement is the autosolvability requirement referred to above.

Some marginal notes are in order. In the investigations concerning functional units, only two of the three instruction sequence processing operators proposed in this paper are used. The unused instruction sequence processing operator generalizes the use operators that are used in [\cite=BM07g] [\cite=BM06c] among others. In this paper, we use an extension of a program notation rooted in program algebra instead of an extension of program algebra itself. The program notation in question has been chosen because it turned out to be appropriate. However, in principle any program notation that is as expressive as the closed terms of program algebra would do.

This paper is organized as follows. First, we give a survey of the program notation used in this paper (Section [\ref=sect-PGLBbt]) and define its semantics using basic thread algebra (Section [\ref=sect-BTAbt]). Next, we introduce service families, the composition operator for service families (Section [\ref=sect-SF]), and the three operators that are related to the processing of instructions by service families (Section [\ref=sect-TSI]). Then, we propose to comply with conventions that exclude the use of terms that are not really intended to denote anything (Sections [\ref=sect-RUC]). After that, we give an example related to the processing of instructions by service families (Section [\ref=sect-example]). Further, we present an interesting variant of one of the above-mentioned operators related to the processing of instructions (Section [\ref=sect-abstr-use]). Thereafter, we introduce the concept of a functional unit and related concepts (Section [\ref=sect-func-unit]). Subsequently, we investigate functional units for natural numbers (Section [\ref=sect-func-unit-nat]). We also make some remarks about functional units for finite state spaces (Section [\ref=sect-func-unit-fin]). Then, we define autosolvability and related notions in terms of functional units related to Turing machine tapes (Section [\ref=sect-func-unit-sbs]). After that, we discuss the weakness of interpreters when it comes to solving the halting problem (Section [\ref=sect-interpreters]) and give positive and negative results concerning the autosolvability of the halting problem (Section [\ref=sect-autosolvability]). Finally, we make some concluding remarks (Section [\ref=sect-concl]).

This paper consolidates material from [\cite=BM09k] [\cite=BM09l] [\cite=BM09m].

with Boolean Termination

In this section, we introduce the program notation  (PGLB with Boolean termination). In [\cite=BL02a], a hierarchy of program notations rooted in program algebra is presented. One of the program notations that belong to this hierarchy is  (ProGramming Language B). This program notation is close to existing assembly languages and has relative jump instructions.  is  extended with two termination instructions that allow for the execution of instruction sequences to yield a Boolean value at termination.

In , it is assumed that a fixed but arbitrary non-empty finite set [formula] of basic instructions has been given. The intuition is that the execution of a basic instruction may modify a state and produces [formula] or [formula] at its completion.

has the following primitive instructions:

for each [formula], a plain basic instruction a;

for each [formula], a positive test instruction [formula];

for each [formula], a negative test instruction [formula];

for each [formula], a forward jump instruction [formula];

for each [formula], a backward jump instruction [formula];

a plain termination instruction [formula];

a positive termination instruction [formula];

a negative termination instruction [formula].

instruction sequences have the form [formula], where [formula] are primitive instructions of .

On execution of a  instruction sequence, these primitive instructions have the following effects:

the effect of a positive test instruction [formula] is that basic instruction a is executed and execution proceeds with the next primitive instruction if [formula] is produced and otherwise the next primitive instruction is skipped and execution proceeds with the primitive instruction following the skipped one - if there is no primitive instructions to proceed with, deadlock occurs;

the effect of a negative test instruction [formula] is the same as the effect of [formula], but with the role of the value produced reversed;

the effect of a plain basic instruction a is the same as the effect of [formula], but execution always proceeds as if [formula] is produced;

the effect of a forward jump instruction [formula] is that execution proceeds with the l-th next primitive instruction - if l equals 0 or there is no primitive instructions to proceed with, deadlock occurs;

the effect of a backward jump instruction [formula] is that execution proceeds with the l-th previous primitive instruction - if l equals 0 or there is no primitive instructions to proceed with, deadlock occurs;

the effect of the plain termination instruction [formula] is that execution terminates and in doing so does not deliver a value;

the effect of the positive termination instruction [formula] is that execution terminates and in doing so delivers the Boolean value [formula];

the effect of the negative termination instruction [formula] is that execution terminates and in doing so delivers the Boolean value [formula].

From Section [\ref=sect-func-unit], we will use a restricted version of  called  ( with strict Boolean termination). The primitive instructions of  are the primitive instructions of  with the exception of the plain termination instruction. Thus,  instruction sequences are  instruction sequences in which the plain termination instruction does not occur.

In Section [\ref=sect-example], we will give examples of instruction sequences for which the delivery of a Boolean value at termination of their execution is natural. There, we will write [formula], where [formula] are  instruction sequences, for the  instruction sequence [formula].

Thread Extraction

In this section, we make precise in the setting of  (Basic Thread Algebra with Boolean termination) which behaviours are exhibited on execution by  instruction sequences. We start by introducing . In [\cite=BL02a],  (Basic Polarized Process Algebra) is introduced as a setting for modelling the behaviours exhibited by instruction sequences under execution. Later,  has been renamed to  (Basic Thread Algebra).  is  extended with two constants for termination at which a Boolean value is yielded.

In , it is assumed that a fixed but arbitrary non-empty finite set [formula] of basic actions, with [formula], has been given. We write [formula] for [formula]. The members of [formula] are referred to as actions.

A thread is a behaviour which consists of performing actions in a sequential fashion. Upon each basic action performed, a reply from an execution environment determines how it proceeds. The possible replies are the Boolean values [formula] (standing for true) and [formula] (standing for false). Performing the action Τ will always lead to the reply [formula].

has one sort: the sort [formula] of threads. We make this sort explicit because we will extend  with additional sorts in Section [\ref=sect-TSI]. To build terms of sort [formula],  has the following constants and operators:

the deadlock constant [formula];

the plain termination constant [formula];

the positive termination constant [formula];

the negative termination constant [formula];

for each [formula], the binary postconditional composition operator [formula].

We assume that there is a countably infinite set of variables of sort [formula] which includes x,y,z. Terms of sort [formula] are built as usual. We use infix notation for postconditional composition. We introduce action prefixing as an abbreviation: [formula], where p is a term of sort [formula], abbreviates [formula].

The thread denoted by a closed term of the form [formula] will first perform a, and then proceed as the thread denoted by p if the reply from the execution environment is [formula] and proceed as the thread denoted by q if the reply from the execution environment is [formula]. The thread denoted by [formula] will become inactive, the thread denoted by [formula] will terminate without yielding a value, and the threads denoted by [formula] and [formula] will terminate and with that yield the Boolean values [formula] and [formula], respectively.

has only one axiom. This axiom is given in Table [\ref=axioms-BTAbt].

Each closed  term of sort [formula] denotes a thread that will become inactive or terminate after it has performed finitely many actions. Infinite threads can be described by guarded recursion. A guarded recursive specification over  is a set of recursion equations [formula], where V is a set of variables of sort [formula] and each tx is a  term of the form [formula], [formula], [formula], [formula] or [formula] with t and t' that contain only variables from V. We are only interested in models of  in which guarded recursive specifications have unique solutions, such as the appropriate expansion of the projective limit model of  presented in [\cite=BB03a]. Regular threads, i.e. threads that can only be in a finite number of states, are solutions of finite guarded recursive specifications.

To reason about infinite threads, we assume the infinitary conditional equation AIP (Approximation Induction Principle). AIP is based on the view that two threads are identical if their approximations up to any finite depth are identical. The approximation up to depth n of a thread is obtained by cutting it off after it has performed n actions. In AIP, the approximation up to depth n is phrased in terms of the unary projection operator [formula]. AIP and the axioms for the projection operators are given in Table [\ref=axioms-AIP]. In this table, a stands for an arbitrary action from [formula] and n stands for an arbitrary natural number.

We can prove that the projections of solutions of guarded recursive specifications over  are representable by closed  terms of sort [formula].

Let E be a guarded recursive specification over , and let x be a variable occurring in E. Then, for all [formula], there exists a closed  term p of sort [formula] such that [formula].

In the case of , this is proved in [\cite=BM06a] as part of the proof of Theorem 1 from that paper. The proof concerned goes through in the case of .

The behaviours exhibited on execution by  instruction sequences are considered to be regular threads, with the basic instructions taken for basic actions. The thread extraction operation [formula] defines, for each  instruction sequence, the behaviour exhibited on its execution. The thread extraction operation is defined by [formula], where [formula] is defined by the equations given in Table [\ref=axioms-thread-extr] (for [formula] and [formula]) and the rule that [formula] if ui is the beginning of an infinite jump chain. This rule can be formalized, cf. [\cite=BM07g].

Services and Service Families

In this section, we introduce service families and a composition operator for service families. We start by introducing services.

It is assumed that a fixed but arbitrary set [formula] of methods has been given. Methods play the role of commands. A service is able to process certain methods. The processing of a method may involve a change of the service. At completion of the processing of a method, the service produces a reply value. The set [formula] of reply values is the set [formula].

In , the algebraic theory of service families introduced below, the following is assumed with respect to services:

a set [formula] of services has been given together with:

for each [formula], a total function [formula];

for each [formula], a total function [formula];

satisfying the condition that there exists a unique [formula] with [formula] and [formula] for all [formula];

a signature [formula] has been given that includes the following sort:

the sort [formula] of services;

and the following constant and operators:

the empty service constant [formula];

for each [formula], the derived service operator [formula];

[formula] and [formula] are such that:

each service in [formula] can be denoted by a closed term of sort [formula];

the constant [formula] denotes the unique [formula] such that [formula] and [formula] for all [formula];

if closed term t denotes service S, then [formula] denotes service [formula].

When a request is made to service S to process method m:

if [formula], then S processes m, produces the reply [formula], and next proceeds as [formula];

if [formula], then S rejects the request to process method m.

The unique service S such that [formula] and [formula] for all [formula] is called the empty service. It is the service that is unable to process any method.

It is also assumed that a fixed but arbitrary non-empty finite set [formula] of foci has been given. Foci play the role of names of services in the service family offered by an execution environment. A service family is a set of named services where each name occurs only once.

has the sorts, constants and operators in [formula] and in addition the following sort:

the sort [formula] of service families;

and the following constant and operators:

the empty service family constant [formula];

for each [formula], the unary singleton service family operator [formula];

the binary service family composition operator [formula];

for each [formula], the unary encapsulation operator [formula].

We assume that there is a countably infinite set of variables of sort [formula] which includes u,v,w. Terms are built as usual in the many-sorted case (see e.g. [\cite=ST99a] [\cite=Wir90a]). We use prefix notation for the singleton service family operators and infix notation for the service family composition operator.

The service family denoted by [formula] is the empty service family. The service family denoted by a closed term of the form f.H consists of one named service only, the service concerned is the service denoted by H, and the name of this service is f. The service family denoted by a closed term of the form [formula] consists of all named services that belong to either the service family denoted by C or the service family denoted by D. In the case where a named service from the service family denoted by C and a named service from the service family denoted by D have the same name, they collapse to an empty service with the name concerned. The service family denoted by a closed term of the form [formula] consists of all named services with a name not in F that belong to the service family denoted by C.

The service family composition operator takes the place of the non-interfering combination operator from [\cite=BP02a]. As suggested by the name, service family composition is composition of service families. Non-interfering combination is composition of services, which has the disadvantage that its usefulness is rather limited without an additional renaming mechanism.

The axioms of  are given in Table [\ref=axioms-SFA]. In this table, f stands for an arbitrary focus from [formula] and H and H' stand for arbitrary closed terms of sort [formula]. The axioms of  simply formalize the informal explanation given above.

In Section [\ref=sect-example], we will give an example of the use of the service family composition operator. There, we will write [formula], where [formula] are terms of sort [formula], for the term [formula].

Use, Apply and Reply

A thread may interact with the named services from the service family offered by an execution environment. That is, a thread may perform an basic action for the purpose of requesting a named service to process a method and to return a reply value at completion of the processing of the method. In this section, we combine  with  and extend the combination with three operators that relate to this kind of interaction between threads and services, resulting in .

The operators in question are called the use operator, the apply operator, and the reply operator. The difference between the use operator and the apply operator is a matter of perspective: the use operator is concerned with the effects of service families on threads and therefore produces threads, whereas the apply operator is concerned with the effects of threads on service families and therefore produces service families. The reply operator is concerned with the effects of service families on the Boolean values that threads possibly deliver at their termination. The reply operator does not only produce Boolean values: it produces special values in cases where no Boolean value is delivered at termination or no termination takes place. The use operator and the apply operator introduced here are mainly adaptations of the use operators and the apply operators introduced in [\cite=BP02a] to service families. The reply operator has no counterpart in [\cite=BP02a].

For the set [formula] of basic actions, we take the set [formula]. All three operators mentioned above are concerned with the processing of methods by services from a service family in pursuance of basic actions performed by a thread. The service involved in the processing of a method is the service whose name is the focus of the basic action in question.

has the sorts, constants and operators of both  and  and in addition the following sort:

the sort [formula] of replies;

and the following constants and operators:

the reply constants [formula];

the binary use operator [formula];

the binary apply operator [formula];

the binary reply operator [formula].

We use infix notation for the use, apply and reply operators.

The thread denoted by a closed term of the form [formula] and the service family denoted by a closed term of the form [formula] are the thread and service family, respectively, that result from processing the method of each basic action with a focus of the service family denoted by C that the thread denoted by p performs, where the processing is done by the service in that service family with the focus of the basic action as its name. When the method of a basic action performed by a thread is processed by a service, the service changes in accordance with the method concerned, and affects the thread as follows: the basic action turns into the internal action Τ and the two ways to proceed reduces to one on the basis of the reply value produced by the service. The value denoted by a closed term of the form [formula] is the Boolean value that the thread denoted by [formula] delivers at its termination if it terminates and delivers a Boolean value at termination, the value [formula] (standing for meaningless) if it terminates and does not deliver a Boolean value at termination, and the value [formula] (standing for divergent) if it does not terminate.

The axioms of  are the axioms of , the axioms of , and the axioms given in Tables [\ref=axioms-use], [\ref=axioms-apply] and [\ref=axioms-reply]. In these tables, f stands for an arbitrary focus from [formula], m stands for an arbitrary method from [formula], H stands for an arbitrary term of sort [formula], and n stands for an arbitrary natural number. The axioms simply formalize the informal explanation given above and in addition stipulate what is the result of use, apply and reply if inappropriate foci or methods are involved. Axioms A10 and R10 allow for reasoning about infinite threads in the contexts of apply and reply, respectively. The counterpart of A10 and R10 for use, i.e. follows from AIP and U10.

We can prove that each closed  term of sort [formula] can be reduced to a closed  term of sort [formula].

For all closed  terms p of sort [formula], there exists a closed  term q of sort [formula] such that p  =  q is derivable from the axioms of .

In the special case of singleton service families, this is in fact proved in [\cite=BM06a] as part of the proof of Theorem 3 from that paper. The proof of the general case goes essentially the same.

In the case of , the notion of a guarded recursive specification is somewhat adapted. A guarded recursive specification over  is a set of recursion equations [formula], where V is a set of variables of sort [formula] and each tx is a  term of sort [formula] that can be rewritten, using the axioms of , to a term of the form [formula], [formula], [formula], [formula] or [formula] with t and t' that contain only variables from V. We are only interested in models of  in which guarded recursive specifications have unique solutions.

A thread p in a model [formula] of  in which guarded recursive specifications have unique solutions is definable if it is representable by a closed  term or it is the solution in [formula] of a guarded recursive specification over .

Below, we will formulate a proposition about the use, apply and reply operators using the foci operation [formula] defined by the equations in Table [\ref=eqns-foci] (for foci [formula] and terms H of sort [formula]). The operation [formula] gives, for each service family, the set of all foci that serve as names of named services belonging to the service family. We will only make use of the following properties of [formula] in the proof of the proposition:

[formula] iff [formula] or [formula] for all [formula];

[formula] iff [formula].

This means that the proposition could be formulated without using the foci operation, but that would make it less intelligible.

If x is a definable thread and [formula], then:

[formula];

[formula];

[formula].

By the definitions of definable thread and guarded recursive specification over , Lemmas [\ref=lemma-projections-BTAbt] and [\ref=lemma-elimination], and axioms AIP, U10, A10 and R10, it is sufficient to prove that the following equations are derivable for each closed  term p of sort [formula]:

[formula];

[formula];

[formula].

This is easy by induction on the structure of p, using the above-mentioned properties of [formula].

Let p and C be  terms of sort [formula] and [formula], respectively. Then p converges on C, written [formula], is inductively defined by the following clauses:

[formula];

[formula] and [formula];

if [formula], then [formula];

if [formula] and [formula], then [formula];

if [formula] and [formula], then [formula];

if [formula], then [formula];

and p diverges on C, written [formula], is defined by [formula] iff not [formula]. Moreover, p converges on C with Boolean reply, written [formula], is inductively defined by the clauses [formula] for [formula] with everywhere [formula] replaced by [formula].

The following two propositions concern the connection between convergence and the reply operator.

Let p be a closed  term of sort [formula]. Then:

if [formula], [formula] occurs in p and both [formula] and [formula] do not occur in p, then [formula];

if [formula], [formula] occurs in p and both [formula] and [formula] do not occur in p, then [formula];

if [formula], [formula] occurs in p and both [formula] and [formula] do not occur in p, then [formula].

By Lemma [\ref=lemma-elimination], it is sufficient to prove it for all closed  terms p of sort [formula]. This is easy by induction on the structure of p.

If x is a definable thread, then [formula] iff [formula] or [formula] or [formula].

By the definitions of definable thread and guarded recursive specification over , the last clause of the inductive definition of [formula], Lemmas [\ref=lemma-projections-BTAbt] and [\ref=lemma-elimination], and axiom R10, it is sufficient to prove [formula] iff [formula] or [formula] or [formula] for each closed  term p of sort [formula]. This is easy by induction on the structure of p.

Because the use operator, apply operator and reply operator are primarily intended to be used to describe and analyse instruction sequence processing, they are called instruction sequence processing operators.

We introduce the apply operator and reply operator in the setting of  by defining: for all  instruction sequences P. Similarly, we introduce convergence in the setting of  by defining: for all  instruction sequences P.

Relevant Use Conventions

In the setting of service families, sets of foci play the role of interfaces. The set of all foci that serve as names of named services in a service family is regarded as the interface of that service family. Unavoidably there are cases in which processing does not halt or, even worse (because it is statically detectable), interfaces do not match. This means that there are cases in which there is nothing that we intend to denote by a term of the form [formula], [formula] or [formula].

We propose to comply with the following relevant use conventions:

[formula] is only used if it is known that [formula];

[formula] is only used if it is known that [formula];

[formula] is only used if it is known that [formula].

The condition found in the first convention is justified by the fact that in the projective limit model of , for definable threads x, [formula] if [formula]. We do not have [formula] only if [formula]. For instance, [formula] whereas [formula]. Similar remarks apply to the condition found in the second convention.

The idea of relevant use conventions is taken from [\cite=BM09j], where it plays a central role in an account of the way in which mathematicians usually deal with division by zero in mathematical texts. According to [\cite=BM09j], mathematicians deal with this issue by complying with the convention that [formula] is only used if it is known that q  ≠  0. This approach is justified by the fact that there is nothing that mathematicians intend to denote by [formula] if q  =  0. It yields simpler mathematical texts than the popular approach in theoretical computer science, which is characterized by complete formality in definitions, statements and proofs. In this computer science approach, division is considered a partial function and some logic of partial functions is used. In [\cite=BT07a], deviating from this, division is considered a total function whose value is zero in all cases of division by zero. It may be imagined that this notion of division is the one with which mathematicians make themselves familiar before they start to read and write mathematical texts professionally.

We think that the idea to comply with conventions that exclude the use of terms that are not really intended to denote anything is not only of importance in mathematics, but also in theoretical computer science. For example, the consequence of adapting Proposition [\ref=prop-ispo] to comply with the relevant use conventions described above, by adding appropriate conditions to the three properties, is that we do not have to consider in the proof of the proposition the equality of terms by which we do not intend to denote anything.

In the sequel, we will comply with the relevant use conventions described above.

We can define the use operators introduced earlier in [\cite=BM07g] [\cite=BM06c], The use operators introduced in [\cite=BP02a] are counterparts of the abstracting use operator introduced later in Section [\ref=sect-abstr-use]. the apply operators introduced earlier in [\cite=BP02a], and similar counterparts of the reply operator as follows: These definitions give rise to the derived conventions that [formula] is only used if it is known that [formula] and [formula] is only used if it is known that [formula].

Example

In this section, we use an implementation of a bounded counter by means of a number of Boolean registers as an example to show that there are cases in which the delivery of a Boolean value at termination of the execution of an instruction sequence is quite natural. We also show in this example that it is easy to compose a number of Boolean register services by means of the service family composition operation. Accomplishing this with the non-interfering service combination operation from [\cite=BP02a] is quite involved.

First, we describe services that make up Boolean registers. The Boolean register services are able to process the following methods:

the set to true method [formula];

the set to false method [formula];

the get method [formula].

It is assumed that [formula].

The methods that Boolean register services are able to process can be explained as follows:

[formula] : the contents of the Boolean register becomes [formula] and the reply is [formula];

[formula] : the contents of the Boolean register becomes [formula] and the reply is [formula];

[formula] : nothing changes and the reply is the contents of the Boolean register.

For the set [formula] of services, we take the set [formula] of Boolean register services. For each [formula], we take the functions [formula] and [formula] such that ([formula]): Moreover, we take the names used above to denote the services in [formula] for constants of sort [formula].

We continue with the implementation of a bounded counter by means of a number of Boolean registers. We consider a counter that can contain a natural number in the interval

[formula]

Abstracting Use

With the use operator introduced in Section [\ref=sect-TSI], the action Τ is left as a trace of a basic action that has led to the processing of a method, like with the use operators on services introduced in e.g. [\cite=BM07g] [\cite=BM06c]. However, with the use operators on services introduced in [\cite=BP02a], nothing is left as a trace of a basic action that has led to the processing of a method. Thus, these use operators abstract fully from internal activity. In other words, they are abstracting use operators. For completeness, we introduce an abstracting variant of the use operator introduced in Section [\ref=sect-TSI].

That is, we introduce the following additional operator:

the binary abstracting use operator [formula].

We use infix notation for the abstracting use operator.

The axioms for the abstracting use operator are given in Table [\ref=axioms-ause]. Owing to the possible concealment of actions by abstracting use, [formula] is not a plausible axiom. However, axiom AU10 allows for reasoning about infinite threads in the context of abstracting use.

Functional Units

In this section, we introduce the concept of a functional unit and related concepts.

It is assumed that a non-empty set [formula] of states has been given. As before, it is assumed that a non-empty finite set [formula] of methods has been given. However, in the setting of functional units, methods serve as names of operations on a state space. For that reason, the members of [formula] will henceforth be called method names.

A method operation on [formula] is a total function from [formula] to [formula]. A partial method operation on [formula] is a partial function from [formula] to [formula]. We write [formula] for the set of all method operations on [formula]. We write Mr and Me, where [formula], for the unique functions [formula] and [formula], respectively, such that [formula] for all [formula].

A functional unit for [formula] is a finite subset [formula] of [formula] such that [formula] and [formula] implies M  =  M'. We write [formula] for the set of all functional units for [formula]. We write [formula], where [formula], for the set [formula]. We write [formula], where [formula] and [formula], for the unique [formula] such that [formula].

We look upon the set [formula], where [formula], as the interface of [formula]. It looks to be convenient to have a notation for the restriction of a functional unit to a subset of its interface. We write [formula], where [formula] and [formula], for the functional unit [formula].

Let [formula]. Then an extension of [formula] is an [formula] such that [formula].

The following is a simple illustration of the use of functional units. An unbounded counter can be modelled by a functional unit for [formula] with method operations for set to zero, increment by one, decrement by one, and test on zero.

According to the definition of a functional unit, [formula]. By that we have a unique functional unit with an empty interface, which is not very interesting in itself. However, when considering services that behave according to functional units, [formula] is exactly the functional unit according to which the empty service [formula] (the service that is not able to process any method) behaves.

The method names attached to method operations in functional units should not be confused with the names used to denote specific method operations in describing functional units. Therefore, we will comply with the convention to use names beginning with a lower-case letter in the former case and names beginning with an upper-case letter in the latter case.

We will use  instruction sequences to derive partial method operations from the method operations of a functional unit. We write [formula], where [formula], for the set of all  instruction sequences, taking the set [formula] as the set [formula] of basic instructions.

The derivation of partial method operations from the method operations of a functional unit involves services whose processing of methods amounts to replies and service changes according to corresponding method operations of the functional unit concerned. These services can be viewed as the behaviours of a machine, on which the processing in question takes place, in its different states. We take the set [formula] as the set [formula] of services. We write [formula], where [formula] and [formula], for the service [formula]. The functions [formula] and [formula] are defined as follows: where s' is a fixed but arbitrary state in S. We assume that each [formula] can be denoted by a closed term of sort [formula]. In this connection, we use the following notational convention: for each [formula], we write [formula] for an arbitrary closed term of sort [formula] that denotes [formula]. The ambiguity thus introduced could be obviated by decorating [formula] wherever it stands for a closed term. However, in this paper, it is always immediately clear from the context whether it stands for a closed term. Moreover, we believe that the decorations are more often than not distracting. Therefore, we leave it to the reader to make the decorations mentally wherever appropriate.

Let [formula], and let [formula]. Then an instruction sequence [formula] produces a partial method operation [formula] as follows: where If [formula] is total, then it is called a derived method operation of [formula].

The binary relation [formula] on [formula] is defined by [formula] iff for all [formula], M is a derived method operation of [formula]. The binary relation [formula] on [formula] is defined by [formula] iff [formula] and [formula].

[formula] is transitive;

[formula] is an equivalence relation.

Property 1: We have to prove that [formula] and [formula] implies [formula]. It is sufficient to show that we can obtain instruction sequences in [formula] that produce the method operations of [formula] from the instruction sequences in [formula] that produce the method operations of [formula] and the instruction sequences in [formula] that produce the method operations of [formula]. Without loss of generality, we may assume that all instruction sequences are of the form [formula], where, for each i∈[1,k], ui is a positive test instruction, a forward jump instruction or a backward jump instruction. Let [formula], let M be such that [formula], and let [formula] be such that [formula]. Suppose that [formula]. For each i∈[1,n], let M'i be such that [formula] and let [formula] be such that [formula]. Consider the [formula] obtained from xm as follows: for each i∈[1,n], (i) first increase each jump over the leftmost occurrence of [formula] in xm with ki  +  1, and next replace this instruction by [formula]; (ii) repeat the previous step as long as their are occurrences of [formula]. It is easy to see that [formula].

Property 2: It follows immediately from the definition of [formula] that [formula] is symmetric and from the definition of [formula] that [formula] is reflexive. From these properties, Property 1 and the definition of [formula], it follows immediately that [formula] is symmetric, reflexive and transitive.

The members of the quotient set [formula] are called functional unit degrees. Let [formula] and [formula]. Then [formula] is a functional unit degree below [formula] if there exists an [formula] such that [formula].

Functional Units for Natural Numbers

In this section, we investigate functional units for natural numbers. The main consequences of considering the special case where the state space is [formula] are the following: (i) [formula] is infinite, (ii) there is a notion of computability known which can be used without further preparations.

An example of a functional unit in [formula] is an unbounded counter. The method names involved are [formula], [formula], [formula], and [formula]. The method operations involved are the functions [formula], [formula], [formula], [formula] defined as follows: The functional unit [formula] is defined as follows:

There are infinitely many functional unit degrees below [formula].

For each [formula], we define a functional unit [formula] such that [formula] as follows: where Let [formula] be such that n  <  m. Then [formula]. However, there does not exist an [formula] such that [formula] because [formula]. Hence, [formula] for all [formula] with n  <  m.

A method operation [formula] is computable if there exist computable functions [formula] such that [formula] for all [formula], where [formula] is inductively defined by [formula] and [formula]. A functional unit [formula] is computable if, for each [formula], M is computable.

Let [formula] be such that [formula]. Then [formula] is computable if [formula] is computable.

We will show that all derived method operations of [formula] are computable.

Take an arbitrary [formula] such that [formula] is a derived method operations of [formula]. It follows immediately from the definition of thread extraction that [formula] is the solution of a finite linear recursive specification over , i.e. a finite guarded recursive specification over  in which the right-hand side of each equation is a  term of the form [formula], [formula], [formula] or [formula] where x and y are variables of sort [formula]. Let E be a finite linear recursive specification over  of which the solution for x1 is [formula]. Because [formula] is total, it may be assumed without loss of generality that [formula] does not occur as the right-hand side of an equation in E. Suppose that From this set of equations, using the relevant axioms and definitions, we obtain a set of equations of which the solution for F1 is [formula]: where, for every i∈[1,n], the function [formula] is such that for all [formula]: and the functions [formula] are defined as usual: It follows from the way in which this set of equations is obtained from E, the fact that [formula] and χi are computable for each i∈[1,n], and the fact that [formula] and [formula] are computable, that this set of equations is equivalent to a set of equations by which [formula] is defined recursively in the sense of Kleene (see [\cite=Kle36a]). This means that [formula] is general recursive, and hence computable.

In a similar way, it is proved that [formula] is computable.

A computable [formula] is universal if for each computable [formula], we have [formula]. There exists a universal computable functional unit for natural numbers.

There exists a computable [formula] that is universal.

We will show that there exists a computable [formula] with the property that each computable [formula] is a derived method operation of [formula].

As a corollary of Theorem 10.3 from [\cite=SS63a], we have that each computable [formula] can be computed by means of a register machine with six registers, say [formula], [formula], [formula], [formula], [formula], and [formula]. The registers are used as follows: [formula] as input register; [formula] as output register for the output in [formula]; [formula] as output register for the output in [formula]; [formula], [formula] and [formula] as auxiliary registers. The content of [formula] represents the Boolean output as follows: 0 represents [formula] and all other natural numbers represent [formula]. For each i∈[0,5], register [formula] can be incremented by one, decremented by one, and tested for zero by means of instructions [formula], [formula] and [formula], respectively. We write [formula] for the set of all  instruction sequences, taking the set [formula] as the set [formula] of basic instructions. Clearly, [formula] is adequate to represent all register machine programs using six registers.

We define a computable functional unit [formula] whose method operations can simulate the effects of the register machine instructions by encoding the register machine states by natural numbers such that the contents of the registers can reconstructed by prime factorization. This functional unit is defined as follows: where the method operations are defined as follows: and, for each i∈[0,5]: As usual, we write [formula] for y is divisible by x. where [formula] is the (i  +  1)th prime number, i.e. [formula], [formula], [formula],  .

We define a function [formula] from [formula] to [formula], which gives, for each instruction sequence P in [formula], the instruction sequence in [formula] by which the effect produced by P on a register machine with six registers can be simulated on [formula]. This function is defined as follows: where where, for each i∈[0,5]:

Take an arbitrary computable [formula]. Then there exist an instruction sequence in [formula] that computes M. Take an arbitrary [formula] that computes M. Then [formula]. Hence, M is a derived method operation of [formula].

The universal computable functional unit [formula] defined in the proof of Theorem [\ref=theorem-universal-fu] has 20 method operations. However, three method operations suffice.

There exists a computable [formula] with only three method operations that is universal.

We know from the proof of Theorem [\ref=theorem-universal-fu] that there exists a computable [formula] with 20 method operations, say M0, , M19. We will show that there exists a computable [formula] with only three method operations such that [formula].

We define a computable functional unit [formula] with only three method operations such that [formula] as follows: where the method operations are defined as follows: where

We have that, for each i∈[0,19], [formula]. For each primitive instruction u, the instruction sequence un is defined by induction on n as follows: [formula], u1  =  u and [formula]. Hence, M0, , M19 are derived method operations of [formula].

The universal computable functional unit [formula] defined in the proof of Theorem [\ref=theorem-universal-fu-three-meths] has three method operations. We can show that one method operation does not suffice.

There does not exist a computable [formula] with only one method operation that is universal.

We will show that there does not exist a computable [formula] with one method operation such that [formula]. Here, [formula] is the functional unit introduced at the beginning of this section.

Assume that there exists a computable [formula] with one method operation such that [formula]. Let [formula] be such that [formula] has one method operation and [formula], and let m be the unique method name such that [formula]. Take arbitrary [formula] such that [formula] and [formula]. Then [formula] and [formula]. Instruction f.m is processed at least once if P1 is applied to [formula] or P2 is applied to [formula]. Let k0 be the number of times that instruction f.m is processed on application of P1 to [formula] and let k1 be the number of times that instruction f.m is processed on application of P2 to [formula] (irrespective of replies). Then, from state 0, state 0 is reached again after f.m is processed k0  +  k1 times. Thus, by repeated application of P1 to [formula] at most k0  +  k1 different states can be reached. This contradicts with [formula]. Hence, there does not exist a computable [formula] with one method operation such that [formula].

It is an open problem whether two method operations suffice.

Functional Units for Finite State Spaces

In this short section, we make some remarks about functional units for finite state spaces.

In the special case where the state space is [formula], the state space consists of only two states. Because there are four possible unary functions on [formula], there are precisely 16 method operations in [formula]. There are in principle 216 different functional units in [formula], for it is useless to include the same method operation more than once under different names in a functional unit. This means that 216 is an upper bound of the number of functional unit degrees in [formula]. However, it is straightforward to show that [formula] has only 12 different functional unit degrees.

In the more general case of a finite state space consisting of k states, say Sk, there are in principle [formula] different functional units in [formula]. Already with k  =  3, it becomes unclear whether the number of functional unit degrees in [formula] can be determined manually. Actually, we do not know at the moment whether it can be determined with computer support either.

Functional Units Relating to Turing Machine Tapes

In this section, we define some notions that have a bearing on the halting problem in the setting of  and functional units. The notions in question are defined in terms of functional units for the following state space:

The states from [formula] resemble the possible contents of the tape of a Turing machine whose tape alphabet is [formula]. Consider a state [formula]. Then v corresponds to the content of the tape to the left of the position of the tape head and w corresponds to the content of the tape from the position of the tape head to the right - the indefinite numbers of padding blanks at both ends are left out. The colon serves as a seperator of bit sequences. This is for instance useful if the input of a program consists of another program and an input to the latter program, both encoded as a bit sequences.

A method operation [formula] is computable if there exist computable functions [formula] such that [formula] for all [formula], where [formula] is a bijection and [formula] is inductively defined by [formula] and [formula]. A functional unit [formula] is computable if, for each [formula], M is computable.

It is assumed that, for each [formula], an injective function from [formula] to [formula] has been given that yields for each [formula], an encoding of x as a bit sequence. We use the notation [formula] to denote the encoding of x as a bit sequence.

Let [formula], and let [formula]. Then:

[formula] produces a solution of the halting problem for [formula] with respect to [formula] if:

[formula] produces a reflexive solution of the halting problem for [formula] with respect to [formula] if x produces a solution of the halting problem for [formula] with respect to [formula] and [formula];

the halting problem for [formula] with respect to [formula] is autosolvable if there exists an [formula] such that x produces a reflexive solution of the halting problem for [formula] with respect to [formula];

the halting problem for [formula] with respect to [formula] is potentially autosolvable if there exist an extension [formula] of [formula] and the halting problem for [formula] with respect to [formula] is autosolvable;

the halting problem for [formula] with respect to [formula] is potentially recursively autosolvable if there exist an extension [formula] of [formula] and the halting problem for [formula] with respect to [formula] is autosolvable and [formula] is computable.

These definitions make clear that each combination of an [formula] and an [formula] gives rise to a halting problem instance.

In Section [\ref=sect-interpreters] and [\ref=sect-autosolvability], we will make use of a method operation [formula] for duplicating bit sequences. This method operation is defined as follows:

Let [formula] be such that [formula], let [formula] be such that [formula], let [formula], and let [formula] and [formula] be such that w  =  v or [formula] for some [formula]. Then [formula].

This follows immediately from the definition of [formula] and the axioms for [formula].

In Sections [\ref=sect-interpreters] and [\ref=sect-autosolvability], we will make use of two simple transformations of  instruction sequences that affect only their termination behaviour on execution and the Boolean value yielded at termination in the case of termination. Here, we introduce notations for those transformations.

Let x be a  instruction sequence. Then we write [formula] for x with each occurrence of [formula] replaced by [formula] and each occurrence of [formula] replaced by [formula], and we write [formula] for x with each occurrence of [formula] replaced by [formula]. In the following proposition, the most important properties relating to these transformations are stated.

Let x be a  instruction sequence. Then:

if [formula] then [formula] and [formula];

if [formula] then [formula] and [formula].

Let p be a closed  term of sort [formula]. Then we write [formula] for p with each occurrence of [formula] replaced by [formula] and each occurrence of [formula] replaced by [formula], and we write [formula] for p with each occurrence of [formula] replaced by [formula]. It is easy to prove by induction on i that [formula] and [formula] for all [formula]. By this result, Lemma [\ref=lemma-projections-BTAbt], and axiom R10, it is sufficient to prove the following for each closed  term p of sort [formula]:

if [formula] then [formula] and [formula];

if [formula] then [formula] and [formula].

This is easy by induction on the structure of p.

By the use of foci and the introduction of apply and reply operators on service families, we make it possible to deal with cases that remind of multi-tape Turing machines, Turing machines that has random access memory, etc. However, in this paper, we will only consider the case that reminds of single-tape Turing machines. This means that we will use only one focus (f) and only singleton service families.

Interpreters

It is often mentioned that an interpreter, which is a program for simulating the execution of programs that it is given as input, cannot solve the halting problem because the execution of the interpreter will not terminate if the execution of its input program does not terminate. In this section, we have a look upon the termination behaviour of interpreters in the setting of  and functional units.

Let [formula], let [formula], and let I'  ⊆  I. Then [formula] is an interpreter for [formula] with respect to [formula] if for all [formula] and [formula]: Moreover, [formula] is a reflexive interpreter for [formula] with respect to [formula] if x is an interpreter for [formula] with respect to [formula] and [formula].

The following theorem states that a reflexive interpreter that always terminates is impossible in the presence of the method operation [formula].

Let [formula] be such that [formula], let [formula] be such that [formula], and let [formula] be a reflexive interpreter for [formula] with respect to [formula]. Then there exist an [formula] and a [formula] such that [formula].

Assume the contrary. Take [formula]. By the assumption, [formula]. By Propositions [\ref=prop-cvg-sfreply] and [\ref=prop-swap-f2d], it follows that [formula] and [formula]. By Propositions [\ref=prop-cvg-sfreply] and [\ref=prop-dup], it follows that [formula] and [formula]. Since [formula], we have [formula] and [formula]. Because x is a reflexive interpreter, this implies [formula] and [formula]. This is a contradiction.

In the proof of Theorem [\ref=theorem-interpreter], the presence of the method operation [formula] is essential. It is easy to see that the theorem goes through for all functional units for [formula] of which [formula] is a derived method operation. An example of such a functional unit is the one whose method operations correspond to the basic steps that can be performed on the tape of a Turing machine.

For each [formula], [formula], and [formula], we have [formula]. This leads us to the following corollary of Theorem [\ref=theorem-interpreter].

For all [formula] with [formula] and [formula] with [formula], there does not exist an m∈I such that [formula] is a reflexive interpreter for [formula] with respect to [formula].

Autosolvability of the Halting Problem

Because a reflexive interpreter that always terminates is impossible in the presence of the method operation [formula], we must conclude that solving the halting problem by means of a reflexive interpreter is out of the question in the presence of the method operation [formula]. The question arises whether the proviso "by means of a reflexive interpreter" can be dropped. In this section, we answer this question in the affirmative. Before we present this negative result concerning autosolvability of the halting problem, we present a positive result.

Let [formula]. Then we say that M increases the number of colons if for some [formula] the number of colons in Me(v) is greater than the number of colons in v.

Let [formula] be such that no method operation of [formula] increases the number of colons. Then there exist an extension [formula] of [formula], an [formula], and an [formula] such that x produces a reflexive solution of the halting problem for [formula] with respect to [formula].

Let [formula] be such that [formula]. Take [formula]. Take [formula], where [formula] is defined by induction on the number of colons in the argument of [formula] as follows: Then [formula] produces a reflexive solution of the halting problem for [formula] with respect to [formula].

Theorem [\ref=theorem-autosolv] tells us that there exist functional units [formula] with the property that the halting problem is potentially autosolvable for [formula] with respect to [formula]. Thus, we know that there exist functional units [formula] with the property that the halting problem is autosolvable for [formula] with respect to [formula].

There exists an [formula] for which [formula] as defined in the proof of Theorem [\ref=theorem-autosolv] is computable.

Let [formula] and [formula], where [formula] is as defined in the proof of Theorem [\ref=theorem-autosolv]. Then, [formula] is computable.

It is sufficient to prove for an arbitrary [formula] that, for all [formula], [formula] is decidable. We will prove this by induction on the number of colons in v.

The basis step. Because the number of colons in v equals 0, [formula]. It follows that [formula], where x' is x with each occurrence of [formula] and [formula] replaced by [formula] and each occurrence of [formula] replaced by [formula]. Because x' is finite, [formula] is decidable. Hence, [formula] is decidable.

The inductive step. Because the number of colons in v is greater than 0, either [formula] or [formula]. It follows that [formula], where x' is x with:

each occurrence of [formula] and [formula] replaced by [formula] if the occurrence leads to the first application of [formula] and [formula], and by [formula] otherwise;

each occurrence of [formula] replaced by [formula] if the occurrence leads to the first application of [formula] and [formula], and by [formula] otherwise.

An occurrence of [formula], [formula] or [formula] in x leads to the first application of [formula] iff [formula], where i is its position in x. Because x is finite, it is decidable whether an occurrence of [formula], [formula] or [formula] leads to the first processing of [formula]. Moreover, by the induction hypothesis, it is decidable whether [formula]. Because x' is finite, it follows that [formula] is decidable. Hence, [formula] is decidable.

Theorems [\ref=theorem-autosolv] and [\ref=theorem-comput] together tell us that there exists a functional unit [formula], viz. [formula], with the property that the halting problem is potentially recursively autosolvable for [formula] with respect to [formula].

Let [formula] be such that all derived method operations of [formula] are computable and do not increase the number of colons. Then the halting problem is potentially autosolvable for [formula] with respect to [formula]. However, the halting problem is not always potentially recursively autosolvable for [formula] with respect to [formula] because otherwise the halting problem would always be decidable.

The following theorem tells us essentially that potential autosolvability of the halting problem is precluded in the presence of the method operation [formula].

Let [formula] be such that [formula], and let [formula] be such that [formula]. Then there does not exist an [formula] such that x produces a reflexive solution of the halting problem for [formula] with respect to [formula].

Assume the contrary. Let [formula] be such that x produces a reflexive solution of the halting problem for [formula] with respect to [formula], and let [formula]. Then [formula]. By Propositions [\ref=prop-cvg-sfreply] and [\ref=prop-swap-f2d], it follows that [formula] and either [formula] or [formula].

In the case where [formula], we have by Proposition [\ref=prop-swap-f2d] that (i) [formula] and (ii) [formula]. By Proposition [\ref=prop-dup], it follows from (i) that [formula]. Since [formula], we have [formula]. On the other hand, because x produces a reflexive solution, it follows from (ii) that [formula]. By Proposition [\ref=prop-cvg-sfreply], this contradicts with [formula].

In the case where [formula], we have by Proposition [\ref=prop-swap-f2d] that (i) [formula] and (ii) [formula]. By Proposition [\ref=prop-dup], it follows from (i) that [formula]. Since [formula], we have [formula]. On the other hand, because x produces a reflexive solution, it follows from (ii) that [formula]. By Proposition [\ref=prop-cvg-sfreply], this contradicts with [formula].

Below, we will give an alternative proof of Theorem [\ref=theorem-non-autosolv]. A case distinction is needed in both proofs, but in the alternative proof it concerns a minor issue. The issue in question is covered by the following lemma.

Let [formula], let [formula], let [formula] be such that x produces a reflexive solution of the halting problem for [formula] with respect to [formula], let [formula], and let [formula]. Then [formula] implies [formula].

By Proposition [\ref=prop-cvg-sfreply], it follows from [formula] that either [formula] or [formula].

In the case where [formula], we have by Propositions [\ref=prop-cvg-sfreply] and [\ref=prop-swap-f2d] that [formula] and so [formula].

In the case where [formula], we have by Propositions [\ref=prop-cvg-sfreply] and [\ref=prop-swap-f2d] that [formula] and so [formula].

Let [formula]. By Theorem [\ref=theorem-non-autosolv], the halting problem for [formula] with respect to [formula] is not (potentially) autosolvable. However, it is decidable.

Let [formula]. Then the halting problem for [formula] with respect to [formula] is decidable.

Let [formula], and let x' be x with each occurrence of [formula] and [formula] replaced by [formula] and each occurrence of [formula] replaced by [formula]. For all [formula], [formula]. Therefore, [formula] for all [formula]. Because x' is finite, [formula] is decidable.

Both proofs of Theorem [\ref=theorem-non-autosolv] given above are diagonalization proofs in disguise. Theorem [\ref=theorem-decidable] indicates that diagonalization and decidability are independent so to speak.

Concluding Remarks

We have taken the view that the execution of an instruction sequence involves the processing of instructions by an execution environment that offers a service family and may yield a Boolean value at termination. We have proposed the service family composition operator, the use operator, the apply operator and the reply operator. The latter three operators are directly related to the processing in question. Notice that the apply operator fits in with the viewpoint that programs are state transformers that can be modelled by partial functions. This viewpoint was first taken in the early days of denotational semantics, see e.g. [\cite=Mos74a] [\cite=Sto77b] [\cite=Ten77a]. Pursuant to [\cite=BM09j], we have also proposed to comply with conventions that exclude the use of terms that can be build by means of the proposed operators, but are not really intended to denote anything. The idea to comply with such conventions looks to be wider applicable in theoretical computer science.

A state space is not inherent in the abstract behavioural concept of a service. We have introduced the related but more concrete concept of a functional unit, in which a state space is inherent. Using the instruction sequence processing operators proposed in this paper, we have investigated functional units whose state space is the set of natural numbers and functional units whose state space consists of objects that represent the possible contents of the tapes of Turing machines with a particular tape alphabet. We have established the existence of a universal computable functional unit for natural numbers and results concerning the autosolvability requirement inherent in Turing's result regarding the undecidability of the halting problem.

The latter results extend and strengthen the results regarding the halting problem for programs given in [\cite=BP04a] in a setting which looks to be more adequate to describe and analyse issues regarding the halting problem for programs. It happens that decidability depends on the halting problem instance considered. This is different in the case of the on-line halting problem for programs, i.e. the problem to forecast during its execution whether a program will eventually terminate (see [\cite=BP04a]). An interesting option for future work is to investigate the bounded halting problem for programs, i.e. the problem to determine, given a program and an input to the program, whether execution of the program on that input will terminate after the execution of no more than a fixed number of basic instructions.