The informational nature of quantum mechanics: A novel look at the interference experiment

Introduction

In his classic EPR argument [\cite=Einstein], Einstein concluded that the quantum state of a system can not be an objective physical property of the system. Indeed, it has also an anthropomorphic nature because it is a property of the 'experimental setup', i.e., the situation that we create by the experiments we choose to perform on the system. A given physical system (e.g. an electron) corresponds to many different setups depending on which parameters we choose to observe and/or control. In this respect, the quantum state is like the entropy in thermodynamics which is not a real property of the physical system but rather a property of the 'thermodynamic system'; a given physical system corresponds to many different thermodynamic systems depending on which macrovariables one chooses to observe and/or control [\cite=Jaynes]. The analogy is interesting because a quantum state, like entropy, contains information which, therefore, pertains not to the physical system but to the particular experiments we choose to perform on it. Nevertheless, quantum mechanics denys the possibility for any observer to influence the outcome of a measurement once the experimental setup is prepared and particular qualities of an individual observer do not enter the description. The setup forms the objective context and quantum mechanics predicts what unrolls from that in an observer independent manner. The distribution of the outcome is, thus, a characteristic property of the setup so the latter must be taken into account as conditioning the outcome of the experiment.

Starting from this premises, the nature of the probabilities that enter the theory can be explained in terms of the above conditioning. In its most general form, probability can be viewed as expressing the logical relation between a proposition and its conditioning information (see [\cite=Jaynes2] [\cite=Ballentine] and the references therein); it quantifies what is logically inferable from that information with regard to the particular proposition. The translation of a given information into a definite probability assignment is, thus, an act of inference based on the optimal processing of the available information in a manner that does not arbitrarily ignore any part of it while ensuring that no other arbitrary assumptions have been introduced. In the present context, the conditioning information is the information content of the setup itself; it consists of the preparation information together with whatever physical laws and thought arguments that are relevant to the situation under consideration. The propositions, on the other hand, are the various final results at each repetition of the experiment. The logical relation between the two reduces to a deduction when the information implies the proposition or its denial (in the limit of probability values 1 and 0, respectively); classical mechanics being the ultimate example of such situations. Quantum mechanically, however, the information content of a setup is, in general, inherently insufficient to yield a deduction. Objectively speaking, the degree of control in reproducing a specific result is inherently limited by the setup itself. It is precisely this incomplete information (degree of control) that makes quantum mechanical predictions (experimental results) essentially statistical (irreproducible); the unavailable information (degree of control) is of no consequence to our predictions (the actual results) other than making them statistical (irreproducible). Indeed, by making statistical predictions it is automatically implied that the missing information/degree of control, although relevant to the result of a single repetition, is irrelevant to the outcome as a distribution. Instead, it is the available incomplete information that is represented by a probability distribution and from that it is just not possible to deduce the physical mechanisms that produce a single result. Phrased objectively, a frequency distribution merely represents the limited control of the setup in reproducing a specific result and not the physical mechanisms that give rise to such a result. In other words, it is the information content/degree of control of the situation that is reflected in the actual distribution of the outcome, in the same way that physical causations are reflected in the results of reproducible trials. In short, probability distributions basically describe information and do not correspond to physical causal influences. This is in line with Bell inequality arguments to the effect that quantum mechanical probabilities can not arise out of a causal (local) theory. Adopting such a stand has profound effects on the way we interpret the predictions of quantum mechanics and the actual outcomes of irreproducible trials in general.

What we are essentially implying is that quantum mechanical predictions should be viewed as logical inferences made on the basis of the information content of a given experimental situation. Phrased objectively, they are the only outcomes compatible with the degree of control exerted by the setup itself in reproducing a specific result. In dealing with such situations, the proper question to ask is: what can be logically infered from the prior information about a setup with regard to obtaining the various final results? The (subjective) probability distribution thus assigned is expected to be observed experimentally as the frequency distribution of the outcome, if and only if the information and its logical treatment have been proper. By implementing such a viewpoint in an appropriate framework, it is possible to maintain a sharp distinction between the physical and statistical aspects of quantum mechanics. The former constitutes the information content of a setup while the latter enters the representation of this information by a probability distribution for the outcome through logical inference. This, we suggest, is how quantum mechanics should be viewed and ultimately formulated, i.e., as the theory of optimal processing of (prior) information about given experimental situations. Indeed, the very fact that the physical and statistical aspects of the theory are scrambled up in its present formulation, together with a 'physical' instead of an 'informational' look at the probability itself, has been the source of many paradoxes as well as the need for interpretation. In the following example, we bring the idea into sharp focus by applying it to the double-beam interference experiment (Mach-Zehnder setup) which arguably lies at the heart of quantum mechanics. Our results will coincide with those obtained via the standard formulation of quantum mechanics in a manner that does not bear the mechanism of wave-particle duality at all.

The double-beam interference experiment

In each repetition of the experiment, a single particle is incident on a beam splitter which sends the particle along one of the two arms of length r1 and r2. The particle is then collected by means of two detectors, one facing each arm. Let us refer to this as setup 1. We also consider a different arrangement (setup 2), in which the two secondary beams are mixed via a second beam splitter in the standard manner.

In each repetition of the experiment we find that only one detector clicks which means that we are detecting a single particle. This is true for both setups. However, the distribution of these clicks is a characteristic property of the setup (and not the particle) which describes its information content. Let {Pi} denote the probability distribution of the outcome, where i = 1,2 lables the final result (detector click) at each repetition of the experiment. We are interested in infering {Pi} for each setup on the basis of the information that went into its preparation together with whatever physical arguments that are relevant to the situation. Let us, therefore, consider each setup separately.

Setup 1: This setup is prepared in such a manner that one can associate with every click a path (and hence a path length). This constitutes the prior information about this setup. The length of the arms could have been left unspecified as far as this setup is concerned, because if we change them arbitrarily, the prior information will not be affected in any way. Consistency, then, requires that the subjective probability assigned to this information be independent of the length of the arms. Because of the symmetry of the situation, one infers that [formula] for all r1,r2. This is the distribution that one expects to observe experimentally. It characterizes this setup in that it describes its information content in a unique manner.

Setup 2: Here the preparation is such that, because of the mixing produced by the second beam splitter, one cannot associate with every click a path nor a path length; unless, of course, r1 = r2, where a path length (but not a path) can be associated. This last point, although seemingly trivial, is a part of the prior information about the setup which must not be disregarded unconsciously. It immediately implies that the prior information cannot be indifferent to the path difference x = r1 - r2 because it changes when x = 0. Consistency, then, requires that the subjective probability describing this information must depend on x. We, therefore, write P1 = f(x),P2 = 1 - f(x) where f(x) is an arbitrary (non-constant) function with range

[formula]