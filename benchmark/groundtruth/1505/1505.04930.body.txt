Exploring the Unknown: the Work of Louis Nirenberg on Partial Differential Equations.

Preamble

Partial differential equations are central objects in the mathematical modeling of natural and social sciences (sound propagation, heat diffusion, thermodynamics, electromagnetism, elasticity, fluid dynamics, quantum mechanics, population growth, finance...etc). They were for a long time restricted only to the study of natural phenomena or questions pertaining to geometry, before becoming over the course of time, and especially in the last century, a field in itself.

The second half of the XXth century was the "golden age" of the exploration of partial differential equations from a theoretical perspective.

The mathematical work of Louis Nirenberg since the early 1950s has to a large extent contributed to the growth of this fundamental area of human knowledge. The name Nirenberg is associated with many of the milestones in the study of PDEs.

The award of the Abel Prize to Louis Nirenberg marks a special occasion for us to revisit the development of the field of PDEs and the work of one of the main actors of its exploration.

Introduction

Louis Nirenberg uses to qualify the field of Partial Differential Equations as being "messy" (and also often acknowledges his special taste for what he called this "messiness" ) which is probably a reference to the "intrinsic diversity" of the field. We would like to illustrate the pertinence of this quote by contradiction and by presenting the original attempts made mostly in the XIXth century to see PDE as a whole and the limits and inadequacies this approach has been confronted to.

A general existence result: the Cauchy-Kowalevski theorem

Perhaps the first general systematic study of partial differential equations goes back to the work of Augustin-Louis Cauchy and his existence theorem for quasilinear first order PDEs with real analytic data. In 1874, Sofia Kowalevski (or Kowalevskaya), apparently unaware of Cauchy's work, proved in her thesis a general nonlinear version of the previous result. We present the theorem called nowadays Cauchy-Kowalevski theorem in the particular case of second order non-linear scalar equations

[formula]

Here F(x,q,p,r) is a real analytic function of all the entries [formula], [formula] and [formula]. To that purpose, we introduce the notion of characteristic direction. A direction [formula] is called characteristic at (x,p,q,r) if

[formula]

Given a function u defined in a neighborhood of a point x0, an hyper-surface f(x) = 0 is called non-characteristic at x0 if [formula] is not a characteristic direction at (x0,u(x0),∂u(x0),∂2u(x0)). The Cauchy-Kowaleski theorem requires that initial data, the so called Cauchy data, be given on a non-characteristic hyper-surface. Observe that if the PDE has the form

[formula]

where f does not depend on rnn, the surface xn = 0 is automatically non characteristic. We can now state the Cauchy-Kowalevski theorem in that particular case.

Some inadequacies of the Cauchy-Kowalevski theory

The Cauchy-Kowalevski theorem requires an analytic framework. Its proof (the historical one), consists of an argument based on the convergence of power series. Only the analyticity assumptions with respect to xn could be relaxed. The question of whether there could be more solutions for the same analytic data (in the C∞ class for instance) has stimulated much research, and, although there are uniqueness theorems for some classes of linear PDEs, there are also counter-examples to uniqueness (see [\cite=Met]). The general question remains to be settled.

If one seeks global solutions, which are expected to exist in physical problems, there is an "intrinsic" need to relax the analytic framework, since singularities can appear in "finite time" (the time variable here being xn) even though all data are analytic. Consider for instance the Cauchy solution to

[formula]

The gradient on each level set of [formula] for any u0∈( - 1,1) is constant, hence each level set is made of straight segments leaving the point (x0,0) in the direction given by the vector (1,u0). These segments have to meet at points where u thus necessarily ceases to be continuous.

In her thesis, Sofia Kowalevski illustrated the need for the assumption that the initial surface be non-characteristic by the following example. Consider locally an analytic solution of

[formula]

An elementary computation gives the explicit value of the coefficients of the Taylor series expansion for the solution, which happens not to converge at the origin. Hence, near the origin, there is no analytic solution to that equation with the given initial data. The reason why Cauchy's theorem does not apply in this case, is that x2 = 0 is characteristic for the equation. However this equation is nothing but the heat equation modeling in particular the diffusion of heat in an homogeneous material starting from the data u(x1,0). A non-existence result certainly seems counter-intuitive! It suggests that one should leave the analytic framework imposed by Cauchy and Kowalevski.

The conclusion at this stage is that the analysis of PDEs having simply to do with the convergence of power series.

Local solvability

The notion of local solvability and Lewy's counterexample

The first attempt to go beyond the Cauchy-Kowalevski theory would be to give up uniqueness requirements and look at "germs" of PDEs at a point. We are thus led to considering the linear framework and we ask whether one can enlarge the class of possible solutions from the analytic class to the C∞ class, or even to the space of distributions D'. Is a linear PDE always locally solvable? Precisely, consider [formula] to be a family of C∞ complex coefficients defined in a neighborhood of the origin in [formula] and indexed by [formula] where [formula] and [formula], for some [formula]. Given any [formula], does there exist locally near the origin a complex-valued solution (if need be, even in the very weak sense of distributions) to

[formula]

If for a given L and any f, the answer to the question is "yes", the PDE is called locally solvable at 0. Around 1955, Leon Ehrenpreis and Bernard Malgrange proved independently the local solvability of any linear PDE with constant coefficients [formula] (see [\cite=Ehr], [\cite=Mal]). Using Laurent Schwartz theory of tempered Distribution such a PDE can be converted into a convolution equation, and the problem is reduced to a division problem in function algebra. Encouraged by this result, the conjecture asserting that any linear operator L should be locally solvable became notorious in the PDE community. That was until Hans Lewy came up in 1957 with a spectacular counter-example, namely: there exists a non-analytic function f∈C∞ such that the PDE

[formula]

has no C1 solution in any neighborhood of the origin in [formula] (see [\cite=Lew]). This counter-example triggered an intense research activity which involved many prominent analysts of that time (such as Lars Hörmander, Louis Nirenberg, Fran cois Trèves, Yuri Vladimirovich Egorov,...). They were seeking what necessary and sufficient conditions would ensure local solvability.

The Nirenberg-Trèves local solvability condition

In three fundamental papers, Louis Nirenberg and Fran cois Trèves (see [\cite=NT1], [\cite=NT2] and [\cite=NT3]) in 1963 have proposed a condition on the principal symbol of the PDE

[formula]

that should be necessary and sufficient for local solvability, the so called (P) condition. The bi-characteristics of a real function A(x,ξ) are the curves (x(t),ξ(t)) that solve the Hamilton-Jacobi equation

[formula]

On such a curve, A(x(t),ξ(t)) is constant, and the curves for which this constant is zero are called the null bi-characteristics of A. The Nirenberg-Trèves (P) condition reads as follows

[formula]

The necessity and sufficiency of the Nirenberg-Trèves (P) condition for the local solvability was established for a growing number of cases in successive works by Nirenberg and Trèves themselves, then by Beals and Fefferman [\cite=BF], by Hörmander [\cite=Ho2], until a very recent result of Nils Dencker in 2006 (see [\cite=Den]) which establishes the sufficiency of the generalized Nirenberg-Trèves (P) condition for general pseudo-differential operators, the so called Nirenberg-Trèves (ψ) condition.

Cauchy problems and global solvability for linear PDEs

The notion of Cauchy problem

Understanding the local solvability of a PDE is certainly one important question, but one might argue that its relevance should not come into play in physical applications where solutions are expected to be globally defined on a given subdomains of spacetime.

The question of global solvability is traditionally coupled with that of uniqueness, and together they form what is called a Cauchy problem. A Cauchy problem, or well-posed problem, consists of a linear PDE L, of a function space E in which the data (the input) makes sense, of a function space F to which the expected solution (the output - also called the "unknown") should belong, with the requirements that:

there exists exactly one solution in F of the PDE L for any given data in the function space E ;

the dependence of the solution on the data is continuous from E into F.

Finding appropriate Cauchy problems for linear PDEs has generated a tremendous amount of mathematical activities in the last century. It also gives the "asymptotes", or "constraints at the horizon", in order to solve many non-linear problems, as we shall see.

One can illustrate the notion of Cauchy problem by looking at examples of ill-posed problems. One of them deals with finding a holomorphic extension in the disc D2 of a prescribed C1 boundary data. In other words, given [formula], one seeks [formula] satisfying

[formula]

This is an ill-posed problem, because not every [formula] admits a C1 holomorphic extension in D2 (take for instance φ(θ) = e- i  θ). The ill-posedness can however be thwarted by replacing [formula] with the subspace of C1 functions that are L2-orthogonal to e- i  k  θ for any [formula].

The fragmentation of the analysis of PDEs

The search for Cauchy problems has imposed a fragmentation of the field of PDEs into multiple areas of analysis, which have often been developed independently of each other. This is due to the very different behaviors of various differential operators. The analysis of PDEs cannot be encapsulated into a single theory, and it is intrinsically split. It is in fact a field that might seem disorderly from the outside. But this "messiness", which sometimes discourages young vocations, is in the very nature of PDEs and it is the source of an infinite diversity of phenomena, arguments, and results. One may nevertheless attempt to put some order in this diversity, by singling out three main families of operators that we briefly present in the framework of linear second order scalar equations with constant coefficients:

[formula]

with symmetric principal symbol : aij = aji.

The elliptic operators are those for which L has no characteristic direction:

[formula]

The archetype of the elliptic operator is the laplacian operator

[formula]

The Laplace equation Δu = 0, also called the potential equation, has been introduced in the physics of gravitational and electromagnetic fields. The field is generated by the potential u satisfying Δu = f, where f denotes either the mass or the charge density.

The parabolic operators are those for which one direction is singled out and does not appear in the second derivatives. They have the form

[formula]

where the (aij) operator for the remaining variables is (negative) elliptic:

[formula]

The model case of a parabolic operator is the heat operator

[formula]

The heat equation ∂tu - Δu = 0 is a fundamental tool in the modeling of diffusion (heat, combustion, chemical reactions, ...).

The hyperbolic operators are those for which the matrix (aij) has signature [formula]. The prototype is the wave operator

[formula]

The wave equation ∂2t2u - Δu = 0 is a fundamental equation arising in the modelling of propagation of waves in gases and fluids.

This (overly) simplified classification leaves out many equations, including ones that are relevant to physical phenomena, such as the Schrödinger equation or the Korteweg-deVries water-wave equation. Nonetheless, understanding how the three basic families differ from one another constitutes a first step in the study of "hybrid" and of more complicated PDEs. Parabolic equations can be understood as elliptic equations with time propagation, and thus these two families enjoy many similar properties, such as smoothing effect and infinite speed propagation. Hyperbolic equations on the other hand are very different, and they involve, for examples, finite speed propagation and the "transport" of singularities. The work of Louis Nirenberg has a barycenter whose location lies closer to the first two families, and this is why we shall mostly restrict this discussion to elliptic and parabolic PDEs.

The birth of Cauchy problems: the Dirichlet principle

Peter Gustav Lejeune Dirichlet was a German mathematician of the first half of the XIXth century. His interest for physics led him to formulate a mathematical problem related to potential theory, a field which finds its roots in Newtonian mechanics. This problem, named after him by Riemann, is formulated as follows:

A bounded domain empty of charge being given as well as the value of the potential at its boundary, show mathematically that it produces a unique electromagnetic field in the interior of the domain.

In his lecture on potential theory in Göttingen in 1857, Dirichlet gave a more precise mathematical formulation of the problem. Namely, show that for any bounded connected (smooth) domain Ω in [formula] and for any continuous differentiable function φ on ∂Ω, there exists a unique continuously differentiable function u equal to φ on ∂Ω and minimizing the following integral, now called Dirichlet energy,

[formula]

Such a function satisfies the Laplace equation

[formula]

The claims made by Dirichlet in his lecture were not completely settled, but they were however used in the following years by Bernhard Riemann in two-dimensional complex analysis. This situation created some trouble in the mathematical community and the Dirichlet principle came under attack, in particular in the work of Karl Weierstrass, who produced examples of coercive Lagrangians (akin to the Dirichlet energy) which do not possess minimizers for some boundary data. The revival of the Dirichlet principle came in the early XXth century in the work of David Hilbert who solved it rigorously in some special cases and devoted the 20th of his famous list of 23 problems to this principle. It is hard to find papers of the beginning of the XXth century on PDE without any mention of the Dirichlet principle. A detailed description of the steps towards the full resolution of Dirichlet's assertions would take us on too long, although very instructive, a detour. The resolution of Dirichlet's problem gave rise to numerous ad-hoc tools from functional analysis for solving PDEs, such as the notion of Sobolev spaces, distributions, weak solutions, ... Let us also mention the names of Henri Léon Lebesgue, Leonida Tonelli, Sergei Sobolev, Laurent Schwartz.

The modern way to solve the Dirichlet principle goes as follows. One introduces the so called Sobolev Space of Lebesgue measurable functions u on the bounded domain Ω whose Schwartz distributional derivatives lie in the Hilbert space of square integrable functions:

[formula]

where the distributional derivatives of u are defined by duality with compactly supported smooth functions

[formula]

This space is equipped with the scalar product for which it is complete, namely,

[formula]

The Hilbert Sobolev space W1,2 has favorable analytical properties, such as weak sequential pre-compactness (from any sequence with uniformly bounded norm one can extract a subsequence converging weakly - in duality with smooth functions - to a function in W1,2). Furthermore, the Dirichlet energy E(u) is weakly sequentially lower semi-continuous and for any weakly converging sequence uk with limit u∞, there holds

[formula]

One proves that smooth functions are dense in this Hilbert space. Moreover, the map which to a smooth function in [formula] assigns its restriction to the boundary ∂Ω is continuous from [formula] into the space of square integrable functions on the boundary ∂Ω, and therefore extends continuously to a well defined map from [formula] into L2(∂Ω). These facts combined together give the existence of a minimizer of the Dirichlet energy for any weak boundary data (L2 function φ) which admits a W1,2 extension inside Ω. This subspace of L2(∂Ω) is denoted by H1 / 2(∂Ω). The use of distribution theory makes it possible to assert that any such minimum u satisfies the Laplace equation in a weak sense:

[formula]

A fundamental lemma of Laurent Schwartz states that such a function u has to be analytic in the interior of the domain Ω and is the unique solution to ([\ref=I.1]). This full resolution of the Cauchy problem for the Dirichlet question can be extended without much difficulty in the case when "inside charges" are present, and one shows that for any smooth function f in Ω and any smooth function φ in ∂Ω, there is a unique solution - smooth inside Ω - to the inhomogeneous problem

[formula]

The Agmon-Douglis-Nirenberg elliptic Cauchy problems in the Banach Lp spaces

Numerous problems from classical mechanics, quantum mechanics, chemistry, biology, and from geometry can be described by means of elliptic non-linear PDEs of the form

[formula]

where the highest-order term is given by the Laplace operator or more generally by an elliptic operator which has no null characteristic. Considering this PDE on a bounded smooth domain Ω with zero boundary condition, it is tempting to view it as a perturbation of ([\ref=I.2]) and use the inverse of the Dirichlet problem, which was given in the previous section for φ = 0 and which we denote by ( - Δ)- 10. Then ([\ref=I.3a]) becomes

[formula]

The idea behind this reformulation is to ultimately use a fixed point argument for solving the PDE. This is done in the same vein as for proving Cauchy-Lipschitz-Picard existence theorem for ODEs of the form [formula]. One writes the solution as an integral

[formula]

before applying a fixed point argument. The difficulty is to find the right space in which to work. In the ODE case, for smooth f, the integral operator is very explicit and one shows that the space of Lipschitz functions gives an ad-hoc framework for the fixed point argument to work. In the case of PDEs, one must first have a thorough understanding of the operator ( - Δ)- 10 and how it acts on elements of various Banach spaces.

In two fundamental papers published in 1959 and in 1964, Schmuel Agmon, Avron Douglis, and Louis Nirenberg solved the elliptic Cauchy problems and the invertibility of elliptic operators of arbitrary orders in domains (see [\cite=ADN1] and [\cite=ADN2]). They worked in the context of Banach Lp spaces. They obtained a series of optimal results that opened the way to explore not only linear, but also non-linear PDEs, which were beforehand completely out of reach. We give below the simplest example of boundary problem solved by the Agmon-Douglis-Nirenberg theory of Cauchy problems in Banach spaces bearing in mind that the theory applies to a very wide family of problems. With such an estimate at hand, it becomes possible to use the operator ( - Δ)- 10 and a fixed point argument in the Banach spaces Lp so as to obtain a solution to non-linear PDEs. A major piece of the puzzle was brought in in 1952 by Alberto Calderón and Antoni Zygmund. The"Singular integral theory" says in particular that, for Schwartz functions, u, the mapping

[formula]

is continuous for the [formula] norm into [formula] for any p∈(1, +   ∞  ) (see [\cite=CaZ1] and [\cite=CaZ2]). The Agmon-Douglis-Nirenberg Lp-theory is parallel to a previous theory developed by the Polish mathematician Juliusz Schauder around 1930, which involves the more regular Hölder spaces instead of Lp or Sobolev spaces.

Inequalities and a-priori estimates

Gagliardo-Nirenberg interpolation inequalities

The field of PDEs is structured by inequalities. They are the "power horses" of the field. In the mid 1950s, functional analysis was already rich in inequalities: Hölder, Minkowski, Poincaré, Poincaré-Wirtinger, Young, Hausdorff-Young, Hardy, Hardy-Littlewood...etc and the more recent Sobolev inequalities. Deep scaling considerations (a common trait in Louis Nirenberg's work) led Louis Nirenberg around 1959 (see [\cite=Ni1] and [\cite=Ni2]), and independently Emilio Gagliardo ( see [\cite=Gag]), to discover a large family of inequalities for Sobolev norms "sitting" between two others. As an illustration, we have that for any p∈[1,  +     ∞ ], any r∈[1,  +     ∞ ], and any [formula], there exists a constant C > 0 such that for all Schwartz functions [formula], there holds:

[formula]

where q- 1 = 2- 1  (p- 1 + r- 1) and dxn denotes the Lebesgue measure on [formula]. In the family of Gagliardo-Nirenberg interpolation inequalities, one also finds the following one that we shall use later on. For any 1  ≤  p  ≤  q <  +   ∞   and any [formula], there exists C > 0 such that for all Schwartz functions [formula] there holds:

[formula]

where t = p  q- 1. The discovery of these estimates, together with the pioneering works of Marcel Riesz, Olaf Thorin, and Józef Marcinkiewicz, lies at the origin of an important subfield of functional analysis developed by Jacques-Louis Lions, by Jaak Peetre (see [\cite=LP]) and by Alberto Calderón ([\cite=Cal]), and called interpolation theory.

The use of Gagliardo-Nirenberg inequalities for proving a-priori estimates

The notion of a-priori estimates is central in PDEs. Roughly speaking, it deals with finding an estimate of the form

[formula]

for some suitable Banach space E, all the while assuming we have a solution u of some PDE, but prior to having actually proved the existence of such a solution. In concrete situations, looking at a given non-linear PDE problem, one establishes such an a-priori bound in order to perform one of the numerous available analytical methods in order to finally prove the existence of a solution satisfying that bound: fixed point argument in a perturbative approach, continuity method, topological techniques (ex: Leray-Schauder theory), functional analysis approaches (Ex. monotone operator theory, Hille Yosida), successive approximation (ex : Galerkin method, convex integration), penalization approaches (ex : elliptization or viscosity method), variational appraoches (ex : minimization, min-max methods, Morse theory)...

Gagliardo-Nirenberg inequalities are mostly used to control non-linear terms in PDEs, and to establish a-priori estimates. There are countless applications for these inequalities. In order to illustrate their might in dealing with non-linearities, the author of these notes is cherry-picking a subject dear to his heart: the Dirichlet problem for maps taking values into submanifolds, also called Harmonic map or vectorial Dirichlet problem. This problem has many applications in geometry (in minimal surface theory and in complex geometry - it is used to describe the Teichmüller space of 2-dimensional surfaces, ...) as well as in physics (for instance the Dirichlet problem for maps taking values into the sphere is the main mathematical object of the Ericksen-Leslie modeling of liquid crystals).

We consider exactly the same problem as the one posed by Dirichlet, that is to find critical points of the Dirichlet energy E on a smooth bounded domain Ω for some boundary condition, but this time under the additional constraint that the "unknown" u take value in a given closed sub-manifold [formula] of Euclidian space. Having fixed φ∈C1(∂Ω,Nn), we seek a critical point u of E with the constraint that u∈Nn everywhere. This constraint generates a new equation generalizing the Laplace equation ([\ref=I.1]) and one shows that the problem is equivalent to

[formula]

where Tu(x)Nn denotes the tangent space to Nn in [formula] at the point u(x). The equation Δu∈Tu(x)Nn is a natural generalization of the Laplace equation previously obtained for the unconstrained Dirichlet problem. Indeed, it says that the tangential component of Δu to the constraint is zero which simply implies that [formula] when there is no constraint. ([\ref=I.1b]) can be recast as an elliptic non-linear equation of the form

[formula]

This PDE is said to be semi-linear, because the term involving the highest order derivatives is linear. In contrast with the original Dirichlet problem ([\ref=I.1]), one can show that ([\ref=I.2b]) sometimes has more than one solution (and sometimes has infinitely many of them!). To which extent is this non-linear Dirichlet problem degenerate, and what sufficient conditions would ensure that ([\ref=I.2b]) is a well posed Cauchy problem? Taking two solutions u and v, the difference u - v satisfies

[formula]

In order to proceed to a "contraction mapping argument" we need to find a function space E in which the difference of the non-linearities [formula] is controlled by the norm of the difference u - v in the same space, weighted by a constant k < 1:

[formula]

Such an inequality, also called a-priori estimate - since we haven't yet settled the question of existence neither for u nor for v - offers the possibility to "absorb" the non-linear right-hand side of ([\ref=I.3b]) into the linear left-hand side u - v, and in turn deduce that u = v.

The Gagliardo-Nirenberg interpolation inequalities are essential to prove such a-priori estimates as ([\ref=I.5b]). Our example, picked among countless others, was chosen to illustrate the possibility to solve Cauchy problems for non-linear PDEs. It is however representative of the might of the Gagliardo-Nirenberg inequalities.

Among the various inequalities pertaining to vectorial Dirichlet problems, there is a particularly elegant one, which, in combination with the Agmon-Douglis-Nirenberg Lp theory, enables to show the well-posedness of the vectorial Dirichlet problem for two dimensional domains under small energy assumptions. Namely, there exists a constant C(Ω) > 0 such that for any smooth function w supported in the two dimensional domain Ω the following inequality holds:

[formula]

This inequality was centrally used by Michael Struwe in the framework of the vectorial Dirichlet problem to obtain a-priori estimates that imply the existence and uniqueness for the corresponding flow, also called called harmonic map flow, in two dimensions (see [\cite=Str]).

The John-Nirenberg BMO space: when elasticity meets harmonic analysis

The analysis of PDEs has evolved and keeps evolving in close "partnership" with the development of functional analysis and function space theory. Many linear and non-linear problems in PDE have stimulated the introduction of new function spaces - we have already outlined above the importance of the Sobolev spaces for solving the Dirichlet problem. The converse is also true: knowledge and properties of certain function spaces can trigger a new understanding of PDE problems.

In 1961, the mathematician Fritz John was studying a rigidity problem from elasticity ([\cite=Joh]). The strain exerted on a perfect elastic solid can be measured by the distance of the gradient of the resulting deformation with respect to the orthogonal group. In relation with this fundamental notion in elasticity, he asked the following question:

[formula]

By "close to", it was originally meant in the L∞ norm. This rigidity question finds its origin in a work of the mathematician Arthur Korn from 1914 ([\cite=Kor]). Extending Korn's results and now celebrated inequalities, Kurt Friedrichs proved in an important work in 1947 (see [\cite=Fri]) that the gradient of a deformation is everywhere antisymmetric if and only if it is constant, provided that suitable boundary conditions, which exclude rigid motions, are imposed. This result is an infinitesimal version of the question asked by John.

F. John gave first a relatively straightforward counter-example to the L∞ version of the question, but he also proved that on every ball [formula] of arbitrary center x and radius r > 0, there exists a rotation Rx,r such that

[formula]

where |Br(x)| is the volume of the ball Br(x). Thus John was proving that although the gradient of such a deformation could not be close to one single rotation globally, it is in average in the L1-norm at any scale, close to a rotation Rx,r that possibly depends on the ball.

In a subsequent collaboration [\cite=JN], which has since become a milestone in analysis, Fritz John and Louis Nirenberg systematically studied the sub-space of locally integrable functions, called space of functions of Bounded Mean Oscillation (BMO), whose elements satisfy

[formula]

where [formula] is the average of u on the ball Br(x). They proved that this space is strictly larger than L∞, the space of globally bounded functions (for example, [formula]), but that it is smaller than Lploc for any p <  +   ∞  . Precisely following an ingenious decomposition of [formula] of Calderón-Zygmund type they proved the existence of αn > 0 such that for any ball [formula]

[formula]

where [formula] is the average of u on B. The existence of such a bound for any ball is proved to characterize uniquely the space BMO.

The space BMO, which naturally arose in the context of elasticity in 1960, was apparently unknown to functional analysts. It was therefore a big surprise to discover, after the remarkable work of Elias Stein and Charles Fefferman in 1972 ([\cite=FeSt]), that BMO was the Banach dual of a famous space introduced in complex function theory some 40 years earlier by Friedrich Riesz [\cite=Rie] and named "Hardy space" after a famous work by Godfrey Hardy from 1915 [\cite=Har]. Historically, the Hardy space H1 was defined in the context of holomorphic functions on the disc D2: it is made of the traces on the circle S1 of holomorphic functions f such that

[formula]

Note that this integral is an increasing function of the parameter r for any holomorphic function f. The Hardy space was later extended to a much broader context of real function space theory. The dual spaces H1 and BMO play a fundamental role in PDEs. Empirically, one could say that they are the "natural replacements" for L1 and L∞. These two spaces are not compatible with Calderón-Zygmund theory, and in fact the Agmon-Douglis-Nirenberg results do not hold either for L1 or for L∞. In contrast, H1 and BMO are well-behaved in these theories.

It is unfortunately beyond the scope of this presentation to expose in its full glory the usefulness of the duality H1 - BMO in the analysis of PDEs. It plays a central role for instance in a theory called integrability by compensation, where some non-linear quantities appear in the form of products with such algebraic structures that improved integrability might be deduced. This has frequently been used in fluid mechanics as well as in geometry.

We content ourselves with mentioning one application. Using some straightforward integration by parts, one proves the following Gagliardo Nirenberg interpolation inequality: for any [formula] there exists Cn > 0 such that for all Schwartz functions u in [formula] one has

[formula]

Using more sophisticated arguments (Littlewood-Paley decomposition of tempered distributions) the author of these notes in collaboration with Yves Meyer prove a "slight" improvement of this inequality by replacing the L∞ norm of u with its BMO-norm, namely:

[formula]

This improved inequality entering in a larger class of inequalities by David Adams and Michael Fraizer (see [\cite=AF]) has been crucially used in [\cite=MR] for proving a partial regularity result for stationary Yang-Mills fields, which was obtained independently by Terence Tao and Gang Tian (see [\cite=TT]).

The maximum principle

Nirenberg's strong maximum principle for parabolic equations

It would be impossible to speak about the work of Louis Nirenberg without mentioning the maximum principle. The contrast between the immense range of applications of this principle and the simplicity of the heuristic idea behind it is amazing.

In one dimension, the maximum principle states that a continuously twice differentiable function on the segment

[formula]

The notion of "barriers", the "moving plane" method, and the Gidas-Ni-Nirenberg symmetry principle

The heuristic idea behind the strong maximum principle, at least in the simpler elliptic framework, has an interesting geometric representation. We say that a linear elliptic operator L satisfies the strong maximum principle if the following holds. Let any pair of hyper-surfaces realized by two graphs of respectively a sub-solution u and super-solution v over a bounded domain, with one of them sitting above the other (i.e. u  ≥  v) be given. The strong maximum principle says that if they touch at some point, then the two hyper-surfaces are necessarily identical. A sub-solution satisfying Lu  ≥  0 is then said to be a "barrier" with respect to a super solution satisfying Lv  ≤  0, and vice versa. This geometric interpretation is an incentive to manufacture barriers with respect to solutions, sub-solutions, and to super-solutions in order to prove pointwise inequalities via the maximum principle. This fruitful technique has become a classic in analysis, where it is known as a comparison argument. Devising suitable barriers is nothing short of being an art in itself. It requires deep intuition and thorough experience of the problems considered.

The geometric interpretation of the maximum principle in both its strong and weak formulations was probably first used in the 1955 work of Alexander Danilowitsch Alexandrov (see [\cite=Ale] for a later publications of his original ideas that he presented for the first time in Zürich in 1955 according to Heinz Hopf [\cite=Hopf]). He used a comparison argument between the solution itself and some reflections of it in order to prove that embedded constant mean curvature closed surfaces in [formula] are necessarily isometric to a dilation of the unit sphere S2. The relevance of the maximum principle and of elliptic theory in the resolution of this geometric problem is apparent in the equation satisfied by the graph u of constant mean curvature H, namely:

[formula]

Following an important paper by James Serrin [\cite=Ser], Louis Nirenberg in collaboration with Basilis Gidas and Wei Ming Ni , converted Alexandrov's original idea for constant mean curvature surfaces into a general method, as beautiful as it is efficient, nowadays known as the "moving plane method", see [\cite=GNN]. With it, one can prove symmetry results (either with respect to a given direction, or full rotational symmetry) and uniqueness results for positive solutions to semi-linear scalar equations of the form

[formula]

These symmetry and uniqueness results are of utmost importance, since they extend to a non-linear framework a fundamental principle in quantum mechanics and in spectral theory; stating that the ground state of the Laplace operator, which is necessarily positive,

[formula]

enjoys special symmetries and has multiplicity one (i.e. it is unique - Krein-Rutman theorem). This method and the ensuing symmetry results have important applications to diverse areas of science: the study of ground states of non-linear Schrödinger models in quantum mechanics, the vortex theory of Onsager in thermodynamics, turbulence in statistical physics, phase-transitions in Van der Walls fluids, the Yamabe problem in differential geometry (which is concerned with finding constant scalar curvature metrics in a given conformal class), etc.

The moving plane method consists in comparing an arbitrary solution u for the semilinear equation ([\ref=II.2]) with its successive reflections [formula] across a continuous family of parallel hyper-planes. These reflections [formula] are used as barrier functions for u. A key ingredient of the method is the strong version of the maximum principle and a refinement of it discovered by E. Hopf in the 1950s, and now known as "Hopf lemma". It states that at maximum points on the boundary, the outward normal derivative of a sub-solution is strictly positive unless the sub-solution is identically constant.

Later on, Louis Nirenberg in collaboration with Henri Berestycki introduced a new method, still based on the strong maximum principle, and called "sliding method" (see for instance [\cite=BN]). This new method was devised to prove various pointwise estimates and asymptotic behaviors for solutions in cylindrical domains to semi-linear equations of the form ([\ref=II.2]), as well as for their parabolic counterparts. The sliding method has numerous important applications to traveling fronts problems in the mathematical modeling of combustion and flame propagation . Its novel idea consists in comparing the solution with its translations along the axis of the cylinder, rather than using the images by successive symmetries of the solution as barriers. It requires the use of a version of the maximum principle on "narrow domains" where the sign of the 0th order coefficient c(x) is not required to be controlled due to S.R. Srinivasa Varadhan (see [\cite=BNV]).

The Dirichlet problem for non-linear second order elliptic equations

We have stressed the importance of a priori estimates for solving the Dirichlet problem of semi-linear equations. In order to prove such estimates, we have combined the Agmon-Douglis-Nirenberg Lp-theory for boundary-value problems along with the Gagliardo-Nirenberg estimates in various Banach spaces. For many scalar equations of elliptic type which are more non-linear and also more degenerate than semi-linear equations, the maximum principle is an additional tool that can be added into the mix to reach the desired estimates.

In a series of five fundamental papers written in collaboration with Luis Caffarelli and Joel Spruck, Louis Nirenberg identified the maximum principle as a fundamental device to obtain a priori estimates, and to solve the Dirichlet problem for "highly" non-linear PDEs known as fully non-linear PDEs (see [\cite=CNS1] [\cite=CNS2] [\cite=CNS3] [\cite=CNS4] [\cite=CNS5]). An example of such an equation is the Monge-Ampère equation which appears in problems related to optimal transport as well as in geometric problems of prescribed curvatures. The strict convexity requirement imposed on the solution forces ellipticity on the problem. To see this, let [formula]. Let [formula] denote the inverse of the Hessian matrix of u. Assuming that u is convex, the matrix (uij) is symmetric and positive definite. Hence:

[formula]

which is tantamount to ellipticity. The core of the argument involves several steps. First, one establishes a-priori estimates for the Hölder norm of the solution (assumed to exist). These estimates follow from the classical elliptic Agmon-Douglis-Nirenberg Lp-theory or Schauder theory for Hölder spaces, provided that F(∂2u) is uniformly elliptic:

[formula]

for some constants 0 < λ  <  Λ, and also provided that the modulus of continuity of ∂rF(∂2u) can be controlled up to the boundary. In other words, the task is to prove that ∂2u is uniformly bounded and uniformly continuous up to the boundary. This is done with the help of the maximum principle and comparison arguments. Eventually, the authors reach the a-priori estimate

[formula]

where C0,α is the Hölder norm defined in ([\ref=oo]). Once ([\ref=ooi]) is established, the final part of the argument relies on a continuity method, where one interpolates φ with the determinant of the Hessian matrix of a function which coincides with φ on the boundary.

In these highly intricate works, the maximum principle is showing its full quintessence and potential to obtain hidden a-priori estimates. The core of the argument involves the sophisticated construction of barrier functions with which the solution u and its successive derivatives (or finite differences) are compared.

These five papers by Caffarelli, Nirenberg, Spruck and also by Joseph Kohn for one of them, have stimulated a tremendous amount of research activity on fully non-linear equations since their publications. These equations have an immense range of applications in many fields of science, including material sciences, finance, computer vision, ... The original ideas of Nirenberg et al. have influenced the development of a whole branch of analysis, called viscosity theory for PDEs, where the maximum principle plays a central and decisive rôle. The viscosity theory for PDEs was introduced by Lawrence Craig Evans [\cite=Eva] and by Michael Crandall and Pierre-Louis Lions [\cite=CL].

Solving problems from geometry

The analysis of PDEs and differential geometry are intimately intertwined by essence. The central rôles played by the Laplace operator and by the [formula]-operator in Riemann surface theory, constitutes the simplest illustration of this imbrication. The second half of the XXth century saw a dramatic acceleration of the transfer of techniques from non-linear PDEs to the resolution of problems that seem a-priori confined to geometry. A spectacular example of the might of the PDE approach in geometry is the recent proof of the Poincaré conjecture by Grigori Perelman, which heavily relies on the parabolic Ricci flow devised by Richard Hamilton.

Nirenberg's resolution of the Weyl problem

The taste for geometry and the influence of geometric questions are manifest in Louis Nirenberg's work. He is among the pioneers who introduced elaborate analysis tools for solving questions pertaining to embeddings, tensors, curvature, complex structures, ... His doctoral work itself dealt with geometry, and, following the invitation from his advisors James Stoker and Kurt Friedrichs, he solved a problem originally posed by Hermann Weyl:

[formula]

Nirenberg answered this question assuming the given metric is four times continuously differentiable in [\cite=Ni0]. In this first work, the general "philosophy" we have discussed is already present, and it will remain recurrent in Louis Nirenberg's papers: one looks for a-priori estimates, and combine them with suitable continuity methods that leave the a-priori estimates unchanged along the deformation. The link with the previous section is made by writing the PDE satisfied by a graph (x,u(x)) of Gaussian curvature K(x) at (x,u(x)):

[formula]

Its associated Dirichlet problem was the subject of the last part of the first paper of the aforementioned series by L. Caffarelli, L. Nirenberg, and J. Spruck.

The Nirenberg problem

The original "Nirenberg problem" can be stated as follows:

[formula]

By "pointwise conformal", we mean the existence of a function u on S2 such that g = e2ug0. Stated differently, the Nirenberg problem consists in establishing the existence (or lack thereof) of a solution to the Liouville equation

[formula]

where Δg0 is the negative Laplace Beltrami operator for g0, the canonical metric of S2. This simply formulated question has brought forth an enormous amount of work since the early 1970s. Not only because it is the "simplest" instance of a wide range of similar questions (higher dimension, different curvature tensor, scalar curvature, Q-curvature, σk  -  curvatures, fractional curvatures etc...), but also because it gives rise to the major issues faced by conformal geometric analysts in their study of "critical non-linear PDEs", such as concentration of compactness phenomena, Palais-Smale sequences, Morse theory, inter alia. These issues appear as well in many celebrated problems: the Yamabe problem, harmonic map theory, Yang-Mills equations, constant mean curvature surfaces, to name a few. The apparent simplicity of the Nirenberg problem fosters the universal difficulties arising in conformal geometric analysis.

It would be much beyond the scope of the present report to give a detailed account of the various arguments and creativity which have flourished in the quest for solving Nirenberg's problem. We content ourselves with mentioning that not every choice for K gives rise to a solution. This is seen, for example, using the Gauss-Bonnet theorem, and the now well-known Kazdan-Warner necessary condition. Let us also mention an important sufficient condition for the existence due to Alice Sun-Yung Chang and Paul Yang [\cite=ChY]. Let K be positive on S2 with only non-degenerate critical points and with at least two local maxima. Suppose further that Δg0K > 0 at all saddle points of K. Then Nirenberg's problem has a solution.

The Newlander-Nirenberg complex Fröbenius theorem

Louis Nirenberg has made important contributions to complex geometry and complex analysis. Once again, PDE techniques lie at the heart of the approach he favored to tackle various geometric questions. An important one deals with the integrability of almost complex structures. The question goes as follows. Let a map J from [formula] into the space of real-valued (n  ×  n) matrices be given. Assume it satisfies everywhere the condition

[formula]

where In is the (n  ×  n) identity matrix.

[formula]

For n = 1, the question amounts to solving locally a Beltrami equation

[formula]

This is successfully achieved by introducing the singular integral operator associated to the inverse of the Cauchy-Riemann operator [formula] and by using an elementary fixed point argument.

The general case n > 1 is much more involved and leads to an overdetermined system of coupled linear Cauchy-Riemann type PDEs of the form

[formula]

where zj are complex coordinates for the complex structure given by the value of J at the point in the neighborhood of which we are working. The system being overdetermined (indeed, differentiating in [formula] the j-th equation has to give the same result as differentiating in [formula] the k-th equation, namely: [formula]) there must be a structural constraint on the system for it to be locally solvable. A necessary condition was discovered by Albert Nijenhuis in his 1951 doctoral thesis, and independently by Paulette Libermann in [\cite=Lib], as well as by Beno Eckmann and Alfred Frölicher in [\cite=EF]. It can be stated as follows. We consider the complexification of the tangent space to [formula] at each point, and we call a (0,1) vector any vector of the complexified tangent space and of the form

[formula]

where X is a real vector. The necessary condition says that the space of (0,1) vectors has to be stable under bracket operation. Louis Nirenberg and his student A. Newlander succeeded in proving that this complex Fröbenius type condition is in fact sufficient for the local solvability in the C∞ framework. Note that, unlike in the one-dimensional case, applying the inverse of the Cauchy-Riemann operator [formula] to the right-hand side of ([\ref=oao]) does not enable an iteration argument in any classical Banach space (Hölder, Sobolev). Indeed, an integration in zj is applied to a derivative in zk of w, for k  ≠  j: this leads nowhere. Nirenberg and Newlander in [\cite=NN] had the idea to recast the problem in terms of the inverse z(w) of the diffeomorphism w(z). It solves a PDE system of the form

[formula]

Although this problem is now becoming non-linear (!), unlike the original one which was linear, it is this time possible to implement a scheme similar to the one devised in the one-dimensional case, since differentiation occurs with respect to only one of the independent variables in each equation. This problem is solvable in classical Hölder spaces.

We have decided to end this presentation with this remarkable work, which can but trigger the admiration of any mathematician, even beyond the field of partial differential equation, and this over 58 years after its original publication!

Conclusion

At the end of these notes, one feels somewhat frustrated to have only presented one part of the prolific and monumental work of Louis Nirenberg. Many important contributions have been omitted such as the analyticity of solutions to analytic PDEs (in collaboration with Charles Morrey, [\cite=MN]), the regularity of free-boundary problems (in collaboration with David Kinderlehrer and Joel Spruck, [\cite=KiN1],[\cite=KNS1], [\cite=KNS2]) or the partial regularity of solutions to the Navier-Stokes equation (in collaboration with Luis Caffarelli and Robert Kohn, [\cite=CKN]) which to this day remains the optimal step towards solving the Millenium problem. The author of these notes also apologizes to the numerous collaborators of Louis Nirenberg whose joint-works with him have not been mentioned here. Louis Nirenberg's scientific endeavor is an exemplary reminder to all of us that research is first and foremost a collective venture, in which debating, discussing, and exchanging ideas play a decisive rôle. ..

It is the result of no coincidence that Louis Nirenberg made his professional home at the Courant Institute at New York University. A prestigious institution that has fostered since its very creation a unique laboratory for the free exchange of scientific ideas. Although there are still many important theoretical questions to answer, the analysis of partial differential equations is nowadays mostly aimed at better understanding other fields of science, with applications in geometry, physics, mechanics, chemistry, biology, social sciences, technology. These developments, and the ones to come, anchor their roots on the immense efforts deployed in the last century by human intelligence in this area of mathematics. Mathematical knowledge is however not only made of an accumulation of truths and results confined to papers and books, and transmitted in this form to future generations. A large and immaterial share of mathematical knowledge resides in the "living part" of Mathematics, in mathematicians themselves, with their intuitions, their hesitations, their perseverance, and most importantly with their esthetical quest and search for beauty (as surprising as it may sound to non-mathematicians!). Hermann Weyl once said "My work always tried to unite the truth with the beautiful, but when I had to choose one or the other, I usually chose the beautiful". We do not know whether Louis Nirenberg would agree with this quote, but we would nonetheless like to thank him for the beautiful mathematics he has produced and for generously sharing it with us all for so many years.