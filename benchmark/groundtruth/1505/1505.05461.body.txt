Network driven sampling; a critical threshold for design effects

Introduction

Statistical inference takes conclusions from a small set of observations and extends them to the entire population; "sampling" drastically reduces the burden of research in various disciplines. However, classical sampling techniques require a sampling frame that lists each individual in the population and a way of contacting each individual. In many settings, a sampling frame is not available. In others, it is too expensive to compile or only covers a biased subset of the population. Given the continual decline in response rates to telephone surveys, even standard sampling frames are becoming less useful; Pew Research Center reported that the typical response rate in telephone surveys declined from 36% to 9% between 1997 and 2012 [\citep=pew]. Network driven sampling has the potential to circumvent these difficulties because it does not require a sampling frame (e.g. [\cite=heckathorn1997respondent]).

In many populations of interest, the members are connected by a network; a social network, a hyperlinked network, or a protein-protein interaction network. This network provides a viable means for reaching the target population; the people, the webpages, or the proteins. Using a network to reach a target population goes by many names in various disciplines; respondent-driven sampling / snowball sampling, web crawling / link-tracing / breadth-first search, and Co-immunoprecipitation / chromatin immunoprecipitation. These disparate techniques are united in providing researchers access to otherwise hard-to-reach populations by essentially asking friends to refer friends. This paper studies random sampling in the context of a networked population.

Within public health research on HIV, respondent-driven sampling (RDS) is a popular technique to sample marginalized and/or hard-to-reach populations [\citep=heckathorn1997respondent]. RDS has become widely and particularly popular in HIV research because the populations most at risk for HIV (i.e. people who inject drugs, female sex workers, and men who have sex with men) cannot be sampled by conventional techniques. Several domestic and international institutions use RDS to quantify the prevalence of HIV in at risk populations, including the Centers for Disease Control (CDC), the World Health Organization (WHO), and the Joint United Nations Programme on HIV/AIDS (UNAIDS) [\citep=WHO]. RDS serves as a motiving application in this paper. However, the results herein are applicable to network driven sampling in other domains.

This paper studies the design effect of network driven sampling. The design effect is the variance of an estimator constructed from a network driven sample divided by the variance of that estimator constructed from an independent random sample. For example, if the design effect is three, then a network driven sample increase the variance by a factor of three. Said another way, a network driven sample would require [formula] times more samples to obtain an estimator with the same standard error.

The Markov model of network driven sample has been extensively used in the previous literature. [\cite=salganik2004sampling] and others have modeled RDS as a simple random walk on the social network; such a model presumes that each person refers exactly one participant. [\cite=goel2009respondent] modeled the RDS referral process as a Markov process indexed by a tree; this allows for the fact that some individuals make multiple referrals. When indexing the Markov process by a tree, the initial participant (i.e. the "seed node") forms the root of the tree. Following the tree down to any leaf creates a standard Markov chain. Due to properties of the Markov chain, the dependence between samples decays exponentially fast along the branches of the referral tree. However, due to the branching structure, most pairs of samples are merely O( log n) apart. As such, observations in a tree are more dependent than observations in a chain.

Previous results in [\cite=goel2009respondent] studied a tree structure where every individual refers exactly two more individuals. These results only apply to a social network in which the adjacency matrix is rank two; this supposes that there are exactly two communities in the network and connection within and between these communities are entirely homogeneous. Theorem [\ref=thm:var] extends these results by making no assumptions on the referral tree and requiring only minimal assumptions on the social network (e.g. connected, unipartite, etc.). To do this, the proof relies on the spectral decomposition of the Markov transition matrix. This allows for the comparison of (1) the logarithmically expanding distances in the tree against (2) the exponential convergence of the Markov chain. Comparing these quantities identifies the critical threshold that is discussed in the abstract.

A key function [formula] relates the referral tree to the Markov process and determines the asymptotic behavior of the design effect. Sample two nodes I,J uniformly from the referral tree and compute their graph distance in the tree, D  =  d(I,J); this is the number of referrals between I and J. Evaluate the probability generating function for this random variable D at λ2 < 1, the second eigenvalue of the Markov transition matrix on the social network:

[formula]

where the subscript n denotes the number of samples in the referral tree. As n grows, the tree grows and the distribution of D changes. Under certain conditions on the distribution of the outcome of interest (e.g. HIV status) in the network, the design effect of a Horvitz-Thompson (HT) based estimator [\citep=volz2008probability] is asymptotically proportional to [formula]. The rate of [formula] has two regimes. Suppose that the tree is "balanced" in a sense described in Section [\ref=sec:tree] and let m be the average number of referrals. If m  <  λ- 22, then the design effect is bounded, [formula]. However, if m > β, then the design effect grows with n, [formula] where α  =   log mλ- 22∈(0,1). When the design effect grows with n, it means that under the network driven sample, the variance of the HT estimator converges slower than the standard 1 / n rate.

The value λ2 is widely studied in the literature on Markov chains and spectral graph theory [\citep=levin2009markov] [\citep=chung1997spectral] and it plays a key role in the critical threshold. It measures what the RDS literature refers to as "bottlenecks" in the referral process. Suppose there are two communities in the network, EAST and WEST. If the seed belongs to EAST and several waves of sampling fail to refer someone in WEST, then this indicates a bottleneck in the referral process and it creates additional dependence between successive samples. Such a bottleneck corresponds to a large value of λ2 [\citep=von2007tutorial]; this concept is formalized by the Cheegar cut [\citep=chung1997spectral]. Because [formula] is increasing with z > 0, a strong bottleneck creates additional variance.

The paper is organized as follows. Section [\ref=sec:prelim] defines the following four separate pieces that constitute the model for RDS that is used throughout the paper: a social network, a Markov transition matrix, a referral tree, and a node feature that we wish to describe. Section [\ref=sec:var] gives Theorem [\ref=thm:var] which provides an exact formula for the variance of an RDS estimator. In standard applications, the formula for the variance can not be computed by observed data. Section [\ref=sec:paths] briefly mentions two possible paths that allow for tractable estimation of the variance. Section [\ref=sec:tree] gives upper and lower bounds on [formula] as a function of the sample size n (i.e. the number of nodes in the tree). These bounds require some conditions on the referral tree. m-trees, where every non-leaf node refers exactly m participants, trivially satisfy these conditions. Theorem [\ref=thm:critical] combines the previous results to show that, under certain conditions, the bounds apply to random Galton-Watson referral trees. Section [\ref=sec:replacement] studies the rate at which the Markov model resamples nodes. Section [\ref=sec:emp] illustrates the key elements of the variance formula in (1) the popular political blog network and (2) 18 different referral trees that have been published in previous RDS studies.

Previous literature

There are three strains of literature that are relevant to this paper. First, the extensive empirical and statistical literature on RDS. Second, the probability literature on Markov processes indexed by chains and trees. Finally, a highly computational and experimental data mining literature in web graph sampling. The relevant pieces of these literatures are summarized below.

RDS was first proposed in [\cite=heckathorn1997respondent] and it is an extension of snowball sampling, a more commonly used term and technique [\citep=handcock2011comment]. The classical statistical results on snowball sampling in [\cite=goodman1961snowball] studies estimators of the social network structure. More recently, these sampling techniques have been applied to situations where the network structure is ancillary; it is used only to reach/sample participants from a hard to reach population. A key innovation of RDS is the use of dual incentives to first participate and then, to refer future participants. The techniques of RDS have been refined in numerous publications since its introduction. [\cite=salganik2004sampling] first discussed RDS as a random walk on a social network. Several others examined the procedure and proposed various refined estimators [\citep=volz2008probability] [\citep=goel2009respondent] [\citep=goel2010assessing] [\citep=gile2010respondent] [\citep=handcock2010modeling]. A common concern in this literature has been the variability of the RDS estimators. [\cite=salg] [\cite=gile2011improved] [\cite=RSSA12091] proposed techniques to estimate the variance and the design effects of RDS estimators. Using the bootstrap estimator proposed in [\cite=salg], [\cite=szwarcwald2011analysis] and [\cite=johnston2013empirical] reanalyzed a wide variety of RDS samples. In these range of studies, the estimated design effect of RDS is between four and eight. These bootstrap techniques underestimate the actual variability (e.g. [\cite=neely2009statistical] [\cite=goel2010assessing] [\cite=verdery2013network]). Using a rank two network model and a perfect binary referral tree, [\cite=goel2009respondent] shows that that the standard RDS estimator can converge slower than the standard rate. The results in the current paper extend this result to a more general network model. Moreover, the results below allow for more general referral trees. These generalizations allow for the identification of the critical threshold.

The current paper relates two strings of previous literature in probability; one that studies the variability of Markov chain sampling and another that studies Markov processes indexed by a tree. For example, primarily motivated by applications to Markov Chain Monte Carlo, [\cite=geyer1992practical] [\cite=aldous1reversible] and [\cite=jones2004markov] studied the variability of Markov chain sampling. This extant literature does not address tree indexing. The literature that has studied Markov processes indexed by a tree (e.g. [\cite=benjamini1994markov] [\cite=peres1999probability] [\cite=yang2003some] [\cite=dembo2005large]), has not addressed the questions relevant to RDS-in particular, where there is an underlying graph with node features. Both of these literatures have open source texts for reference- see [\cite=aldous1reversible] and [\cite=levin2009markov] for results on Markov chains and mixing times and see [\cite=lyons2005probability] for random processes indexed by trees or graphs.

In an entirely separate thread of literature, several data mining papers have applied network driven sampling to hyperlinked webpages. These sampling techniques have been applied for various purposes (visualization, compression, storing and retrieval) [\citep=krishnamurthy2005reducing]. More recently, this literature has studied the various biases induced by different sampling mechanisms (e.g. [\cite=leskovec2006sampling] [\cite=stutzbach2009unbiased] [\cite=kurant2010bias] [\cite=gjoka2010walking] [\cite=ribeiro2010estimating] [\cite=avrachenkov2010improving]). These data mining papers seek to find a representative sample of the nodes and edges so that conclusions from the sample can be extended to the entire graph. Much of the evidence in this literature is highly computational, based on simulations and computer experiments rather than statistical theory.

Preliminaries

There are four mathematical pieces necessary to model the statistical performance of the RDS estimators; a social network represented as a graph, a Markov transition matrix on the nodes of the graph, a referral tree to index the Markov process on the graph, and finally, a node feature defined for each node in the graph. The aim of network sampling is to measure the average node feature for all nodes in the graph, using only the features of the sampled nodes.

Markov processes on a graph

A node set [formula] contains the people in the social network and an edge set E  =  {(i,j):} contains the friendships. Together, they form the social network, G  =  (V,E). The results in this paper require that the graph is undirected; they do not require that the graph is unweighted. If the graph is unweighted, define the degree of node i as the number of connections to node i, [formula]. If the graph is weighed, define the degree as the sum of the edge weights. Throughout the text i∈G is used synonymously with i∈V to simplify notation.

Markov chain on G

Denote [formula] as a Markov chain on the individuals from the social network G. For example, given that X(t)  =  i∈G, choose X(t + 1) uniformly from i's friends,

[formula]

this is a simple random walk on the nodes of G. The transition matrix for a Markov chain [formula] defines the transition probabilities,

[formula]

If we presume that coupons can only be transmitted along edges in the social network, then P has the restriction that

[formula]

Let [formula] denote the eigenvalues of P. All eigenvalues of P are less than or equal to one in absolute value (see e.g. Lemma 12.1 in [\cite=levin2009markov]). The literature on spectral graph theory and spectral clustering has extensively studied the second largest eigenvalue of P [\citep=chung1997spectral] [\citep=von2007tutorial]. If λ2 is close to one, then there are clusters or communities in the graph. In particular, if the simple random walk transition matrix has λ2 = 1, then the social network is disconnected; this represents an extreme bottleneck.

The Markov chain is reversible if there is a function [formula] that satisfies

[formula]

For example, if G is undirected, then the simple random walk on G is reversible. If P is reversible and |λ2| < 1, the function π is the stationary distribution and it satisfies

[formula]

When G is undirected and P is the simple random walk,

[formula]

The popular Volz-Heckathorn (VH) estimator is a Horvitz-Thompson estimator (defined in Section [\ref=sec:measurements]) that uses these terms as inclusion probabilities. Under certain assumptions, the VH estimator is asymptotically unbiased.

The spectral properties of the Markov transition matrix enable tractable calculations. The following Lemma from Chapter 12 of [\cite=levin2009markov] provides the essential pieces.

Let P be a reversible Markov transition matrix on the nodes in G with respect to the stationary distribution π. The eigenvectors of P, denoted as [formula], are real valued functions of the nodes i∈G and orthonormal with respect to the inner product

[formula]

If λ is an eigenvalue of P, then |λ||  ≤  1. The eigenfunction f1 corresponding to the eigenvalue 1 can be taken to be the constant vector [formula], in which case the probability of a transition from i∈G to j∈G in t steps can be written as

[formula]

The second eigenvector f2 plays a fundamental role in the rest of the paper. Each of the leading eigenvectors represents a bottleneck in the referral process. In the previous example with two communities EAST and WEST, suppose that P corresponds to the simple random walk. If EAST and WEST correspond to the most dominant partition in the network, then f2(i) and f2(j) will have the same signs (i.e. +/-) if and only if i and j belong to the same community. By looking at the signs, f2 partitions the graph into EAST and WEST. The Cheegar bound [\citep=chung1997spectral] makes this concept rigorous and provides an argument for why spectral clustering can partition a graph [\citep=von2007tutorial].

Markov process on G indexed by a tree

Another graph beyond the social network G is needed to index the network driven sample. While G contains the entire population, the second graph contains the sampled nodes. For example, under a Markov chain, this second graph contains the nodes [formula] and the edges t - 1  →  t for [formula]. In this second graph, an edge corresponds to a referral in the sampling process. Because some participants provide multiple referrals and other participants provide zero referrals, this rest of the paper indexes the Markov process with a tree. Let [formula] be a rooted tree-a connected graph with n nodes, no cycles, and a vertex 0. The seed participant is vertex 0 in [formula] (cf Figure [\ref=fig:graphSeq]).

To simplify notation, [formula] is used synonymously with σ belonging to the vertex set of [formula]. For any node in the tree [formula], denote [formula] as the parent of σ (the node one step closer to the root). Let [formula] denote the set of σ and all its descendants in [formula]. The Markov process indexed by [formula] is the set of random variables [formula] satisfying the Markov property

[formula]

Just as in the standard Markov chain, the transition matrix P∈[0,1]N  ×  N describes the transition probabilities,

[formula]

[\cite=benjamini1994markov] called this process a [formula] . Unless stated otherwise, it will be presumed throughout that under the [formula], X0 is initialized from the stationary distribution of P.

In the social network G, an edge represents friendship. In the tree, an edge from [formula] to [formula] represents that random individual Xτ∈G refers random individual Xσ∈G in the [formula].

Denote the height of [formula] as [formula]; this is the number of rounds of sampling in the RDS, or the maximum graph distance in [formula] from the root to any node.

Measurements and estimators

For each node i∈G, let [formula] denote some characteristic of this node. For example, y(i)  =  1 represents that i∈G is HIV+ and y(i)  =  0 represents that i∈G is HIV-. We wish to estimate the population average

[formula]

Under the previous example, this is the proportion of the population that is HIV+. We estimate μtrue with observations

[formula]

where Xτ is a [formula]. Denote

[formula]

where a subscript of ·  RDS denotes that expectation are computed with the [formula] . The sample average,

[formula]

is an unbiased estimate of μ. However, π is not necessarily uniform. So, it is not necessarily true that μ  =  μtrue.

If P is a simple random walk on G, then the popular Volz-Heckathorn estimator [\citep=volz2008probability] provides an asymptotically unbiased estimate of μtrue under the [formula]. It uses generalized Horvitz-Thompson reweighting,

[formula]

The results in this paper apply to an idealized form of the Volz-Heckathorn estimator, where we suppose that the normalization factor in [formula] can be properly identified. For i∈G, wi  =  nπi is the expected number of times that node i appears in the sample. Thus, the Horvitz-Thompson estimator is

[formula]

The graph G, the node features y(i), and the probabilities πi are all fixed. It is the sample Xτ that is random. Define a new node feature

[formula]

and new node measurements Yπτ  =  yπ(Xτ). The sample average of the new measurements is exactly the idealized Volz-Heckathorn estimator HT that is an unbiased estimator of μtrue. Because of this simple transformation, the theorems below that study [formula] can also study HT by substituting yπ for y.

This paper studies the design effect of the [formula] with the estimator [formula]. The design effect compares the [formula] to a random sample. Define VarRDS() as the variance of [formula] under the [formula]. Define [formula] as independent random samples with [formula]. Define

[formula]

The design effect of the [formula] is

[formula]

In many of the results below, a key assumption is that y has non-negligible correlation with f2, the second eigenvector of P.

Denote the population correlation between y and the second eigenvector of P as

[formula]

where σ2  =  VarRDSY0 and 〈  ·  ,  ·  〉π is defined in equation [\eqref=def:inner].

If the social graph is split into two communities (e.g. EAST and WEST) and f2 corresponds to this partition, then the [formula] has the potential to oversample one of these communities. If ρπ(y,f2) is large, then the referral bottleneck corresponding to f2 induces dependence between the samples. However, if the correlation ρπ(y,f2) is zero or close to zero, then the two communities have similar distributions of y values (e.g. similar rate of HIV+). As such, over sampling one of the communities will not contribute excess variance to the estimator, making this bottleneck is irrelevant.

Two examples

Throughout the paper, two specific models will illustrate the results.

Continuing the previous example where f2 partitions the network into the EAST and WEST communities, suppose that f2(i) is positive when i is a node in EAST and negative when i is a node in WEST. Assume that for each node i∈G, y(i)  =  μ  +  σf2(i). This simple model implies that y is larger than μ on the EAST nodes and smaller than μ on the WEST nodes.

This model will be useful below because ρπ(y,f2) = 1 and [formula] for [formula]. This leads to several simplifications.

A key limitation of the [formula] is that it samples nodes "with replacement" (Section [\ref=sec:replacement] examines the rate of resampling). In classical sampling, "sampling with replacement" is justified when the population N is infinite. The second example model will illustrate the results for network driven sampling on a model for an infinite population graph.

The Stochastic Blockmodel for a random network G supposes that each node is assigned to one of K classes with probabilities [formula]. Conditioning on these class assignments, nodes connect independently with probabilities that depend only on the class memberships [\citep=holland1983stochastic]; for symmetric Ψ∈[0,1]K  ×  K,

[formula]

Let G be sampled from the Stochastic Blockmodel and let P be a simple random walk. Define

[formula]

As the graph population N increases, Buv contains the limiting probabilities that a node in class u refers a node in class v. If the node features y(i) are constant within the blocks, then the infinite population graph can be studied with

[formula]

Here, the random walk on the infinite population simplifies to a random walk on the K different classes in the Stochastic Blockmodel.

The standard O-notation is used below; h(n)  =  o(g(n)) means that h(n) / g(n)  →  0 as n  →    ∞  ; h(n) = O(g(n)) means that h(n)  ≤  Mg(n) for all n, for some constant M.

The variance of RDS

The next theorem provides an exact formula for VarRDS() as a functional of [formula], defined as follows.

Select two nodes I,J uniformly at random from the tree [formula]. Define the random variable D  =  d(I,J) to be the graph distance in [formula] between I and J. Define [formula] as the probability generating function for D,

[formula]

In practice, [formula] is observed. So, the function [formula] can be computed (e.g. see Figure [\ref=fig:bothTrees]). In many studies there are multiple seed nodes. In these cases, [formula] is a "forest" and [formula] can be computed by setting d(I,J)  =    ∞   if I and J are in different connected components of [formula].

Suppose that the Markov transition matrix P is reversible with respect to π and that the second eigenvalue of P is less than one in absolute value, then

[formula]

where the subscript RDS denotes that data have been collected through a [formula], [formula] is defined in Equation [\eqref=eq:avg], 〈  ·  ,  ·  〉π is defined in Equation [\eqref=def:inner], [formula] are the eigenvectors of P corresponding to eigenvalues [formula], and [formula] is defined in Definition [\ref=def:probgen].

This theorem gives a closed form expression for the variance of [formula] by decomposing y with the eigenbasis for the Markov transition matrix P. In an asymptotic setting where the number of samples is growing, the coefficient [formula] and the eigenvalues [formula] remain unchanged; it is the function [formula] that changes with n. In previous research, [\cite=verdery2013network] and [\cite=acrds] have proven this theorem for the special case that [formula] is a chain.

In the various forms of network driven sampling, it is likely that the tree [formula] will change from one experiment to the next. Theorem [\ref=thm:var] shows that the variance of [formula] changes with the tree, via the function [formula]. A similar phenomenon happens in linear regression, where the design matrix controls the covariance of the estimator and the design matrix may change if the experiment were repeated. Because of this, the standard estimators of the covariance condition on the design. One argument for conditioning is formalized by the conditionality principal in [\citep=birnbaum1962foundations]. In an analogous fashion, Theorem [\ref=thm:var] conditions on the tree [formula] .

The first step of the proof shows that if d(σ,τ)  =  t, then by the reversibility of P,

[formula]

where [formula] is a Markov chain with the same transition matrix P. Then, using Equation [\eqref=eq:tsteps] in Lemma [\ref=lem:spec],

[formula]

Summing over all σ,τ and exchanging summations yields the result. The appendix contains the full proof.

In Example [\ref=ex:yf2], y(i)  =  μ  +  σf2(i) for all nodes i∈G. Under this model, Equation [\eqref=eq:var] has a particularly simple form,

[formula]

Motivated by this example, the next corollary simplifies Equation [\eqref=eq:var] with bounds that do not depend on the simple form y(i)  =  μ  +  σf2(i). Recall that the ordering of the eigenvalues is in absolute value, [formula].

Under the conditions of Theorem [\ref=thm:var], if λ2  >  0, then

[formula]

where DE() is the design effect defined in Equation [\eqref=eq:de].

If the outcome of interest y correlates with the largest bottleneck in the network (i.e. ρ2π(y,f2) > 0), then the design effect is asymptotically proportional to [formula]. As such, the [formula] has a bounded design effect if and only if [formula]. To examine this, Section [\ref=sec:tree] gives upper and lower bounds for [formula].

Paths towards estimating the variance

Motivated by the two example models in Section [\ref=sec:examples], this section highlights two paths towards estimating the variance define in Theorem [\ref=thm:var]. The first estimator does not have any precedence in the literature. The second estimator provides a closed form generalization of a popular bootstrap estimator that was proposed in [\cite=salg]. Due to space limitations, the details of these estimators are not explored in the current paper.

Example [\ref=ex:yf2]

Under the model y  =  μf1  +  σfk, for k  >  1, VarRDS() has a particularly simple form, [formula]. To form a plug-in estimator, there are standard estimators for σ and the function [formula] is easily computable. To estimate the only remaining quantity λk requires the model on y. Using this model, the covariance between adjacent observations [formula] simplifies from Equation [\eqref=eq:cov],

[formula]

So, the autocorrelation (at lag one) of the [formula] is exactly λk. The sample autocorrelation provides an estimator. The resulting plug-in estimator will be explored in future research.

Example [\ref=ex:sbm]; model based inference

To examine the [formula] in an infinite population model, Example [\ref=ex:sbm] proposes the Stochastic Blockmodel. Suppose that each of the K blocks has a mean outcome [formula]. For each observation [formula], we observe Yτ  =  y(Xτ)  +  ετ, where Xτ is the block membership of sample [formula] and ετ is an independent error with mean zero and variance σ̃2. From Theorem [\ref=thm:var], if Xτ is a [formula],

[formula]

where [formula], and π are not defined with respect the transition matrix P, but instead with respect to the transition matrix B in Equation [\eqref=eq:sbmB] on the blocks [formula].

Previous research has estimated VarRDS() for binary outcome y by using y to construct a two block Stochastic Blockmodel and employing a parametric bootstrap [\citep=salg] [\citep=szwarcwald2011analysis] [\citep=johnston2013empirical]. Equation [\eqref=eq:sbmvar] generalizes this approach and provides a closed form solution. In both the case here and the case in [\cite=salg], the underlying network is modeled with a Stochastic Blockmodel where observed node features (e.g. demographic characteristics, health status, etc) determine the blocks; then, B̂ and ŷ can be computed with sample proportions. The resulting plug-in estimator is

[formula]

This estimator will be explored in future research.

Asymptotic behavior of the design effect

To understand the design effect of RDS, Corollary [\ref=cor:DEbounds] shows that it is necessary to understand how [formula] depends on the sample size n. If [formula] as n  →    ∞  , then the design effect for [formula] is bounded. Otherwise, the design effect grows with n.

Subsections [\ref=sec:lowerBound] and [\ref=sec:upperBound] give lower and upper bounds to [formula], respectively. These subsections illustrate the upper and lower bounds with m-trees. These are trees in which every participant refers exactly m future participants, until the final round, in which there are zero referrals. Section [\ref=sec:gwp] applies the bounds to random trees in which each participant refers an iid number of participants (i.e. Galton-Watson trees).

Lower bounds for [formula]

Select two nodes I,J from [formula] uniformly at random. Define the random variable D  =  d(I,J) to be the graph distance in [formula] between I and J. Define [formula] to be the distance from J to the root. Then

[formula]

where [formula] is the average distance from the seed node, [formula] is the diameter of the [formula], and [formula] is the height of the tree.

Define β  =  1 / λ22. If [formula] is an m-tree, with m  >  β, then

[formula]

where the second inequality follows from the fact that when [formula] is an m-tree, [formula]. This implies that the design effect grows when m  >  β. However, for m < β, this lower bound is not tight.

When z > 0, [formula]

This bound matches the bound in inequality [\eqref=eq:Galpha] when m  =  β. Together Facts [\ref=fact:Gbounds] and [\ref=fact:oneovern] show that when m  <  β, the design effect does not converge to zero, and when m  >  β the design effect grows with n. Said another way, when m  <  β, the estimators do not converge faster than the standard [formula] rate, and when m  >  β, the estimators converge slower than the standard [formula] rate. These are lower bounds. The next section gives a matching upper bound under an additional "balanced" condition on [formula].

Upper bound for [formula]

Upper bounding [formula] requires a more global assumption about the "balance" of [formula]. Note that [formula] is small when d(I,J) is likely to be big (i.e. [formula] has a smaller variance when most distances are large). Define [formula] to be the distance from the root to node I. For [formula], define [formula] to be the most recent common ancestor of σ and τ. The formula

[formula]

shows that most pairwise distances d(I,J) are large when [formula] is large for most nodes and when [formula] is small for most pairs. In essence, the balanced condition is a way of ensuring that [formula] is small.

For [formula], define [formula] as the set of ancestors of σ, that is the nodes in [formula] that fall along the shortest path between σ and the root (for convenience, include [formula]). Define the descendants of [formula] in the nth generation as

[formula]

Because 0 is the root node, [formula] contains all nodes in generation n and [formula] is the number of nodes in generation n. A tree [formula] grows at rate m if there exist positive constants [formula] and [formula] such that for all n,

[formula]

Notice that this implies [formula] is an infinite tree. The results below study [formula], the induced subgraph of [formula] that is formed by all nodes τ with [formula].

Suppose that [formula] grows at rate m. For [formula] with [formula], define

[formula]

Because [formula] and the tree is assumed to grow at rate m, these constants are finite; cτ  ≤  mk  <    ∞  . However, under a sequence of τn, cτn could be unbounded. A tree satisfies the balanced assumption if there exists a constant c such that for all n,

[formula]

That is, the second moment of the cτ's is uniformly bounded across all generations. For example, m-trees grow at rate m and satisfy the balanced assumption because cτ  =  1 for all τ.

Let [formula] be an infinite tree that grows at rate m. Define [formula] as the node induced subgraph of [formula] that contains all nodes [formula] satisfying [formula]. Define [formula] as in Definition [\ref=def:probgen] with tree [formula]. If [formula] satisfies the balanced assumption, then

[formula]

where β  =  λ- 22, α  =   log mλ- 22, and c is a constant that could depend on m and λ2, but is independent of n.

The growth rate assumption implies that [formula] has n  =  O(mh) nodes. So, Fact [\ref=fact:Gbounds] yields matching lower bounds; the β threshold is identical and the rates differ only by log n terms.

The upper bound in Theorem [\ref=thm:upperBound] comes from upper bounding [formula], where I and J are nodes selected uniformly at random from [formula]. First, condition on [formula] and [formula]. Then, [formula] is determined by [formula]. In order to use the fact that I and J are independent,

[formula]

These terms are related to c2τ. So, the balance condition provides a bound. Finally, the growth rate assumption provides bounds for [formula]. Appendix [\ref=ap:upperBound] contains the full proof for Theorem [\ref=thm:upperBound].

To see the necessity of the balanced condition, suppose that a tree grows at rate m > 1 and every generation t - 1 contains a single node that produces all nodes in generation t. Because m > 1 there is a non-vanishing probability that I and J come from the final generation h. On this event, I and J have the same parent and D  =  d(I,J)  =  2. As h grows, [formula] will not decay. So, to have an upper bound that decays as the tree grows must prevent this unbalanced tree. An assumption similar to the balanced condition has appeared previously; Proposition 3.3 in [\cite=lyons1990] implies that a balanced tree is "quasi-spherical."

Galton-Watson [formula]

A Galton-Watson (GW) tree is a random tree parameterized by its offspring distribution. Starting at the root node, and iterating through all future generations, each node takes an iid draw from the offspring distribution and produces this many offspring. This process is highly studied with several classical results (e.g. [\cite=athreya1972branching]).

Let ξ be a generic draw from the offspring distribution distribution and denote [formula]. The results from the last section identified the critical threshold m  ≥  λ- 22 using m-trees (i.e. Var(ξ) = 0). This section shows that this threshold also applies to GW trees with Var(ξ) > 0, under the assumption that [formula].

To have a positive probability that the tree generates an infinite number of nodes, the results below require that m > 1. Denote [formula] as the sub-tree of [formula] that includes all nodes within distance h of the root.

[\citep=kesten1966limit] Suppose [formula] is a random Galton-Watson tree. Let ξ be a single draw from the offspring distribution; presume that [formula] and [formula]. Conditioned on the survival of the GW process, [formula] grows at rate m, a.s..

See [\cite=lyons1995conceptual] for a conceptual proof of the Kesten-Stigum Theorem.

Under the conditions of Theorem [\ref=thm:ks], [formula] has n  =  O(mh) nodes. As such, the function [formula] built from [formula] will have the same lower bound as m-trees (see the discussion after after Fact [\ref=fact:Gbounds]). A matching upper bound on [formula] requires a fourth moment assumption on ξ.

Suppose [formula] is a random Galton-Watson tree. Let ξ be a single draw for the offspring distribution; presume that [formula] and [formula]. Conditioned on the survival of the GW process, [formula] satisfies the conditions of Theorem [\ref=thm:upperBound] (i.e. it grows at rate m and it is balanced, a.s.).

In the context of RDS, the offspring distribution is typically bounded by three. As such, the assumption that [formula] is certainly satisfied. The proof relies on the fact that cτ is the supremum of the standard Galton-Watson martingale. Then, it relies upon the Lp maximal inequality for martingales. The full proof is contained in the appendix, Section [\ref=app:gwp]. The following theorem combines the previous results, identifying a critical threshold for the design effect, DE().

Suppose [formula] is a random Galton-Watson tree. Let ξ be a single draw for the offspring distribution; presume that [formula] and [formula]. Conditioned on the survival of the GW process. Define [formula] as the node induced subgraph of [formula] that contains all nodes [formula] satisfying [formula]. Let P be a Markov transition matrix on G that is reversible with respect to its stationary distribution π. Under the [formula], let h be constructed with the samples from [formula]. If ρ2π(y,f2)  >  0 and λ2 > 0, then

[formula]

where DE is defined in Equation [\eqref=eq:de], [formula] is equality up to ( log n)2 terms, β  =  λ- 22, and α  =   log mλ- 22.

The proof combines the previous results. It is contained in Section [\ref=app:gwp] of the appendix. Note that after making the appropriate substitutions, Theorem [\ref=thm:critical] holds under the infinite population model from Example [\ref=ex:sbm].

While it would be exceedingly interesting to allow the number of referrals of node [formula] to depend on Xτ or Yτ, potentially confounding the results, our results do not allow for this. For Theorem [\ref=thm:var] to hold, [formula] must be independent of the Markov process.

The gap between sampling with and without replacement

The [formula] is a Markov model for the network driven sampling mechanism. This model allows for nodes to be sampled multiple times. However, several applications of network driven sampling do not allow "with replacement sampling." In classical sampling, when the sample size n is small with respect to the population size N, "with replacement sampling" can approximate "without replacement sampling". This section extends this notion to network driven sampling. This section shows that under certain conditions, the rate of resampling for the [formula] is not affected by the critical threshold m > λ- 22.

Define the number of repeated pairs as

[formula]

The argument below studies the asymptotic behavior of [formula] as n and N grow in tandem. In short, [formula] (with some additional assumptions) implies that the rate of [formula] does not depend on λ2. This argument shows that, in expectation, the critical threshold does not create additional repeated pairs.

Under the [formula], suppose that G is undirected and P is a simple random walk. If node degrees in G are less than D, then

[formula]

The proof is based on the fact that if Xσ  =  i, the probability of transitioning back to the state of Xσ' is 1 / deg(i)  ≥  1 / D. The full proof is contained in Section [\ref=app:replacement] of the appendix.

As Proposition [\ref=prop:lowerRn] shows, the [formula] can have several repeated samples. However, this alone does not prevent the variance from decaying at rate 1 / n; the decay of the variance is determined by the critical threshold, m  >  λ- 22.

Because Rn counts pairs of repeats, [formula] could grow at rate n2. The next result shows that under certain conditions, this is not the case; when ignoring log terms, Theorem [\ref=thm:upperRn] provides a matching upper bound on [formula].

Consider a sequence of samples [formula] that are sampled from a [formula] -walk on GN, where n and N are both growing. Suppose that the sequence [formula] satisfies the conditions of Theorem [\ref=thm:upperBound]; that is, there is a balanced infinite tree [formula] that grows at rate m and [formula] is a sequence of subtrees that successively add one generation at a time.

If (1) the stationary distribution is bounded, πi  ≤  c / N for all i and all N; (2) the number of eigenvalues [formula] that exceed the critical threshold [formula] is bounded by k for all N; and (3) [formula], then

[formula]

Notice that condition (1) is implied by the sparse graph assumption in Proposition [\ref=prop:lowerRn]. Importantly, this upper bound does not depend on λ2. So, under the conditions of these results, λ2 and the critical threshold do not effect the rate of [formula].

The key to proving Theorem [\ref=thm:upperRn] is the relationship between the trace of a matrix and its eigenvalues. First, notice that

[formula]

Then, this probability relates to the trace of P.

[formula]

Sum over σ  ≠  τ (from Equation [\eqref=eq:ern]), exchange summations, and express the terms as [formula] functions. Theorem [\ref=thm:upperBound] bounds these terms. The full proof is contained in Section [\ref=app:replacement] of the appendix.

A simulation of without replacement sampling and the [formula]

This simulation compares the [formula] to without replacement network sampling. The simulations are performed on networks simulated from the Stochastic Blockmodel. The ten panels in Figure [\ref=fig:replacement] correspond to ten different networks that are simulated from ten different Stochastic Blockmodels. Each of the ten networks has N  =  10k nodes, equally balanced between group zero and group one. The probability of a connection between two nodes in different blocks is r and the probability of connection between two nodes in the same block is p + r. Figure [\ref=fig:replacement] controls the parameters p and r with the expected degree rN  +  pN / 2 and the second eigenvalue of [formula],

[formula]

where expectations are under the Stochastic Blockmodel (cf example on page 1893 of [\cite=rohe2012sp]). In group zero, yi  =  0 and in group one, yi = 1. The horizontal axis in each plot represents the sample size; the vertical axis represents the design effect (as estimated via simulation). The five columns of plots correspond to five different values of [formula].

The trees are simulated to have m = 2. So, Theorem [\ref=thm:critical] suggests that design effect should grow when λ2 exceeds [formula]. In the left most plots, the solid lines are roughly flat. In the right most plots, the solid lines are quickly increasing. This shows that the [formula] has a critical threshold somewhere between .6 and .8; this is consistent with the theory. Similarly, the dashed lines are roughly flat in the left plots and quickly increasing in the right plots. This confirms that without replacement network sampling has a similar critical threshold.

In the first row of plots, each node has an expected degree of fifty. In the second row of plots, each node has an expected degree of fifteen. In the top row, the solid and dashed lines are close because there are fewer repeated samples. In the bottom row, the lines for the sparse graphs are not as close. However, both rows display the same qualitative behavior (flat when λ2  =  .6 and increasing when λ2 = .8). The specific simulation settings are described in Section [\ref=app:replacementSim].

Empirical illustration

Theorem [\ref=thm:var] expresses the variance of the RDS derived estimator as a function of the eigenstructure of the referral process P and the function [formula], which is computed from the sampling tree [formula]. To illustrate the various ways that P and [formula] can influence the variance, the next two subsections investigate the properties of P and [formula] for previously recorded data. Subsection [\ref=sec:pol] examines the political blog network from [\cite=adamic2005political]. Subsection [\ref=sec:empiricalTrees] examines the function [formula] computed from 18 different referral trees that have been previously published in the RDS literature.

Eigenstructure of the political blog network

[\cite=adamic2005political] recorded the hyperlink network among popular political blogs after the 2004 US presidential election between Bush and Kerry. Numerous publications on the Stochastic Blockmodel have studied this network (e.g. [\cite=karrer2011stochastic] and [\cite=chen2012fitting]). The nodes in this data have a feature that indicates whether the blog supported Kerry or Bush. A connection between the blogs corresponds to a hyperlink. All edges in the networks have been made symmetric and the following analysis uses the largest connected component in the 2-core of the networks. Taking this network as G, this experiment samples the network with a [formula]. The node feature y(i) is a binary variable indicating whether blog i supports Kerry. The population average μtrue  ≈  .5 is the proportion of blogs which support Kerry.

Theorem [\ref=thm:var] allows for the computation of the exact design effect, conditional on the sampling tree [formula]. Figure [\ref=fig:blogDE] provides the results for three trees sampled from the Galton-Watson distribution (see Section [\ref=sec:gwp] for a definition). In this network, the critical threshold is λ- 22  ≈  1.2. Each of the three trees has a different average number of referrals that each participant provides 1, 1.2, and 3.

Figure [\ref=fig:blogDE] shows very large design effects. The reason for this is explored in Figure [\ref=fig:blogGraphs] which displays (1) the network of political blogs, with nodes colored by the politician that they support, and (2) the leading eigenvectors [formula] of the simple random walk Markov transition matrix P. To emphasize the structure of the eigenvectors, the figures dichotomize the individual elements into +/- values, represented by black and white. The title of each plot gives the corresponding eigenvalue. Because the Kerry-Bush divide creates a strong bottleneck (only about 10% of edges cross the political partition), the bottleneck is represented in the leading eigenspace of the P. As such, the Volz-Heckathorn estimator for "the proportion of blogs which are Kerry blogs" is likely to have a large standard error.

The design effect with empirical referral trees

In practice, the function [formula] is exactly computable because [formula] is observed. Using 18 trees that were published in previous RDS papers, Figure [\ref=fig:bothTrees] presents the function [formula] as a function of λ2∈[0,1]. To ensure a fair comparison across different sample sizes, the vertical axis represents the design effect under the assumption that y = f2, so that the design effect is exactly [formula] (cf Example [\ref=ex:yf2]). In practice, the design effect could be estimated by creating an estimate for λ2 (cf Section [\ref=sec:paths]).

The legend gives the number of samples in each tree. The tree of 586 comes from a study of drug users in New York City [\citep=abdul2006effectiveness]. The tree of 112 comes from a study of injection drug users in Connecticut [\citep=heckathorn1997respondent]. The trees of 14, 19, 23, 23, 65, and 152 come from a study of men who have sex with men in Higuey, Dominican Republic [\citep=gile2015diagnostics]. The remaining ten trees come from a study of 25 villages in rural Uganda [\citep=mccreesh2012evaluation]. As expected, all of the lines are upward sloping, indicating that stronger bottlenecks produce larger design effects. Moreover, the larger trees are more sensitive to the bottleneck strength.

The right panel of Figure [\ref=fig:bothTrees] further illustrates this result. It presents the function [formula] for a set of 2-trees, where every node has exactly two offspring. Here again, the larger trees are more sensitive to stronger bottlenecks; the design effect explodes when [formula]. However, so long as [formula], the design effect is largely insensitive to the bottleneck.

Discussion

This paper studies network driven sampling using the [formula]. Under this approach, only the referrals are random. The network and node features are fixed. Theorem [\ref=thm:var] gives a closed form expression for the variance of [formula] when it is constructed from a network driven sample. This expression combines the following three elements: (1) the eigenfunctions and eigenvalues [formula] of the Markov transition matrix P, (2) the covariance between the node feature and the eigenfunctions [formula], and (3) the bushiness of the referral tree as measured by the function [formula]. Corollary [\ref=cor:DEbounds] shows that if ρ2π(y,f2) > 0, then the design effect is asymptotically proportional to [formula]. Using two example models, Section [\ref=sec:paths] proposes two paths towards estimating the variance from observed data.

The formula for VarRDS() in Theorem [\ref=thm:var] is conditional on the sampling tree [formula]. To study the asymptotic behavior of the design effect requires that the tree grows. The results in Section [\ref=sec:tree] identify the fundamental features of the tree that characterize this asymptotic behavior. Under the assumption that the tree is balanced, the growth rate m determines the asymptotic rates for the design effect. The specifics of the tree only appear in the constants. When the tree is balanced and grows at rate m, the upper and lower bounds identify the same critical threshold. If m < β  =  λ- 22, then ignoring log terms, the design effect is O(1). However, if m  >  β, then ignoring log terms, the design effect is O(n1 - α), where α  =   log mβ∈(0,1). In order for the upper and lower bound to match, the balanced assumption is necessary. To understand the stringency of the balanced condition, Section [\ref=sec:gwp] shows that if [formula] is a random Galton-Watson tree with [formula], where ξ is a draw from the offspring distribution, then the tree is balanced a.s.. The lower bound does not require the balanced assumption; the classical Kesten-Stigum theorem shows that the lower bound only requires [formula].

Section [\ref=sec:replacement] examines how well the "with replacement" [formula] approximates a "without replacement" network driven sampling mechanism. Proposition [\ref=prop:lowerRn] and Theorem [\ref=thm:upperRn] give matching lower and upper bounds on [formula], the expected number of repeated pairs in a [formula]. So long as [formula], and some further technical conditions, These bounds show that λ2 and the critical threshold do not affect the rate of [formula]. As such, the critical threshold does not create additional repeated pairs. Subsection [\ref=sec:replacementSim] presents a simulation comparing the [formula] to a without replacement network driven sample. Under the simulation settings, both the with replacement and without replacement samples displayed a similar critical threshold.

To illustrate the analytic results for the [formula], Section [\ref=sec:emp] studies simulated and empirical data. Subsection [\ref=sec:pol] uses [formula] to sample the political blog network. Because the node covariate is strongly related to the leading eigenspace, network driven estimators have an excessively large design effect. Figure [\ref=fig:bothTrees] in Subsection [\ref=sec:empiricalTrees] gives the design effect for synthetic 2-trees and empirically observed referral trees from a wide range of RDS studies. In both, the larger trees display a greater sensitivity to the bottlenecks in the social network.

Taken together, this research presents a disheartening bias-variance tradeoff that arrises in the process of data collection. Applications of RDS initialize with a convenience sample (i.e. not the stationary distribution). So, estimators are potentially biased. However, because the process converges to the stationary distribution exponentially fast in the number of steps, the VH estimator is asymptotically unbiased. For this reason, practitioners strive for longer chains. To obtain long chains, while ensuring that the process does not die, many studies obtain one very large recruitment tree; often there are several other trees which are much smaller. In this respect, the critical threshold and Figure [\ref=fig:bothTrees] present a disheartening conflict; the larger trees are more sensitive to the strength of the bottleneck λ2 and they have larger design effects. While longer chains are preferred for an unbiased sample, if these long chains are achieved by a bushy structure in [formula], then the variance can be excessive relative to the number of sample obtained. As such, there is a fundamental conflict between obtaining an unbiased sample and small standard errors. [\cite=goel2009respondent] realized this conflict under a 2-tree and a simplified network model. Future research should study various data collection procedures to manage this conflict. For example, both the bias and variance would decrease if (1) implementation prevented [formula] from growing geometrically, while (2) ensuring that the referral process does not go extinct.

Proof of Theorem [\ref=thm:var]

The proof requires some notation and the following lemma. Throughout, let [formula] be a [formula]. Let [formula] be a Markov chain with the same transition matrix P that is initialized from π. Define d(σ,τ) as the graph distance between nodes σ and τ in [formula].

If the transition matrix P is reversible, then for any two nodes σ and τ in the referral tree,

[formula]

Let [formula] be the most recent common ancestor of σ and τ. By the reversibility of the process,

[formula]

The following is a proof of Theorem [\ref=thm:var].

[formula]

For ease of notation, let t  =  d(σ,τ). From Lemma [\ref=lem:rev] (and suppressing the RDS subscript),

[formula]

Using the spectral decomposition of P (see Lemma [\ref=lem:spec]), with the fact that f1 is a constant vector and λ1 = 1 [\citep=levin2009markov],

[formula]

Terms cancel. So,

[formula]

Then,

[formula]

Proof of Corollary [\ref=cor:DEbounds]

The proof of Corollary [\ref=cor:DEbounds], uses two lemmas.

For σ2  =  VarRDS(Y0),

[formula]

This proof is given on page 342 of [\cite=levin2009markov] and is repeated here for completeness.

[formula]

For any [formula] that satisfies the conditions of Theorem [\ref=thm:var],

[formula]

Define y  =  fk, then [formula] For k = 1, [formula].

Now, a proof of Corollary [\ref=cor:DEbounds]

By the definition of the ordering, [formula] and the assumption λ2  >  0, it follows that [formula] for [formula]. This implies [formula] for any d. It then follows that [formula]. So,

[formula]

Because [formula] for all [formula],

[formula]

To convert to DE, divide by Varπ()  =  VarRDS(Y0) / n  =  σ2  /  n.

Proof of lower bounds

The following is a proof of Fact [\ref=fact:Gbounds].

The first inequality follows directly from Jensen's inequality. The next inequalities use

[formula]

Also, notice that [formula]. The result follows from the restriction that |z| < 1.

The following is a proof of Fact [\ref=fact:oneovern].

As before, denote D  =  d(I,J).

[formula]

Proof of upper bounds

The proof will use the following fact about a finite geometric series:

[formula]

The following is a proof of Theorem [\ref=thm:upperBound].

An upper bound on [formula] provides an upper bound on [formula].

[formula]

First, bound the terms on [formula] and [formula] with the growth rate assumption,

[formula]

To bound the [formula] term, define

[formula]

A key idea in what follows is that [formula]. Then, because I and J are independent, this probability breaks apart into two terms.

[formula]

By the definition of cτ,

[formula]

So,

[formula]

By the balanced assumption, there is a constant c  <    ∞   such that for all [formula],

[formula]

So, use equation [\eqref=eq:geoseries] and let the constant depend on m,

[formula]

By the growth rate assumption, m- h  ≤  cn- 1 and h  ≤  c log n. So,

[formula]

When mz2 = 1, the sum contributes 2h  ≤  c log n and the rate is n- 1( log n)2. Using the fact about geometric series in equation [\eqref=eq:geoseries], for [formula],

[formula]

When mz2 < 1, the leading term gives the rate because the fraction converges to a constant. However, when mz2 > 1, the fraction explodes.

[formula]

GWP

The following is a proof of Lemma [\ref=thm:gwp].

Because trees that go extinct are balanced, it is not necessary to condition on survival. The proof below shows that if [formula] is generated from the GW with a finite fourth moment, then it is balanced a.s..

Each node [formula] generates an identically distributed GW tree below it. Denote

[formula]

Across all values of τ, Wτ+ are identically distributed. Moreover, within a single generation of the tree (i.e. [formula]), Wτ+ are independent. The same holds for Zτn,Wτn and Wτ. So, dropping the superscript τ will correspond to a generic iid draw from the same distribution.

The values Wτ+ correspond to the cτ's in the balanced assumption. We wish to bound

[formula]

where C is a random variable that does not depend on h.

Under the conditions of the theorem, [formula].

A proof of this lemma is given following the proof of the theorem.

Using Borel-Cantelli, the argument below will show that for [formula] and ε > 0,

[formula]

As such, a.s. there exists a variable C(ω) that satisfies the balanced condition.

Denote Zk  =  Z0k. Let [formula] denote the filtration [formula]. By Chebyshev's inequality,

[formula]

Then,

[formula]

Using this to bound equation [\eqref=eq:lastone],

[formula]

By Theorem 1 in [\cite=ney2003harmonic], there exists some constant ρ < 1 and some other constant c such that

[formula]

Because this is a summable sequence, Borel-Cantelli implies the desired result.

The following is a proof of Lemma [\ref=lem:limW].

Define

[formula]

By the Monotone Convergence Theorem, [formula]. So, it is enough to show that [formula].

By the Lp maximum inequality (e.g. Theorem 5.4.3 in [\cite=durrett]), [formula], and Jensen's inequality,

[formula]

[\cite=bingham1974asymptotic] shows that [formula] implies [formula], concluding the proof.

Next a proof of Theorem [\ref=thm:critical].

First, a proof of the upper bound. From Corollary [\ref=cor:DEbounds], [formula]. By the Kesten-Stigum Theorem, [formula] grows at rate m. From Lemma [\ref=thm:gwp], [formula] is balanced. So, Theorem [\ref=thm:upperBound] gives upper bounds for [formula]. Multiplying the bounds by n yields the upper bound on DE given in Equation [\eqref=eq:critical].

For the lower bound, [formula] for a generic positive constant, c  >  0. By Fact [\ref=fact:Gbounds], [formula]. By the Kesten-Stigum Theorem, [formula] grows at rate m. So, [formula]. So, h  ≤   log mn  -  c. Performing the algebra analogous to Equation [\eqref=eq:Galpha], yields [formula]. Multiplying by n and combining this with Fact [\ref=fact:oneovern] yields the lower bound.

Sampling with replacement results in Section [\ref=sec:replacement]

The following is a proof of Proposition [\ref=prop:lowerRn].

Let [formula] denote a node that is distance two away from [formula]. Let [formula] be the intermediate node between σ and σ''. Because G is undirected and P is a simple random walk, P is reversible. So, the direction of the edges between σ,σ', and σ'' does not matter.

[formula]

The following is a proof of Theorem [\ref=thm:upperRn]

Using properties of the trace function,

[formula]

Then,

[formula]

where

[formula]

From properties of the Markov transition matrix, λ1 = 1. So, [formula]. By assumption (2), [formula] for some constant k. By Theorem [\ref=thm:upperBound], [formula] implies [formula] for α  =   log mλ- 22  >  0. Similarly, [formula] implies [formula]. Substituting these values,

[formula]

By assumption (3), the first two terms converge to zero, leaving the third and final term which yields the result.

Simulation settings for Figure [\ref=fig:replacement]

Figure [\ref=fig:replacement] compares the [formula] to without replacement network driven sampling. The simulation first generates [formula] as a Galton-Watson tree with offspring distribution 1  +   Binomial(2,1 / 2). Trees are sampled until a tree reaches 2000 nodes; while only 500 samples are kept, it will become clear why [formula] must be initialized to be large that 500. This tree is seeded with a node selected from the stationary distribution. The simulation iterates through the tree, one node at a time in the fashion of a breadth first search, filling the future generations of [formula] by sampling without replacement from the viable friend list; a friend is viable if it has not yet appeared in [formula]. If [formula] should produce three referrals, but Xσ does not have that many viable friends, then the tree is pruned accordingly; all viable friends are sampled and the remaining descendants in [formula] are removed; this happens infrequently in the simulation. Once 500 nodes are sampled, the remaining nodes in [formula] are pruned. This pruned tree is then used to run the [formula]. For each of the ten networks, this process is simulated 1000 times. The sample variance across these 1000 samples is divided by the variance of uniform with replacement sampling, (4n)- 1.

Bibliography