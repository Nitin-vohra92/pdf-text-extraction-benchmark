Towards Real-Time Detection and Tracking of Blob-Filaments in Fusion Plasma Big Data

Shell : Bare Demo of IEEEtran.cls for Computer Society Journals

"big data" has increasing influence on our daily life and research activities, it poses significant challenges on various scientific research areas. To extract knowledge from the massive amounts of data available, data mining techniques are frequently used. Many traditional data mining techniques attempt to find patterns occurring frequently in the data. In this work, we explore outlier detection approaches to discover patterns occurring infrequently. Outlier detection is employed in a variety of applications such as fraud detection, time-series monitoring, medical care, and public security [\cite=hodge2004survey] [\cite=han2006data]. A well-known definition of "outlier" is given in [\cite=han2006data]: "a data object that deviates significantly from the rest of the objects, as if it were generated by a different mechanism". In some cases, outliers are treated as errors or noise to be eliminated; while in many other cases, outliers can lead to the discovery of important information in the data.

With increased global energy needs, magnetic fusion could be a viable future energy that is inexhaustible, clean, and safe. The success of magnetically-confined fusion reactors, like the International Thermonuclear Experimental Reactor (ITER) [\cite=aymar2002iter], demand steady-state plasma confinement which is challenged by the blob-filaments driven by the edge turbulence. A blob-filament (or blob) is a magnetic-field-aligned plasma structure that appears near the edge of the confined plasma, and has significantly higher density and temperature than the surrounding plasma [\cite=d2011convective]. Blobs are particularly important to study since they convect filaments of plasma outwards towards the containment wall, which results in substantial heat loss, degradation of the magnetic confinement, and erosion of the containment wall. By identifying and tracking these blob-filaments from fusion plasma data streams, physicists can improve their understanding of the dynamics and interactions of such coherent structures (blobs) with edge turbulence.

During the last decade, there has been a significantly increasing need for knowledge discovery in spatial-temporal databases. Classical multi-dimensional outlier detection techniques are designed to detect global outliers. However, these techniques do not distinguish between non-spatial attributes and spatial attributes and do not consider apriori information about the statistical distribution of the data [\cite=shekhar2003unified]. Since spatial-temporal data types have unique characteristics and their relations are more complicated than ordinary data, dedicated outlier detection techniques are typically required to examine anomalies in data across space and time[\cite=Gupta2014Outlier]. In this study, we consider outliers with respect to their spatial neighbors and then track them over time. A spatial outlier is a spatial object whose non-spatial attribute values are sigfinicantly different from those of other spatial objects in its spatial neighborhood [\cite=shekhar2003unified]. In fusion plasma data, spatial outliers are associated with blob-filaments, which do not happen at a collection of scattered points but usually several groups of adjoining spatial points or regions. Detection and tracking of these multiple regions from a continuously arriving stream is a challenging task due to the various spatial scales and shapes of region outliers [\cite=zhao2003detecting] [\cite=lu2004wavelet].

This work is motivated by several considerations responding to extreme scale computing and big data challenges in fusion energy. Fusion experiments and numerical simulations can easily generate massive amounts of data per run. During a magnetic fusion device experiment (or "shot"), terabytes of data are generated over short time periods (on the order of hundreds of seconds). In the XGC1 fusion simulation [\cite=chang2009compressed] [\cite=ku2009full], a few tens of terabytes can be generated per second. Timely access to this amount of data can already be a challenge [\cite=Dong:2013:1] [\cite=Dong:2013:2], but analyzing all this data in real time is impractical. Currently, there are three types of analyses in most of fusion experiments: in-shot-analysis, between-shot-analysis, and post-run-analysis. All existing blob detection methods address post-run-analysis, but in this work, we focus on the more challenging first two cases to provide a real-time analysis so that scientists can monitor the progress of fusion experiments. Figure [\ref=fig:fusion_data_stream] presents a real-time analysis frame for finding blob-filaments in fusion plasma data streams. To perform this data analysis in real time, we utilize effectively modern supercomputers.

This work has been integrated into the International Collaboration Framework for Extreme Scale Experiments (ICEE), a wide-area in-transit data analysis framework for near real-time scientific applications [\cite=choi2013icee]. ICEE takes advantage of an efficient IO solution ADIOS [\cite=lofstead2008flexible], and a cutting-edge indexing solution FastBit [\cite=wu2009fastbit], to design and construct a real-time remote data processing framework over wide-area networks for international collaborations such as ITER. In this system, a blob detection algorithm is used to monitor the health of the fusion experiments at the Korea Superconducting Tokamak Advanced Research (KSTAR). However, existing data analysis approaches are often single-threaded, only for post-run analysis, and take a long time to produce results. Also, compared to the simulation data, the resolution of the raw camera data may be coarse, but interesting features can still be identified after normalization. In order to meet real-time feedback requirement, we develop a real-time blob detection method, which can leverage in-situ raw data in the ICEE server and find blob-filaments efficiently during the fusion experiments. Our blob detection algorithm is not limited to KSTAR only, and can be applied to other real fusion experiments and numerical simulations.

In this research, we apply outlier detection techniques to effectively tackle the fusion blob detection problem on extremely large parallel machines. The blob-filaments are detected as outliers by constantly monitoring specific features of the experimental or simulation data and comparing the real-time data with these features. Below we summarize our main contributions:

We formulate the blob detection and tracking problems as identifying different spatial region outliers over time in terms of the spatial-temporal fusion plasma data streams.

We propose a two-phase region outlier detection method for finding blob-filaments. In the first phase, we apply a distribution-based outlier detection scheme to identify blob candidate points. In the second phase, we adopt a fast two-pass connected component labeling (CCL) algorithm from [\cite=wu2009optimizing] to find different region outliers on a refined triangular mesh. To the best of our knowledge, this is the first time the CCL algorithm has been used to detect region outliers such as blob-filaments in fusion plasma.

We develop a high-performance blob detection approach to meet real-time feedback requirements by exploiting many-core architectures in a large cluster system. This is the first work to achieve real-time blob detection in only a few milliseconds.

We propose a scheme to efficiently track the movement of region outliers by linking the centers of the region outlier over consecutive frames.

We have implemented our blob detection algorithm with hybrid MPI/OpenMP, and demonstrated the effectiveness and efficiency of our implementation with a set of data from the XGC1 fusion simulations. Our tests show that we can achieve linear time speedup and complete blob detection in two or three milliseconds using a cluster at NERSC. In addition, we demonstrate that our method has better detection accuracy than recently developed state-of-the-art blob detection methods in [\cite=davis2014fast] [\cite=myra2013edge].

The rest of paper is organized as follows. In Section II, we give the problem formulation of the blob detection and discuss related work. In Section III we describe a two-phase region outlier detection algorithm and a tracking scheme for identifying and tracking blobs. We then present a real-time blob detection approach by leveraging MPI/OpenMP parallelization in a large cluster in Section IV. The blob detection and tracking results and its real time evaluation are shown in Section V. We conclude the paper, and give our future plans in Section VI.

Problem Definition and Related Work

In this section, we introduce our problem definitions and discuss previous work related to our study. For related work, we first discuss existing research work on outlier detection, and then review previous work on blob detection in fusion plasma domain.

Problem Definition

In fusion plasma, the definition of a blob is varied in the literature depending on fusion experiments or numerical simulations as well as available diagnostic information for measurements [\cite=d2011convective]. This makes blob detection a challenging task. Figure [\ref=fig:density_regions] shows an image of the local normalized density distribution in the regions of interest in one time frame. We can observe that there are two reddish spots located at the left portion of the image, which are associated with blob-filaments and are significantly different from their surrounding neighbors. It is clear that a reddish spot is not a single point but a group of connected points or a region. Therefore, we formulate the blob detection problem as a region outlier detection problem. Similar to the definition of a spatial outlier [\cite=shekhar2003unified], a region outlier is a group of spatial connected objects whose non-spatial attribute values are significantly different from those of other spatial surrounding objects in its spatial neighborhood. As shown in Figure [\ref=fig:density_regions], blobs are region outliers. The number of region outliers detected will be determined by pre-defined criteria provided by domain experts.

The problem is to design an efficient and effective approach to detect and track different shapes of region outliers simultaneously in fusion plasma data streams. By identifying and monitoring these blob-filaments (region outliers), scientists can gain a better understanding about this phenomena. In addition, a data stream is an ordered sequence of data that arrives continuously and has to be processed online. Due to the high arrival rate of data, the blob detection must finish processing before the next data chunk arrives [\cite=sadik2014research]. Therefore, another critical problem is to develop a high-performance blob detection approach in order to meet the real-time requirements.

Outlier Detection

The existing approaches to outlier detection can be classified into four categories: distance-based, density-based, clustering-based and distribution-based approaches [\cite=hodge2004survey] [\cite=han2006data].

Distance-based methods [\cite=knox1998algorithms] [\cite=angiulli2007detecting] use a distance metric to measure the distances among data points. It is based on comparing a data point with a given number of other data points. If the number of data points within a certain distance from the given point are less than some pre-defined threshold, then this point is determined to be an outlier. This approach could be very useful if the pre-defined threshold can be specified accurately. However, in practice, the data points often exhibit different densities in different regions of the data across space or time, then it may not be proper to use a simple threshold value.

Density-based methods [\cite=breunig2000lof] assign a local outlier factor (LOF) to each sample based on their local density. The LOF determines the degree of outlierness, which provides ranking scores for all sample points. Samples with high LOF value are identified as outliers. The advantage of this approach is that it does not require any prior knowledge of the underlying distribution of the data. However, this approach has a high computational complexity since the distance between each sample point and all other points has to be computed to obtain each local density value.

Clustering-based methods [\cite=guha1998cure] [\cite=he2003discovering] conduct clustering-based techniques on the sample points of the data to characterize the local data behavior. Since the clustering algorithms do not focus on outlier detection, the outliers are produced as by-products [\cite=guha1998cure] and thereby they are not optimized for outlier detection.

Distribution-based methods [\cite=Eskin00anomalydetection] [\cite=shekhar2003unified] applies machine learning techniques to estimate a probability distribution over the data and develop a statistical test to detect outliers. These methods can be broadly classified into two categories: one-dimensional outlier detection and multi-dimensional outlier detection [\cite=shekhar2003unified]. One-dimensional outlier detection considers the statistical distribution of the non-spatial attributes and ignores the spatial attributes of the objects when conducting statistical tests. Multi-dimensional outlier detection methods model data sets in a multi-dimensional isometric space and apply tests based on distance or density. These methods use all dimensions to define a neighborhood for comparison and do not distinguish non-spatial attributes from spatial attributes.

In this work, we first apply distribution-based outlier detection to detect outlier points by considering only non-spatial attributes and then leverage CCL to construct the region outliers to take spatial-attributes into account. We choose distribution-based outlier detection since it can solve the problem of finding outliers efficiently if an accurate approximation of a data distribution can be properly found [\cite=shekhar2003unified] [\cite=subramaniam2006online]. Normally the distribution of the stream data may change over time [\cite=Gupta2014Outlier]. However, this assumption may not hold in the fusion experiments since a real fusion experiment lasts very short time period from a few seconds to hundreds of seconds.

Blob Detection in Fusion Plasma

Independently, fusion blob detection problems have been researched by the physics community in the context of coherent structures in fusion plasma [\cite=d2011convective]. Various post-run blob detection methods have been proposed to identify and track these structures, to study the impact of the size, movement and dynamics of blobs. A plasma blob is most commonly determined by some threshold, computed statistically in the local plasma density signal [\cite=xu2012turbulent] [\cite=fuchert2013influence] [\cite=zweben1985search] [\cite=muller2006probabilistic]. However, the exact criteria have varied from one experiment to another, which reflects the intrinsic variability and complexity of the blob structures. In [\cite=xu2012turbulent], a conditional averaging approach is applied to analyze spatiotemporal fluctuation data obtained from a two-dimensional probe array inside the last closed flux surface (LCFS) of the HL-2A tokamak. When the vorticity is larger than one standard deviation at some time frame, a blob is considered to be detected by the probe. In [\cite=fuchert2013influence], the conditional averaging technique is also used to study the evolution of the blob-filaments using Langmuir probes and a fast camera. If a reference signal, with a certain sampling interval, has large fluctuation amplitude greater than a specified trigger condition, a blob structure is declared at that time frame.

Without using a conditional averaging technique, [\cite=zweben1985search] searches for blob structures can be done using local measurements of the 2D density data obtained from a 2D probe array. Identification of a blob is based on the choices of several constraints such as the threshold intensity level, the minimum distance of blob movement, and the maximum allowed blob movement between successive frames. The trajectories of the different blobs can be computed with the blob centers based on identification results in each time frame. The seminal work by Zweben, et. al.[\cite=zweben1985search] was the first attempt to take only individual time frame data into account to detect blobs and track their movements, although the process of identification of a blob was somewhat arbitrary and oversimplified. In [\cite=muller2006probabilistic], an analysis method was presented in terms of object-related observables to allow a sound probabilistic analysis. After preprocessing the signals from 2D imaging data to form signal matrix, a threshold-segmentation approach is used to identify blob structures when the local density is greater than an appropriately chosen threshold. Bounding polygons are also employed to track blob movements and compute their trajectories.

Due to the emergence of fast cameras and beam emission spectroscopy in the last decade, the situations of insufficient diagnostic access and limited spatial and temporal resolution have been greatly improved. In [\cite=love2007image], an image analysis for the identification of blobs has been presented based on gas puff imaging (GPI) diagnostic images from an ultra-high speed, high resolution camera. The raw images are first processed to remove the noise spikes, followed by further smoothing using a Gaussian filter. The blobs are identified by various image segmentation techniques after further processing which removes the background intensity from the images. However, due to noise and lack of a ground truth image, this approach can be sensitive to the setting of parameters, and it is hard to use generic method for all images. Some sophisticated statistical analysis techniques have been exploited to characterize the blob structures and motions. In [\cite=xu2006multiscale] [\cite=tanaka20102d], various researchers have leveraged eigenvalue or singular value decomposition technique to identify the basic components and properties of blob structures.

Recently, several researchers [\cite=davis2014fast] [\cite=kube2013blob] [\cite=myra2013edge] have developed a blob-tracking algorithm that uses raw fast camera data directly with GPI technique. In [\cite=davis2014fast] [\cite=myra2013edge], they leverage a contouring method, database techniques and image analysis software to track the blob motion and changes in the structure of blobs. After normalizing each frame by an average frame created from roughly one thousand frames around the target time frame, the resulting images are contoured and the closed contours satisfying certain size constraints are determined as blobs. Then, an ellipse is fitted to the contour midway between the smallest level contours and the peak. All information about blobs are added into a SQL database for more data analysis. This method is close to our approach but it can not be used for real-time blob detection since they compute time-averaged intensity to normalize the local intensity. Additionally, only closed contours are treated as blobs, which may miss blobs at the edges of the regions of interest. Finally, these methods are still post-run-analysis, which cannot provide real-time feedback in real fusion experiments.

Our proposed approach

In this section, we provide a detailed description of our proposed approach to region outlier detection for finding blobs. Given a fusion data stream, which consists of a time ordered sequence of sample frames that arrive continuously from real fusion experiments or numerical simulations through remote direct memory access protocols. Our data sets are simulated electron density from the fusion simulation code XGC1 [\cite=chang2009compressed] [\cite=ku2009full]. In the present data sets, simulation data is captured every 2.5 microseconds for a total time window of 2.5 milliseconds. Each point si∈S in a time frame t has a spatial attribute (r,z,t) which defines its location in a triangulated measurement grid, and some non-spatial attributes including all important plasma quantities such as electron density ne(r,z,t) as well as connectivity information in a poloidal plane. The spatial neighborhoods are defined for each point from the connectivity database in a triangulated grid. Formally, an region outlier responding to a blob is defined as a spatial area in the regions of interest where a subset Bi  ⊆  S is a group of connected outlier points si.

Our overall goal is to develop an algorithm to detect and track spatial region outliers (blobs) using a stream of fusion data. To achieve this, we propose a two-phase approach, as shown in Figure [\ref=fig:Two-phase_region_outlier_detection]. In the first phase, we apply a distribution-based outlier detection algorithm to the fusion data stream in order to detect outlier points which have significantly higher non-spatial attributes than other points. The outputs of this step are tuples (si,ne(ri,zi,t)), the 2D spatial attributes, and non-spatial attributes such as electron density. These tuples, as well as connectivity information, are used as input for the second phase, where region outlier are detected by applying a fast CCL [\cite=wu2009optimizing] to efficiently find different connected components on the triangular mesh. The outputs of the CCL-based region outlier detection algorithm are a set of connected components with outlier points inside, which are associated with blobs if some criteria are satisfied.

Note that our approach consists of two orthogonal steps, therefore each of the two phases can be replaced by other outlier detection methods. For example, one can leverage density-based outlier detection to find outlier points in the first phase. In addition, edge detection with fuzzy classifier can be used to detect the boundary of region outlier in the second phase [\cite=lu2004wavelet].

In the following section, we describe the proposed two-phase region outlier detection in detail.

Distribution-Based Outlier detection

The main task of this phase is to perform efficient outlier detection to determine outlier points which form the region outliers associated with blobs. In this work, we propose a two-step, distribution-based outlier detection algorithm based on the electron density with various criteria for fusion plasma data streams. We separate spatial attributes from non-spatial attributes and consider the statistical distribution of the non-spatial attributes to develop a test based on distribution properties, since it is more suitable for detecting spatial outliers [\cite=shekhar2003unified]. As claimed in [\cite=subramaniam2006online], it is very efficient to find outliers by using a data distribution approximation if we estimate the underlying distribution of data accurately. Values for various criteria are determined by domain experts or subjectively by examining the resulting images and adjusting them until satisfied.

The first step of the proposed outlier detection is to preprocess the sample frame to compute needed quantities in the region of interests, as shown in Figure [\ref=fig:Region_of_interests]. Then it is analyzed by normalizing the total electron density ne(r,z,t) (which includes fluctuations) with respect to the initial background electron density, ne(r,z,1) (if using real diagnostic data from, e.g. GPI, actual emission intensity I(r,z,t) would be used instead of electron density). Note that using the initial time frame as the benchmark is an important factor to achieve real-time blob detection. The normalized electron density in the subsequent time frames can be easily computed, especially compared to the time-average electron density with a long time interval [\cite=myra2013edge].

To obtain meaningful region outliers using the CCL method, it is necessary to have fine grained connectivity information. This particular simulation mesh has coarse vertical resolution, so resolution enhancement techniques are applied to generate a higher resolution triangular mesh based on the original triangulated mesh. As shown in Algorithm [\ref=alg:triangular_mesh_refinement_algorithm], the resulting triangular mesh is refined to achieve four times better granularity. We create four times vertices by using three middle points of the original mesh edges in each triangle. The corresponding density of generated vertices can be obtained using linear interpolation of the original triangular mesh. This step can be applied recursively until the satisfactory resolution of the triangular mesh is computed. Figure [\ref=fig:Refined_and_original_vertices] shows the resulting triangular mesh vertices after applying the triangular mesh refinement algorithm once.

In order to apply an appropriate predefined quantile in two-step distribution-based outlier detection, it is advised to perform exploratory data analysis to exploit main characteristics of the data sets. Figure [\ref=fig:exploratory_data_analysis] reveals that extreme value distribution and log normal distribution are fitted best with one of our sample data sets (after comparing over sixteen different common distributions). After analyzing the underlying distribution, a two-step outlier detection is performed to determine outlier points in the regions of interest. The basic idea of the proposed two-step outlier detection is motivated from the observations that there are relatively high density areas (a half banded ellipse area with cyan color) in the edge and several significantly high density small regions (a few small areas with reddish yellow color) in these relatively high density areas, as shown in Figure [\ref=fig:density_regions]. The proposed outlier detection method extends the previous approach that applies statistical detection with conditional averaging intensity value [\cite=xu2012turbulent] [\cite=fuchert2013influence], and applies more intelligent two-step outlier detection with only considering individual time frame data. Compared to traditional single threshold segmentation approach, our approach is more generic, flexible and easier to tune a satisfactory result.

In the first step, the standard deviation σ and the expected value μ are computed over all sixteen poloidal planes in one time frame. Using the best fitted distribution, we apply first step outlier detection to identify the relative high density areas with a specified predefined quantile:

[formula]

where N is the normalized electron density, α is the multiple of σ associated to the specified predefined quantile and Γ is the domain in the region of interests. Once the relative high density regions are determined, we compute another standard deviation σ2 and the expected value μ2 in these areas. Then we employ second step outlier detection to identify the outlier points in the relative high density areas with an appropriately chosen predefined quantile:

[formula]

where β is the multiple of σ2 associated to the judiciously chosen confidence level and Γ2 is the domain of blob candidates. In practice, α and β can be chosen to be same or different, depending on the characteristics of blob-filaments. In our experience, the α value is generally greater than β since the standard deviation σ over the region of interests is much smaller than the standard deviation σ2 from the relative high density areas.

However, two-step outlier detection alone cannot be used to distinguish the blob candidates since identified blob candidates may actually have small density, which does not satisfy traditional definition of blobs. Therefore, the density of the mesh points in the outlier points smaller than a certain minimum absolute value criterion need to be filtered out. On the other hand, it is also possible that the middle areas between surrounding plasmas and outlier points have density higher than the given minimum absolute value criterion. Thus, we also apply a minimum relative value criterion to remove these unwanted points. To combine these two rules together, we have a more robust and flexible criterion:

[formula]

where dma and dmr are minimum absolute value and minimum relative value respectively, and Γ3 is the domain of good blob candidates.

CCL-Based Region Outlier Detection

The main task of the second phase is to apply an efficient connected component labeling algorithm adopted from [\cite=wu2009optimizing] on a refined triangular mesh to find different blob candidate components. A connected component labeling algorithm generally considers the problem of labeling binary 2D images with either 4-connectedness or 8-connectedness. It performs an efficient scanning technique, and fills the label array labels so that the neighboring object pixels have the same label. Wu [\cite=wu2009optimizing] presents an efficient two-pass labeling algorithm that is much faster than other state-of-the-art methods and theoretically optimal. However, since we process a refined triangular mesh rather than the traditional 2D images, we have modified their CCL algorithm to take the special features of a triangular mesh into account. As shown in Algorithm [\ref=alg:connected_component_labeling_algorithm_on_triangular_mesh], each triangle is scanned first rather than a point. Since we know the three vertices in a triangle are connected, we can reduce unnecessary memory accesses once any vertex in a triangle is found to be connected with another vertex in a different triangle. Then we compute the current minimum parent label in this triangle, and assign each vertex a parent label if its label has already filled or a label if its label has not initialized yet. If all three vertices in a triangle are scanned for the first time, then a new label number is issued and assigned to their labels and the associated parent label. After the label array is filled full, we need flatten the union and find tree. Finally, a second pass is performed to correct labels in the label array, and all blob candidates components are found. Note that to perform efficient union-find operations, the union-find data structure is implemented with a single array as suggested in [\cite=wu2009optimizing].

After all blob candidates are determined, a blob is claimed to be found if the median of a blob candidate component satisfies a certain minimum absolute median value criterion. The reason we are setting this constraint to select the blobs is that the minimum value criterion has to be a reasonably small value in order to produce more blob candidate components. It is possible that if the minimum absolute median value criterion is too large, it may also remove the blobs. On the other hand, it is also possible if this value is too small, it does not have effect on filtering out unwanted components. Therefore, with the same philosophy of measurement, a minimum relative median value criterion is also applied to determine the blobs. However, in order to protect the blobs from being removed due to the extremely large mean value μ2, we also set the maximum absolute median value criterion to limit the power of minimum relative median value criterion. We unify these three rules to be one:

[formula]

where ma, mr and xa are minimum absolute median value, minimum relative median value and maximum absolute median value respectively and Γ4 is the domain of blobs.

Tracking Region Outliers

Another objective of this work is to track the direction and speed of the detected blobs over time. The blob tracking algorithm has to cope with the problem of tracking multiple region outliers simultaneously even when the blobs merge together or split into separated ones. On the other hand, the blob tracking method should be simple and efficient to meet real-time requirements. To achieve this goal, we propose an efficient blob tracking algorithm by leveraging cues from changes of blobs area and distance of center of blobs. We compute the correspondence between previously tracked blobs and currently detected blobs, and then recover the trajectories of the tracked blobs.

To identify the location center of detected blob, we compute the density-weighted average of the spatial coordinates of each point inside a blob.

[formula]

where M is summation of ne of all points in a blob. The density-weighted average is used to better capture the center of density of a blob. We track the movement of these detected blobs by linking the centers in consecutive time frames. In order to obtain the boundary of region outliers (blobs), we compute the convex hull [\cite=chan1996optimal] of a set of points in a blob. The area of a blob is computed by counting the number of points in a blob.

As shown in Algorithm [\ref=alg:Efficient_blob_tracking_algorithm], the input parameters are current detected blobs and the previous blob tracks. The data structure of a blob track is composed of the track ID, the length of track, the area of previous blob, the time-stamps, the center points, the boundary points, and the velocity. There are two heuristics to verify whether a blob is associated with an existing blob track. The first heuristic is based on the fact that the area of a blob between consecutive time frames cannot decrease or increase significantly. The second heuristic takes into account the distance of the centers of a blob does not change dramatically over very short time period (microseconds). The proper thresholds for these two heuristics are provided by domain experts. Since blobs can appear, disappear, merge together or split, a greedy scheme is applied to find the best matching pair of blob and track based on closest distance of the centers of current detected blob and the latest blob in a blob track. Based on computed correspondence between a blob track and the currently detected blobs, existing blob tracks are automatically processed through corresponding operations such as adding a blob into a track, creating a new track, and a track ending. If the length of a track is smaller than 3 consecutive time frames, the track will be treated an anomaly and deleted due to errors in data or inappropriate blob detection thresholds. The speed and direction of the blobs can thus be computed from two consecutive center points. Finally, we can recover the trajectories of the tracked blobs by monitoring the movement of blob centers.

A real-time blob detection approach

Existing blob detection approaches cannot tackle the two challenges of the large amount of data produced in a shot and the real-time requirement. In addition, existing data analysis approaches are often operated in a single thread, only for post-run analysis and often take a few hours to generate the results [\cite=muller2006probabilistic]. In order to meet the real-time feedback requirement, we address these challenges by developing a high performance blob detection approach, which can leverage in situ raw data and find blob-filaments efficiently in fusion experiments or numerical simulations.

A hybrid MPI/OpenMP parallelization

In our approach, we can complete our blob detection in a few milliseconds using a hybrid MPI/OpenMP parallelization with in situ evaluation. The key idea is to exploit many cores in a large cluster system by running MPI to allocate n processes to process one or several time frames at the high level, and by leveraging OpenMP to accelerate the computations using m threads at the low level. Our hybrid MPI/OpenMP parallelization for blob detection is shown in Figure [\ref=fig:_blob_hybridChat].

In order to achieve blob detection in real time, the goal is to minimize data movements at the memory and speed up computation. Ideally, the performance is optimal without any communication if we can perform the job correctly. The proposed blob detection algorithm in the previous section supports embarrassed parallel since we only need the initial time frame and the target time frame to do the computation. This is an important difference between our blob detection method and recently developed methods [\cite=davis2014fast] [\cite=myra2013edge] in terms of real-time requirement. Furthermore, we explore many-core processor architectures to speed up the computation of each MPI task by taking advantage of multithreading in the shared memory. Therefore, our real-time blob detection approach based on hybrid MPI/OpenMP parallelization is a natural choice and is expected to provide the optimal performance for fusion plasma data streams.

A practical interesting issue is how to tune the number of MPI processes and OpenMP threads for the best performance by taking both analysis speed and memory size into account. As shown in Figure [\ref=fig:performance_of_hybrid_MPI/OpenMP_parallelization], we vary the number of MPI processes and OpenMP threads but fix the total number to be 24 for investigating the performance when processing the same amount of time frames data. A faster analysis speed is achieved when increasing the number of MPI processes since more data frames can be processed simultaneously. On the other hand, the analysis speed remains constant with a few OpenMP threads and degrades with more OpenMP threads due to lack of enough computation in one time frame. However, more OpenMP threads could significantly reduce the memory demands. Therefore, in this study, we choose the number of OpenMP threads to be four for each MPI task, to achieve a good trade off between analysis speed and memory savings.

Outline of the implementation

We implement our blob detection algorithm in C with a hybrid MPI/OpenMP parallelization. Algorithm [\ref=alg:real-time_ourlier_detection_algorithm_for_finding_blobs] summarizes the proposed blob detection algorithm without considering OpenMP. Users can specify the regions of interest by (Rmin, Rmax, Zmin, Zmax), the range of target time frames by (t_start, t_end), and the location of the data sets. However, with in situ evaluation, there is no need to specify the file location since all data are already in memory. We use static scheduling to evenly divide the number of time frames for each MPI task for efficiency. The n MPI processes are allocated to process one or several time frames and m OpenMP threads are launched to accelerate the computation in one time frame. Note that the MPI process is also the master thread in the runtime environment.

Experiments and Results

In this section we present experimental evaluations of our blob detection and tracking algorithms, and report the performance of the real-time blob detection under both strong and weak scaling. Before showing experimental results in the next section, we briefly introduce our experimental environment, data sets, and parameters setting in our blob detection and tracking algorithms. We have tested our implementation on the NERSC's newest supercomputer Edison, where each compute node has two Intel "Ivy Bridge" processors (2.4GHz with 12 cores) and 64 GB of memory. Our data sets are small simulation data sets (30GB) with 1024 time frames based on the XGC1 simulation [\cite=chang2009compressed][\cite=ku2009full] from the Princeton Plasma Physics Laboratory, which last around 2.5 milliseconds. One of our main goals is that we can control analysis speed by varying the number of processes to complete the blob detection on the entire data set in a time close to 2.5 milliseconds. It would indicate that our algorithm could monitor fusion experiments in real time (neglecting data transfer latency). If we consider internet transfer latency in real experiments or numerical simulation, the system needs at least 1 to 25 milliseconds to transfer one time frame data depending on size of data, which may give us more time for data analysis.

Another goal is to validate the effectiveness of the proposed algorithms. In Algorithm [\ref=alg:real-time_ourlier_detection_algorithm_for_finding_blobs], we apply various criteria to identify the blobs. The parameters for blob detection and tracking in our experiments are given in Table [\ref=ta:_blob_criteria]. One criterion we have not mentioned in the previous section is parameter "minArea". This parameter is used to decide how many points a blob should have, which is used to remove impossibly small blobs. In our experiment, this parameter is set to three since there are at least three vertices connected as a 2D component in a triangular mesh. Another criteria are parameters "maxFrames" and "minFrames", which are used to control the length of a blob track and remove noisy tracks. It is important to note that these parameters need to be tuned in order to achieve optimal performance in different fusion experiments or numerical simulations. The reasons for this uncertainty in the context of blob detection are from the intrinsic variability and complexity of the blob structures observed in different experiments [\cite=d2011convective].

Performance comparison

We first conduct experiments to compare our method with recently developed state-of-the-art blob detection methods in [\cite=davis2014fast] [\cite=myra2013edge]. Since their methods are based on the contouring methods and thresholding, we call their methods the contouring-based methods. We have to point out that strictly quantitative comparisons are not possible since the blob itself is not well-defined [\cite=d2011convective]. Due to this reason, there are rarely direct comparisons between any new proposed method and existing ones in the literature in the domain of fusion plasma. [\cite=xu2012turbulent] [\cite=fuchert2013influence] [\cite=zweben1985search] [\cite=muller2006probabilistic] [\cite=love2007image] [\cite=davis2014fast] [\cite=kube2013blob] [\cite=myra2013edge]. However, in order to demonstrate that our methods have better accuracy than the contouring-based methods, we compare these two methods in two typical cases to shed light on their performance in terms of the detection accuracy.

Figure [\ref=fig:comparing_our_region_outlier_detection_method_with_the_Contouring-based_methods] shows the comparison of the blob detection results between our region outlier detection method and the contouring-based methods in two different time frames. As shown in Figures [\ref=fig:contouring_method_in_time_frame_45] and [\ref=fig:region_outlier_detection_method_in_time_frame_45], we can see that our region outlier detection method does not miss detecting the blob at the edge of the regions of interest while the contouring-based methods fail the detection. The reason is that the contouring-based methods require the computed contours are closed, which do not exist at the edge of the regions of interest. In Figures [\ref=fig:contouring_method_in_time_frame_87] and [\ref=fig:region_outlier_detection_method_in_time_frame_87], we notice that our region outlier detection method can accurately detect all blobs. However, the contouring-based methods have much worse performance that it either yields the blobs with incorrect areas (much larger and smaller), or misdetect the wrong area as a blob. This is because that it is hard to use one single threshold to identify the blobs for all cases even in the same experimental data sets. Our region outlier detection method does not have such problem since we use more generic two-step distribution-based outlier detection.

More blob detection results

We perform more experiments to comprehensively examine the blob detection results in five continuous time frames and four different poloidal planes as shown in Figure [\ref=fig:blob_detection]. As we can see from the figure, our region outlier detection method can provide satisfactory results in different situations. In addition, our method does not miss any blobs at the edge of the regions of interest, as shown in subfigures [\ref=fig:Time_frame_83_and_poloidal_plane_1], [\ref=fig:Time_frame_83_and_poloidal_plane_2], [\ref=fig:Time_frame_84_and_poloidal_plane_1] and [\ref=fig:Time_frame_84_and_poloidal_plane_2]. It is interesting to see that large-scale blob structures are often generated, which could cause substantial plasma transport [\cite=zweben1985search]. As pointed out in [\cite=xu2006multiscale], these large-scale structures are mainly contributed by the low-frequency and long-wavelength fluctuating components, which may be responsible for the observations of long-range correlations. We also noticed that different poloidal planes may display significant diversity in edge turbulence, even in the same time frame. We have shown that we are able to effectively detect the blobs and reveal some interesting results to help physicists improve their understanding of the characteristic of blobs and their correlation with other plasma properties.

Blob tracking results

In this experiment, we investigate the blob tracking results in two different situations. Figure [\ref=fig:2D_trajectory_for_detected_blobs] exhibits a 2D trajectory of a blob. Again, the trajectory is generated by plotting the location of the density peak of the detected blobs over five consecutive time frames. We can see that our blob tracking algorithm can track two separate blobs simultaneously. The blob size can grow when they move towards confined plasma in the right region of separatrix. Figure [\ref=fig:3D_trajectory_for_detected_blobs] shows a 3D trajectory for a detected blob over fifteen consecutive time frames. In this case, the blob seems to maintain its size for a few time frames, then gradually decreases, and eventually disappears. Through these interesting results, physicists may be able to understand the characteristics of blobs better.

Real-time blob detection under strong scaling

We have illustrated the accuracy and effectiveness of the proposed blob detection and tracking methods. Next, we perform a set of experiments to demonstrate the performance of our real-time blob detection approach under strong scaling and weak scaling.

Our most encouraging results are that we can complete blob detection on the simulation data set described above in around 2 milliseconds with MPI/OpenMP using 4096 cores and in 3 milliseconds with MPI using 1024 cores. In Figure [\ref=fig:Real_time_blob_detection_with_MPI/OpenMP_under_strong_scaling], we can achieve linear time speedup in blob detection time under strong scaling. The MPI and the MPI/OpenMP implementations accomplish 800 and 1200 times speedup respectively, when the number of processes is scaled to 1024. Also, we can see that the hybrid MPI/OpenMP implementation is about two times faster than the MPI implementation when varying the number of processes from 1 to 512. With 1024 processes, both of them achieve similar performance, but the MPI/OpenMP one is slightly better. This demonstrates that we are able to control analysis speed by varying the number of processes to meet real-time analysis requirement.

Real-time blob detection under weak scaling

In this set of experiments, we evaluate the performance of our real-time blob detection under weak scaling. We replicate existing data sets (30GB) in order to obtain adequate experimental data sets (4.3TB). The basic unit data contains 128 time frames and the size of data increases linearly with the number of processes. In Figure [\ref=fig:Real_time_blob_detection_with_MPI/OpenMP_under_weak_scaling], the blob detection time remains almost constant under weak scaling, which indicates that our implementations scale very well to solve much larger problems. Also, both the MPI and the MPI/OpenMP implementations achieve high parallel efficiency as the number of processes increases from 1 to 1024.

Conclusion and future work

Near real-time data analysis of the long-pulse fusion plasma experiments presents both opportunities and challenges responding to extreme scale computing and big data in fusion energy. In this paper, we propose, for the first time, a real-time blob detection approach for finding blob-filaments in real fusion experiments or numerical simulations. The key idea of the proposed two-phase region outlier detection scheme is based on distribution-based outlier detection with various criteria and a fast CCL method to find blob components. In addition, an efficient blob tracking scheme is presented to recover the trajectories of the motions of blobs. We have implemented our blob detection algorithm with hybrid MPI/OpenMP and demonstrated the accuracy and efficiency of our implementation with a set of data from the fusion plasma simulation code XGC1. Our tests show that we can achieve linear time speedup and complete blob detection in two or three milliseconds using a cluster at NERSC.

We are currently working on integrating our blob detection algorithm into the ICEE system for consuming fusion plasma data streams where the blob detection function is used in a central data analysis component and the resulting detection results are monitored and controlled from portable devices, such as an iPad. We plan to test the proposed method in both numerical simulations and real fusion experiments.

Acknowledgments

Acknowledgment

The authors would like to thank Scientific Data Management Group at LBNL, and our collaborators in PPPL and ORNL for their contributions to this work. The authors thank Edmund Novak and Daniel Graham for their valuable comments to improve the readability of this paper. The authors would also like to thank the referees for their valuable comments. This work was supported by the Office of Advanced Scientific Computing Research, Office of Science, of the U.S. Department of Energy under Contract No. DE-AC02-05CH11231 and partially supported by NSF under grants No. CCF 1218349 and ACI SI2-SSE 1440700, and by DOE under a grant No. DE-FC02-12ER41890.