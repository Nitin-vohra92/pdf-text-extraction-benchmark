Proof:   [formula]

in in in in in

The Binary Energy Harvesting Channel with a Unit-Sized Battery

This work was supported by NSF Grants CNS 09-64364/CNS 09-64632 and CCF 14-22347/CCF 14-22111, and presented in part at the IEEE International Symposium on Information Theory, Istanbul, Turkey, July 2013 and the IEEE International Symposium on Information Theory, Honolulu, HI, June 2014.

Introduction

We consider an energy harvesting communication channel, where the transmitter harvests energy from an exogenous source to sustain power needed for its data transmission. The transmitter stores harvested energy in a finite-sized battery, and each channel input is constrained by the remaining energy in the battery. Consequently, stored energy can be viewed as the state of this channel, which is naturally known causally at the encoder, but unknown at the decoder. This state is correlated over time, and is driven by the exogenous energy harvesting process, energy storage capacity of the battery, and the past channel inputs. As such, this channel model introduces unprecedented constraints on the channel input, departing from traditional channels with average or peak power constraints, and requires new approaches to determine its capacity.

References [\cite=ozel2012achieving] [\cite=ozel2011awgn] [\cite=mao2013capacity] [\cite=dong2014near] [\cite=jog2014energy] study the capacity of channels with energy harvesting transmitters with an infinite-sized battery [\cite=ozel2012achieving], with no battery [\cite=ozel2011awgn], and with a finite-sized battery [\cite=mao2013capacity] [\cite=dong2014near] [\cite=jog2014energy]. Reference [\cite=ozel2012achieving] shows that the capacity with an infinite-sized battery is equal to the capacity with an average power constraint equal to the average recharge rate. This reference proposes save-and-transmit and best-effort-transmit schemes, both of which are capacity achieving when the battery size is unbounded. At the other extreme, [\cite=ozel2011awgn] studies the case with no battery, and shows that this is equivalent to a time-varying stochastic amplitude-constrained channel. Reference [\cite=ozel2011awgn] views harvested energy as a causally known state, and combines the results of Shannon on channels with causal state at the transmitter [\cite=shannon1958channels] and Smith on amplitude constrained channels [\cite=smith1971information], and argues that the capacity achieving input distribution is discrete as in the case of [\cite=smith1971information]. More recent work [\cite=mao2013capacity] [\cite=dong2014near] [\cite=jog2014energy] consider the case with a finite-sized battery. Reference [\cite=mao2013capacity] provides a multi-letter capacity expression that is hard to evaluate, since it requires optimizing multi-letter Shannon strategies [\cite=shannon1958channels] for each channel use. The authors conjecture that instantaneous Shannon strategies are optimal for this case, i.e., strategies that only observe the current battery state to determine the channel input are sufficient to achieve the capacity. Reference [\cite=dong2014near] finds approximations to the capacity of the energy harvesting channel within a constant gap of 2.58 bits/channel use. For a deterministic energy harvesting profile, [\cite=jog2014energy] provides a lower bound on the capacity by exploiting the volume of energy-feasible input vectors.

We consider a single-user communication scenario with an energy harvesting encoder that has a finite-sized battery, as shown in Fig. [\ref=fig_model]. In each channel use, the encoder harvests energy that is a multiple of a fixed unit, and stores it in a battery which has a capacity that is also a multiple of this unit. Each channel input then consumes an integer number of units of energy. In this paper, we consider the binary version of this setting, which we refer to as the binary energy harvesting channel (BEHC). In a BEHC, energy is harvested in binary amounts (0 or 1 unit), the battery has unit size, and the channel inputs are binary. Sending a 1 through the channel requires one unit of energy per channel use, while sending a zero is free in terms of energy. Hence, the encoder may only send a 1 when it has the required energy in the battery; it can send a 0 anytime. A similar abstraction of communicating with energy packets over an interactive link can be found in [\cite=popovski2012interactive].

In an energy harvesting channel, the channel input in each channel use is constrained by the battery state of the transmitter. Since the battery is at the transmitter, this state is naturally causally available at the encoder, but is not available at the decoder. This results in a channel with causally known state information at the encoder. In such channels, if the state is independent and identically distributed (i.i.d.) over time, and is independent of the channel inputs, then the capacity is achieved using Shannon strategies [\cite=shannon1958channels]. However, in the BEHC, the battery state has memory since the battery stores the energy through channel uses. Further, the evolution of the battery state depends on the past channel inputs since different symbols consume different amounts of energy. Therefore, Shannon strategies of [\cite=shannon1958channels] are not necessarily optimal for this channel. This channel model resembles the model of reference [\cite=weissman2010capacity] with action dependent states, where the encoder controls the state of the channel through its own actions. However, different from [\cite=weissman2010capacity], in the case of BEHC, actions and channel inputs are equal, i.e., the two cannot be chosen independently. This yields a conflict between choosing inputs with the purpose of communicating, and with the purpose of controlling the state.

In this paper, we consider a special case of the BEHC with no channel noise. Even in this special case, finding the capacity is challenging due to the memory in the state, the lack of battery state information at the receiver, and the inter-dependence of the battery state and the channel inputs. In essence, the uncertainty in this model is not due to the communication channel, but due to the random energy harvests and the battery state that impose intricate constraints on the channel inputs. For this case, we first propose achievable rates using Shannon strategies in [\cite=shannon1958channels]. Next, we develop an equivalent representation for the channel in terms of the time differences between consecutive 1s sent through the channel. This is analogous to the timing channel in [\cite=anantharam1996bits], or its discrete-time version in [\cite=prabhakar2003entropy], where the message is encoded in the arrival times of packets to a queue. Observing that the states are i.i.d. in this equivalent representation, we find a single-letter expression for the capacity of the BEHC by combining approaches from [\cite=shannon1958channels] and [\cite=anantharam1996bits]. This expression is difficult to evaluate due to an involved auxiliary random variable. We give achievable rates based on certain selections of this auxiliary random variable which resemble lattice coding for the timing channel. We develop upper bounds for the capacity by using a genie-aided method, and also by quantifying the leakage of the state information to the receiver. We find that our bounds are tight asymptotically as energy harvesting rate goes to zero. We extend our results to the case of ternary channel inputs. We numerically evaluate the achievable rates and the upper bounds and show that our achievable schemes give the capacity of the binary channel within 0.03 bits/channel use and the ternary channel within 0.05 bits/channel use. We observe that the proposed timing channel based achievable schemes outperform basic Shannon strategies that consider only instantaneous battery state, for all parameter values, for this noiseless binary case.

Channel Model

We consider the binary channel with an energy harvesting transmitter shown in Fig. [\ref=fig_model]. The battery at the transmitter is of size Emax. The harvested energy is first stored in the battery before being used for transmission. The encoder transmits a symbol Xi∈{0,1} in channel use i. At each channel use, the channel input Xi is constrained by the energy available in the battery at that channel use. Hence, for the transmitter to send an Xi = 1, it must have a unit of energy in the battery; the transmitter can send an Xi = 0 anytime. Next, the encoder harvests an energy unit with probability q, i.e., Ei is Bernoulli(q), and stores it in its battery of size Emax units. The harvests are i.i.d. over time. If the battery is full, harvested energy is lost, i.e., Ei cannot be used immediately in the same time slot without storing. We refer to this particular sequence of events within a channel use as the transmit first model, since the encoder first sends Xi and then harvests energy Ei.

The battery state Si denotes the number of energy units available in the battery at the beginning of channel use i, and evolves as

[formula]

where Xi = 0 if Si = 0 due to the energy constraint. The encoder knows the battery state Si causally, i.e., at the beginning of time slot i, but does not know what Ei or Si + 1 will be until after sending Xi. The decoder is unaware of the energy harvests at the encoder, and therefore the battery state. As seen from ([\ref=eqn_model_update]), the battery state Si has memory, is affected by the channel inputs Xj for j  ≤  i, and imposes a constraint on the channel input Xi. In this work, we focus on the case of a unit-sized battery, i.e., Emax = 1, and a noiseless channel, i.e., Yi = Xi.

Achievable Rates with Shannon Strategies

For a channel with i.i.d. and causally known states at the transmitter, Shannon shows in [\cite=shannon1958channels] that the capacity is achieved using the now so-called Shannon strategies. In particular, the codebook consists of i.i.d. strategies Ui∈U, which are functions from channel state Si to channel input Xi. In channel use i, the encoder observes Si and puts Xi = Ui(Si) into the channel. The capacity of this channel is given by

[formula]

where pU is the distribution of U over all functions from Si to Xi.

In the BEHC, the state of the channel, i.e., the battery state of the encoder, is not i.i.d. over time. Therefore, ([\ref=eqn_shannon_capacity]) does not give the capacity for this system. To overcome the memory in the state, [\cite=mao2013capacity] uses strategies that are functions of all past battery states to express the capacity in a multi-letter form. However, since the dimension of such strategies grow exponentially with the number of channel uses, this approach is intractable. Alternatively, it is possible to use the method in [\cite=shannon1958channels] to develop encoding schemes based on Shannon strategies to obtain achievable rates. One tractable such scheme is obtained when strategies are functions of the current battery state only, which is proposed as an achievable rate in [\cite=mao2013capacity] and [\cite=tutuncuoglu2013binary]; and is conjectured to be capacity achieving in [\cite=mao2013capacity]. In this section, we consider such encoding schemes.

For the Emax = 1 case, we have two states, Si∈{0,1}. We denote a strategy U as [formula], where U(0) = X and [formula], i.e., X is the channel input when S = 0 and [formula] is the channel input when S = 1. Due to the inherent energy constraint of the BEHC, X = 1 requires S = 1, and thus, we have two feasible strategies, namely (0,0) and (0,1).

We first construct a codebook by choosing Ui i.i.d. for each codeword and channel use. Let the probability of choosing Ui = (0,1) be p for all i and all codewords. We will consider two alternative approaches to decoding the message. First, note that the i.i.d. codebook construction yields an ergodic battery state process for any message, with the transition probabilities

[formula]

yielding the stationary probability

[formula]

The receiver can ignore the memory in the model, consider a channel with i.i.d. states with the state probability given in ([\ref=eqn_shannon_naive_prob]), and perform joint typicality decoding. This is similar to the approach used in [\cite=popovski2012interactive] for a communication scenario with energy exchange. Denoting U = (0,0) as 0 and U = (0,1) as 1, this channel is expressed as

[formula]

where δ(u) is 1 at u = 0, and zero elsewhere. Since the channel is memoryless, its capacity is given by ([\ref=eqn_shannon_capacity]). Note that this is an achievable rate, but it is not the capacity of the BEHC, since the decoder treats the channel as if it was memoryless. Hence, we refer to this scheme as the naïve  i.i.d. Shannon strategy (NIID). The best achievable rate for the NIID scheme is given by

[formula]

where H2(p) =  - p log (p) - (1 - p) log (1 - p) is the binary entropy function.

While the NIID scheme permits an easy analysis, it fails to make use of the memory in the channel. Instead, the decoder can exploit the memory by using the n-letter joint probability p(un,yn) when performing joint typicality decoding. Since this is the best that can be done for an i.i.d. codebook, we will refer to this scheme as the optimal i.i.d. Shannon strategy (OIID), which yields the achievable rate

[formula]

The challenge with this scheme is in calculating the limit of the n-letter mutual information I(Un;Yn). To this end, we use the message passing algorithm proposed in [\cite=arnold2006simulation]. This algorithm requires that the joint probability p(yi,ui,si + 1|si) is independent of the channel index i. In our case, we have independent ui, which yields

[formula]

where p(yi,si + 1|ui,si) is independent of i by the definition of the channel. Thus, we can use the algorithm in [\cite=arnold2006simulation] to exhaustively search p and solve ([\ref=eqn_shannon_oiid_rate]).

It is possible to further improve such achievable rates by constructing more involved codebooks. For example, reference [\cite=mao2013capacity] considers generating codewords with Markov processes, which introduces additional memory to the system through the codewords. This approach improves the achievable rate as shown in [\cite=mao2013capacity] at the cost of increased computational complexity in the Markov order of the codebook. We evaluate and compare these achievable rates in Section [\ref=sect_numerical].

Timing Representation of the BEHC

In this section, we propose an alternative representation of the BEHC, which yields a simpler analysis via a single-letter expression for the capacity. In particular, we equivalently represent channel outputs Yi with the number of channel uses between instances of Yi = 1. We show that this transformation eliminates the memory in the state of the system, and allows constructing tractable achievable rates and upper bounds for the BEHC.

The input Xi and the output Yi of the noiseless BEHC are both binary. Let [formula] be defined as the number of channel uses before the first instance of output Y = 1, and [formula] for k  ≥  2 be defined as the number of channel uses between the (k - 1)st instance of output Y = 1 and the kth instance of output Y = 1. In other words, the sequence Tm represents the differences between the channel uses where 1s are observed at the output of the channel. Clearly, Tm and Yn are equivalent since there is a unique sequence Tm corresponding to each Yn and vice versa.

When a 1 is transmitted in the ith channel use, the entire energy stored in the unit-sized battery of the encoder is consumed. Hence, the encoder cannot transmit another 1 until another energy unit is harvested. We define the idle time [formula] of the encoder as the number of channel uses the encoder waits for energy after the (k - 1)st 1 is transmitted. Since the probability of harvesting an energy unit is distributed i.i.d. with Bernoulli(q), Zk is also i.i.d. and distributed geometric(q) on [formula]. Note that during the idle period, the encoder cannot send any 1s. Once the energy is harvested, the encoder observes Zk and chooses to wait [formula] channel uses before sending the next 1. Hence, we have a timing channel with causally known state Zk, channel input Vk, and channel output Tk, satisfying

[formula]

We illustrate the variables Tk, Vk and Zk in Fig. [\ref=fig_timing_model]. In slots representing one use of the BEHC, an energy arrival, i.e., Ei = 1, is marked with a circle and sending a 1, i.e., Xi = 1, is marked with a triangle. Note that one use of the timing channel spans T uses of the BEHC.

We remark that the timing channel constructed from the time difference between consecutive 1s resembles the noiseless channel with symbols of varying durations [\cite=shannon1948]. The symbol durations in [\cite=shannon1948] are fixed, while the symbol durations in our model depend on the energy harvesting process, and therefore may change each time a symbol is sent. Hence, while [\cite=shannon1948] studies the problem of packing the most information within a given block length, our problem is also concerned with the randomness introduced by energy harvesting. In this sense, the timing channel defined here is analogous to the telephone signaling channel in [\cite=anantharam1996bits] and its discrete time counterpart in [\cite=prabhakar2003entropy], with the exception of causal knowledge of Zk at the encoder in our model.

Equivalence of the BEHC and the Timing Channel

In the timing channel, the decoder observes Tm, which can be used to calculate the BEHC output sequence Yn. The encoder observes Zm causally, which can be combined with past timing channel inputs Vm - 1 to find the state sequence Sn causally. Hence, any encoding/decoding scheme for the BEHC can be implemented in the timing channel, and vice versa, implying that the two channels are equivalent. However, note that in the timing channel, the kth channel use consists of Tk uses of the BEHC. To take the time cost of each timing channel use into consideration, we define the timing channel capacity CT as the maximum achievable message rate per use of the BEHC channel. In particular, given a timing channel codebook consisting of M codewords of length m, sending a codeword takes [formula] uses of the BEHC on average, and the corresponding rate is defined as

[formula]

We remark that this definition is a variation of the rate of the telephone signaling channel introduced in [\cite=anantharam1996bits]. With both rates defined per use of the binary channel, the timing channel and the BEHC have the same capacity. This is due to the encoders and decoders of these channels having different but equivalent representations of the same channel. We state this fact as a lemma.

The timing channel capacity with additive causally known state at the encoder, CT, and the BEHC capacity, CBEHC, are equal, i.e., CBEHC = CT.

Capacity of the Timing Channel

The timing channel defined in ([\ref=eqn_timing_channel]) is memoryless since Zk are independent. For such channels, the capacity is given by ([\ref=eqn_shannon_capacity]), or more explicitly by the following expression [\cite=shannon1958channels]

[formula]

where U is an auxiliary random variable that represents the Shannon strategies, and v(U,Z) is a mapping from auxiliary U and state Z to the channel input V. The cardinality bound on the auxiliary random variable is |U|  ≤   min {(|V| - 1)|Z| + 1,|T|}. As stated in [\cite=el2011network], a deterministic v(u,z) can be assumed without losing optimality. Hence, solving ([\ref=eqn_timing_csit]) requires finding the optimal distribution for U, p(u), and the optimal deterministic mapping v(u,z).

Due to Lemma [\ref=lem_timing_equivalent], we are interested in CT, which is defined per use of the binary channel, i.e., with a time cost of Tk for the kth channel use. To this end, we combine the approaches in [\cite=shannon1958channels] for channels with causal state information at the transmitter, and [\cite=anantharam1996bits] for timing channels, to state the following theorem.

The capacity of the timing channel with additive causally known state, CT, is

[formula]

Let W denote the message which is uniform on [formula]. Let n be the maximum number of binary channel uses, averaged over the energy arrivals Ei, to send a message W = w. We note that by definition, we have

[formula]

where the expectation is over the energy arrival sequence Ei and the message W.

For the converse proof, we define Uk  =  (W,Tk - 1). Since Ei is an i.i.d. random process, Zk is independent of W and Tk - 1, and therefore Uk. We write

[formula]

where ([\ref=eqn_timing_conv_5]) follows from ([\ref=eqn_timing_proof1]), and ([\ref=eqn_timing_conv_6]) follows from Ui being independent of Zi and the inequality [formula], for ai,bi > 0. When m  →    ∞  , if the probability of error goes to zero, then Fano's inequality implies H(W|Tm)  →  0. Combining this with ([\ref=eqn_timing_scaled_rate]) and ([\ref=eqn_timing_conv_6]), we get [formula], which completes the converse proof.

For the achievability of this rate, we use the encoding scheme in [\cite=shannon1958channels]. In particular, the message rate I(U;T) per use of the timing channel is achievable with a randomly generated codebook consisting of strategies Uk [\cite=shannon1958channels]. Therefore, as m  →    ∞  , we have [formula], and the message rate [formula] per use of the BEHC is achievable, completing the achievability proof.

We noted in Section [\ref=sect_shannon] that the optimal distribution over Shannon strategies can be found numerically for the BEHC. This is due to the fact that for a binary input Xi and binary state Si, there are only two feasible Shannon strategies. However, for the timing channel, both the input [formula] and the state [formula] have infinite cardinalities. This also implies that the cardinality bound on U is infinite. Therefore, although ([\ref=eqn_timing_capacity]) is a single-letter expression, it is difficult to evaluate explicitly. In the following sections, we first develop upper bounds for the capacity using a genie-aided method and using a method that quantifies the leakage of the state information to the receiver; and then develop lower bounds (explicit achievable schemes) by certain specific selections for p(u) and v(u,z); and compare these achievable rates and the upper bounds.

Upper Bounds on the Capacity of the BEHC

Genie Upper Bound

We first provide the timing channel state Zk to the decoder as genie information. This yields an upper bound since the decoder can choose to ignore Zk in decoding. However, with the knowledge of Zk, the decoder can calculate Vk = Tk - Zk, and thus we obtain the upper bound

[formula]

Note that in ([\ref=eqn_ub_genie_2]), we partition the maximization into choosing the optimal [formula] and choosing the optimal distribution of V with [formula]. The equality in ([\ref=eqn_ub_genie_2]) holds since the term [formula] is decreasing in μ, and therefore the optimal μ equals the expectation of the optimal V. The second maximization in ([\ref=eqn_ub_genie_2]) involves finding the entropy maximizing probability distribution over the discrete support set [formula] with the constraint [formula]. The solution to this problem is a geometric distributed V with parameter [formula]. Its entropy is given by [formula], where H2(p) is the binary entropy function. Noting that Z is also geometrically distributed with parameter q, the genie upper bound reduces to

[formula]

The genie upper bound in ([\ref=eqn_ub_genie_final]) overcomes the state dependence of the timing channel by effectively removing the state Zk from the channel. Although this neglects the main challenges of our model, we will show in Section [\ref=sub_achievable_asymptotic] that this is a useful upper bound which in fact is asymptotically optimal as q  →  0.

State Leakage Upper Bound

Another approach to obtain an upper bound is to quantify the minimum amount of information Tm carries about Zm. Since Zm is independent of the message, information leaked about it via Tm reduces the potential information that can be carried in Tm about the message. Following this intuition, in this subsection, we find an upper bound on H(Z|T = t,U = u), which yields the state leakage upper bound for the timing channel capacity.

An example that relates to this idea can be found in [\cite=tavan2013bits]. This reference considers communicating through a queue with a single packet buffer, where the encoding is performed over arrival times to the buffer. The decoder recovers the message by observing the buffer departure times of packets, which have suffered random delays through the buffer. What this example suggests is that it is possible to achieve a positive message rate through a buffer that causes random delays. In a similar manner, we can consider timing channel input V as random delay, and achieve a positive rate between the harvesting process and the decoder in addition to the message rate of the timing channel. Since the total message rate is limited to H(Y) or [formula] by the cutset bound, quantifying this nonzero rate between the harvesting process and the decoder is useful in finding an upper bound.

We first present the following lemma, where we provide an upper bound for H(Z|T = t,U = u). This conditional entropy represents the amount of uncertainty remaining in Z after the decoder receives T and successfully decodes U.

For the timing channel T = V + Z, where Z is geometric with parameter q, and V = v(U,Z) with the auxiliary random variable U independent of Z, we have

[formula]

where Zt is a truncated geometric random variable on [formula] with the probability mass function

[formula]

We first examine the joint distribution p(z,t|u) resulting from a deterministic v(U,Z), which is depicted as a two-dimensional matrix in Fig. [\ref=fig_ub_leakage_lemma]. Given Z = z and U = u, the output of the channel is T = v(u,z) + z. Therefore, each row of p(z,t|u) in the figure contains one non-zero term. We also have

[formula]

since v(u,z) is positive by definition. This is denoted by the shaded area in the figure. Moreover, we write

[formula]

implying that the non-zero term in row z is equal to [Z  =  z]. Here, the second equality in ([\ref=eqn_ub_leakage_l2]) follows from the independence of U and Z.

To find H(Z|T = t,U = u), we focus on column t of the probability matrix p(z,t|u), which is marked with a bold rectangle in the figure. Let [formula] denote the set of indices [formula] for which p(z,t|u) = p(z). As such, we can write p(z|t,u) as

[formula]

We next prove that H(Z|T = t,U = u) is maximized when [formula], i.e., when all terms in the bold rectangle in Fig. [\ref=fig_ub_leakage_lemma] are non-zero. To this end, we show that the distribution pA*(z) is majorized by pA(z) for all index sets [formula], k  ≤  t. Without loss of generality, we assume that [formula], which implies the ordering

[formula]

for any A. For 0  ≤  n  ≤  k - 1, we write

[formula]

where we obtain ([\ref=eqn_ub_leakage_lp3]) by subtracting

[formula]

from both the numerator and the denominator, and we obtain ([\ref=eqn_ub_leakage_lp5]) by adding

[formula]

to the denominator. Note that both δ1 and δ2 are non-negative since an - ai  ≥  n - i, for n  ≥  i. Finally, ([\ref=eqn_ub_leakage_lp7]) follows from k  ≤  t.

Due to the concavity of f(x) =  - x log (x), and since the set A is finite, the majorization shown in ([\ref=eqn_ub_leakage_lp1])-([\ref=eqn_ub_leakage_lp7]) implies that H(Z|T = t,U = u) is maximized for [formula]. In this case, the conditional distribution of Z given t and u is truncated geometric. Hence, for any v(U,Z), H(Z|T = t,U = u) is upper bounded by the entropy of a truncated geometric random variable, H(Zt).

Using the bound obtained in Lemma [\ref=lem_ub_truncated], we next present the leakage upper bound on the timing channel capacity CT.

The capacity of the timing channel and therefore the BEHC is upper bounded by

[formula]

where H2(  ·  ) is the binary entropy function, and

[formula]

Using the chain rule of mutual information, we write the numerator of ([\ref=eqn_timing_capacity]) as

[formula]

where the last equality follows since T = v(U,Z) + Z is a deterministic function of U and Z. Note that the I(Z;T|U) term in ([\ref=eqn_ub_leakage_thm1]) quantifies the information leaked to the decoder about the energy harvesting process Z. We lower bound this term as

[formula]

where ([\ref=eqn_ub_leakage_thm2]) is due to the independence of Z and U, and ([\ref=eqn_ub_leakage_thm3]) is due to Lemma [\ref=lem_ub_truncated]. Substituting ([\ref=eqn_ub_leakage_thm1]) and ([\ref=eqn_ub_leakage_thm4]) in ([\ref=eqn_timing_capacity]), we get

[formula]

Note that the objective is a function of pT(t) only. Therefore, without loss of generality, we can perform the maximization over distributions pT(t) that are achievable by some auxiliary pU(u) and function v(U,Z). Since T > Z by definition, such a distribution must satisfy

[formula]

As a result, the distribution pT(t) induced by any pU(u) and v(U,Z) lies in the set of distributions P defined in ([\ref=eqn_ub_leakage_p]). We finally note that for geometrically distributed Z and truncated geometric distributed Zt, we have

[formula]

Substituting ([\ref=eqn_ub_leakage_thm6]) and ([\ref=eqn_ub_leakage_thm7]) in ([\ref=eqn_ub_leakage_thm5]), we arrive at the upper bound in ([\ref=eqn_ub_leakage_upperbound])-([\ref=eqn_ub_leakage_p]).

Computing the State Leakage Upper Bound

Solving ([\ref=eqn_ub_leakage_upperbound]) requires finding the optimal p(t) distribution in P. We next find the properties of the optimal distribution p*(t) to simplify its calculation. We begin by rewriting the maximization problem in ([\ref=eqn_ub_leakage_upperbound]) as

[formula]

where we have defined [formula]. The inner maximization in ([\ref=eqn_ub_calculating_1]) is a convex program since it has a concave objective and linear constraints. For this problem, we write the KKT optimality conditions[\cite=bertsekas1999nonlinear] as

[formula]

where λt, γt, μ and η are the Lagrange multipliers for the constraints p(t)  ≥  0, [formula], [formula], and [formula], respectively.

In order to have p(t) = 0 for some t, we need the exponent term in ([\ref=eqn_ub_calculating_stat1]) to go to -    ∞  . This makes λt in the expression of p(t) redundant due to ([\ref=eqn_ub_calculating_cs1]). Hence, we assign λt = 0 for all t, and obtain

[formula]

where we have defined A = e-  η  -  1. We find A from ([\ref=eqn_ub_calculating_cs4]) for all μ  ≥  0 and γi as

[formula]

which, together with ([\ref=eqn_ub_calculating_stat2]), gives us a class of distributions with parameters γt and μ. In addition, from ([\ref=eqn_ub_calculating_cs2]), we know that γt is positive only when the constraint in ([\ref=eqn_ub_leakage_thm6]) is satisfied with equality. As a result, for each value of β, we can find the optimal distribution p*(t) numerically by searching the class of distributions in ([\ref=eqn_ub_calculating_stat2]) for the optimal γt and μ satisfying the above conditions.

Achievable Rates for the BEHC

In this section, we propose two choices for the auxiliary random variable U and the mapping v(u,z) in ([\ref=eqn_timing_capacity]) and find lower bounds on the timing channel capacity and hence the BEHC capacity.

Modulo Encoding with Finite Cardinality Auxiliary Random Variables

Let U be distributed over the finite support set [formula], where N is a parameter to be optimized. We choose the mapping

[formula]

which gives a channel input V = v(U,Z) in [formula]. The output of the timing channel becomes T = V + Z = (U - ZN)  +  1  +  Z. The decoder calculates

[formula]

and therefore perfectly recovers U in each channel use. Hence, the achievable rate for this N is

[formula]

We then find the best rate achievable with this scheme by optimizing over N as

[formula]

This encoding scheme has the following interpretation for the BEHC: Consider that after each instance of Xi = 1, future channel uses are indexed cyclically with the numbers [formula], as illustrated in Fig. [\ref=fig_achievable_modulo] for N = 4. These indices are available to both the encoder and the decoder since the channel is noiseless. The encoder can then convey any symbol [formula] to the decoder by sending a 1 in a channel use indexed with U. This is performed at the earliest possible such channel use in which the required energy is available. For example, U1 = 2 in the figure is conveyed in the first channel use indexed with a 2 (in the first frame of N channel uses) as the energy becomes available for that transmission. However, U2 = 1 in the figure is conveyed in the second channel use indexed with a 1 (in the second frame of N channel uses), since energy is not yet harvested in the first channel use indexed by a 1 (in the first frame of N channel uses). As such, in this coding scheme, the encoder partitions future channel uses into frames of length N, and uses the earliest feasible frame to convey its symbol Uk.

This encoding scheme resembles the idea of concentration proposed by Willems in [\cite=willems1988gaussian] [\cite=willems2000signaling] for Gaussian channels with causal state information. In particular, part of the channel input in [\cite=willems1988gaussian] [\cite=willems2000signaling] is used to concentrate the channel state onto a set of values so that it can be decoded and eliminated at the decoder. Here, by waiting for the next frame of length N when necessary, the effective state Zk is concentrated onto the lattice of the integer multiples of N. The concentrated state is then removed by the decoder with the modulo operation when calculating [formula]. Hence, this encoding scheme can also be interpreted as lattice-coding in the timing channel.

Asymptotic Optimality of Modulo Encoding

We next show that the modulo encoding scheme proposed in Section [\ref=sub_achievable_modulo] is asymptotically optimal as the harvest rate q  →  0. We establish this by comparing the achievable rate of the modulo encoding scheme in ([\ref=eqn_achievable_modulo_rn])-([\ref=eqn_achievable_modulo_r]) with the genie-aided upper bound in ([\ref=eqn_ub_genie_final]).

The modulo encoding scheme for the timing channel with auxiliary [formula] and the channel input given in ([\ref=eqn_achievable_modulo_v]) is asymptotically optimal as energy harvest rate q  →  0.

We show that the upper bound CgenieUB and the achievable rate RmodA scale with the same rate as q goes to zero, i.e.,

[formula]

For fixed q, the problem in ([\ref=eqn_ub_genie_final]) is convex since the objective is continuous, differentiable, and concave in p. Therefore, the optimal p* solving ([\ref=eqn_ub_genie_final]) is the solution of

[formula]

which reduces to

[formula]

for q > 0. Consequently, there exists an optimal 0  <  p*  ≤  0.5 for all harvest rates 0  <  q  ≤  1, which approaches zero with q, i.e.,

[formula]

We choose the parameters of the encoding scheme as [formula], and p(u) = 1 / N for 0  ≤  u  ≤  N - 1, i.e., U is uniformly distributed. Note that p*  ≤  0.5 implies N  ≥  2. Since U is uniform and independent of Z, from ([\ref=eqn_achievable_modulo_v]), we observe that V is distributed uniformly on [formula]. This gives [formula], and the achievable rate for this scheme becomes

[formula]

where [formula]. Observing that the last term in ([\ref=eqn_achievable_asymptotic_thm4]) is increasing in N within the interval

[formula]

Theorem [\ref=thm_asymptotic] states that as q  →  0, the capacity achieving encoding scheme approaches a uniformly distributed U over [formula], where N  →    ∞  . This gives us a simple and asymptotically optimal encoding scheme for scenarios with very low energy harvesting rates.

Extended Modulo Encoding

To improve the rates achievable with modulo encoding of Section [\ref=sub_achievable_modulo], we propose an extended version of the scheme with [formula] and

[formula]

The interpretation of this encoding scheme for the BEHC is given in Fig. [\ref=fig_achievable_extended] for N = 4. Unlike modulo encoding, we index channel uses with [formula] in this case. If the required energy is harvested by the channel use indexed with Uk, then the encoder sends a 1 in that channel use, as is the case for U1 in the figure. However, if the intended channel use is missed due to lack of energy, the encoder sends a 1 within N channel uses after harvesting energy, such that the channel index and Uk are equal in modulo N. An example is U2 in the figure, where the channel index and U2 are equal in modulo N, i.e.,

[formula]

The achievable rate for this scheme is calculated by solving

[formula]

numerically by searching distributions of U. Although this problem is more difficult than that in ([\ref=eqn_achievable_modulo_r]), it is more tractable than ([\ref=eqn_timing_capacity]) since the function v(U,Z) is fixed.

We note that this scheme is an extended version of the modulo encoding scheme in Section [\ref=sub_achievable_modulo], where U is not restricted to be within

[formula]

Capacity with Infinite-Sized Battery and No Battery

For the purposes of comparison, in this section, we present two extreme cases, the case of no energy storage, and the case of infinite-sized energy storage.

Capacity with Zero Energy Storage

We first consider an encoder without energy storage capability. That is, we allow a non-zero channel input Xi = 1 only if energy is harvested within that channel use, i.e., Ei = 1. We note that this is slightly different than the transmit first model described in Section [\ref=sect_model], where the channel input is sent before energy harvesting in each channel use. In contrast, here we consider a harvest first model. For this model, Ei can be considered as an i.i.d. channel state known at the encoder [\cite=ozel2011awgn], for which the capacity is given in ([\ref=eqn_timing_csit]). Using the Shannon strategies U1 = (0,0) and U2 = (0,1), with [U2] = p, the capacity in this case becomes

[formula]

where H2(p) is the binary entropy function.

Capacity with Infinite Energy Storage

Next, we consider the case with an infinite-sized battery at the encoder. Reference [\cite=ozel2012achieving] studies the Gaussian counterpart of this channel, showing that the save-and-transmit scheme is optimal. A similar argument applies for the binary case, implying that a rate of H(X) can be achieved, where X is constrained as [formula]. Hence, the capacity of the channel with an infinite-sized storage is

[formula]

Extension to the Ternary Channel

The equivalence of the energy harvesting channel and the timing channel extends beyond binary channels. As an example, in this section, we present results for the ternary energy harvesting channel (TEHC). The TEHC has three input and output symbols, X,Y∈{ - 1,0,1}, and both X =  - 1 and X = 1 require one unit of energy to be transmitted. This extension can further be generalized to M-ary channels, with each symbol consuming either 0 or 1 unit of energy.

Achievable Rates with Shannon Strategies

In this section, we consider achievable rates with Shannon strategies in the actual channel use index of TEHC. As in the BEHC case, we only have two states, Si∈{0,1}. A strategy U is in the form [formula], where U(0) = X and [formula]. Note that X = 1 or X =  - 1 is possible only when S = 1, and thus we only have three feasible strategies, namely (0,0), (0, - 1) and (0,1).

We first consider codebooks generated by choosing Ui i.i.d. for each codeword and channel use. Let the probability of choosing Ui = (0, - 1) and Ui = (0,1) be p2 and p3, respectively, for all i and all codewords. First, note that this construction yields an ergodic battery state process, with the transition probabilities

[formula]

yielding the stationary probability

[formula]

Note that the stationary probability is a function of p2 + p3, rather than p2 and p3 individually. Denoting U = (0,0) as 0, U = (0, - 1) as - 1 and U = (0,1) as 1, the channel in the case of naïve  Shannon strategies is expressed as

[formula]

The best achievable rate with this scheme is given by

[formula]

where H2(p) is the binary entropy function. We observe that whenever p2  +  p3 is kept constant, the channel in ([\ref=eqn_shannon_naive_channel2]) and the term [formula] in ([\ref=eqn_shannon_naive_rate2]) remain unchanged. On the other hand, H(Y) is a concave function of the distribution of Y. Hence, by Jensen's inequality, when we fix p2 + p3 = 2p, selecting p2 = p3 = p yields the highest rate in ([\ref=eqn_shannon_naive_rate2]). Therefore, the optimum selection is p2 = p3 = p, and we obtain the following simpler rate expression:

[formula]

Similar to the BEHC case, the decoder can exploit the memory by using the n-letter joint probability p(un,yn) for the channel and obtain optimal i.i.d. Shannon strategy (OIID), which achieves the following rate:

[formula]

where again p2 = p3 = p, whose optimality follows from similar arguments as before. Calculating the limit of the n-letter mutual information rate [formula] is possible by using the algorithm in [\cite=arnold2006simulation]. Moreover, we can further improve such achievable rates by constructing codebooks with Markovian Shannon strategies. We evaluate and compare these achievable rates in Section [\ref=sect_numerical].

Timing Equivalence and Related Bounds

In order to find a timing equivalent for the TEHC, we represent the channel output Yn∈{ - 1,0,1} with two sequences, [formula] and Lm∈{ - 1,1}m. Here, Tk is the duration between the (k - 1)st and the kth non-zero outputs in Yn, and Lk is the sign of the kth non-zero output. As in the binary case, (Tm,Lm) and Yn are different and complete representations of the same channel output, and therefore are equivalent.

The timing equivalent of the TEHC consists of two parallel channels, namely a timing channel and a sign channel, expressed as

[formula]

where Qk is the sign of the kth non-zero input. Extending Lemma [\ref=lem_timing_equivalent] to include the sign channel, we observe that the sum capacity of the two independent channels in ([\ref=eqn_ternary_channels]) is equal to the capacity of the TEHC. The capacity of the noiseless sign channel is log 2|L| = 1 bit per channel use. One use of the sign channel also requires [formula] uses of the TEHC on average. Considering this, the capacity of the TEHC is given in the following theorem.

The capacity of the ternary energy harvesting channel is

[formula]

This result is parallel to those in reference [\cite=anantharam1996bits] on queues with information-bearing packets. In the timing equivalent of the TEHC, each non-zero channel input can be interpreted as a packet bearing one bit of information. Hence, as in [\cite=anantharam1996bits], coding for the two channels in ([\ref=eqn_ternary_channels]) is performed independently, yielding the capacity in ([\ref=eqn_ternary_capacity]).

The upper and lower bounds for the BEHC immediately extend to the TEHC, since the capacity for the sign channel is simple. The two upper bounds on CTEHC become

[formula]

where P is given in ([\ref=eqn_ub_leakage_p]), and the two achievable rates become

[formula]

with v(U,Z) is given in ([\ref=eqn_achievable_modulo_v]) for the modulo encoding scheme, and in ([\ref=eqn_achievable_extended_v]) for the extended modulo encoding scheme.

Capacities with Zero and Infinite Storage

We first consider the capacity with zero energy storage. That is, we allow a non-zero channel input Xi = 1 or Xi =  - 1 only when energy is harvested in that channel use, i.e., Ei = 1. Using the Shannon strategies U1 = (0,0), U2 = (0, - 1) and U3 = (0,1), with [U2] = p2 and [U3] = p3, the capacity becomes

[formula]

where Y has the ternary distribution (p2q,1 - (p2 + p3)q,p3q) and H2(p) is the binary entropy function. Since H(Y) is a concave function of the distribution of Y, when p2  +  p3 is fixed, by Jensen's inequality p = p2  =  p3 is the optimal selection. Therefore, we get

[formula]

where Y has the distribution (pq,1 - 2pq,pq).

Next, we consider the capacity with an infinite-sized battery. Similar to the binary case, a rate of H(X) can be achieved, where X is a ternary variable that is constrained as [formula]. Hence, the capacity of the channel with infinite-sized storage is

[formula]

where H(q / 2,1 - q,q / 2) denotes the entropy of the ternary distribution (q / 2,1 - q,q / 2).

Numerical Results

In this section, we compare the timing channel upper bounds and achievable rates in Sections [\ref=sect_upperbounds] and [\ref=sect_achievable], Shannon strategy based achievable rates in Section [\ref=sect_shannon] and capacity results for extreme cases in Section [\ref=sect_inf0] for the BEHC, followed by the results in Section [\ref=sect_ternary] for the TEHC. The upper bounds and achievable rates for the BEHC evaluated at [formula] are given in Table [\ref=table_values].

Fig. [\ref=fig_numerical_behc_some] shows the genie upper bound CgenieUB in ([\ref=eqn_ub_genie_final]), the leakage upper bound CleakageUB in ([\ref=eqn_ub_leakage_upperbound]), the modulo encoding achievable rate RmodA in ([\ref=eqn_achievable_modulo_r]), and the extended encoding achievable rate RextA in ([\ref=eqn_achievable_extended_r]) in comparison with the zero storage capacity CZS in ([\ref=eqn_inf0_zero_capacity]) and the infinite-sized storage capacity CIS in ([\ref=eqn_inf0_infinite_capacity]). All of these quantities are zero at q = 0, because in this case, no energy is harvested, and thus no communication is possible. Moreover, they are all equal to 1 at q = 1, because in this case, the battery is always full, and the channel is equivalent to a binary noiseless discrete memoryless channel without any energy constraints.

From Fig. [\ref=fig_numerical_behc_some], we first observe that the leakage upper bound, CleakageUB, and the achievable rate with the extended encoding scheme, RextA, provide a gap smaller than 0.03 bits per channel use for the capacity, for all harvesting rates q. For small q, both upper bounds and both achievable rates get very close, as expected from the asymptotic optimality of RmodA as q  →  0. On the other hand, for large q, we observe that the genie upper bound CgenieUB is looser compared to the leakage upper bound CleakageUB. This implies that the correlation between the harvesting process and the channel outputs is high in this regime. Finally, we note that although the gap between the infinite storage capacity CIS and the zero storage capacity CZS is large, a unit-sized energy storage device recovers a significant amount of this difference. This demonstrates that even the smallest sized energy storage device can be very beneficial in energy harvesting communication systems.

We next compare the modulo and extended achievable rates, RmodA and RextA, with the Shannon strategy based achievable rates described in Section [\ref=sect_shannon]. We remind that the schemes in Section [\ref=sect_shannon], which are also studied in [\cite=mao2013capacity], only observe the instantaneous battery state in each channel use. Thus, we have simple Shannon strategies, but we allow a Markovian dependence over time in the codewords. Fig. [\ref=fig_numerical_behc_achievable] shows RmodA and RextA along with the optimal i.i.d. Shannon strategy rate ROIID in ([\ref=eqn_shannon_oiid_rate]) and the optimal 1st and 2nd order Markov Shannon strategy rates RM1 and RM2. We observe that although RmodA outperforms ROIID for all q, the 1st and 2nd order Markov Shannon strategies outperform RmodA for large q, as seen in the inset in Fig. [\ref=fig_numerical_behc_achievable]. However, the extended encoding rate RextA outperforms both RM1 and RM2, for all harvesting rates q. These can also be observed partially (for harvesting rates [formula]) from Table [\ref=table_values]. We note that the increase in the achievable rate with the Markov order of the input seems to be small. However, due to the exponential increase in the computational complexity with the Markov order, it was not tractable to simulate and compare inputs of higher Markov orders, i.e., 3rd and higher Markov orders.

A parameter of interest is the optimal frame length N for the modulo encoding scheme in Section [\ref=sub_achievable_modulo], which we present in Fig. [\ref=fig_numerical_behc_Noptimal]. The larger N is, the larger the support of U is, and more information can be packed into a single use of the timing channel. However, as N increases, so does [formula], and thus each symbol takes more time, and more harvested energy is potentially wasted. Thus, for small harvest rates, e.g., q  ≤  0.7, optimal N decreases with increasing q so that less harvested energy is wasted. On the other hand, for q > 0.7, the node is receiving excessive energy, and thus the optimal N increases to pack more information in each timing channel use.

Finally, we present the upper bounds and the achievable rates for the ternary channel, given in ([\ref=eqn_ternary_genie])-([\ref=eqn_ternary_extended]), together with the zero and infinite-sized battery capacities CZS and CIS given in ([\ref=eqn_zero_ter_zero_capacity])-([\ref=eqn_inf_ter_infinite_capacity]), in Fig. [\ref=fig_numerical_tehc_some]. We also compare the achievable rates in Section [\ref=sect_achievable] with the optimal i.i.d. and the 1st order Markov Shannon strategies for the ternary channel in Fig. [\ref=fig_numerical_tehc_achievable]. Note that in the ternary channel, the q = 1 case corresponds to a ternary noiseless discrete memoryless channel, and thus has a capacity of log 2(3) = 1.58 bits per channel use. We observe that similar to the binary case, the leakage upper bound CleakageUB and the extended encoding rate RextA approximate the capacity within 0.05 bits per channel use, and the extended encoding rate outperforms the i.i.d. and the 1st order Markov Shannon strategies, for all harvesting rates q.

Conclusion

Finding the capacity of the binary energy harvesting channel is challenging due to the memory and the input dependence of the battery state. In this paper, we have addressed a simpler case of the binary energy harvesting channel with unit-sized energy storage and without channel noise. For this case, we have shown that the binary channel can also be represented as a timing channel, where the states do not have memory and are not input dependent. Using this equivalence, we have derived two upper bounds: the genie upper bound by providing battery state to the decoder, and the leakage upper bound by quantifying the information leaked to the decoder about energy harvests. We have also proposed two encoding schemes based on a modulo encoding strategy, showing that they are asymptotically optimal for small energy harvesting rates. We have extended these results to the ternary energy harvesting channel. Comparing the upper and lower bounds, we have found the capacities of the binary and ternary energy harvesting channels within 0.03 bits per channel use and 0.05 bits per channel use, respectively. We have also observed that the timing channel based achievable rates outperform i.i.d. and the 1st and 2nd order Markov Shannon strategies that only consider instantaneous battery states.