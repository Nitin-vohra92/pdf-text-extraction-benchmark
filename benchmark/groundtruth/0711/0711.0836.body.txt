Machine Structure Oriented Control Code Logic

Introduction

In theoretical computer science, the meaning of programs usually plays a prominent part in the explanation of many issues concerning programs. Moreover, what is taken for the meaning of programs is mathematical by nature. On the other hand, it is customary that practitioners do not fall back on the mathematical meaning of programs in case explanation of issues concerning programs is needed. More often than not, they phrase their explanations from the viewpoint that a program is code that is capable of controlling the behaviour of some machine. Both theorists and practitioners tend to ignore the existence of this contrast. In order to break through this, we as theorists make in this paper an attempt to map out the way in which practitioners explain issues concerning programs.

We informally define control code as code that is capable of controlling the behaviour of some machine. There are control codes that fail to qualify as programs according to any conceivable theory of programming. For that reason, we make the distinction between control codes and programs. However, there are issues concerning programs that can be explained at the level of control codes by considering them as control codes that qualify as programs. Relative to a fixed machine, the machine-dependent concept of control code that qualifies as program is more abstract than the machine-independent concept of program: control code that qualifies as program is just representative (on the fixed machine) of behaviour associated with a program with which it is possible to explain the behaviour. This might be an important motive to explain issues concerning programs at the level of control codes.

To simplify matters, we consider in this paper non-interactive behaviour only. We consider this simplification desirable to start with. Henceforth, control codes are implicitly assumed to control non-interactive behaviour only and the behaviours associated with programs are implicitly assumed to be non-interactive.

Our attempt to map out the way in which practitioners explain issues concerning programs yields a logical approach to explain issues concerning control codes that are independent of the details of the behaviours that are controlled. Machine structures are used as a basis of the approach. They are inspired by the machine functions introduced in [\cite=ES70a] to provide a mathematical basis for the T-diagrams proposed in [\cite=Bra61a]. A machine structure offers a machine model at a very abstract level.

We illustrate the approach by means of some examples. The issues explained in the examples are well understood for quite a time. They are primarily meant to demonstrate the effectiveness of the approach. In the explanations given, we have consciously been guided by empirical viewpoints usually taken by practitioners rather than theoretical viewpoints. Those empirical viewpoints may be outside the perspective of some theorists.

Mapping out the way in which practitioners explain issues concerning programs, phrased as a matter of applied mathematics, seems to lead unavoidably to unexpected concepts and definitions. This means among other things that steps made in this paper cannot always be motivated directly from the practice that we map out. This is an instance of a general property of applied mathematics that we have to face: the design of a mathematical theory does not follow imperatively from the problems of the application area concerned.

We believe that the presented approach is useful because in various areas frequently no distinction is made between programs and control codes and interest is primarily in issues concerning control codes that are independent of the details of the behaviours that are controlled. Some examples of such areas are software asset sourcing and software patents. Software asset sourcing is an important part of IT sourcing, see e.g. [\cite=LV92a] [\cite=Ver05a] [\cite=Del07a]. An extensive study of software patents and their implications on software engineering practices can be found in [\cite=BK06a]. Moreover, we find that control code production is in the end what software construction is about.

Machine structures in themselves are not always sufficient to explain issues concerning control codes that are independent of the details of the behaviours that are controlled. If systems that provide execution environments for the executable codes of machine structures are involved, then more is needed. We introduce an execution architecture for machine structures as a model of such systems and explain portability of control codes using this execution architecture. An extension of basic thread algebra, introduced in [\cite=BL02a] under the name basic polarized process algebra, is used to describe processes that operate upon the execution architecture. The reason to use basic thread algebra is that it has been designed as an algebra of processes that interact with machines of the kind to which also the execution architecture belongs. It is quite awkward to describe processes of that kind using a general process algebra such as ACP [\cite=Fok00], CCS [\cite=Mil89] or CSP [\cite=Hoa85].

This paper is organized as follows. First, we introduce machine structures (Section [\ref=sect-machine-structures]). Next, we introduce control code notations and program notations (Section [\ref=sect-cc-and-prg]). Then, we present our approach to explain issues concerning control codes by means of examples about the production of a new assembler using an existing one and the production of a new compiler using an existing one (Section [\ref=sect-assembler-compiler]). We also use this approach to explain the relation between compilers and interpreters (Section [\ref=sect-interpreter]). Following this, we sum up the effects of withdrawing a simplifying assumption concerning the representation of control codes made in the foregoing (Section [\ref=sect-bs-repr-cc]). After that, we outline an execution architecture for machine structures (Section [\ref=sect-exearch]). Then, we review the extension of basic thread algebra that covers the effects of applying threads to services (Section [\ref=sect-TA]). Following this, we formalize the execution architecture for machine structures and define the family of services determined by it (Section [\ref=sect-exearch-formal]). After that, we explain portability of control codes using thread algebra and the execution architecture services (Section [\ref=sect-cc-exearch]). Finally, we make some concluding remarks (Section [\ref=sect-concl]).

Up to Section [\ref=sect-exearch], this paper is a major revision of [\cite=Ber04a]. It has been substantially rewritten so as to streamline the material. Several important technical aspects have been significantly modified.

Machine Functions and Machine Structures

In this section, machine structures are introduced. Machine structures are the basis for our approach to explain issues concerning control codes. They are very abstract machine models and cover non-interactive machine behaviour only.

First, we introduce the notion of machine function introduced in [\cite=Ber04a]. It generalizes the notion of machine function introduced in [\cite=ES70a] by covering machines with several outputs. Machine functions are very abstract machine models as well, but they are less suited than machine structures to model general purpose machines such as computers. Machine structures can easily be defined without reference to machine functions. The introduction of machine functions is mainly for expository reasons.

Machine Functions

A machine function [formula] is actually a family of functions: it consists of a function [formula] for each natural number n  >  0. Those functions map each finite sequence of bit sequences to either a bit sequence or [formula] or [formula]. Here, [formula] stands for meaningless and [formula] stands for divergent. A machine function is supposed to model a machine that takes several bit sequences as its inputs and produces several bit sequences as its outputs unless it does not halt on the inputs. Let [formula] be bit sequences. Then the connection between the machine function [formula] and the machine modelled by it can be understood as follows: We write [formula] for the empty sequence, [formula] for the sequence having x as sole element, and [formula] for the concatenation of finite sequences χ and χ'. We use [formula] as a shorthand for [formula]. We write [formula] for the set of all finite sequences with elements from set X. Concerning the machine modelled by a machine function, we assume the following: The intuitions behind the first two assumptions are obvious. The intuition behind the third assumption is that, with respect to not halting, a machine does not use more inputs than it needs. The intuition behind the last assumption is that, with respect to producing outputs, a machine does not use more inputs than it needs.

Henceforth, we write [formula] for the set [formula] of bit sequences. It is assumed that [formula] and [formula].

We now define machine functions in a mathematically precise way.

Let [formula]. Then a machine function [formula] on [formula] is a family of functions satisfying the following rules: We write [formula] for the set of all machine functions.

Take a high-level programming language [formula] and an assembly language [formula]. Consider a machine function [formula], which models a machine dedicated to compiling [formula] programs, and a machine function [formula], which models a machine dedicated to disassembling executable codes. Suppose that the compiling machine takes a bit sequence representing a [formula] program as its only input and produces a bit sequence representing an [formula] version of the [formula] program as its first output, a bit sequence representing a listing of error messages as its second output, and an executable code for the [formula] program as its third output. Moreover, suppose that the disassembling machine takes an executable code as its only input and producing a bit sequence representing an [formula] version of the executable code as its first output and a bit sequence representing a listing of error messages as its second output. The relevant properties of the machines modelled by [formula] and [formula] that may now be formulated include: These formulas express that executable code is produced by the compiling machine unless errors are found, disassembly succeeds unless errors are found, and disassembly is the inverse of assembly.

Machines such as the compiling machine and the disassembling machine are special purpose machines. They are restricted to exhibit a particular type of behaviour. Computers are general purpose machines that can exhibit different types of behaviour at different times. This is possible because computers are code controlled machines. A code controlled machine takes one special input that controls its behaviour. In general, not all bit sequences that a code controlled machine can take as its inputs are capable of controlling the behaviour of that machine. The bit sequences that are capable of controlling its behaviour are known as its executable codes. Note that executable code is a machine-dependent concept.

Machine functions can be used to model code controlled machines as well. We will use the phrase code controlled machine function for machine functions that are used to model a code controlled machine. We will use the convention that the first bit sequence in the argument of the functions that make up a code controlled machine function corresponds to the special input that controls the behaviour of the machine modelled. Because, in general, not all bit sequences that a code controlled machine can take as its inputs are executable codes, more than just a machine function is needed to model a code controlled machine. That is why we introduce machine structures.

Machine Structures

A machine structure [formula] consists a set of bit sequences [formula], functions [formula] that make up a machine function on [formula], and a subset [formula] of [formula]. If [formula] is empty, then the machine structure [formula] is essentially the same as the machine function contained in it. If [formula] is not empty, then the machine structure [formula] is supposed to model a code controlled machine. In the case where [formula] is not empty, the connection between the machine structure [formula] and the code controlled machine modelled by it can be understood as follows: The assumptions made about the machine modelled by a machine structure are the same as the assumptions made before about the machine modelled by a machine function. It is tempting to add the following assumption: We refrain from adding this assumption because it is to be expected that: (a) we can do without it in explaining issues concerning control codes; (b) it does not hold good for all machines that we may encounter. Moreover, in case we would incorporate this assumption in the notion of machine structure, it would not supersede the notion of machine function.

We now define machine structures in a mathematically precise way.

A machine structure [formula] is a structure composed of where the family of functions [formula] is a machine function on [formula]. We say that [formula] is a code controlled machine structure if [formula], and we say that [formula] is a dedicated machine structure if [formula].

Let [formula] be a code controlled machine structure, and let [formula]. Then the meaning of x with respect to [formula], written [formula], is the machine function where the functions [formula] are defined by Moreover, let [formula]. Then x' is behaviourally equivalent to x'' on [formula], written [formula], if [formula].

Let [formula] be a code controlled machine structure. Then we will write Moreover, we will write We will also omit [formula] if the machine structure is clear from the context.

Take a code controlled machine structure [formula]. Consider again the machine functions [formula] and [formula] from Example [\ref=example-machine-function]. These machine functions model a machine dedicated to compiling programs in some high-level programming language [formula] and a machine dedicated to disassembling executable codes, respectively. Let [formula] be such that Then [formula] and [formula] are executable codes that control the behaviour of the code controlled machine modelled by [formula] such that this machine behaves the same as the dedicated machine modelled by [formula] and the dedicated machine modelled by [formula], respectively. This implies that for all [formula] and [formula]: Note that for [formula] there may be an [formula] with [formula] such that [formula], and likewise for [formula].

A code controlled machine structure [formula] determines all by itself a machine model. For an execution, which takes a single step, an executable code [formula], a sequence [formula] of inputs and the machine function [formula] are needed. The executable code is not integrated in the machine in any way. In particular, it is not stored in the machine. As nothing is known about any storage mechanism involved, due to the abstract nature of machine structures, it is not plausible to classify the model as a stored code machine model.

Identifying the Input that Controls Machine Behaviour

It is a matter of convention that the first bit sequence in the argument of the functions that make up the machine function of a code controlled machine structure corresponds to the special input that controls the behaviour of the machine modelled. The issue is whether a justification for this correspondence can be found in properties of the code controlled machine structure. This amounts to identifying the input that controls the behaviour of the machine modelled.

Take the simple case where always two inputs are needed to produce any output and always one output is produced. Then a justification for the correspondence mentioned above can be found only if the machine function involved is asymmetric and moreover the first bit sequence in the argument of the function that yields the first output overrules the second bit sequence. Here, by overruling is meant being more in control.

In this simple case, the criteria of asymmetry and overruling can easily be made more precise. Suppose that [formula] is a code controlled machine structure that models a machine that needs always two inputs to produce any output and produces always one output. Then the machine function [formula] is asymmetric if there exist [formula] such that [formula]. The first bit sequence in the argument of the function [formula] overrules the second one if there exist [formula] and [formula] with z1  ≠  z2 such that [formula] and [formula] for all [formula]. It is easily proved that the first bit sequence in the argument of the function [formula] overrules the second one only if the second bit sequence in the argument of the function [formula] does not overrule the first one.

The criterion of overruling becomes more interesting if more than two inputs may be needed to produce any output, because this is usually the case with general-purpose machines. For example, on a general-purpose machine, the first input may be an executable code for an interpreter of intermediate codes produced by a compiler for some high-level programming language [formula], the second input may be a bit sequence representing the intermediate code for a [formula] program, and one or more subsequent inputs may be bit sequences representing data needed by that program. In this example, the first input overrules the second input and subsequent inputs present and in addition the second input overrules the third input and subsequent inputs present.

Control Code Notations and Program Notations

In this section, we introduce the concepts of control code notation and program notation in the setting of machine structures and discuss the differences between these two concepts. The underlying idea is that a control code is a code that is capable of controlling the behaviour of some machine and a program is a control code that is acquired by programming. The point is that there exist control codes that are not acquired by programming. In [\cite=Jan08a], which appeared after the report version of the current paper [\cite=BM07bP], a conceptual distinction is made between proper programs and dark programs. We found that proper programs correspond with control codes that are acquired by programming and dark programs correspond with control codes that are not acquired by programming. As a matter of fact, the notion of machine structure allows for the discussion of proper and dark programs in [\cite=Jan08a] to be made more precise.

Control Code Notations

The intuition is that, for a fixed code controlled machine, control codes are objects (usually texts) representing executable codes of that code controlled machine. The principal examples of control codes are the executable codes themselves. Note that, like the concept of executable code, the concept of control code is machine-dependent. A control code notation for a fixed code controlled machine is a collection of objects together with a function which maps each of the objects from that collection to a particular executable code of the code controlled machine.

In order to make a code controlled machine transform members of one control code notation into members of another control code notation, like in compiling and assembling, control codes that are not bit sequences must be represented by bit sequences. To simplify matters, we will assume that all control code notations are collections of bit sequences. Assuming this amounts to identifying control codes with the bit sequences representing them. In Section [\ref=sect-bs-repr-cc], we will withdraw this assumption.

Let [formula] be a code controlled machine structure. Then a control code notation for [formula] consists of a set [formula] and a function [formula]. The members of [formula] are called control codes for [formula]. The function ψ is called a machine structure projection.

Let [formula] be a control code notation for a code controlled machine structure [formula]. Then we assume that ψ(c)  =  c for all [formula].

Let [formula] be a code controlled machine structure, let [formula] be a control code notation for [formula], and let [formula]. Then the meaning of c with respect to [formula], written [formula], is [formula].

Control codes, like executable codes, are given a meaning related to one code controlled machine structure. The executable codes of a code controlled machine structure themselves make up a control code notation for that machine structure. Let [formula] be a code controlled machine structure, and let 1E be the identity function on E. Then [formula] is a control code notation for [formula]. We trivially have [formula] for all e∈E. Henceforth, we loosely write [formula] for the control code notation [formula].

Program Notations

To investigate the conditions under which it is appropriate to say that a control code notation qualifies as a program notation, it is in fact immaterial how the concept of program is defined. However, it is at least convenient to make the assumption that, whatever the program notation, there is a hypothetical machine model by means of which the intended behaviour of programs from the program notation can be explained at a level that is suited to our purpose. We believe that this assumption is realistic.

Let some theory of programming be given that offers a reliable definition of the concept of program. Then an acknowledged program notation is a set [formula] of programs. It is assumed that there is a well-understood hypothetical machine model by means of which the intended behaviour of programs from [formula] can be explained at a level that allows for the input-output relation of programs from [formula], i.e. the kind of behaviour modelled by machine functions, to be derived. It is also assumed that this hypothetical machine model determines a function [formula] which maps programs to the machine functions modelling their behaviour at the abstraction level of input-output relations.

In [\cite=BL02a], a theory, called program algebra, is introduced in which a program is a finite or infinite sequence of instructions. Moreover, the intended behaviour of instruction sequences is explained at the level of input-output relations by means of a hypothetical machine model which involves processing of one instruction at a time, where some machine changes its state and produces a reply in case the instruction is not a jump instruction. This hypothetical machine model is an analytic execution architecture in the sense of [\cite=BP04a]. In the current paper, the definition of the concept of program from [\cite=BL02a] could be used. However, we have not fixed a particular concept of program because we intend to abstract from the details involved in any such conceptual definition.

Note that programs, unlike control codes, are given a meaning using a hypothetical machine model. This means that the given meaning is not related to some code controlled machine structure.

Control Code Notations Qualifying as Program Notations

The intuition is that a control code notation for a code controlled machine qualifies as a program notation if there exist an acknowledged program notation and a function from the control code notation to the program notation that maps each control code to a program such that, at the level of input-output relations, the machine behaviour under control of the control code coincides with the behaviour that is associated with the corresponding program. If a control code notation qualifies as a program notation, then its elements are considered programs.

Let [formula] be a code controlled machine structure, and let [formula] be a control code notation for [formula]. Then [formula] qualifies as a program notation if there exist an acknowledged program notation [formula] and a function [formula] such that for all [formula]: This definition implies that, in the case of a control code notation that qualifies as a program notation, control codes can be given a meaning using a hypothetical machine model. Control code by itself is just representative of machine behaviour without any indication that it originates from a program with which it is possible to explain the behaviour by means of a well-understood hypothetical machine model. The function φ whose existence is demanded in the definition is suggestive of reverse engineering: by its existence, control codes look to be implementations of programs on a code controlled machine. We might say that the reason for classifying a control code notation in the ones that qualify as a program notation lies in the possibility of reverse engineering. The function φ is the opposite of a representation. It might be called a co-representation.

Suppose that [formula] is a code controlled machine structure and [formula] qualifies as a program notation. Then [formula] models a code controlled machine whose executable codes constitute a control code notation that qualifies as a program notation. Therefore, it is appropriate to call [formula] a program controlled machine structure. A program controlled machine structure is a code controlled machine structure, but there is additional information which is considered to make it more easily understood from the tradition of computer programming: each executable code can be taken for a program and the intended behaviour of that program can be explained by means of a well-understood hypothetical machine model. It is plausible that, for any code controlled machine structure modeling a real machine, there is additional information which is considered to make it more easily understood from some tradition or another.

We take the view that a code controlled machine structure having both executable codes that can be considered programs and executable codes that cannot be considered programs are improper. Therefore, we introduce the notion of proper code controlled machine structure.

Let [formula] be a code controlled machine structure. Then [formula] is a proper code controlled machine structure if [formula] qualifies as a program notation for some E'  ⊆  E only if [formula] qualifies as a program notation.

Control Code Notations Not Qualifying as Program Notations

The question arises whether all control code notations qualify as program notations. If that were true, then the conceptual distinction between control code notations and program notations is small. If a control code notation qualifies as a program notation, then all control codes concerned can be considered the result of implementing a program on a code controlled machine. This indicates that counterexamples to the hypothesis that all control code notations qualify as program notations will concern control codes that do not originate from programming. We give two counterexamples where control codes arise from artificial intelligence.

Consider a neural network in hardware form, which is able to learn while working on a problem and thereby defining parameter values for many firing thresholds for artificial neurons. The parameter values for a particular problem may serve as input for a machine that needs to address that problem. These problem dependent parameter inputs can be considered control codes by all means. However, there is no conceivable theory of programming according to which these problem dependent parameter inputs can be considered programs. The feature of neural networks that is important here is their ability to acquire control code by another process than programming.

Consider a purely hardware made robot that processes geographical data loaded into it to find a target location. The loaded geographical data constitute the only software that determines the behaviour of the robot. Therefore, the loaded geographical data constitute control code. However, there is no conceivable theory of programming according to which such control codes can be considered programs. They are certainly acquired by another process than programming.

In the case of control code notations that qualify as program notations, the control codes are usually produced by programming followed by compiling or assembling. The examples illustrate different forms of control code production that involve neither programming nor compiling or assembling. The first example shows that control codes can be produced without programming by means of artificial intelligence based techniques. The second example shows that the behaviour of machines applying artificial intelligence based techniques can be controlled by control codes that are produced without programming.

Assemblers and Compilers

In the production of control code, practitioners often distinguish two kinds of control codes in addition to executable codes: assembly codes and source codes. An assembler is a control code corresponding to an executable code of a code controlled machine that controls the behaviour of that code controlled machine such that it transforms assembly codes into executable codes and a compiler is a control code corresponding to an executable code of a code controlled machine that controls the behaviour of that code controlled machine such that it that transforms source codes into assembly codes or executable codes.

In this section, we consider the issue of producing a new assembler for some assembly code notation using an existing one and the similar issue of producing a new compiler for some source code notation using an existing one. Whether an assembly code notation or a source code notation qualifies as a program notation is not relevant to these issues.

Assembly Code Notations and Source Code Notations

At the level of control codes for machine structures, the control code notations that are to be considered assembly code notations and the control code notations that are to be considered source code notations cannot be characterized. The level is too abstract. It happens to be sufficient for many issues concerning assemblers and compilers, including the ones considered in this section, to simply assume that some collection of control code notations comprises the assembly code notations and some other collection of control code notations comprises the source code notations.

Henceforth, we assume that, for each machine structure [formula], disjoint sets [formula] and [formula] of control code notations for [formula] have been given. The members of [formula] and [formula] are called assembly code notations for [formula] and source code notations for [formula], respectively.

The following gives an idea of the grounds on which control code notations are classified as assembly code notation or source code notation. Assembly code is control code that is very close to executable code. This means that there is a direct translation of assembly codes into executable codes. An assembly code notation is specific to a machine. Source code is control code that is not very close to executable code. The translation of source code into executable code is more involved than the translation of assembly code into executable code. Usually, a source code notation is not specific to a machine.

A high-level programming language, such as Java [\cite=GJSB00a] or C# [\cite=HWG03a], is considered a source code notation. The term high-level programming language suggests that it concerns a notation that qualifies as a program notation. However, as mentioned above, whether a source code notation qualifies as a program notation is not relevant to the issues considered in this section.

Control Code Notations Involved in Assemblers and Compilers

Three control code notations are involved in an assembler or compiler: it lets a code controlled machine transform members of one control code notation into members of another control code notation and it is itself a member of some control code notation. We introduce a special notation to describe this aspect of assemblers and compilers succinctly.

Let [formula] be a code controlled machine structure, and let [formula], [formula] and [formula] be control code notations for [formula]. Then we write [formula] for We say that [formula] is in executable form if [formula], that [formula] is in assembly form if [formula], and that [formula] is in source form if [formula].

The Assembler Fixed Point

In this subsection, we consider the issue of producing a new assembler for some assembly code notation using an existing one.

Let [formula] be a code controlled machine structure, and let [formula] be a control code notation for [formula] that belongs to [formula]. Suppose that [formula] is an existing assembler for [formula]. This assembler is in executable form. Suppose further that a new assembler [formula] for [formula] is made available. This new assembler is not in executable form. It needs to be assembled by means of the existing assembler. The new assembler is considered correct if behaviourally equivalent executable codes are produced by the existing assembler and the one obtained by assembling the new assembler by means of the existing assembler, i.e.

[formula]

Let [formula] be the new assembler in executable form obtained by assembling [formula] by means of [formula], i.e. [formula]. Now, [formula] could be assembled by means of [formula] instead of [formula]. In case [formula] produces more compact executable codes than [formula], this would result in a new assembler in executable form that is more compact. Let [formula] be the new assembler in executable form obtained by assembling [formula] by means of [formula], i.e. [formula]. If [formula] is correct, then [formula] and [formula] produce the same executable codes. That is,

[formula]

This is easy to see: rewriting in terms of [formula] and [formula] yields

[formula]

which follows immediately from ([\ref=eqn-correct-assembler]).

Now, [formula] could be assembled by means of [formula] instead of [formula]. However, if [formula] is correct, this would result in [formula] again. That is,

[formula]

This is easy to see as well: rewriting the left-hand side in terms of [formula] and [formula] yields

[formula]

which follows immediately from ([\ref=eqn-equiv-assemblers]). The phenomenon expresses by equation ([\ref=eqn-assembler-fix]) is called the assembler fixed point.

In theoretical computer science, correctness of a program is taken to mean that the program satisfies a mathematically precise specification of it. For the assembler [formula], [formula] would be an obvious mathematically precise specification. More often than not, practitioners have a more empirical view on the correctness of a program that is a new program serving as a replacement for an old one on a specific machine: correctness of the new program is taken to mean that the old program and the new program give rise to the same behaviour on that machine. The correctness criterion for new assemblers given above, as well as the correctness criterion for new compilers given below, is based on this empirical view.

The Compiler Fixed Point

In this subsection, we consider the issue of producing a new compiler for some source code notation using an existing one. Compilers may produce assembly code, executable code or both. We deal with the case where compilers produce assembly code only. The reason for this choice will be explained at the end this subsection.

Let [formula] be a code controlled machine structure, let [formula] be a control code notation for [formula] that belongs to [formula], and let [formula] be a control code notation for [formula] that belongs to [formula]. Suppose that [formula] is an existing compiler for [formula] and [formula] is an existing assembler for [formula]. The existing compiler is in assembly form. However, a compiler in executable form can always be obtained from a compiler in assembly form by means of the existing assembler. Suppose further that a new compiler [formula] for [formula] is made available. This new compiler is not in assembly form. It needs to be compiled by means of the existing compiler. The new compiler is considered correct if

[formula]

Let [formula] be the new compiler in assembly form obtained by compiling [formula] by means of [formula], i.e. [formula]. Now, [formula] could be compiled by means of [formula] instead of [formula]. In case [formula] produces more compact assembly codes than [formula], this would result in a new compiler in assembly form that is more compact. Let [formula] be the new compiler in assembly form obtained by compiling [formula] by means of [formula], i.e. [formula]. If [formula] is correct, then [formula] and [formula] produce the same assembly codes. That is,

[formula]

This is easy to see: rewriting in terms of [formula], [formula] and [formula] yields

[formula]

which follows immediately from ([\ref=eqn-correct-compiler]).

Now, [formula] could be compiled by means of [formula] instead of [formula]. However, if [formula] is correct, this would result in [formula] again. That is,

[formula]

This is easy to see as well: rewriting the left-hand side in terms of [formula], [formula] and [formula] yields

[formula]

which follows immediately from ([\ref=eqn-equiv-compilers]). The phenomenon expresses by equation ([\ref=eqn-compiler-fix]) is called the compiler fixed point. It is a non-trivial insight among practitioners involved in matters such as software configuration and system administration.

The explanation of the compiler fixed point proceeds similar to the explanation of the assembler fixed point in Section [\ref=subsect-assembler-fix], but it is more complicated. The complication vanishes if compilers that produce executable code are considered. In that case, due to the very abstract level at which the issues are considered, the explanation of the compiler fixed point is essentially the same as the explanation of the assembler fixed point.

Intermediate Code Notations and Interpreters

Sometimes, practitioners distinguish additional kinds of control codes. Intermediate code is a frequently used generic name for those additional kinds of control codes. Source code is often implemented by producing executable code for some code controlled machine by means of a compiler or a compiler and an assembler. Sometimes, source code is implemented by means of a compiler and an interpreter. In that case, the compiler used produces intermediate code. The interpreter is a control code corresponding to an executable code of a code controlled machine that makes that code controlled machine behave as if it is another code controlled machine controlled by an intermediate code.

In this section, we briefly consider the issue of the correctness of such a combination of a compiler and an interpreter.

Intermediate Code Notations

At the level of control codes for machine structures, like the control code notations that are to be considered assembly code notations and the control code notations that are to be considered source code notations, the control code notations that are to be considered intermediate code notations of some kind cannot be characterized. It happens to be sufficient for many issues concerning compilers and interpreters, including the one considered in this section, to simply assume that some collection of control code notations comprises the intermediate code notations of interest.

Henceforth, we assume that, for each machine structure [formula], a set [formula] of control code notations for [formula] has been given. The members of [formula] are called intermediate code notations for [formula].

The following gives an idea of the grounds on which control code notations are classified as intermediate code notation. An intermediate code notation is a control code notation that resembles an assembly code notation, but it is not specific to any machine. Often, it is specific to a source code notation or a family of source code notations.

An intermediate code notation comes into play if source code is implemented by means of a compiler and an interpreter. However, compilers for intermediate code notations are found where interpretation is largely eliminated in favour of just-in-time compilation, see e.g. [\cite=Ayc03a], which is material to contemporary programming languages such as Java and C#.

In the case where an intermediate code notation is specific to a family of source code notations, it is a common intermediate code notation for the source code notations concerned. The Common Intermediate Language from the .NET Framework [\cite=WHA03a] is an example of a common intermediate code notation.

Interpreters

Interpreters are quite different from assemblers and compilers. An assembler for an assembly code notation makes a code controlled machine transform members of the assembly code notation into executable codes and a compiler for a source code notation makes a code controlled machine transform members of the source code notation into members of an assembly code notation or executable codes, whereas an interpreter for an intermediate code notation makes a code controlled machine behave as if it is a code controlled machine for which the members of the intermediate code notation serve as executable codes.

We consider the correctness of an interpreter combined with a compiler going with it. The correctness criterion given below is in the spirit of the empirical view on correctness discussed at the end of Section [\ref=subsect-assembler-fix].

Let [formula] be a code controlled machine structure, let [formula] be a control code notation for [formula] that belongs to [formula], let [formula] be a control code notation for [formula] that belongs to [formula], and let [formula] be a control code notation for [formula] that belongs to [formula]. Suppose that [formula] is an existing compiler for [formula] and [formula] is an existing assembler for [formula]. The compiler [formula] lets [formula] transform source codes into assembly codes. Suppose further that a new compiler [formula] for [formula] and a new interpreter [formula] for [formula] are made available. The compiler [formula] lets [formula] transform source codes into intermediate codes.

The combination of [formula] and [formula] is considered correct if

[formula]

While being controlled by an interpreter, the behaviour of a code controlled machine can be looked upon as another code controlled machine of which the executable codes are the intermediate codes involved. The latter machine might appropriately be called a virtual machine. By means of interpreters, the same virtual machine can be obtained on different machines. Thus, all machine-dependencies are taken care of by interpreters. A well-known virtual machine is the Java Virtual Machine [\cite=LY96a].

Bit Sequence Represented Control Code Notations

In order to make a code controlled machine transform members of one control code notation into members of another control code notation, like in assembling and compiling, control codes that are not bit sequences must be represented by bit sequences. To simplify matters, we assumed up to now that all control code notations are collections of bit sequences. In this section, we present the adaptations needed in the preceding sections when withdrawing this assumption. It happens that the changes are small.

The Concept of Bit Sequence Represented Control Code Notation

First of all, we have to generalize the concept of control code notation slightly.

Let [formula] be a code controlled machine structure. Then a bit sequence represented control code notation for [formula] consists of a set [formula], a function [formula], and an injective function [formula]. For all [formula], ρ(c) is called the bit sequence representation of c on [formula]. The function ρ is called the bs-representation function of [formula].

Let [formula] be a bit sequence represented control code notation for a code controlled machine structure [formula]. Then we assume that ψ(c)  =  c for all [formula], ρ(c')  =  c' for all [formula], and ρ(c'')  =  c'' for all [formula] with [formula]. The last assumption can be paraphrased as follows: if an executable code is the bit sequence representation of some control code, then it is its own bit sequence representation. It excludes bs-representation functions that inadvertently produce executable codes.

The Special Notation [formula]

We have to change the definition of the special notation [formula] slightly.

Let [formula] be a code controlled machine structure, and let [formula], [formula] and [formula] be bit sequence represented control code notations for [formula]. Then we write [formula] for

The Explanation of the Assembler Fixed Point

In the explanation of the assembler fixed point given in Section [\ref=subsect-assembler-fix], we have to replace the definitions of [formula] and [formula] by [formula] and [formula], assuming that ρ is the bs-representation function of [formula]. Moreover, we have to adapt Formulas ([\ref=eqn-correct-assembler]), ([\ref=eqn-equiv-assemblers-long]), ([\ref=eqn-assembler-fix]), and ([\ref=eqn-assembler-fix-long]) slightly. Formula ([\ref=eqn-correct-assembler]) must be replaced by Formula ([\ref=eqn-equiv-assemblers-long]) must be replaced by Formula ([\ref=eqn-assembler-fix]) must be replaced by Formula ([\ref=eqn-assembler-fix-long]) must be replaced by

The Explanation of the Compiler Fixed Point

In the explanation of the compiler fixed point given in Section [\ref=subsect-compiler-fix], we have to replace the definitions of [formula] and [formula] by [formula] and [formula], assuming that [formula] is the bs-representation function of [formula] and [formula] is the bs-representation function of [formula]. Moreover, we have to adapt Formulas ([\ref=eqn-correct-compiler]), ([\ref=eqn-equiv-compilers-long]), ([\ref=eqn-compiler-fix]), and ([\ref=eqn-compiler-fix-long]) slightly. Formula ([\ref=eqn-correct-compiler]) must be replaced by Formula ([\ref=eqn-equiv-compilers-long]) must be replaced by Formula ([\ref=eqn-compiler-fix]) must be replaced by Formula ([\ref=eqn-compiler-fix-long]) must be replaced by

The Correctness Criterion for Interpreters

The correctness criterion for interpreters given in Section [\ref=subsect-interpreter], i.e. Formula ([\ref=eqn-correct-interpreter]), must be replaced by assuming that [formula] is the bs-representation function of [formula] and [formula] is the bs-representation function of [formula].

An Execution Architecture for Machine Structures

Machine structures in themselves are not always sufficient to explain issues concerning control codes that are independent of the details of the behaviours that are controlled. In cases where systems that provide execution environments for the executable codes of machine structures are involved, such as in the case of portability of control codes, an abstract model of such systems is needed. In this section, we outline an appropriate model. This model is referred to as the execution architecture for code controlled machine structures. It is a synthetic execution architecture in the sense of [\cite=BP04a]. It can be looked upon as an abstract model of operating systems restricted to file management facilities and facilities for loading and execution of executable codes.

The execution architecture for code controlled machine structures, which is parameterized by a code controlled machine structure [formula], is an abstract model of a system that provides an execution environment for the executable codes of [formula]. It can be looked upon as a machine. This machine is operated by means of instructions that either yield a reply or diverge. The possible replies are [formula] and [formula]. File names are used in the instructions to refer to the bit sequences present in the machine. It is assumed that a countably infinite set [formula] of file names has been given. While designing the instruction set, we focussed on convenience of use rather than minimality.

Let [formula] be a code controlled machine structure. Then the instruction set consists of the following instructions: We write [formula] for this instruction set.

We say that a file name is in use if it has a bit sequence assigned. A state of the machine comprises the file names that are in use, the bit sequences assigned to those file names, a flag indicating whether there is a loaded executable code, and the loaded executable code if there is one.

The instructions can be explained in terms of the effect that they have and the reply that they yield as follows: and the reply is [formula];

if [formula], then nothing changes and the reply is [formula];

if [formula], then the machine does not halt; otherwise, nothing changes and the reply is [formula]. Note that there are three cases in which the instruction [formula] yields the reply [formula]: (a) there is no loaded executable code; (b) there is some file name among [formula] that is not in use; (c) there is no output produced, although the machine halts.

The instructions of which the effect depends on the code controlled machine structure [formula] are the load and execute instructions only. All other instructions could be eliminated in favour of executable codes, assigned to known file names. However, we believe that elimination of these instructions would not contribute to a useful execution architecture. The distinction made between loading and execution of executable codes allows for telling load-time errors from run-time errors.

Thread Algebra

The execution architecture for code controlled machine structures outlined above can be looked upon as a machine which is operated by means of instructions that yield [formula] or [formula] as reply. In cases where this execution architecture is needed to explain issues concerning control codes, such as in the case of portability of control codes, processes that operate upon the execution architecture have to be described. An existing extension of  (Basic Thread Algebra), first presented in [\cite=BP02a], is tailored to the description of processes that operate upon machines of the kind to which the execution architecture belongs. Therefore, we have chosen to use in Section [\ref=sect-cc-exearch] the extension of  in question to describe processes that operate upon the execution architecture. In this section, we review , including guarded recursion and the approximation induction principle, and the relevant extension.

Basic Thread Algebra

is concerned with the behaviours produced by deterministic sequential programs under execution. The behaviours concerned are called threads. It does not matter how programs are executed: threads may originate from execution by a computer, or they may originate from execution by a human operator. In [\cite=BL02a],  is introduced under the name  (Basic Polarized Process Algebra).

In , it is assumed that there is a fixed but arbitrary set of basic actions [formula]. The intuition is that each basic action performed by a thread is taken as a command to be processed by a service provided by the execution environment of the thread. The processing of a command may involve a change of state of the service concerned. At completion of the processing of the command, the service produces a reply value. This reply is either [formula] or [formula] and is returned to the thread concerned.

Although  is one-sorted, we make this sort explicit. The reason for this is that we will extend  with additional sorts in Section [\ref=subsect-apply].

The algebraic theory  has one sort: the sort [formula] of threads.  has the following constants and operators: Terms of sort [formula] are built as usual. Throughout the paper, we assume that there are infinitely many variables of sort [formula], including u,v,w.

We use infix notation for postconditional composition. We introduce action prefixing as an abbreviation: [formula], where p is a term of sort [formula], abbreviates [formula].

Let p and q be closed terms of sort [formula] and [formula]. Then [formula] will perform action a, and after that proceed as p if the processing of a leads to the reply [formula] (called a positive reply) and proceed as q if the processing of a leads to the reply [formula] (called a negative reply).

Each closed term of sort [formula] from the language of  denotes a finite thread, i.e. a thread of which the length of the sequences of actions that it can perform is bounded. Guarded recursive specifications give rise to infinite threads.

A guarded recursive specification over  is a set of recursion equations [formula], where V is a set of variables of sort [formula] and each tX is a term of sort [formula] that has the form [formula], [formula] or [formula]. We write [formula] for the set of all variables that occur on the left-hand side of an equation in E. We are only interested in models of  in which guarded recursive specifications have unique solutions, such as the projective limit model of  presented in [\cite=BB03a].

We extend  with guarded recursion by adding constants for solutions of guarded recursive specifications and axioms concerning these additional constants. For each guarded recursive specification E and each [formula], we add a constant of sort [formula] standing for the unique solution of E for X to the constants of . The constant standing for the unique solution of E for X is denoted by [formula]. Moreover, we add the axioms for guarded recursion given in Table [\ref=axioms-rec] to , where we write [formula] for tX with, for all [formula], all occurrences of Y in tX replaced by [formula]. In this table, X, tX and E stand for an arbitrary variable of sort [formula], an arbitrary term of sort [formula] from the language of , and an arbitrary guarded recursive specification over , respectively. Side conditions are added to restrict the variables, terms and guarded recursive specifications for which X, tX and E stand. The equations [formula] for a fixed E express that the constants [formula] make up a solution of E. The conditional equations [formula] express that this solution is the only one.

We will write + for  extended with the constants for solutions of guarded recursive specifications and axioms RDP and RSP.

In [\cite=BM05c], we show that the processes considered in + can be viewed as processes that are definable over ACP [\cite=Fok00].

Closed terms of sort [formula] from the language of + that denote the same infinite thread cannot always be proved equal by means of the axioms of +. We introduce the approximation induction principle to remedy this. The approximation induction principle,  in short, is based on the view that two threads are identical if their approximations up to any finite depth are identical. The approximation up to depth n of a thread is obtained by cutting it off after performing a sequence of actions of length n.

is the infinitary conditional equation given in Table [\ref=axioms-AIP]. Here, following [\cite=BL02a], approximation of depth n is phrased in terms of a unary projection operator [formula]. The axioms for the projection operators are given in Table [\ref=axioms-pin]. In this table, a stands for an arbitrary member of [formula].

Applying Threads to Services

We extend + to a theory that covers the effects of applying threads to services.

It is assumed that there is a fixed but arbitrary set of foci [formula] and a fixed but arbitrary set of methods [formula]. For the set of basic actions [formula], we take the set [formula]. Each focus plays the role of a name of a service provided by the execution environment that can be requested to process a command. Each method plays the role of a command proper. Performing a basic action f.m is taken as making a request to the service named f to process the command m.

We introduce a second sort: the sort [formula] of services. However, we will not introduce constants and operators to build terms of this sort. [formula] is a parameter of theories with thread-to-service application. [formula] is considered to stand for the set of all services. It is assumed that each service can be represented by a function [formula] with the property that [formula] for all [formula] and [formula]. This function is called the reply function of the service. Given a reply function H and a method [formula], the derived reply function of H after processing m, written [formula], is defined by [formula].

The connection between a reply function H and the service represented by it can be understood as follows: Henceforth, we will identify a reply function with the service represented by it.

It is assumed that there is an undefined service [formula] with the property that [formula] for all [formula].

For each [formula], we introduce the binary apply operator [formula]. Intuitively, [formula] is the service that evolves from H on processing all basic actions performed by thread p that are of the form f.m by H. When a basic action f.m performed by thread p is processed by H, p proceeds on the basis of the reply value produced.

The axioms for the apply operators are given in Table [\ref=axioms-apply]. In this table, f and g stand for arbitrary foci from [formula] and m stands for an arbitrary method from [formula]. The axioms show that [formula] does not equal [formula] only if thread p performs no other basic actions than ones of the form f.m and eventually terminates successfully.

Let p be a closed term of sort [formula] from the language of + and H be a closed term of sort [formula]. Then p converges from H on f if there exists an [formula] such that [formula]. Notice that axiom TSA7 can be read as follows: if u does not converge from H on f, then [formula] equals [formula].

The extension of  introduced above originates from [\cite=BP02a]. In the remainder of this paper, we will use just one focus. We have introduced the general case here because the use of several foci might be needed on further elaboration of the work presented in this paper.

The Execution Architecture Services

In order to be able to use the extension of  presented above to describe processes that operate upon the execution architecture for code controlled machine structures outlined in Section [\ref=sect-exearch], we have to associate a service with each state of the execution architecture. In this section, we first formalize the execution architecture for code controlled machine structures and then associate a service with each of its states.

The Execution Architecture Formalized

The execution architecture for code controlled machine structures consists of an instruction set, a state set, an effect function, and a yield function. The effect and yield functions give, for each instruction u and state s, the state and reply, respectively, that result from processing u in state s.

It is assumed that [formula]. Here, [formula] stands for a state of divergence.

Let [formula] be a code controlled machine structure. Then the execution architecture for [formula] consists of We use the following notation for functions: [formula] for the empty function; [formula] for the function f with [formula] such that f(d)  =  r; [formula] for the function h with [formula] such that for all [formula],  h(d)  =  f(d) if [formula] and h(d)  =  g(d) otherwise; and [formula] for the function g with [formula] such that for all [formula],  g(d)  =  f(d).

Let [formula], and let [formula]. Then [formula] is in use if [formula], and there is a loaded executable code if [formula]. If [formula] is in use, then [formula] is the bit sequence assigned to [formula]. If there is a loaded executable code, then x is the loaded executable code.

Execute instructions can diverge. When an instruction diverges, a situation arises in which no reply can be produced and no further instructions can be processed. This is modelled by [formula] producing [formula] and [formula] producing [formula].

The Family of Execution Architecture Services

Each state of the execution architecture for code controlled machine structures can be looked upon as a service by assuming that [formula] and extending the functions [formula] and [formula] from [formula] to [formula] by stipulating that [formula] and [formula] for all [formula] and s∈S.

We define, for each s∈S, a cumulative effect function [formula] in terms of s and [formula] as follows: We define, for each s∈S, an execution architecture service [formula] in terms of [formula] and [formula] as follows: For each s∈S, Hs is a service indeed: [formula] for all [formula] and [formula]. This follows from the following property of the execution architecture for code controlled machine structures: The witnessing state of this property is [formula]. This state is connected with the undefined service [formula] as follows: [formula].

It is worth mentioning that [formula] and [formula].

We write [formula] for the family of services [formula].

Control Codes and Execution Architecture Services

In this section, we make precise what it means that a control code is installed on an execution architecture service and what it means that a control code is portable from one execution architecture service to another execution architecture service.

Installed Control Codes

The intuition is that a control code is installed on an execution architecture service if either some file name has assigned an executable version of the control code or some file name has assigned an interpretable version of the control code and an appropriate interpreter is also installed on the execution architecture service.

Let [formula] be a code controlled machine structure, let [formula] be a control code notation for [formula], let [formula], and let [formula]. Then c is installed on [formula] if there exist [formula] with [formula] such that A control code is pre-installed on an execution architecture service if the execution architecture service can be expanded to one on which it is installed, using only control codes and data already assigned to file names. Thread algebra is brought into play to make precise what it means that an execution architecture service can be expanded to another execution architecture service.

Let [formula] be a code controlled machine structure, let [formula], and let [formula]. Then [formula] is expansible to [formula] if:

Let [formula] be a code controlled machine structure, let [formula] be a control code notation for [formula], let [formula], and let [formula]. Then c is pre-installed on [formula] if

Take an assembly code notation [formula] and a source code notation [formula]. Consider an execution architecture service [formula] on which file name [formula] has assigned an executable version of an assembler for [formula], file name [formula] has assigned an [formula] version of a compiler for [formula], and file name [formula] has nothing assigned. Suppose that no file name has assigned an executable version of the compiler. Then the compiler is not installed on [formula]. However, the compiler is pre-installed on [formula] because it is installed on the expanded execution architecture service [formula].

Portable Control Codes

We take portability of control code to mean portability from a service defined by the execution architecture for one machine structure to a service defined by the execution architecture for another machine structure.

Transportability is considered a property of all bit sequences, i.e. each bit sequence can be transported between any two services defined by execution architectures for machine structures. Therefore, it is assumed that every bit sequence assigned to a file name on a service can be assigned to a file name on another service by means of an instruction of the form [formula].

A prerequisite for portability of a control code from a service defined by the execution architecture for one machine structure to a service defined by the execution architecture for another machine structure is that, for all inputs covered by the former machine structure, the outputs produced under control of the control code coincide for the two machine structures concerned. Moreover, it must be possible to expand the service from which the control code originates such that the control code is pre-installed on the other service after some bit sequences assigned to file names on the expanded service are assigned to file names on the other service.

Let [formula] and [formula] be code controlled machine structures such that [formula], let [formula] and [formula] be control code notations for [formula] and [formula], respectively, let [formula], and let [formula] and [formula]. Then c is portable from [formula] to [formula] if

Because we assume that the set [formula] of file names is countably infinite, this definition does not imply that the bit sequences to be transported have to be assigned to the same file names at both sides.

Take a source code notation [formula] and an assembly code notation [formula]. Consider an execution architecture service [formula] on which file name [formula] has assigned an executable version of a compiler for [formula] that produces assembly codes from [formula], file name [formula] has assigned a source code from [formula], and file name [formula] has nothing assigned. Moreover, consider another execution architecture service [formula] on which file name [formula] has assigned an executable version of an assembler for [formula], and file name [formula] has nothing assigned. Suppose that the above-mentioned prerequisite for portability of the source code is fulfilled. Then the source code is portable from [formula] to [formula] because it is pre-installed on [formula] where [formula] is the bit sequence assigned to [formula] on [formula].

Conclusions

We have presented a logical approach to explain issues concerning control codes that are independent of the details of the behaviours that are controlled at a very abstract level. We have illustrated the approach by means of examples which demonstrate that there are non-trivial issues that can be explained at this level. In the explanations given, we have consciously been guided by empirical viewpoints usually taken by practitioners rather than theoretical viewpoints. The issues that have been considered are well understood for quite a time. Application of the approach to issues that are not yet well understood is left for future work. We think among other things of applications in the areas of software asset sourcing, which is an important part of IT sourcing, and software patents. At least the concept of control code can be exploited to put an end to the lack of conceptual clarity in these areas about what is software.

We have based the approach on abstract machine models, called machine structures. If systems that provide execution environments for the executable codes of machine structures are involved in the issues to be explained, then more is needed. We have introduced an execution architecture for machine structures as a model of such systems and have explained portability of control codes using this execution architecture and an extension of basic thread algebra. The execution architecture for machine structures, as well as the extension of basic thread algebra, may form part of a setting in which the different kinds of processes that are often transferred when sourcing software assets, in particular software exploitation, can be described and discussed.

We have looked at viewpoints of practitioners from a theoretical perspective. Unfortunately, it is unavoidable that the concepts introduced cannot all be associated directly with the practice that we are concerned about. This means that reading of the paper might be difficult for practitioners. Therefore, the paper must be considered a paper for theorists.

We have explained issues originating from the areas of compilers and software portability. The literature on compilers is mainly concerned with theory and techniques of compiler construction. A lot of that has been brought together in textbooks such as [\cite=AU77a] [\cite=Wir96a]. To our knowledge, the phenomenon that we call the compiler fixed point is not even informally discussed in the literature on compilers. The literature on software portability is mainly concerned with tools, techniques and guidelines to achieve portability. The best-known papers on software portability are early papers such as [\cite=PW75a] [\cite=TKB78a]. To our knowledge, the concept of portable program is only very informally discussed in the literature on software portability. Moreover, we are not aware of formal descriptions of compiler fixed point and portable program in the literature on formal methods.