Relational Models

Synonyms

Relational learning, statistical relational models, statistical relational learning, relational data mining

Glossary

and

The probability for a world x is written as P(X  =  x) where X  =  {XR,t}R,t is the set of random variables and x denotes their values in the world (see Figure [\ref=fig:rdb])

Definition

Relational models are machine-learning models that are able to truthfully represent some or all distinguishing features of a relational domain such as long-range dependencies over multiple relationships. Typical examples for relational domains include social networks and knowledge bases. Relational models concern nontrivial relational domains with at least one relation with an arity of two or larger that describes the relationship between entities, e.g., knows, likes, dislikes. In the following we will focus on nontrivial relational domains.

Introduction

Social networks can be modelled as graphs, where actors correspond to nodes and where relationships between actors such as friendship, kinship, organizational position, or sexual relationships are represented by directed labelled links (or ties) between the respective nodes. Typical machine learning tasks would concern the prediction of unknown relationship instances between actors, as well as the prediction of actors's attributes and class labels. In addition, one might be interested in a clustering of actors. To obtain best results, machine learning should take an actors's network environment into account. Thus two individuals might appear in the same cluster because they have common friends.

Relational learning is a branch of machine learning that is concerned with these tasks, i.e. to learn efficiently from data where information is represented in form of relationships between entities.

Relational models are machine learning models that truthfully model some or all distinguishing features of relational data such as long-range dependencies propagated via relational chains and homophily, i.e. the fact that entities with similar attributes are neighbors in the relationship structure. In addition to social network analysis, relational models are used to model knowledge graphs, preference networks, citation networks, and biomedical networks such as gene-disease networks or protein-protein interaction networks. Relational models can be used to solve the aforementioned machine learning tasks, i.e., classification, attribute prediction, clustering. Moreover, relational models can be used to solve additional relational learning tasks such as relationship prediction and entity resolution. Relational models are derived from directed and undirected graphical models or latent variable models and typically define a probability distribution over a relational domain.

Key Points

Statistical relational learning is a subfield of machine learning. Relational models learn a probabilistic model of a complete networked domain by taking into account global dependencies in the data. Relational models can lead to more accurate predictions if compared to non-relational machine learning approaches. Relational models typically are based on probabilistic graphical models, e.g., Bayesian networks, Markov networks, or latent variable models.

Historical Background

Inductive logic programming (ILP) was maybe the first machine learning effort that seriously focussed on a relational representation. It gained attention in the early 1990s and focusses on learning deterministic or close-to-deterministic dependencies, with representations derived from first order logic. As a field, ILP was introduced in a seminal paper by Muggleton [\cite=Muggleton91]. A very early and still very influential algorithm is Quinlan's FOIL [\cite=DBLP:journals/ml/Quinlan90]. ILP will not be a focus in the following, since social networks exhibit primarily statistical dependencies. Statistical relational learning started around the beginning of the millennium with the work by Koller, Pfeffer, Getoor and Friedman [\cite=Koller:89] [\cite=DBLP:conf/ijcai/FriedmanGKP99]. Since then many combinations of ILP and relational learning have been explored. The Semantic Web, Linked Open Data are producing vast quantities of relational data and [\cite=Tresp:09] [\cite=Nickel2012] describe the application of statistical relational learning to these emerging fields. Relational learning has been applied to the learning of knowledge graphs, which model large domains as triple databases. [\cite=nickel2016review] is a recent review on the application of relational learning to knowledge graphs. An interesting application is the semi-automatic completion of knowledge graphs by analysing information from the Web and other sources, in combination with relational learning, which exploits the information already present on the knowledge graph [\cite=dong2014knowledge].

Machine Learning in Relational Domains

Relational Domains

Relational domains are domains that can truthfully be represented by relational databases. The glossary defines the key terms such as a relation, a predicate, a tuple and a database. Nontrivial relational domains contain at least one relation with an arity of two or larger that describes the relationship between entities, e.g., knows, likes, dislikes. The main focus here is on nontrivial relational domains.

Social networks are typical relational domains, where information is represented by multiple types of relationships (e.g., knows, likes, dislikes) between entities (here: actors), as well as through the attributes of entities.

Generative Models for a Relational Database

Typically, relational models can exploit long-range or even global dependencies and have principled ways of dealing with missing data. Relational models are often displayed as probabilistic graphical models and can be thought of as relational versions of regular graphical models, e.g., Bayesian networks, Markov networks, and latent variable models. The approaches often have a "Bayesian flavor" but a fully Bayesian statistical treatment is not always performed.

The following section describes common relational graphical models.

Non-relational Learning

Although we are mostly concerned with relational learning, it is instructive to analyse the special case of non-relational learning. Consider a database with a key entity class actor with elements ei and with only unary relations; thus we are considering a trivial relational domain. Then one can partition the random variables into independent disjoint sets according to the entities, and the joint distribution factorizes as

[formula]

where the binary random variable XR,ei is assigned to tuple ei in unary relation R (see glossary).

Thus the set of random variables can be reduced to non-overlapping independent sets of random variables. This is the common non-relational learning setting with i.i.d. instances, corresponding to the different actors.

Non-relational Learning in a Relational Domain

An common approximation to a relational model is to model unary relations of key entities in a similar way as in a non-relational model as

[formula]

where [formula] is a vector of relational features that are derived from the relational network environment of the actor i. Relational features provide additional information to support learning and prediction tasks. For instance, the average income of an individual's friends might be a good covariate to predict an individual's income in a social network. The underlying mechanism that forms these patterns might be homophily, the tendency of individuals to associate with similar others. The goal of this approach is to be able to use i.i.d. machine learning by exploiting some of the relational information. This approach is commonly used in applications where probabilistic models are computationally too expensive. The application of non-relational machine learning to relational domains is sometimes referred to as propositionalization.

Relational features are often high-dimensional and sparse (e.g., there are many people, but only a small number of them are an individual's friends; there are many items but an individual has only bought a small number of them) and in some domains it can be easier to define useful kernels than to define useful features. Relational kernels often reflect the similarity of entities with regard to the network topology. For example a kernel can be defined based on counting the substructures of interest in the intersection of two graphs defined by neighborhoods of the two entities [\cite=DBLP:conf/esws/LoschBR12] (see also the discussion on RDF graphs further down).

Learning Rule-Premises in Inductive Logic Programming

Some researchers apply a systematic search for good features and consider this as an essential distinction between relational learning and non-relational learning: in non-relational learning features are essentially defined prior to the training phase whereas relational learning includes a systematic and automatic search for features in the relational context of the involved entities. Inductive logic programming (ILP) is a form of relational learning with the goal of finding deterministic or close-to-deterministic dependencies, which are described in logical form such as Horn clauses. Traditionally, ILP involves a systematic search for sensible relational features that form the rule premises [\cite=Dz:07].

Relational Models

In this section we describe the most important relational models in some detail. These are based on probabilistic graphical models, which efficiently model high-dimensional probability distributions by exploiting independencies between random variables. In particular, we consider Bayesian networks, Markov networks and latent variable models. We start with a more detailed discussion on possible world models for relational domains and with a discussion on the dual structures of the triple graph and the probabilistic graph.

Random Variables for Relational Models

As mentioned before, a probabilistic database defines a probability distribution over the possible worlds under consideration. The goal of relational learning is to derive a model of this probability distribution.

In a canonical representation, we assign a binary random variable XR,t to each possible tuple in each relation. Then

[formula]

and

[formula]

The probability for a world x is written as P(X  =  x) where X  =  {XR,t}R,t is the set of random variables and x denotes their values in the world (see Figure [\ref=fig:rdb]). What we have just described corresponds to a closed-world assumption where all tuples, which are not part of the database instance, map to R(t) =  and thus XR,t  =  0. In contrast in an open world assumption, we would consider the corresponding truth values and states as being unknown and the database instance as being only partially observed. Often in machine learning some form of a local closed-world assumption is applied with a mixture of true, false and unknown ground predicates [\cite=dong2014knowledge] [\cite=krompass2015type]. For example one might assume that, if at least one child of an individual is specified, it implies that all children are specified (closed-world), whereas if no child is specified, children are considered unknown (open-world). Another aspect is that type constraint imply that certain ground predicates are false. For example, only individuals can get married, but neither cities or buildings. Other types of background knowledge might materialize tuples that are not explicitly specified. For example, if individuals live in Munich, by simple reasoning one can conclude that they also live in Bavaria and Germany. The corresponding tuples can be added to the database.

Based on background knowledge, one might want to modify the canonical representation, which uses only binary random variables. For example, discrete random variables with N states are often used to implement the constraint that exactly one out off N ground predicates is true, e.g. that an individual belongs exactly to one out of N income classes or age classes. It is also possible to extend the model towards continuous variables.

So far we have considered an underlying probabilistic model and an observed world. In probabilistic databases one often assumes a noise process between the actual database instance and the observed database instance by specifying a conditional probability

[formula]

Thus only YR,t is observed whereas the real interest is on XR,t: One observes a t∈Iy(R)    ⇔    YR,t  =  1 from which one can infer for the database instance P(t∈I(R))    ⇔    P(XR,t  =  1). With an observed YR,t  =  1, there is a certain probability that XR,t  =  0 (error in the database) and with an observed YR,t  =  0 there is a certain probability that XR,t  =  1 (missing tuples).

The theory of probabilistic databases focussed on the issues of complex query answering under a probabilistic model. In probabilistic databases [\cite=DBLP:series/synthesis/2011Suciu] the canonical representation is used in tuple-independent databases, while multi-state random variables are used in block-independent-disjoint (BID) databases.

Most relational models assume that all entities (or constants) and all predicates are known and fixed (domain closure assumption). In general these constraints can be relaxed, for example if one needs to include new individuals in the model. Also, latent variables derived from a cluster or a factor analysis can be interpreted as new "invented" predicates.

Triple Graphs and Probabilistic Graphical Networks

A triple database consists of binary relations represented as subject-predicate-object triples. An example of a triple is: (Jack, knows, Mary). A triple database can be represented as a knowledge graph with entities as nodes and predicates as directed links, pointing from the subject node to the object node. Triple databases are able to represent web-scale knowledge bases and sociograms that allow multiple types of directed links. Relations of higher order can be reduced to binary relations by introducing auxiliary entities ("blank nodes"). Figure [\ref=fig:rdf] shows an example of a triple graph. The Resource Description Framework (RDF) is triple based and is the basic data model of the Semantic Web's Linked Open Data. In social network analysis, nodes would be individuals or actors and links would correspond to ties.

For each triple a random variable is introduced. In Figure [\ref=fig:rdf] these random variables are represented as elliptical red nodes. The binary random variable associated with the tripe (s = i,p = k,o = j) will be denoted as Xk(i,j).

Directed Relational Models

The probability distribution of a directed relational model, i.e. a relational Bayesian model, can be written as

[formula]

Here {XR,t}R,t refers to the set of random variables in the directed relational model, while XR,t denotes a particular random variable. In a graphical representation, directed arcs are pointing from all parent nodes (XR,t) to the node XR,t (Figure [\ref=fig:rdf]). As {Equation [\ref=eq:drm] indicates the model requires the specification of the parents of a node and the specification of the probabilistic dependency of a node, given the states of its parent nodes. In specifying the former, one often follows a causal ordering of the nodes, i.e., one assumes that the parent nodes causally influence child nodes and their descendents. An important constraint is that the resulting directed graph is not permitted to have directed loops, i.e. that it is a directed acyclic graph. A major challenge is to specify P(XR,t|(XR,t)), which might require the calculation of complex aggregational features as intermediate steps.

Probabilistic Relational Models

Probabilistic relational models (PRMs) were one of the first published directed relational models and found great interest in the statistical machine learning community [\cite=Koller:89] [\cite=Getoor:07]. An example of a PRM is shown in Figure [\ref=fig:prm]. PRMs combine a frame-based (i.e., object-oriented) logical representation with probabilistic semantics based on directed graphical models. The PRM provides a template for specifying the graphical probabilistic structure and the quantification of the probabilistic dependencies for any ground PRM. In the basic PRM models only the entities' attributes are uncertain whereas the relationships between entities are assumed to be known. Naturally, this assumption greatly simplifies the model. Subsequently, PRMs have been extended to also consider the case that relationships between entities are unknown, which is called structural uncertainty in the PRM framework [\cite=Getoor:07].

In PRMs one can distinguish parameter learning and structural learning. In the simplest case the dependency structure is known and the truth values of all ground predicates are known as well in the training data. In this case, parameter learning consists of estimating parameters in the conditional probabilities. If the dependency structure is unknown, structural learning is applied, which optimizes an appropriate cost function and typically uses a greedy search strategy to find the optimal dependency structure. In structural learning, one needs to guarantee that the ground Bayesian network does not contain directed loops.

In general the data will contain missing information, i.e., not all truth values of all ground predicates are known in the available data. For some PRMs, regularities in the PRM structure can be exploited (encapsulation) and even exact inference to estimate the missing information is possible. Large PRMs require approximate inference; commonly, loopy belief propagation is being used.

More Directed Relational Graphical Models

A Bayesian logic program is defined as a set of Bayesian clauses [\cite=Kersting:01]. A Bayesian clause specifies the conditional probability distribution of a random variable given its parents. A special feature is that, for a given random variable, several such conditional probability distributions might be given and combined based on various combination rules (e.g., noisy-or). In a Bayesian logic program, for each clause there is one conditional probability distribution and for each random variable there is one combination rule. Relational Bayesian networks [\cite=Jaeger:97] are related to Bayesian logic programs and use probability formulae for specifying conditional probabilities. The probabilistic entity-relationship (PER) models [\cite=Heck:07] are related to the PRM framework and use the entity-relationship model as a basis, which is often used in the design of a relational database. {Relational dependency networks [\cite=Neville:2004] also belong to the family of directed relational models and learn the dependency of a node given its Markov blanket (the smallest node set that make the node of interest independent of the remaining network). Relational dependency networks are generalizations of dependency networks as introduced by [\cite=Heck:00] [\cite=Hof:97]. A relational dependency networks typically contains directed loops and thus is not a proper Bayesian network.

Undirected Relational Graphical Models

The probability distribution of an undirected graphical model, i.e. a Markov network, is written as a log-linear model in the form

[formula]

where the feature functions fi can be any real-valued function on the set xi  ⊆  x and where [formula]. In a probabilistic graphical representation one forms undirected edges between all nodes that jointly appear in a feature function. Consequently, all nodes that appear jointly in a function will form a clique in the graphical representation. Z is the partition function normalizing the distribution.

A major advantage is that undirected graphical models can elegantly model symmetrical dependencies, which are common in social networks.

Markov Logic Network (MLN)

A Markov logic network (MLN) is a probabilistic logic which combines Markov networks with first-order logic. In MLNs the random variables, representing ground predicates, are part of a Markov network, whose dependency structure is derived from a set of first-order logic formulae (Figure [\ref=fig:mln]).

Formally, a MLN L is defined as follows: Let Fi be a first-order formula, (i.e., {a logical expression containing constants, variables, functions and predicates) and let [formula] be a weight attached to each formula. Then L is defined as a set of pairs (Fi,wi) [\cite=Richardson:06] [\cite=Domingos:07].

From L the ground Markov network ML,C is generated as follows. First, one generates nodes (random variables) by introducing a binary node for each possible grounding of each predicate appearing in L given a set of constants [formula] (see the discussion on the canonical probabilistic representation). The state of a node is equal to one if the ground predicate is true, and zero otherwise. The feature functions fi, which define the probabilistic dependencies in the Markov network, are derived from the formulae by grounding them in a domain. For formulae that are universally quantified, grounding is an assignment of constants to the variables in the formula. If a formula contains N variables, then there are |C|N such assignments. The feature function fi is equal to one if the ground formula is true, and zero otherwise. The probability distribution of the ML,C can then be written as

[formula]

where ni(x) is the number of formula groundings that are true for Fi and where the weight wi is associated with formula Fi in L.

The joint distribution [formula] will be maximized when large weights are assigned to formulae that are frequently true. In fact, the larger the weight, the higher is the confidence that a formula is true for many groundings. Learning in MLNs consists of estimating the weights wi from data. In learning, MLN makes a closed-world assumption and employs a pseudo-likelihood cost function, which is the product of the probabilities of each node given its Markov blanket. Optimization is performed using a limited memory BFGS algorithm.

The simplest form of inference in a MLN concerns the prediction of the truth value of a ground predicate given the truth values of other ground predicates. For this task an efficient algorithm can be derived: In the first phase of the algorithm, the minimal subset of the ground Markov network is computed that is required to calculate the conditional probability of the queried ground predicate. It is essential that this subset is small since in the worst case, inference could involve all nodes. In the second phase, the conditional probability is then computed by applying Gibbs sampling to the reduced network.

Finally, there is the issue of structural learning, which, in this context, means the learning of first order formulae. Formulae can be learned by directly optimizing the pseudo-likelihood cost function or by using ILP algorithms. For the latter, the authors use CLAUDIAN [\cite=Raedt:97], which can learn arbitrary first-order clauses (not just Horn clauses, as in many other ILP approaches).

An advantage of MLNs is that the features and thus the dependency structure is defined using a well-established logical representation. On the other hand, many people are unfamiliar with logical formulae and might consider the PRM framework to be more intuitive.

Relational Markov Networks (RMNs)

RMNs generalize many concepts of PRMs to undirected relational models [\cite=DBLP:conf/uai/TaskerPK02]. RMNs use conjunctive database queries as clique templates, where a clique in an undirected graph is a subset of its nodes such that every two nodes in the subset are connected by an edge. RMNs are mostly trained discriminately. In contrast to MLNs and similarly to PRMs, RMNs do not make a closed-world assumption during learning.

Relational Latent Variable Models

In the approaches described so far, the structures in the graphical models were either defined using expert knowledge or were learned directly from data using some form of structural learning. Both can be problematic since appropriate expert domain knowledge might not be available, while structural learning can be very time consuming and possibly results in local optima which are difficult to interpret. In this context, the advantage of relational latent variable models is that the structure in the associated graphical models is purely defined by the entities and relations in the domain.

The additional complexity of working with a latent representation is counterbalanced by the great simplification by avoiding structural learning. In the following discussion, we assume that data is in triple format; generalizations to relational databases haven been described [\cite=Xu:06] [\cite=krompass2014probabilistic].

The IHRM: A Latent Class Model

The infinite hidden relational model (IHRM) [\cite=Xu:06] (a.k.a infinite relational model [\cite=Kemp:06]) is a generalization to a probabilistic mixture model where a latent variable with states [formula] is assigned to each entity ei. If the latent variable for subject s = i is in state r and the latent variable for object o = j is in state q, then the triple (s = i,p = k,o = j) exists with probability P(Xk(i,j)|r,q). Since the latent states are unobserved, we obtain

[formula]

which can be implemented as the sum-product network of Figure [\ref=fig:rdflatent].

In the {IHRM the number of states (latent classes) in each latent variable is allowed to be infinite and fully Bayesian learning is performed based on a Dirichlet process mixture model. For inference Gibbs sampling is employed where only a small number of the infinite states are occupied in sampling, leading to a clustering solution where the number of states in the latent variables is automatically determined. Models with a finite number of states have been studied as stochastic block models [\cite=nowicki2001estimation].

Since the dependency structure in the ground Bayesian network is local, one might get the impression that only local information influences prediction. This is not true, since latent representations are shared and in the ground Bayesian network the latter are parents to the random network variables Xk,(i,j). Thus common children with evidence lead to interactions between the parent latent variables. Thus information can propagate in the network of latent variables.

The IHRM has a number of key advantages. First, no structural learning is required, since the directed arcs in the ground Bayesian network are directly given by the structure of the triple graph. Second, the IHRM model can be thought of as an infinite relational mixture model, realizing hierarchical Bayesian modeling. Third, the mixture model can be used for a cluster analysis providing insight into the relational domain.

The IHRM has been applied to social networks, recommender systems, for gene function prediction and to develop medical recommender systems. The IHRM was the first relational model applied to trust learning [\cite=Rettinger:08].

In [\cite=AiroldiBFX08] the IHRM is generalized to a mixed-membership stochastic block model, where entities can belong to several classes.

RESCAL: A Latent Factor Model

The RESCAL model was introduced in [\cite=Nickel2011] and follows a similar dependency structure as the IHRM as shown in Figure [\ref=fig:rdflatent]. The main differences are that, first, the latent variables do not describe entity classes but are latent entity factors and that, second, there are no nonnegativity or normalization constraints on the factors. The probability of a triple is calculated with

[formula]

as

[formula]

where (x)  =  1 / (1  +   exp  - x).

As in the IHRM, factors are unique to entities which leads to interactions between the factors in the ground Bayesian network, enabling the propagation of information in the network of latent factors. The relation-specific matrix GR  =  g(k,:,:) encodes the factor interactions for a specific relation and its asymmetry permits the representation of directed relationships.

The calculation of the latent factors is based on the factorization of a multi-relational adjacency tensor where two modes represent the entities in the domain and the third mode represents the relation type (Figure [\ref=fig:RESCAL]). With a closed-world assumption and a squared-error cost function, efficient alternating least squares (ALS) algorithm can be used; for local closed world assumptions and open world assumptions, stochastic gradient descent is being used.

The relational learning capabilities of the RESCAL model have been demonstrated on classification tasks and entity resolution tasks, i.e., the mapping of entities between knowledge bases. One of the great advantages of the RESCAL model is its scalability: RESCAL has been applied to the YAGO ontology [\cite=DBLP:conf/www/SuchanekKW07] with several million entities and 40 relation types [\cite=Nickel2012]! The YAGO ontology, closely related to DBpedia [\cite=DBLP:conf/semweb/AuerBKLCI07] and the Google Knowledge Graph [\cite=Singhal], contains formalized knowledge from Wikipedia and other sources.

RESCAL is part of a tradition on relation prediction using factorization of matrices and tensors. [\cite=YuCYTX06] describes a Gaussian process-based approach for predicting a single relation type, which has been generalized to a mutli-relational setting in [\cite=XuKT09].

A number of variations and extensions exist. The SUNS approach [\cite=Tresp:09] is based on a Tucker1 decomposition of the adjacency tensor, which can be computed by a singular value decomposition (SVD). The Neural Tensor Network  [\cite=socher2013reasoning] combines several tensor decompositions. Approaches with a smaller memory footprint are TransE [\cite=bordes2013translating] and HolE [\cite=nickel2015holographic]. The multiway neural network in the Knowledge Vault project [\cite=dong2014knowledge] combines the strengths of latent factor models and neural networks and was successfully used in semi-automatic completion of knowledge graphs. [\cite=nickel2016review] is a recent review on the application of relational learning to knowledge graphs.

Key Applications

Typical applications of relational models are in social networks analysis, knowledge graphs, bioinformatics, recommendation systems, natural language processing, medical decision support, and Linked Open Data.

Future Directions

As a number of publications have shown, best results can be achieved by committee solutions integrating factorization approaches with user defined or learned rule patterns [\cite=nickel2014reducing] [\cite=dong2014knowledge]. The most interesting application in recent years was in projects involving large knowledge graphs, where performance and scalability could clearly be demonstrated [\cite=dong2014knowledge] [\cite=nickel2016review]. The application of relational learning to sequential data and time series opens up new application areas, for example in clinical decision support and sensor networks [\cite=esteban2015predicting] [\cite=esteban2016coev].  [\cite=tresp2015learning] studies the relevance of relational learning to cognitive brain functions.