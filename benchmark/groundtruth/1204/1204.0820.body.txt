Tail-Constraining Stochastic Linear-Quadratic Control: Large Deviation and Statistical Physics Approach

Introduction

Stochastic differential equations are used both in control [\cite=49Wei] [\cite=Kalman1960] [\cite=60Kal] [\cite=60Str] [\cite=61KB] [\cite=63Kal] [\cite=74Kai] and statistical physics [\cite=05Ein] [\cite=06Smo] [\cite=57Ula] [\cite=92Kam] [\cite=04Gar] to state the problems. The two fields also use similar mathematical methods to analyze these equations. However, and in spite of the commonalities, there were relatively few overlaps between the disciplines in the past, even though the communications between two communities improved in the recent years. Some new areas in control, for example stochastic path integral control [\cite=05Kap] [\cite=11Kap] [\cite=10BWK] [\cite=Dj11], have emerged influenced by analogies, intuition and advances in statisical/theoretical physics. Vice versa, many practical experimental problems in physics, chemistry and biology dealing with relatively small systems (polymers, membranes, etc), which are driven and experience significant thermal fluctuations, can now be analyzed and manipulated/controled with accuracy and quality unheard of in the past, see for example [\cite=11Jar] [\cite=05BLR]. Besides, approaches from both control theory and statistical physics started to be applied to large natural and engineered networks, like chemical, bio-chemical and queuing networks [\cite=97MA] [\cite=07SS] [\cite=10CCGT] [\cite=11CCS]. Dynamics over these networks is described by stochastic differential equations, the networks have enough of control knobs, and they function under significant fluctuations which need to be controlled to prevent rare but potentially devastating failures. Related setting of stochastic optimization, i.e. optimization posed under uncertainty, has also came recently in the spot light of statistical physics inspired algorithms and approaches [\cite=ABRZ2011]. Convergence of these are related ideas motivated the manuscript, where we discuss analysis and control of rare events in the simplest possible, but practically rather widespread universal and general, linear setting. We realize that the general topic of linear control is well studied and many (if not all) possible questions, e.g. related to proper way of accounting for risk (rare events), were discussed in the field in the past. In spite of that, we still hope that this manuscript may also be useful not only to physicists, who may wish to explore new and largely unusual (in physics) formulations, but also to control theorists.

Consider first order (in time derivatives) stochastic linear dynamics of a vector [formula] over time interval t'∈[t;T]

[formula]

where A and B are constant matrices; u(t') is the control vector applied at the moment of time t'; and {ξ} = (ξ(t')|t'∈[t;T]) is the zero mean, short-correlated noise with covariance V

[formula]

where one utilizes "statistical physics" notations for the expectation value (average) over noise, [formula]. Here in Eq. ([\ref=xi]) and below the averages are over multiple possible realizations of the noise, each generating a new trajectory of the system, {x} = (x(t')|t'∈[t;T]), under given control {u} = (u(t')|t'∈[t;T]). The Eq. ([\ref=stoch]) is causal, thus assuming retarded (Stratonovich) regularization of the noise on the right-hand-side of the discreet version of Eq. ([\ref=stoch]). The physical meaning of the vectors and matrices in Eq. ([\ref=stoch]) is as follows. A is the matrix explaining stretching, shearing and rotation of the system trajectory in the N-dimensional space if the control and external noise would not be applied. Matrix B describes possible limitations on the degrees of freedom in the system one can control. To simplify notations we consider signal, control and noise vectors having the same dimension, N, where thus B is quadratic. The setting of Eqs. ([\ref=stoch],[\ref=xi]) is classic one in the control theory. It describes the so-called Linear-Quadratic (LQ) stochastic control problem, which was introduced in [\cite=Kalman1960] [\cite=60Kal] [\cite=61KB] [\cite=63Kal] and became foundational for the control theory as a field, see e.g. [\cite=Willems1971] [\cite=Athans1971] and references therein. In the classical formulation one seeks to solve the following optimization, t∈[0;T]:

[formula]

where Q,R and F are pre-defined stationary (time independent) symmetric positive matrices and one uses the super-script asterisk, *  , to mark transposition. J(t;T;{u},{x}) (later on, and when it is not confusing, we will use the shortcut notation J) is a scalar quadratic cost functional of the state vector {x} = (x(t')|t'∈[t;T]), and the control vector, {u} = (u(t')|t'∈[t;T]) evaluated for all intermediate times t' from the

[formula]

Deterministic Case and LQ-optimal control

We start this Section from a disclaimer: all results reported here are classical, described in [\cite=Kalman1960] [\cite=Willems1971] [\cite=Athans1971] [\cite=Jacobson1973] [\cite=Whittle1981] [\cite=Whittle1986] [\cite=Cb1988] and latter papers and books, see e.g. [\cite=02FPE] [\cite=96ZDG] [\cite=09Hes]. We present it here only for making the whole story of the manuscript self-explanatory and coherent.

When the noise is ignored, Eq. ([\ref=stoch]) should be considered as a deterministic constraint, reducing any of the optimal control schemes ([\ref=LQ],[\ref=RS-LQ],[\ref=TO-LQ],[\ref=CC-LQ]) to a simple variation of the cost functional ([\ref=cost]) over u. Using the standard variational technique with a time dependent Lagrangian multiplier for the constraint, and then excluding the multiplier one derives the equation

[formula]

which should be supplied by the boundary condition (also following from the variation), u*(T) + x*(T)FBR- 1 = 0. (Let us remind that we choose the notations where the dimensionality of u coincides with the dimensionality of x. We also assume that inverses of all the matrices involved in the formulation are well defined. This assumption is not critical and is made here only to simplify the notations. In the general case when some of the matrices, in particular R, are not full rank, one can generalize the formulas properly, using a proper notion of the pseudo-inverse.) Substituting, u =  - R- 1B*Πx, in Eq. ([\ref=u_det]) one arrives at the following equation for Π

[formula]

with the boundary condition Π(T) = F. Eq. ([\ref=Pi]), solved backwards in time, results in Π(t) and then, u*(t;x) =  - R- 1B*Π(t)x =  - Kx.

To gain a qualitative understanding of the backwards in time dynamics of Π, let us briefly discuss the simplest possible case with all the matrixes entering Eq. ([\ref=Pi]) replaced by scalars, then yielding the following analytic solution for the optimal K

[formula]

where T0 and ±  1 are chosen to satisfy the boundary condition, K(T) = BF / R. When [formula], the backwards in time dynamics saturates (after a short ~  τ transient) to a F-independent constant, resulting from replacing tanh  in Eq. ([\ref=K_1_no_noise]) by - 1. Therefore, in the stationary regime, T  →    ∞   the optimal control is with the constant in time, frozen K. One also finds that the optimal control in the one dimensional deterministic case is always stable, μ = KB - A > 0.

Returning to the general (finite vector) case one concludes that when T is sufficiently large the optimal control is of the form described by Eq. ([\ref=u-opt]), i.e. it is linear in x and asymptotically time independent, with K = R- 1B*Π0 where Π0 solves Eq. ([\ref=Pi]) with the first term replaced by zero. It is well known in the control theory that (under some standard common sense assumptions on B and R matrices) stable solution of the system of the algebraic Riccati equations is unique and moreover it can be found efficiently. (See e.g. Chapter 12 of Sec[\cite=98Zho] and references therein.)

Let us now discuss the bare LQ control, now in the presence of the noise. Since Eq. ([\ref=stoch]) is linear, one can naturally split the full solution into a sum, x = x1 + x2, where x1 satisfies Eq. ([\ref=stoch]) without noise and it is equivalent to the noise-less solution, just discussed in this Section. Then, the second term satisfies, dx2 / dt' = Ax2  +  ξ, with x2(t) = 0. However, since the noise is zero mean, 〈ξ〉 = 0, x2 is zero mean too, i.e. 〈x2〉 = 0. Next, let us analyze the split of term in 〈J〉, which is the optimization objective of the LQ scheme. Since, x1 and x2 are independent (by construction) and because x2 is zero mean, 〈J〉, splits into two terms, 〈J1〉  +  〈J2〉, each dependent on x1 and x2 vectors only. 〈J1〉 is simply equivalent to J analyzed above in the deterministic case, while 〈J2〉 is u-independent, thus not contributing the optimization at all. To summarize, the LQ optimal control is not sensitive to the noise and it is thus equivalent to the deterministic (noiseless) case described above.

Generating Function

Consider the Generating Function (GF), Z(θ;K), defined by Eq. ([\ref=Z]). Z(θ;K) is of an obvious relevance to the RS-LQ scheme, but it is also useful for analysis of other schemes as well, because of the following (Laplace transform) relation to the PDF of J:

[formula]

where (as before) the asterisk in the sub-script indicates that the PDF was evaluated at u = Kx, with K being yet undefined constant matrix. The inverse of Eq. ([\ref=Laplace1]) is

[formula]

where it is assumed that the integration contour, considered in the complex plain of θ, goes on the right from all the singularities (poles and cuts) of Z(θ;K). In the path integral representation GF gets the following form

[formula]

where p is an auxiliary vector variable (momentum). Here and everywhere below we assume that, even if the dynamics was not stable before application of the control, control stabilizes it. Formally, this means that μ, defined by Eq. ([\ref=tildeQ+mu]), has no eigenvalues with negative real values. The "boundary" (F-dependent term) in Eq. ([\ref=Z-path_int]) was ignored, assuming that (like in the one-dimensional LQ case discussed above) it may only influence how the optimum is approached (backwards in time) but remains inessential for describing asymptotic behavior of the optimal control. This path integral is (most conveniently) evaluated by changing to the Fourier (frequency) domain, expressing pair correlation function as the frequency integral, and then relating it to the derivative of the log-GF over θ,

[formula]

Here in Eqs. ([\ref=pair-corr],[\ref=log-derivative]) the averaging is over the path integral measure described by Eq. ([\ref=Z-path_int]). Further, evaluating the integral over θ, fixing normalization, Z(0;K) = 1, and using the standard formula of matrix calculus, [formula], where 1 stands for the unit matrix, one arrives at the following expression

[formula]

which is asymptotically exact at T  →    ∞  . Moreover, one can show that for any (spatially) finite system next order corrections to the rhs of Eq. ([\ref=Z-full]) are O(1). Note that this representation ([\ref=Z-full]) of the log-GF, as an integral over frequency of a log-det, is similar to the relation discussed in Section 3 of [\cite=Cb1988] in the context of linking the RS-LQG control to the maximum entropy formulation of the H∞ control. The log-det has also appeared in [\cite=07TCCP] where statistics of currents were analyzed in general non-equilibrium (off-detailed-balance) linear system.

To gain intuition let us first analyze Eq. ([\ref=Z-full]) in the simple scalar case where the integral on the rhs can be evaluated analytically

[formula]

Substituting this expression into Eq. ([\ref=Laplace2]) and estimating the integral over θ in a saddle-point approximation (justified when T is large) one arrives at the LD expression ([\ref=LD]) where

[formula]

The LD function is obviously convex and it is defined only for positive j. (The asterisk marks, as before, that the average and the probability are computed conditioned to yet unspecified K.) S*(j) achieves its minimum at, [formula], and shows linear asymptotic, S*(j)  ≈  jμ2 / (V), at j  ≫  〈j〉. Note, that the aforementioned asymptotic is associated with the cut-singularity in the complex θ plane of the GF expression ([\ref=Z-full-1d]). Indeed, substituting Eq. ([\ref=Z-full-1d]) into Eq. ([\ref=Laplace2]) and shifting the integration contour to the left, thus forcing it to surround anti-clockwise the ]  -    ∞  ;θ* =  - μ2 / (V)] cut, and then estimating the integral by a small part of the contour surrounding vicinity of the cut tip at θ*, we arrive at the aforementioned j  ≫  〈j〉 asymptotic, S(j)  ≈   - jθ*.

Returning back to analysis of the general formulas ([\ref=Z-full],[\ref=Laplace2]), one observes that even though to reconstructing S*(j) in its full integrity explicitly as a function of K does not look feasible, we can still, motivated by the scalar case analysis, make some useful general statements about both the average, 〈j〉*, and the j  ≫  〈j〉* asymptotic of S*(j). We will start from the latter problem.

For analysis of the tail the key object of interest is the det  in Eq. ([\ref=Z-full]) considered at zero frequency, ω = 0. Specifically, one aims to find the zero of the determinant with the largest real value:

[formula]

Indeed, any zero (there might be many of these in the general matrix case) marks the tip of the respective cut singularity of Z(θ;K) in the complex θ-plane. Then, the tail, j  ≫  〈j〉*, asymptotic of the LD function becomes, S*(j) =  - jθ*. Note, that this linear in j estimation is valid only in the case of a finite system, when the set (spectrum) of zeros (defined by the condition in Eq. ([\ref=max_zero]) is discrete. In the case of an infinite system, when the spectrum of zeros becomes quasi-continuous, one needs to account for the multiple zeros, as illustrated in the "string" example of Section [\ref=sec:String].

To evaluate 〈j〉* (as a function of K) in the general case one first analyzes it in the time representation. Substituting the u =  - Kx ansatz with constant K in Eq. ([\ref=stoch]), expressing x(t) formally as an integral over time (for a given realization of the noise), substituting the result into Eq. ([\ref=cost]), averaging over noise, and then taking the T  →    ∞   limit one arrives at

[formula]

where the latter expression is implicit (as the condition is a matrix one, thus not resolvable explicitly in general) function of K. It is straightforward but tedious to check (introducing matrix Lagrangian multiplier for the condition in Eq. ([\ref=j-average-time]) and making variation over K and Π) that optimization of Eq. ([\ref=j-average-time]) over K results in the algebraic Riccatti equation equivalent to Eq. ([\ref=Pi]) with the first term ignored. Note that the fact that the optimal control derived from the optimization of the average cost function in the stochastic case coincides with the result of the deterministic optimization (ignoring stochasticity) is the fact very well known in the control theory. The optimal value of the functional in the deterministic case saturates to a constant at T  →    ∞  , while in the stochastic case the average optimal cost grows with time linearly. Asymptotic convergence of the two seemingly different schemes to the same optimal control is thus an indication of the asymptotic self-consistency of the linear ansatz ([\ref=u-opt]).

Differentiating Eq. ([\ref=Z-full]) over θ and then setting θ to zero, one derives an alternative (to Eq. ([\ref=j-average-time])) representation for the average rate of the cost function conditioned to K

[formula]

Note that comparison of Eqs. ([\ref=Z-full],[\ref=j-average-time],[\ref=j-average-frequency]) also allows to derive expression for the derivative of the log-GF as a time integral, and then have it presented in an implicit algebraic form

[formula]

where ṽ = V(1 + θV(μ*)- 1μ- 1)- 1.

Optimal Asymptotic Controls

In this Section we formulate the RS-LQ, TO-LQ and CC-LQ asymptotic schemes in the general vector/matrix form as an optimization over K. (Note that the asymptotic LQ scheme was already stated as a minimum of Eq. ( [\ref=j-average-time]), or equivalently of Eq. ([\ref=j-average-frequency]) in the preceding Section.) Then we illustrate these formulations on the scalar example.

[formula], which is asymptotically optimal for the RS-LQ control considered at θ > 0, is found by maximizing Z(θ;K). Using Eq. ([\ref=Z-full]) one derives

[formula]

where (λ(BK - A)) > 0 denotes the stability condition ensuring that the real values of all the eigen-values of BK - A are positive. Note that constancy of the stationary RS-LQ optimal control was proven in [\cite=Jacobson1973], therefore making our approach self-consistent. An alternative, but obviously equivalent, formulation of the RS-LQ optimal control consists in minimizing - T- 1∂θ log Z(θ;K). Going along this path and utilizing Eq. ([\ref=der-log-Z2]) one arrives at

[formula]

generalizing the LQ formulation stated in the preceding Section as the minimization of Eq. ([\ref=j-average-time]). Solving Eq. ([\ref=RS-LQ-simple]) is reduced to analysis of the respective generalization of the Riccati equations which can than be turned into a linear eigen-value problem described within the so-called Hamiltonian approach to the RS-LQ problem discussed in [\cite=Whittle1986].

From Eq. ([\ref=TO-LQ]), and assuming time-independence of the control, one can state the general asymptotic TO-LQ optimum utilizing Eqs. ([\ref=Laplace2],[\ref=Z-full]) as an optimization of a double integral over frequency and θ. However, in practice one is interested to discuss the TO-LQ optimization only at sufficiently large values of the cost, jT. Using analysis of the preceding Section one derives the desired double asymptotic (valid at large T and large j) and simpler to state expression describing [formula]

[formula]

where max  is over complex θ and the optimal LD value of the PDF tail is exponential,

[formula]

with [formula] solving Eq. ([\ref=max_zero]). Note that the det  = 0 condition in Eq. ([\ref=TO-opt]) is reminiscent of the μ-measure which is the key element of the robust control approach, see [\cite=96ZDG] [\cite=98Zho] and references therein.

In the same double asymptotic (large T and large j) regime the optimal CC-LQ control ([\ref=CC-LQ]) is given by

[formula]

Note that unlike Eqs. ([\ref=RS-opt],[\ref=TO-opt]), Eq. ([\ref=CC-opt]) does not have valid solutions for any value of the log (1 / ε) / J ratio. In fact, it is clear from Eq. ([\ref=LD-TO]) that to have a nonempty solution of Eq. ([\ref=CC-opt]) one needs to require that [formula]. Once the optimum solution is found, one estimates the LD asymptotic of the cost function PDF by an expression similar to the one given by Eq. ([\ref=LD-TO]), with [formula] subscript replaced by the [formula] one.

Scalar case

In the remainder of this Section we illustrate all of the aforementioned formulas on the scalar example. In this simple case integral on the rhs of Eq. ( [\ref=RS-opt]) is equal to

[formula]

resulting in the following optimal value

[formula]

The large deviation tail of the PDF of j at a given K can be extracted from Eq. ([\ref=pdfJ]):

[formula]

Optimizing the PDF over K we find two different cases depending on the sign of A. At A > 0 coefficient in front of the linear in j term on the rhs of Eq. ([\ref=coeff-j]) grows monotonically with K from the (A / B, +   ∞  ) interval. To find the optimal value of K in this case one has to take into the O(j) term thus deriving :

[formula]

In the other case of A =  - |A| < 0 the linear coefficient in Eq. ([\ref=coeff-j]) reaches its maximum at K = BQ / (R|A|), thus resulting in

[formula]

Finally, the CC-optimal formula ([\ref=CC-opt]) has no solution if B2j / (RV) < c in the A > 0 case and if [formula] in the A < 0 case. (Here we assume, as above, that ε(0;T) =  exp ( - cT).) When ε is chosen sufficiently small (i.e. c is sufficiently large), the feasibility domain in Eq. ([\ref=CC-opt]) is not empty and one distinguishes two regimes depending on how Kε, defined by

[formula]

compares with K0, which is the bare LQ optimal value correspondent to Kθ from Eq. ([\ref=K-theta-scalar]) evaluated at θ = 0. One derives

[formula]

where of the two regimes one is achieved within the interior of the optimization domain (tail constraint is not restrictive) while the other one corresponds to the tail imposed by the boundary of the domain. It is worth noting that ([\ref=K-epsilon-scalar]) is valid for both signs of A.

Example of a String

In this Section we discuss an explicitly solvable example of an infinite system where the set of zeros (of the determinant in the condition of Eq. ([\ref=max_zero])) forms a quasi-continuous spectrum. Consider a string, defined as an over-damped system of multiple bids on a line connected to each other by elastic springs of strength D, stretched by the linear force of the strength A and subject to Langevien driving:

[formula]

where [formula], xj marks position of the j-th bid of the string, and the zero-mean white-Gaussian noise is distributed as in Eq. ([\ref=xi]) with Vij  =  Vδij. uj in Eq. ([\ref=spectr1]) stands for control. We are looking for a time-independent linear in x control, assuming that the control acts uniformly on all bids of the string, i.e. uj  =    -  Kxj. Let us also assume that the string is periodic with the period N. Then, solution of Eq. ([\ref=spectr1]) allows expansion in the series over spatial harmonics

[formula]

with the wave vector, q, from the interval, -  π < q < π, and resulting in the following separated equations for the individual harmonics

[formula]

Repeating the steps leading to ([\ref=Z-full-1d]) one arrives at

[formula]

We choose to analyze only the most interesting regime, D  ≫  BK - A, when a nontrivial collective behavior emerges. Then, in the long wave-length, 1 -  cos q  →  q2 / 2, and continuous, [formula], limits one derives

[formula]

where one utilizes the standard K,E notations for the elliptic functions.

Expression on the rhs of Eq. ([\ref=spectr10]) shows a singularity at s =  - 1, coinciding with the singularity (in the complex θ plane) observed in the scalar case at θ*. Substituting Eq. ([\ref=spectr10]) into Eq. ([\ref=Laplace2]) and evaluating the integral over θ in the saddle-point approximation one arrives at

[formula]

Juxtaposing the string expression Eq. ([\ref=spectr13]) to the scalar one Eq. ([\ref=pdfJ]) one notes different behaviors with respect to BK - A. Optimizing Eq. ([\ref=spectr13]) over K at a given large value J = jT, one obtains the same tail expression, second formula in ([\ref=TO-scalar]), however with another optimal control

[formula]

replacing the first formula in Eq. ([\ref=TO-scalar]). Note that in the string case the optimal K scales as J2 / 5 which should be contrasted to the J1 / 2 scaling in the scalar case from Eq. ([\ref=TO-scalar]).

Conclusions and Path Forward

This manuscript contributes the subject in control theory - designing control scheme with some guarantees not only on the average of the cost functions but also on fluctuations, specifically extreme fluctuations related to the tail of the cost function PDF. We consider linear, first order in time derivative, stochastic system of the Langevien type subject to minimization of a quadratic cost function and also with (chance) constraints imposed on the tail of the cost function PDF. In the stationary regime of large time, when control is sufficient to make the system stable, we reduce the stochastic dynamic problem of the "field theory" type to static optimization analysis with objectives and constraints stated in a matrix form. This type of reduction is unusual in the system lacking the fine-tuned Fluctuation Dissipation relation between relaxational and stochastic terms. On the other hand, the progress made is linked to linearity of the underlying stochastic systems which allowed, as in some problems of passive scalar turbulence [\cite=95CFKL] [\cite=98CFK] [\cite=01FGV] and driven linear-elastic systems [\cite=05KAT] [\cite=07TCCP], to formally express solution for the system trajectory as an explicit function of the noise realization. Besides that, main technical ingredients, which allowed us to derive the results, consisted in making plausible assumption about the structure of the control (linear in the state variable and frozen in time), and then performing asymptotic evaluations of the cost functions statistics conditioned to the value of the cost matrix. Techniques of path integral, spectral analysis and large deviation estimations were used. We tested results on the simple scalar case and illustrated utility of the method on an exemplary high-dimensional system (1d chain of particles connected in a string).

We plan to continue exploring the interface between control theory and statistical physics addressing the following challenges.

Computational feasibility of the main formulas of the paper, stating RS-, TO- and CC- controls in Eqs. ([\ref=RS-opt],[\ref=TO-opt],[\ref=CC-opt]) as static optimization problems, need to be analyzed for large systems and networks. After all main efforts in the applied control theory go into designing efficient algorithms for discovering optimal, or close to optimal, control, and we do plan to contribute this important task. Therefore, further analysis is required to answer the important practical question: if the static formulations of the newly introduced TO-QG and CC-QG controls allow computationally favorable exact or approximate expressions in terms of convex optimizations?

We also plan to study weakly non-linear stochastic systems through a singular perturbation stochastic diagrammatic technique of the Martin-Siggia-Rose type [\cite=73MSR]. Besides, some of the methods we used in the manuscript, especially related to large deviation analysis, are not restricted to linear systems. Our preliminary tests show that effects of the non-linearity on the PDF tail are seriously enhanced in comparison with how the same nonlinearity influences the average case control.

It will be interesting to study TO- and CC- versions of the path-integral nonlinear control problems discussed in [\cite=05Kap] [\cite=11Kap] [\cite=10BWK] [\cite=Dj11]. These problems, in their standard min-cost formulations, allow reduction (under some Fluctuation-Dissipation-Theorem like relations between the form of control, covariance matrix of the noise and the cost function) from the generally non-linear Hamilton-Jacobi-Bellman equations for the optimal cost function to a linear equation of a Schrödinger type.

The effects of partial observability and noise in the observations can be easily incorporated in both TO- and CC- schemes discussed in the paper. In fact this type of generalization is standard and widespread in the control theory, where for example the LQG (Linear-Quadratic-Gaussian) control generalizes the LQ control.

In terms of relevance to an application, this work was motivated by recent interest and discussions related to developing new optimization and control paradigms for power networks, so-called smart grids. In this application, strong fluctuations associated with loads and renewable generation, electro-mechanical control of generation, desire to make the energy production cheaper while also (and most importantly) maintaining probabilistic security limitations of the chance-constrained type - all of the above make the theoretical model discussed in this paper an ideal framework to consider. In particular, we plan to extend the approaches of [\cite=11DBC] [\cite=12HBC] and modify and apply the theory developed in this manuscript to design a multi-objective Chance Constrained Optimum Power Flow including better control of generation, loads and storage resources in power grids.

We also anticipate that some of the models and results discussed in the paper are of interest for problems in statistical micro- and bio- fluidics, focusing on adjusting characteristics of individual molecules (polymers, membranes, etc) and also aimed at modifying properties of the medium (non-Newtonian flows) macroscopically. Time independent and linear nature of the control schemes discussed in the paper make them especially attractive for these applications. Natural constrains, e.g. associated with the force-field (optical or mechanical) as well as with some other physical limitations, could be incorporated into control as single- or multi-objective cost functions.

We are thankful to D. Bienstock, L. Gurvits, H.J. Kappen, K. Turitsyn and participants of the "Optimization and Control Theory for Smart Grids" project at LANL for motivating discussions and remarks. Research at LANL was carried out under the auspices of the National Nuclear Security Administration of the U.S. Department of Energy at Los Alamos National Laboratory under Contract No. DE C52-06NA25396.