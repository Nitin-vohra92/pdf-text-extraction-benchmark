Decimation-Enhanced Finite Alphabet Iterative Decoders for LDPC codes on the BSC

Introduction

The design and analysis of message-passing (MP) algorithms for low-density parity-check (LDPC) [\cite=gallager] codes have recieved much attention over the last decade. Techniques such as density evolution [\cite=richardson] by Richardson and Urbanke, have been proposed for asymptotic analysis of MP decoders on LDPC code ensembles. For finite-length analysis of codes with fixed number of iterations, methods such as the use of computation trees by Wiberg [\cite=wiberg], pseudocodeword analysis by Kelly and Sridhara [\cite=kelly], and graph-cover decoding analysis by Vontobel and Koetter [\cite=vontobel], have been proposed. The characterization of the error floor phenomenon of MP algorithms has also been well investigated using the notion of stopping sets for the binary erasure channel (BEC)[\cite=Di] by Di et. al., and using notions of trapping sets by Richardson [\cite=richardsontrap] and instantons by Chernyak et. al. [\cite=chernyak] for other general channels. Burshtein and Miller proposed the technique of using expander arguments for MP for proving that code ensembles can correct a linear fraction of errors [\cite=Burshtein].

Inspite of the aforementioned techniques proposed for finite-length analysis, the problem of analyzing a particular MP algorithm for a fixed number of iterations still remains a challenge. This is because the dynamics of MP gets too complex beyond a certain number of iterations, and there is exponential growth in the number of nodes with number of iterations in the computation trees of the codes. Although Burshtein and Miller's method of using expander arguments which allows for use of large number of iterations, provides bounds of great theoretical value, they are practically less significant. Moreover, for the Binary Symmetric channel (BSC), the problem of correcting a fixed number of errors assumes greater importance as it determines the slope of the error floor in the performance of the decoder [\cite=milos]. Therefore, it would be desirable to have an MP decoder that is able to correct a fixed number of errors within fewest possible iterations, and for which we will be able to provide performance guarantees in terms of guaranteed correction capability. Even from a practical standpoint, this would be an attractive feature with many present-day applications requiring much higher decoding speeds and much lower target frame error rates.

Recently we proposed a new class of finite alphabet iterative decoders (FAID) for LDPC codes on the BSC coined as multilevel decoders in [\cite=planjery] and showed that these decoders have potential to surpass belief propagation (BP) in the error floor region with much lower complexity. These decoders were derived by identifying potentially harmful subgraphs that could be trapping sets present in any finite-length code and designing to correct error patterns on these subgraphs in an isolated manner. Although the numerical results in [\cite=planjery] demonstrated the efficacy of these decoders, providing provable statements in terms of guaranteed error correction capability still remains a difficult task since the convergence of the decoder for an error pattern in a trapping set is heavily influenced by the neighborhood of the trapping set in a non-trivial manner. This was also identified by Declercq et. al. in [\cite=Davidbrest], where subgraphs induced by codewords were used in the decoder design.

In this paper, we propose decimation-enhanced finite alphabet iterative decoders for LDPC codes on the BSC. Decimation, a method originally developed for solving constraint satisfaction problems in statistical physics, involves guessing the values of certain variables and fixing them to these values while continuing to estimate the remaining variables. In [\cite=montonari], Montanari et. al. analyzed a BP-guided randomized decimation procedure that estimates the variables in the k-SAT problem. Dimakis and Wainwright used a similar notion in the form of facet guessing for linear programming (LP) based decoding in [\cite=dimakis], and Chertkov proposed a bit-guessing algorithm in order to reduce error floors of LDPC codes under LP decoding [\cite=chertkov]. In contrast, we propose a simple decimation procedure in this paper that serves as a guide to help the multilevel FAID algorithm to coverge faster on a small number of errors. Our main insight is that the role of decimation should not necessarily be to correct errors, but to ensure that more variable nodes in the graph that initially receive right values from the channel are shielded from the errorneous messages emanating from the error nodes by decimating those correct variable nodes.

The rest of the paper is organized as follows. Section [\ref=sect_Prelim] provides preliminaries. In Section [\ref=sect_faid], we provide a detailed description of the decimation-aided FAID algorithm. Finally in Section [\ref=sect_analysis], we provide some theoretical as well as numerical results and conclude with a discussion.

Preliminaries

Let [formula] denote the Tanner graph of an (n,m) binary LDPC code C with the set of variable nodes [formula] and set of check nodes [formula]. E is the set of edges in G. A code C is said to be dv-left-regular if all variable nodes in V of graph G have the same degree dv. The degree of a node is the number of its neighbors.

Let [formula] be the input to the decoder from the BSC. A trapping set [formula] is a non-empty set of variable nodes in G that are not eventually corrected by the decoder [\cite=richardsontrap]. Note that during analysis of decoders in this paper, it is implicitly assumed that the all-zero codeword is transmitted. This is a valid assumption since we consider only symmetric decoders, as explained in [\cite=richardson].

A multilevel FAID [formula], as defined in [\cite=planjery], is a 4-tuple given by [formula]. The messages are levels confined to a message alphabet M which is defined as M  =  {0,  ±  Li :1  ≤  i  ≤  M}, where [formula] and Li > Lj for any i > j. The set Y denotes the set of possible channel values. For the case of BSC, Y is defined as [formula], and for each variable node vi in G, the channel value yi∈Y is determined by [formula], i.e., we use the mapping [formula] and [formula].

Φv:Y  ×  Mdv - 1  →  M is the update rule used at a variable node with degree dv. The map Φv can be described in closed form as a linear or non-linear threshold function, or simply as a look-up table (LUT). For this paper, we shall use the LUT form. The LUT of Φv for a particularly good 7-level FAID that we shall be using throughout this paper is given in Table [\ref=LUT244325] for [formula] (for [formula], the LUT can be obtained by symmetry).

Φc:Mdc - 1  →  M is the update function used at a check node with degree dc. The function is given by where [formula] denotes the standard signum function.

The important concept of isolation assumption was also introduced in [\cite=planjery] and here we remind the reader on the intution behind it. The isolation assumption provides conditions on the neighborhood of the subgraph, such that the messages entering into the subgraph from outside are not affected by the messages being propagated within the subgraph for a certain a number of iterations. Consequently, for a certain number of iterations, decoding on the subgraph can be carried out in an isolated manner without explicit knowledge of its neighborhood.

Decimation-enhanced faid algorithm

We first provide some basic definitions and notations before we formally introduce the class of decimation-enhanced finite alphabet iterative decoders.

Let N(u) denote the set of neighbors of a node u in the graph G and let N(U) denote the set of neighbors of all u∈U. Let mk(vi,cj) denote the message being passed from a variable node vi to the check node cj, in the kth iteration, and let mk(cj,vi) be defined similarly. Let mk(vi,N(vi)) denote the set of outgoing messages from vi to all its neighbors in the kth iteration, and let mk(cj,N(vi)) be defined similarly. Let bki denote the bit associated to a variable node vi∈V that is decided by the iterative decoder at the end of the kth iteration.

A variable node vi is said to be decimated at the end of lth iteration if [formula] [formula]. Then [formula], [formula] irrespective of its incoming messages mk(N(vi),vi), i.e., vi will always send strongest possible messages.

The process of decimation at the end of some lth iteration is carried out by the iterative decoder using a decimation rule β:Y  ×  Mdv  →  { - 1,0,1} that is a function of the incoming messages and the channel value in the lth iteration. For convenience, with some abuse of notation, let βi denote the output of function β determined at node vi. If βi = 0, then the node is not decimated. If βi  =  1, then [formula], and if βi =  - 1, then [formula].

Remark: In this paper, we only consider decoders that use a single decimation rule β but the same rule may be used in different iterations. Hence, β is not iteration dependent, and whenever we refer to βi, it implies the output of β for node vi at the end of some lth iteration. Note that the function β is symmetric.

A decimation-enhanced multilevel FAID [formula] is defined as a 4-tuple given by [formula], where M, Y, Φc are the same maps defined for a multilevel FAID. The map ΦDv:Y  ×  Mdv - 1  ×  {0,1}  →  M is similar to Φv of the decoder [formula] except that it uses the output of β in some lth, βi, as an additional argument in the function. For the sake of simple exposition, we shall define ΦDv for the case of column-weight three codes and 7 levels. Let m1 and m2 denote incoming messages to a node vi∈V in the kth iteration. Then ΦDv is defined as

We now provide a simple example to illustrate the potential benefits of decimation, and then we will describe the basic decimation scheme used in this paper.

Motivating example

Consider a particular 4-error configuration on a Tanner graph G, whose induced subgraph forms an 8-cycle as shown in Fig. [\ref=example]. In the figure, black circles represent the variable nodes initially in error, whereas white circles represent the intially correct nodes that are in the neighborhood of the 4-error pattern. The black and white squares denote the degree one and degree two checks in the induced subgraph respectively.

Let V'={v1,v2,v3,v4} denote the set of variable nodes initially in error. Let C1={c1,c3,c5,c7} denote the set of degree one checks and C2={c2,c4,c6,c8} denote the set of degree two checks. We shall now examine the behavior of MP on this particular error configuration from the context of multilevel FAID algorithms without any assumptions on its neighborhood. Messages with a positive sign will be referred to as good messages, and messages with a negative sign will be referred to as bad messages (under all-zero codeword assumption). Also a weakly good or bad message refers to ±  L1, and a strongly good or bad message refers to   ±  Li where Li > L1. In the first iteration, for all vi∈V', m1(vi,N(vi)) will be weakly bad, and for all [formula], [formula] entering into the subgraph will be weakly good messages. In the second iteration, for all vi∈V', [formula] will be either weakly good or weakly bad depending on the Φv (such as Table [\ref=LUT244325]), but [formula] which are messages sent to checks in C1, will be strongly bad. As a result, variable nodes [formula] will start receiving strongly bad messages. If the decoder does not converge within the next few iterations, then these bad messages become more stongly bad and can subsequently spread further to other nodes in the graph depending how dense the neighborhood is. Eventually too many nodes get corrupted by the bad messages being propagated in the graph causing the decoder to fail.

Remarks: 1) At the kth iteration, there may have been many variable nodes vi such that [formula], whose incoming messages already converged to the right value in some k' < k iteration, but eventually these nodes became corrupted by the bad messages flowing out of the subgraph. 2) If certain variable nodes initially correct in the neighborhood of the subgraph induced from the error pattern, are isolated from the bad messages possibly through decimation, then the decoder is more likely to converge. This is precisely where the role of decimation becomes important.

Basic scheme for the decimation-enhanced FAID algorithm

We propose a scheme that uses successive decimations for a certain number of iterations. Let the number of successive decimations be Nd. The skeleton of the algorithm is given below. Note that for this proposed scheme, decimation starts at the end of the third iteration (reasons for which we will explain later), and after each decimation, the decoder is restarted.

Note that restarting the decoder implies, that the decimated nodes vi will send βiL3 and the non-decimated nodes vj will send Φv(0,0,yj).

Remarks: 1) The reasons for choice of three iterations to start the decimation are as follows. First, there should exist messages in the graph that have a magnitude of L3 in order to have a reliable decimation process. Secondly and more importantly, decimating only after three iterations makes the algorithm much more amenable to analysis. It becomes possible to analyze whether a particular node will be decimated or not and derive explicit conditions on the graph under which the nodes in error will not get decimated to the wrong value for a particular configuration. We shall in fact derive such conditions for the previous example. 2) Restarting the decoder after each decimation simplifies analysis.

Design of decimation rule β

The design of the rule β can be considered as a procedure of selecting the sets of incoming messages to node vi for which βi  =    ±  1. We would like to do the selection with particular focus on correcting small number of errors typically associated with trapping sets in the error floor region. Referring back to the previous example, a good decimation rule would be one where βj for most or all nodes [formula] is 1 and βi for nodes vi∈V' is 0 or 1, at the end of all decimations. We will now describe a good decimation rule selected for the particular 7-level FAID whose LUT is shown in Table [\ref=LUT244325]. Before we describe the rule, we highlight two main points to be considered during the selection.

Firstly, while considering a particular set of incoming messages, the magnitudes of the incoming messages should play a role in the selection.

Secondly, the inherent structure of the particular Φv used in the decoder must be taken into consideration during selection. For this, we need to look at what outgoing messages a variable node would send for that particular set of incoming messages, and then decide if this set is good to select for decimation. For example, if a variable node vi whose channel value is [formula], receives - L2,- L3,- L2, this set might seem to be a possible candidate (to decimate vi to 1). However, the outgoing messages will be - L3,- L1,- L3, which perhaps indicates that this may not be a reliable node to decimate since all outgoing messages are not - L3 or even - L2.

Table [\ref=decimatetable] shows all possible distinct sets of incoming messages with [formula], for which βi = 1. Using the symmetry of β, we can derive the sets of incoming messages with [formula], for which βi =  - 1. Note that an important condition that was used in defining the rule β, was that there must be a strict majority of signs of messages between all the messages coming to a node vi and channel value yi, and the majority sign must match with the sign of yi, in order for vi to be decimated.

Analysis of decimation-enhanced faid algorithms

Theoretical results

We first state the following lemma which is obtained due to the conditions used for decimation.

The decimation-enhanced FAID algorithm will never decimate a node initally correct to a wrong value, and a node initially wrong to a correct value.

By virtue of β that requires strict majority of signs of messages between incoming messages and yi, and the majority sign matching sign of yi.

Remark: This simplifies the analysis as we need to only be concerned about decimation of nodes that are initially in error. At the same time, note that decimation alone can never correct errors.

As a consequence of Lemma 1, the only necessary condition for success of a decimation-enhanced multilevel decoder is that a node initially in error must not be decimated.

Given an error pattern, if no node initially in error gets decimated at the end of third iteration, then a node initially in error will never get decimated in the susbsequent iterations.

(Details omitted) By restarting the decoder after each decimation, and by virtue of β, a node vi initially in error will not receive the required messages for βi =  - 1.

Now for a particular error configuration in a graph G, we can analyze the conditions under which a node that is initially in error is decimated at the end of third iteration and then use Lemma 2. We can then place conditions on the graph such that the node in error is never decimated. To show this, we revert back to the example of the 4-error configuration whose induced subgraph forms an 8-cycle, and provide such conditions in the following theorem. Note that the proof will involve using Tables [\ref=LUT244325] and [\ref=decimatetable] and also the same notations previously defined in the example.

Firstly note that by virtue of Φv of the 7-level FAID (Table [\ref=LUT244325]), the highest magnitude of a message that any node vi∈V can send is L1 in the first iteration and L2 in the second iteration. Since a node [formula] can be connected to atmost two checks in subgraph, the node vj in the worst case recieves two - L1 messages from checks in [formula] and L1 from outside at the end of first iteration. Node vi∈V' will also receive two - L1 messages from check nodes in C2 and L1 from [formula]. At the end of the second iteration, the node vi∈V' will once again receive two - L1 from checks in C2, and L1 from ck∈C1. This means that node vi will receive two - L1 messages once gain from checks in C2 at the end of third iteration. In order for it to be decimated, from Table [\ref=decimatetable], it must receive - L3 from [formula]. This means that the node vj in the worst case has to receive at least one - L3 at the end of the second iteration, but this is not possible by virtue of Φv in the second iteration. Hence, a node initially in error can not get decimated at the end of third iteration and using Lemma 2, will never get decimated.

Remarks: Note that the above condition is easily satisfied in most practical codes. This implies that on most practical codes, 4 errors on an 8-cycle will not be decimated.

Similarly, we can analyze under what conditions a node initially correct is decimated. For example, we may be able to derive conditions on the neighbors of the 4-error configuration such that they get decimated. In this manner, we can link analytical results of decimation to guaranteed error-correction capability.

Given that nodes initially in error are not decimated, it would be interesting to know whether the decimation-enhanced FAID can perform as good as multilevel FAID. In other words, given the necessary condition is satisfied, if a 7-level decoder corrects a particular K-error pattern, does the decimation-enhanced decoder also correct the pattern. Intuitively, this may appear to be true since only nodes initially correct are decimated and they continuously send strong correct messages for the entire decoding process. However, it is true only under certain conditions given in the following theorem.

Due to page constraints, proof is omitted. But the idea of the proof involves analyzing how messages flowing along the edges of the computation tree towards the root under the FAID algorithm, are affected by using the decimation-enhanced FAID algorithm.

Remark: Although Theorem 2 includes a specific condition on the decimation (under the assumption that nodes initially in error are not decimated), such a condition typically occurs for larger errors and decoding with much larger number of iterations. Therefore on small number of errors in trapping sets with a smartly chosen decimation rule, if nodes initially in error are not decimated, then decimation-enhanced FAID will most likely correct the pattern.

Numerical Results and Discussion

In this subsection, we present numerical results on the well-known (155,93) Tanner code in order to evaluate the performance of the decimation-enhanced FAID. The frame-error rate curves for various decoders are shown in Fig. 2. The decimation-enhanced FAID was run using Nd = 4 and all decoders used a maximum of 100 iterations. Note that the decimation-enhanced FAID was designed primarily to correct a fixed number of errors (in this case 5 errors) in fewer iterations compared to 7-level FAID. On the Tanner code, with Nd = 1, the decimation-enhanced FAID corrects all 5 errors within 10 iterations (after decimation) whereas the 7-level FAID requires 15 iterations. At the same time, we see that decimation-enhanced FAID performs just as good as the 7-level FAID (which was known beforehand to surpass BP), if not better.

We conclude by mentioning that our main goal was to provide a simple decimation scheme for multilvel FAID decoders that allows us to analyze their behaviour while maintaining good performance. From the theoretical analysis, we see that the role of decimation is important not just in improving the decoder performance or reducing the decoder speed but more so in terms of increasing the feasibility to obtain provable statements on the performance MP decoders such as FAID that are known to be empirically good. We finally remark that with more sophisticated versions of decimation such as use of multiple decimation rules, it might be possible to obtain an even more significant performance improvement.

Acknowledgment

This work was funded by NSF under the grants CCF-0830245 and CCF-0963726, and by the NANO2012 project.