=1

Evading the sign problem in random matrix simulations

Dynamical simulations of QCD at nonzero chemical potential are hampered by the sign problem (see ref. [\cite=deForcrand:2010ys] for a review). The problem occurs when the probabilistic weight used in Monte Carlo methods becomes complex, thus precluding the use of standard importance sampling techniques. Methods to study QCD at small chemical potential, where the sign problem is mild, include reweighting methods, Taylor expansions and analytic continuation from imaginary chemical potential [\cite=deForcrand:2010ys]. QCD at zero and nonzero density can also be investigated using random matrix theory because of the universality properties of the Dirac operator to leading order in the epsilon regime. Based on this equivalence, the severity of the sign problem has been studied using the average phase of the fermion determinant [\cite=Splittorff:2006fu] [\cite=Splittorff:2007ck] [\cite=Bloch:2008cf] [\cite=Lombardo:2009aw] [\cite=Bloch:2011jk]. As dynamical simulations of random matrices at nonzero chemical potential also suffer from the sign problem they can be used as a playground for its study. In this letter we present a subset method which avoids the sign problem in this case.

In chiral random matrix theory at nonzero chemical potential μ the Dirac operator for a fermion of mass m can be represented by [\cite=Osborn:2004rf]

[formula]

where the configurations φ = (φ1,φ2) are pairs of complex random matrices φ1 and φ2 of dimension (N + ν)  ×  N with ν the number of zero modes of D (for m = 0). The partition function of the chiral random matrix model with Nf dynamical quarks with equal mass m is

[formula]

with Gaussian weights

[formula]

and integration over the real and imaginary parts of all matrix components. In the presence of a chemical potential the fermion determinant becomes complex, the sign problem arises and the work needed to make reliable measurements on the statistical ensemble grows exponentially with the volume. In reweighting methods this exponential increase comes from the need to compute exponentially small reweighting factors from a statistical sampling of largely canceling contributions [\cite=deForcrand:2010ys].

Herein we propose a method to avoid the sign problem in dynamical simulations of random matrices. The idea is to rewrite the partition function [\eqref=partfun] as an integral over subsets [formula], each containing Ns configurations φi = (φi1,φi2), such that

[formula]

where by construction the Gaussian weights w(φi1)w(φi2) will be invariant for all φi in the subset and can thus be denoted by W(Ω), and we define the fermionic subset weight

[formula]

which depends on m and μ. The construction of the subsets will be described below, but its crucial property is that the sum σμ,m(Ω) over all the determinants in a subset is real and positive, for every Ω of the ensemble, and can thus be used as a probabilistic weight in a Monte Carlo method. The sample average of an observable O over a sample of [formula] subsets Ωk is computed as

[formula]

where φki = (φki1,φki2)∈Ωk. Methods based on partial integrations/summations have also been considered by other authors, see, e.g., refs. [\cite=Gocksch:1988iz] [\cite=Kieu:1993gw] [\cite=Anagnostopoulos:2001yb] [\cite=Ambjorn:2002pz] [\cite=Fodor:2007vv].

We now sketch how the subsets are constructed. As the partition function [\eqref=partfun] is real and positive (for μ < 1) the basic idea is to create subsets of matrices for which σμ,m has the same property. For μ = 0 the Dirac matrices are anti-Hermitian and their determinants are real and positive. When μ is increased the matrices become non-Hermitian, the determinants complex and the sign problem sets in. For μ = 1 and m = 0 the ensemble becomes maximally non-Hermitian, the average phase factor is zero and the sign problem maximal. For this limiting case we ideally want to find a partner configuration ψ = (ψ1,ψ2) for any given φ of the ensemble, such that their fermionic determinants explicitly cancel. This is easily achieved if, given some angle θ, we can find a ψ for which D1,0(ψ) = eiθD1,0(φ). Using [\eqref=Ddef] the latter can be written as

[formula]

where

[formula]

are orthogonal rotations of (φ1,φ2), which emerge when eiθD1,0(φ) is explicitly rewritten in an anti-Hermitian and a Hermitian part. From [\eqref=rmtdis] it follows that w(ψ1)w(ψ2) = w(φ1)w(φ2) such that ψ and φ have the same Gaussian weights in the partition function, for any rotation θ. An exact pairwise cancellation of the fermionic determinants will happen for any θ obeying ei2NNfθ =  - 1. The idea of canceling determinants can be extended from pairs (φ,ψ) to subsets {ψ(φ;θn)}, where the θn are such that the total sum of fermionic determinants cancels for μ = 1 and m = 0, i.e., [formula].

This idea is now ported to arbitrary chemical potential μ and mass m. In the following we will consider subsets

[formula]

with ψ = (ψ1,ψ2) defined in [\eqref=tphi] and Ns a positive integer. To each configuration φ = (φ1,φ2) of the random matrix ensemble corresponds a subset Ω(φ), and the set of all subsets forms an Ns-fold covering of the random matrix ensemble. The configurations ψ(φ;θ) have Gaussian weights independent of θ, but different fermionic weights det Nf  Dμ,m(ψ(φ;θ)).

The method presented in this paper is based on the following theorem: For any Ω constructed according to [\eqref=subset], and for arbitrary μ < 1 and m, the fermionic subset weight σμ,m(Ω) defined in [\eqref=sigma], i.e., the sum of the fermionic determinants of the Ns configurations ψ(φ;θn), is real and positive if Ns  >  NNf.

More specifically, for m = 0 it can be shown that

[formula]

for any μ. As σ0,0 is real and positive, σμ,0 is also real and positive for μ < 1. For μ = 1 the sum of determinants is exactly zero. For nonzero mass we can show that σμ,m is real and σμ,m(Ω)  >  (1 - μ2)NNfσ0,m(Ω) for μ < 1, such that the weight σμ,m is positive. The weights σμ,m can thus be used to generate subsets of random matrices using a Metropolis algorithm and compute observables using [\eqref=avgY]. In practice, Ns will be set to its minimum value, i.e., Ns = NNf + 1.

This theorem can be proven analytically and was thoroughly tested numerically. The proof will be given in a forthcoming paper.

We applied the subset method to compute the chiral condensate of the chiral random matrix ensemble, which is defined as [formula] [\cite=Osborn:2008jp]. We use the Metropolis algorithm to generate subsets Ω according to their weights W(Ω)σμ,m(Ω), where the determinants are computed numerically. Successive subsets in the Markov chain are generated as follows: randomly choose a configuration in the current subset, generate a new configuration by making a random step, construct the subset corresponding to this new configuration, apply an accept-reject step to the newly proposed subset. In each Markov chain we generate 100,000 subsets. The chiral condensate is computed for each configuration and its average is computed using [\eqref=avgY]. As usual, successive configurations in the Markov chains are correlated and the number of independent subsets is smaller by a factor 2τ, where τ is the integrated autocorrelation time. The statistical errors on the measurements are determined using the standard error formula corrected for the autocorrelations.

To compare the subset method with standard reweighting methods, all the simulations were repeated using quenched, phase quenched and sign quenched reweighting [\cite=Bloch:2011jk]. In those cases, we used (NNf + 1)  ×  100,000 random matrices in the Markov chains, such that the total number of matrices generated in the reweighting methods is the same as in the subset method. For the sake of clarity, we only show the results of phase quenched reweighting in the figures below, as its results are representative for the various reweighting methods.

We performed simulations for [formula], choosing Nf = 1 and m = 0.1 / 2N, so that the mass is small w.r.t. the magnitude of the smallest eigenvalue. In fig. [\ref=fig-cc-vs-mu] the chiral condensate is shown as a function of the chemical potential for matrices with N = 2,4,8. We compare the results obtained using the subset method with those from phase quenched reweighting. We also show the exact results computed in ref. [\cite=Osborn:2008jp]. The data are shown in the top row and the corresponding relative statistical errors in the bottom row. As the matrix size increases the reweighting method fails for smaller and smaller μ2 due to the sign and the overlap problem. As expected, the error of the reweighting method grows exponentially, until the method fails when the set of sampled matrices no longer overlaps with the relevant configurations for the given value of μ2 and N. This strongly contrasts with the results of the subset method which are reliable up to much larger values of μ2 and agree with the analytical predictions. Interestingly, the accuracy of the measurements is independent of the chemical potential.

We also measured the chiral condensate as a function of N for fixed values of μ2. The N-dependence of the relative statistical error on the chiral condensate is shown in fig. [\ref=fig-cc-vs-N] (left: subset method, right: phase quenched reweighting) for different values of μ2. For a fixed number of subsets the error in the subset method (left panel) increases approximately as [formula] and is independent of μ (the latter also follows from fig. [\ref=fig-cc-vs-mu]). If we fix the number of matrices, rather than the number of subsets, the error will increase with an additional factor [formula] (as the subset size itself grows with N + 1), such that the overall relative error will grow linearly with N. Turning the argument around, to achieve a constant error the number of subsets would have to grow proportionally to N, i.e., the total number of matrices should approximately grow as N2. The right plot shows the same quantity for phase quenched reweighting (on semi-log scale). We observe that the error grows exponentially with N until the method completely fails when the error stagnates around one and is no longer reliable. Note that for both methods the additional cost for the numerical computation of the determinants is proportional to N3.

For large values of N or μ2 we observed that the subset method breaks down at an N-dependent value μc(N), because the finite precision arithmetic limits the accuracy of σμ,m, which can lead to a violation of its positivity. The breakdown occurs when the sum of the determinants in a subset becomes of the order of the accuracy of the individual determinants. The approximate value μ2c is shown as a function of N in fig. [\ref=fig-muc] for simulations performed in double precision arithmetics. The data are fitted well by μ2c  ≈  1 -  exp ( - 38 / N1.2), whose functional form is inspired by [\eqref=conject]. For large N the fitted curve goes like 1 / N1.2. The breakdown can easily be detected during simulations by monitoring σμ,m and the magnitude of the individual determinants. When the ratio of both quantities is of the order of the machine precision the method no longer gives sensible results. Usually this is accompanied by a numerical violation of the positivity of σμ,m. For simulations at m = 0 this breakdown can be avoided altogether by using the analytic formula [\eqref=conject] to compute the sampling weight σμ,0 from σ0,0.

Note that the breakdown caused by the finite numerical accuracy will equally well show up in standard reweighting methods, even if an exponentially large effort is invested to keep the statistical error under control. This accuracy problem is therefore different from the sign problem, as the latter is of a pure statistical nature and does not depend on the use of finite-precision or exact arithmetic. The former is an additional problem of numerical nature which can be improved upon if necessary by using more sophisticated numerical methods.

What happened to the sign problem in the subset method? In standard reweighting methods the large cancellations, inherent to simulations at real chemical potential, happen through statistical sampling of the partition function. In the subset method these cancellations are removed from the statistical sampling procedure and become confined inside the subsets, which are constructed in a deterministic way and whose partial sums σμ,m yield net real and positive weights. Thus, a fundamental difference between both methods is that the number of configurations in reweighting grows exponentially with the volume to maintain the necessary statistical accuracy on the average weight factor [\cite=deForcrand:2010ys], whereas only NNf + 1 matrices per subset are needed in the subset method to compute the positive subset weights σμ,m, independently of its magnitude. This is how the subset method avoids the large statistical cancellations characterizing the sign problem.

From a practical point of view, even though finite-precision arithmetic in the numerical simulations eventually leads to a breakdown of the subset method, our numerical tests have shown that the method yields a vast improvement over the standard reweighting methods for the dynamical simulation of random matrices. With the new method higher values of μ2 and N can be accessed, without any loss of accuracy when increasing the chemical potential and with a measurement error growing proportionally to N when increasing the matrix size.

The crucial question whether the subset method is also applicable to physically relevant systems will be investigated in future research.

I would like to thank Philippe de Forcrand and Tilo Wettig for useful discussions. This work was supported by the DFG collaborative research center SFB/TR-55.