Reentrant Behavior in the Domany-Kinzel Cellular Automaton

PACS numbers : 87.10.+e, 02.50.+s, 89.80.+h

Cellular automata have been an intensive research field in recent years [\cite=all] [\cite=wolfram] due to their computational simplicity and the wide range of applications in various areas. Even in one dimension a particular probabilistic variant (Domany-Kinzel automaton) of the originally deterministic cellular automata shows a rich phase diagram including directed percolation and other critical phenomena [\cite=domany] [\cite=kinzel]. Only recently a new phase in this model has been explored numerically exhibiting chaotic behavior [\cite=tsallis] [\cite=tsallis2] [\cite=penna]. This region of the diagram, up to a deterministic corner-point, is not accessible to exact treatments up to now.

Nevertheless sophisticated approximation-methods, which systematically go beyond mean-field theory, have been applied successfully [\cite=schreck]. In the so called tree-aproximation [\cite=derrida] one finds reentrant behavior in two directions, which is not fully understood yet. This phenomenon has never been observed in numerical simulations up to now [\cite=tsallis] [\cite=penna]. Therefore one might ask, whether this reentrant behavior is a real feature of the model or just an artifact of the tree-approximation. This issue is the main topic of the present paper, where we try to clearify this point with an alternative approximation method (the cluster-approximation) as well as with large scale Monte-Carlo simulations (up to 3  ×  106 sites). To state the final results already at this place: The cluster-approximation again yields reentrant behavior in two directions and the simulations show clear evidence for reentrance near the tricritical point.

The model we consider is defined as follows: The Domany-Kinzel PCA consists of a one-dimensional chain of N binary variables, [formula], ni taking on the values {0,1} (empty, occupied). All sites are updated simultaneously (i.e. parallel) at discrete time steps and the state of each site at time t + 1 depends only upon the state of the two nearest neighbors at time t according to the following rule:

[formula]

where W(ni|ni + 1,  ni - 1) is the (time-independent) conditional probability that site i takes on the value ni given that its neighbors have the values ni + 1 and ni - 1 at the previous time step. p1 (p2) is the probability that site i is occupied if exactly one (both) of its neighbors is (are) occupied. If neither neighbor is occupied, the site i will also become empty, therefore the state with all sites empty is the absorbing state of the PCA.

The (p1,p2)-phase diagram, as it is known up to now, consists of three different phases. Most of it (small enough p1) is dominated by the frozen phase, where all initial conditions eventually lead into the absorbing state. With other words, the activity

[formula]

tends to zero for t  →    ∞   within the frozen phase. For large enough p1 one enters the [formula] phase, where, starting from a random initial condition, the system ends up in a state with a finite density of active sites. Within this active phase one can distinguish between a chaotic and a non-chaotic part. This difference can be seen by starting with two slighly different (random) initial conditions [formula] and [formula] subjected to the same external noise (local updating rules). Calculating the normalized distance d(t) of these two systems

[formula]

during the update of the replicated systems according to the rule displayed in equation (2) of reference [\cite=schreck] one observes a sharp transition from the chaotic phase, characterized by lim t  →    ∞d(t) = d∞ > 0, to the active phase with d∞ = 0 (in the following we call the active/non-chaotic phase simply the active phase). The underlying picture is that in the latter case the system is characterized by only one attractor, which nevertheless depends strongly on the external noise. With other words, in this phase the noise (and not the initial condition) dominates the dynamics completely. This is not true for the chaotic phase, where the system memorizes the initial state even after infinite time.

First we present analytical results obtained by the application of the so-called cluster-approximation already known in different contexts [\cite=ben] [\cite=schreck2] as probability path method [\cite=kik] or local structure theory [\cite=guto]. In this way we check earlier results [\cite=schreck] derived with a different approximation scheme (the tree-approximation, see [\cite=derrida]). The problem with the dynamical rules defined above is that one cannot write down the probability distribution of the stationary state since no simple detailed balance condition can be derived. Therefore, in principle, it is necessary to solve the dynamics completely in order to obtain the equilibrium properties. This is not possible in general.

One way out of this dilemma is to take into account systematically all possible correlations between m neighboring sites (m-cluster approximation) and to treat interactions over longer distances by conditional probabilities. More formally, given the probability [formula] for the configuration [formula] in an m-cluster-approximation the probabilitiy for configuration [formula] with l > m is approximated to be:

[formula]

Here [formula] denotes the conditional probability to find site m + i in state ni + m given that the m - 1 sites to the left are in the state [formula]. A factorisation of this kind can describe the stationary state exactly only if the interactions extend over not more than m sites. A natural choice for the conditional probaility P̃ is

[formula]

with

[formula]

Simple examples of one-dimensional systems which can be described exactly by a finite value of m are the p-spin-Ising-model where one needs m = p for the exact equilibrium distribution (m = p = 2 being the standard one-dimensional Ising model with next-neighbour interactions only) [\cite=cris]. Another example is the the parallel asymmetric exclusion process where again m = 2 leads to the exact result for the stationary state [\cite=schreck2]

The phase diagram resulting from a calculation based on the cluster approximation with m = 2 is shown in figure 1. Since during one update step according to the rules equation 1 the even (odd) sites only depend on the odd (even) sites at the timestep before we performed two timesteps at once to deal with sites of only one fixed parity. One firstly observes that m = 2 is still far from the exact solution for the stationary state. Unfortunately higher approximations are very hard to obtain due to the exponentially growing number of equations to be analysed simultaneously (especially for the distance d(t) with two replicated systems). Furthermore even for m = 2 the resulting equations cannot be solved analytically with final closed expressions but have to be iterated until one finds a fixed point of the system of equations. In order to obtain a better localisation of the phase boundaries we applied the same method described below to analyse the numerical data from the Monte-Carlo-simulations.

As can be seen from the figure we find reentrant behaviour both in p1- and p2-direction comparable to the result from the tree approximation [\cite=schreck]. It seems that the tricritical point has moved upwards, but a detailed analysis of the results suggests that it remains on the p2 = 0-line. For the frozen/active-phase boundary one can go to larger clusters with higher values of m. In tabular 1 the critical values pc1 (p2 = 0) for of m  ≤  5 are given:

[formula]

A simple least square fit leads to a limiting value for pc1 of about 0.810 which is significantly larger than the known values from the simulations [\cite=penna].

In order to test the predictions of both approximation schemes mentioned above we performed large-scale Monte-Carlo simulations of the Domany-Kinzel cellular automaton with probabilities p1 and p2 in the vicinity of the two end-points of the phase boundary of the chaotic phase (i.e.: (pc1,0) and (1,pc2)), where reentrance could occur according to the above calculations.

The system-sizes were up to N = 3  ×  106 sites with periodic boundary conditions, and the number of iterations t max were maximally 105. In this way one avoids self-correlations (finite size effects), since after t updates those sites separated by a distance smaller than t are correlated. Therefore t max has to be smaller than N. By choosing N much larger than t max one improves the statistics significantly (for obvious reasons, since one can devide the system into many statistically independent subsystems). Therefore no finite-size effects are present in our data (which was checked by comparing results for different system sizes) and we need not to perform a (non-trivial) extrapolation the infinite system N  →    ∞  . Furthermore the probability that the system gets trapped by the absorbing state (ni = 0) after time t increases with decreasing system size. This renders the simultaneous limit N  →    ∞   and t  →    ∞   to a delicate point, which we also avoid by our approach.

Looking at the data obtained from the simulations it turned out to be rather unreliable to try to discriminate between two phases by looking at the long-time limit of the order parameter (activity a(t) or distance d(t)). Apart from the two phase-boundaries we expect exponential decay of a(t) and d(t) to their asymptotic values. Exactly on the phase-boundary we expect the spectrum of relaxation times to extend to infinity and thus the decay to become algebraic. This behavior is illustrated in figure 2: the activity as a function of time is depicted in a log-log plot for increasing values of p1 (p2 = 0). We see that below a certain value the curves are bended downwards, whereas above this value the curves are bended upwards reflecting exactly the behaviour explained above. The curve just in the middle corresponding to p1 = 0.810 is closest (as defined quantitatively by a least square fit) to a straight line. To determine pc1 more accurately we performed longer runs with larger system sizes and depict the result in figure 3. The middle curve, corresponding to p1 = 0.8095, is nicely approximated by an algebraic decay with an exponent - 0.155. This exponent agrees well with the universal order parameter exponent [formula] determined in reference [\cite=kinzel].

From figure 3 we determined pc1 to be [formula]. This is the most accurate estimate of pc1 so far. Surprinsingly it is significantly larger than the value 0.799  ±  0.002 obtained with a different method but with system sizes of around N = 640 [\cite=penna]. It seems that in the latter reference the long transient times (~  10000) together with the small system sizes lower the critical value due to larger correlations in the system as known from similar systems [\cite=schreck2]. As we have mentioned above the finite size scaling analysis of small systems is by no means straightforward and cannot be done without further ad hoc assumptions, from which our method is free. Hence, from our point of view, the results we quote seem to be more reliable. Note that there is no overlap even of the error bars of the two critical values.

In figure 4 we show the same scenario for p2 = 0.04. By the same arguments as above we now locate the critical value of p1 (i.e. the value at which the transition from vanishing to finite activity takes place) to be [formula], which is significantly lower than pc1. For larger increasing values of p2 the phase boundary between frozen and active phase bends down monotonically to smaller values of p1 terminating at the point (p1 = 0.5, p2 = 1) which is exactly known since the whole p2 = 1-line is exactly solvable.

In figure 5 a comparison of the two curves for d(t) at p1 = 0.8090, which is below pc1, for p2 = 0 and p2 = 0.03 is shown. Note that (0.8090,0) lies within the frozen phase. The upper curve bends upwards, which means that (0.8090,0.03) lies within the chaotic phase. This is indicated by the schematic phase diagram depicted in the insert of figure 5 and which has been supported by simulations of various parameters (p1,p2) in this region. The two black dots represent the two curves shown and along the arrow connecting them one finds clear evidence for reentrant behavior. The phase boundary of the chaotic phase therefore bends to the left up to values around p2 = 0.03 and for larger values of p2 it bends monotonically to the right until it terminates at the point (1,pc2). One reason for the fact that this phenomenon was not seen in earlier simulations is that it is in fact a marginal effect observable only in high-precision simulation-data.

We also performed large scale simulations around the other endpoint of the chaotic/active phase boundary. Here it is quite evident that the reentrant behaviour parallel to the p1-axis at (1,pc2) is in fact an artifact of the approximation schemes and not existent in the actual system.

Concerning the question of the conjugate field for the order-parameter of the chaotic phase posed in reference [\cite=tsallis3] one can make on the p2=0-line exact statements. Since both the activity and the chaos order parameter obey exactly the same evolution equations [\cite=schreck] it is easy to conclude that the conjugated fields also should be equivalent. For the activity one chooses independent random numbers at each site and each timestep (on the p2=0-line this is just the role of p1). Accordingly one chooses for the chaotic order parameter independant random numbers at each site and each timestep (rule h1 in ref.[\cite=tsallis3]). The absorbing state now corresponds to identical variables states in the two replicas yielding the same update since the same noise has to be applied for equal configurations in the two systems. This picture remains valid for p2 > 0 although the evolution equations are no longer identical, but the absorbing state has the same properties. Note that on the line p2 = 0 the critical exponents of the order-paramater are also the same. If universality holds away from this line this statement should be true also for p2 > 0 (for p2 = 1 it is known, that the critical exponents are different [\cite=kinzel]).

In summary we have shown in this letter that, in contradiction to previous findings, the chaotic phase in fact shows reentrant behaviour in the vicinity of the tricritical point as predicted by approximative analytical methods. The effect was not seen before since it is relatively small and large scale simulations have to be made to detect it. On the other hand in the near of the p1=1-line the predicted reentrant behaviour is absent.

Furthermore one can see that simulations of small systems with long transient times can lead to erroneous conclusions about the locations of the critical point as well as the shape of the phase boundary since it is difficult to estimate the error due to self correlations. Therefore the error-bars in reference [\cite=penna] seem to neglect these systematic errors and should be larger (which could lead to an agreement with our results). Finally we have seen that the conjugate field to the chaotic order parameter can directly be identified from the equivalence to the activity order parameter on the p2=0-line.

Acknowledgement

We thank G. Kohring, D. Stauffer and C. Tsallis for interesting discussions. This work was performed within the SFB 341 Köln-Aachen-Jülich supported by the DFG.