Generalized Descents and Normality

Introduction

Let [formula] be a permutation. We say that the pair (i,j) is a d-descent in p if i < j  ≤  i + d, and pi > pj. In particular, 1-descents correspond to descents in the traditional sense, and (n - 1)-descents correspond to inversions. This concept was introduced in [\cite=demari] by De Mari and Shayman, whose motivation came from algebraic geometry. They have proved that if n and d are fixed, and ck denotes the number of permutations of length n with exactly k d-descents, then the sequence [formula] is unimodal, that is, it increases steadily, then it decreases steadily. It is not known in general if the sequence [formula] is log-concave or not, that is, whether ck - 1ck + 1  ≤  c2k holds for all k. We point out that in general, the polynomial [formula] does not have real roots only. Indeed, in the special case of d = n - 1, we get the well-known [\cite=combperm] identity

[formula]

which has all nth roots of unity as roots. Indeed, in this case, a d-descent is just an inversion, as we said above.

In this paper, we prove a related property of generalized descents by showing that their distribution converges to a normal distribution as the length n of our permutations goes to infinity. Our main tool is Janson's dependency criterion, which is a tool to prove normality for sums of bounded random variables with a sparse dependency graph.

The Proof of Asymptotic Normality

Background and Definitions

We need to introduce some notation for transforms of the random variable Z. Let  = Z - E(Z), let [formula], and let Zn  →  N(0,1) mean that Zn converges in distribution to the standard normal variable.

For the rest of this paper, let d  ≥  1 be a fixed positive integer. Let Xn = X(d)n denote the random variable counting the d-descents of a randomly selected permutation of length n. We want to prove that Xn converges to a normal distribution as n goes to infinity, in other words, that n  →  N(0,1) as n  →    ∞  . Our main tool in doing so is a theorem called Janson's dependency criterion. In order to state that theorem, we need the following definition.

Let [formula] be an array of random variables. We say that a graph G is a dependency graph for [formula] if the following two conditions are satisfied:

There exists a bijection between the random variables Yn,k and the vertices of G, and

If V1 and V2 are two disjoint sets of vertices of G so that no edge of G has one endpoint in V1 and another one in V2, then the corresponding sets of random variables are independent.

Note that the dependency graph of a family of variables is not unique. Indeed if G is a dependency graph for a family and G is not a complete graph, then we can get other dependency graphs for the family by simply adding new edges to G.

Now we are in position to state Janson's dependency criterion.

[\cite=janson] Let Yn,k be an array of random variables such that for all n, and for all [formula], the inequality |Yn,k|  ≤  An holds for some real number An, and that the maximum degree of a dependency graph of [formula] is Δn.

Set [formula] and [formula]. If there is a natural number m so that

[formula]

then

[formula]

Applying Janson's Criterion

We will apply Janson's theorem with the Yn,k being the indicator random variables Xn,k of the event that a given ordered pair of indices (indexed by k in some way) form a d-descent in the randomly selected permutation [formula]. So Nn is the number of pairs (i,j) of indices so that 1  ≤  i < j  ≤  i + d  ≤  n. Then by definition,

[formula]

There remains the task of verifying that the variables Yn,k satisfy all conditions of Jansen's theorem.

First, it is clear that Nn  ≤  nd, and we will compute the exact value of Nn later. By the definition of indicator random variables, we have |Yn,k|  ≤  1, so we can set An = 1 for all n.

Next we consider the numbers Δn in the following dependency graph of the family of the Yn,k. Clearly, the indicator random variables that belong to two pairs (i,j) and (r,s) of indices are independent if and only if the sets {i,j} and {r,s} are disjoint. So fixing (i,j), we need one of i = r, i = s, j = r or j = s to be true for the two distinct variables to be dependent. So let the vertices of G be the Nn pairs of indices (i,j) so that i < j  ≤  i + d, and connect (i,j) to (r,s) if one of i = r, i = s, j = r or j = s holds. The graph defined in this way is clearly a dependency graph for the family of the Yn,k. For a fixed pair (i,j), each of these four equalities occurs at most d times. (For instance, if i = s, then r has to be one of [formula].) Therefore, Δn  ≤  4d.

If we take a new look at ([\ref=jansencond]), we see that the Janson criterion will be satisfied if we can show that σn is large. This is the content of the next lemma.

If n  ≥  2d, then

[formula]

In particular, [formula] is a linear function of n.

Note that in particular, for d = 1, we get the well-known fact [\cite=combperm] that the variance of Eulerian numbers in permutations of length n is (n + 1) / 12.

By linearity of expectation, we have

[formula]

Clearly, E(Xn,k) = 1 / 2, so the N2n summands that appear in the last line of the above chain of equations with a negative sign are each equal to 1 / 4. As far as the N2n summands that appear with a positive sign, most of them are equal to 1 / 4. More precisely, if Xn,k1 and Xn,k2 are independent, then

[formula]

If k1 = k2, then E(Xn,k1Xn,k2) = E(X2k1 = E(Xk1) = 1 / 2. Otherwise, if Xn,k1 and Xn,k2 are dependent, then either E(Xn,k1Xn,k2) = 1 / 3, or E(Xn,k1Xn,k2) = 1 / 6. Indeed, if Xk1 is the indicator variable of the pair (i,j) being a d-descent and Xk2 is the indicator variable of the pair (r,s) being a d-descent, then as we said above, Xn,k1 and Xn,k2 are dependent if and only if one of i = r, i = s, j = r or j = s holds. If i = r or j = s holds, then E(Xn,k1Xn,k2) = 1 / 3, and if i = s or j = r holds, then E(Xn,k1Xn,k2) = 1 / 6. Indeed, for instance, with i = r, we have Xn,k1 = Xn,k2 = 1 if and only if pi is the largest of the entries pi, pj, and ps. Similarly, with i = s, we have Xn,k1 = Xn,k2 = 1 if and only if pr > pi > pj.

We will now count how many summands E(Xn,k1Xn,k2) are equal to 1 / 2, to 1 / 3, and to 1 / 6.

First, E(Xn,k1Xn,k2) = 1 / 2 if and only if k1 = k2. This happens Nn times, once for each pair (i,j) so that i < j  ≤  i + d. For a given i, there are d such pairs if i  ≤  n - d, and d - t such pairs if i = n - d + t, so

[formula]

Second, E(Xn,k1Xn,k2) = 1 / 3 if i = r, or j = s. By symmetry, we can consider the first case, then multiply by two. If i  ≤  n - d, then we have d(d - 1) choices for j and s, and if i = n - d + t, then we have (d - t)(d - t - 1) choices. So the number of pairs (k1,k2) so that E(Xn,k1Xn,k2) = 1 / 3 is

[formula]

[formula]

Finally, E(Xn,k1Xn,k2) = 1 / 6 if i = s, or j = r. By symmetry, we can again consider the first case, then multiply by two. If d  ≤  i  ≤  n - d, then there are d2 choices for (j,r). If i  ≤  d, then there are d choices for j, and i - 1 choices for r. If n - d < i, then there are n - i choices for j, and d choices for r, assuming that n  ≥  2d. So the number of pairs (k1,k2) so that E(Xn,k1Xn,k2) = 1 / 6 is

[formula]

For all remaining pairs (k1,k2), the variables Xn,k1 and Xn,k2 are independent, and so E(Xn,k1Xn,k2) = 1 / 4.

Comparing our results from cases 1-3 above with ([\ref=variance]), and recalling that in all other cases, E(Xn,k1Xn,k2) = 1 / 4, we obtain the formula that was to be proved.

The proof of our main theorem is now immediate.

Let d be a fixed positive integer. Let Xn be the random variable counting d-descents of a randomly selected n-permutation. Then n  →  N(0,1).

Use Theorem [\ref=janson] with Yn = Xn, Δn = 4d, [formula], and [formula]. All we need to show is that there exists a positive integer m so that

[formula]

for which it suffices to find a positive integer m so that

[formula]

Clearly, any m  ≥  3 suffices, since for any such m, the left-hand side is of the form C / nα, for positive constants C and α.

Further Directions

We see from ([\ref=easier]) that the statement of Theorem [\ref=basic] can be strengthened, from a constant d to a d that is a function of n. Indeed, ([\ref=easier]) is equivalent to saying that

[formula]

This convergence holds as long as d  ≤  n1 - ε for some fixed positive ε, we can choose m so that (m / 2)  ·  ε > 1, and then condition ([\ref=easier]) will be satisfied. So we have proved the following theorem.

Let n  →    ∞  , and let us assume that there exists a positive constant ε so that for n sufficiently large, d = d(n)  ≤  n1 - ε. Let Xn be defined as before. Then

[formula]

This leaves the cases of larger d open. We point out that in the special case of d = n - 1, that is, inversions, asymptotic normality is known [\cite=diaconis], [\cite=fulman].

Another possible direction for generalizations is the following. Let [formula], where the di are positive integers. If p  =  p1...pn is in an n-permutation, let fd(p) be the number of pairs (i,j) such that 0  <  j - i  ≤  di and pi  >  pj. For instance, if [formula] then fd(p) is the number of descents of p. If [formula] then fd(p) is the number of inversions of p. It is known [\cite=demari], by an argument from algebraic geometry, that if

[formula]

then the sequence [formula] is unimodal. Log-concavity and normality are not known. Note that in this paper, we have treated the special case of [formula].

cm

Acknowledgment

I am thankful to Richard Stanley who introduced me to the topic of generalized descents.