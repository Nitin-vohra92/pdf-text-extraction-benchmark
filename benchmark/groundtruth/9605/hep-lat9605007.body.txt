A. Galli Max-Planck-Institut für Physik, D-80805 Munich, Germany

Abstract

The investigation of quantum spin systems is important for understanding the physics related to strongly correlated electrons and high temperature superconductivity. A poverful technique to numerically study quantum spin systems is the quantum Monte Carlo (QMC) method (for a review see [\cite=dagotto]) based on the Suzuki-Trotter formula [\cite=suzuki]. Unfortunately, QMC can suffer from the negative sign problem (NSP), which becomes exponentially serious on large lattices and at low temperature. In this work we present a new algorithm which is able to strongly reduce this problem. A more detailed description of this algorithm and a rigorous proof of its correctness will be published elsewhere [\cite=QM]. This algorithm is general and can be applied to any quantum spin system. Its complexity is only linear in the volume of the lattice. We have tested its efficiency with a simple 2-dimensional fermionic model and we show that for this model the NSP disappears.

We consider a quantum spin system defined on a d-dimensional finite lattice. Its direct simulation is not possible because the requirement in storage and work is exponential in the lattice size of the system. To avoid this complexity, usually one transforms it to a d+1-dimensional classical spin system realized by the application of the Suzuki-Trotter formula to the original d-dimensional system. The extra dimension is a discretization of the inverse temperature. We call it time. This classical spin system allows us to use a Monte Carlo approach for evaluating observables. The co nfigurations v defined on the d+1-dimensional lattice are weighted by w(v) in the partition function

[formula]

The evaluation of the weight w(v) is of small complexity, contrary to the original d-dimensional quantum spin system. The price to pay is that the new classical system has a partition function for which generally not all weights are positive semidefinite. This fundamental difficulty is usually referred to as the "negative sign" problem. It is not related to any approxim ations in the Monte Carlo scheme but it describes the fact that the statistical error of the observables can become very large, increasing exponentially in the inverse temperature β and lattice volume.

Any classical observable A is measured at the first time slice of the d+1-dimensional lattice by averaging over the sample of configurations generated by the Monte Carlo process. For simplicity, we restrict the discussion to classical observables. The ex pectation value of them can be written

[formula]

where < ... > w and < ... > |w| denote the average taken with the weights w and |w(v)|, respectively. If the average sign is small there will be large cancelations making an accurate evaluation of < A >  impossible so that meaningful results are dif ficult to obtain.

We denote a Monte Carlo algorithm φ|w| which generates configurations v in equilibrium with the distribution |w(v)|. This algorithm can be realized in different ways. The explicit realization of it is for the moment irrelevant to the discussion. We denote the expectation value measured with the algorithm φ|w| by eq. ([\ref=evplus]). It is important to notice that the value A(v) of an observable A does not depend on the complete configuration v but only on the part living on the time slice at t = 0. This is a crucial property that we will use for constructing an algorithm whic h is able to reduce the sign problem by substantially increasing the average sign.

We consider a mapping g which maps a configuration v to a configuration gv and which satisfies the following condition: for any observable A we have A(v) = A(gv). Such a mapping is easily constructed: we can require that it does not change the configuration v at t = 0. We consider a set G of such mappings with the additional property that these mappings are bijective. It is easy to prove [\cite=QM] that using the weight defined by

[formula]

we obtain for the expectation value ([\ref=evplus]) of an observable

[formula]

Using this new weight for a simulation it is clear that the expectation value of A measured with a Monte Carlo algorithm φ|w| with state space {v} and equilibrium distribution |w(v)| is the same as the one measured with a Monte Carlo algo rithm φ|w̃| with state space {(v,g)} and equilibrium distribution |w̃(v,g)|.

We suppose that we can construct these mappings g∈G so that the average of the sign if measured with φ|w̃| satisfies

[formula]

where < ... > |w̃| and < ... > |w| mean the expectation taken from the |w̃| and |w| distributions, respectively. In the case that the average sign substantially increases then it is evident that the sign problem is suppressed.

Such a mapping can be realized by flipping clusters of spins in v such that if w(v)  ≠  0 then also w(gv)  ≠  0 and the following condition is satisfied

[formula]

where [formula] denotes the flipping of the spins belonging to the cluster C. The first part of the condition is needed to obtain a positive weight w̃(v,g). The second part of the condition [formula] takes the va lue true if the flipping [formula] maps bijectively the configuration v to gv, otherwiese it takes the value false. This part of the condition is realised with very high accurancy using a hashing technique [\cite=hash]. To be spe cific, the boolean function O(v,v') is defined by the following procedure

[formula]

where h is a hashing function which assigns in an arbitrary way a non vanishing integer label (in an interval [formula]) to any state v, and Htable is a hashing table with Z integer entries.

The search of the clusters follows a fixed order of operations. One can select a point in the d+1-dimensional lattice from a fixed list of points and construct a cluster starting from it. During the construction a fixed list of random numbers can be used . It is important, however, that the two lists always remain the same every time one applies this procedure to a configuration. Changing the lists is equivalent to select a new mapping in G. If the flip of the constructed cluster does not satisfy th e condition ([\ref=co]) the next point in the list can be selected and a new cluster constructed and this search is repeated until the condition ([\ref=co]) is satisfied. If the condition ([\ref=co]) is never satisfied the procedure can be stopped, when all the points in the list are tested once, and the original state is returned as the result. This algorithm defines a mapping g∈G. The complexity of the search of a cluster is in this way linear in the volume of the lattice. The flip of the cluster [formula] is defined so that [formula] for any observable A.

This mapping defines our new weight w̃. A Monte Carlo algorithm φ|w̃| can now be used to update the configurations and the mappings with respect to the new weight. The first part of the condition ([\ref=co]) guarantees us that after average ([\ref=suppression]) is satisfied. The second part of the condition ([\ref=co]) guarantees us that the mapping g maps a configuration v to gv bijectively with probability [formula]. Since the mapping is not always bijective, during the Monte Carlo process a systematic error is produced with probability [formula]. The systematic error in the average ([\ref=evplus]) is then after average over the collected sample of configurations of order [formula]. This systematic error can be tuned in the algorithm by increasing the dimensi on Z of the hashing table. We can chose its dimension so that [formula] is much smaller than the statistical error. In addition the systematic error can be measured by counting the collisions in the hashing table.

If the set of mappings G contains only one element then to avoid too much collisions in the hashing the dimension of the hashing table has to be much larger than the number of Monte Carlo iterations one desires to perform. This is doable but require s a lot of memory. If, however, the set of mappings G contains a huge amount of elements then the hashing table can be small because the algorithm uses a selected mapping only for a short time and then selects a new one according to the distribution |w̃(v,g)| (using a Metropolis acceptance test). If the set G is big enough, the probability that the algorithm selects the same mapping twice is infinitesimal so that there is no need to store the history of the hashing tables of old mappings.

As an example we consider a simple model of free quantum spins in a chemical potential. This example was analyzed by quantum Monte Carlo using the loop algorithm [\cite=evertz] in [\cite=wiese]. We consider fermions living on the sites of a spatially 2-dimensional square lattice with periodic boundary conditions. We consider a particle with only one internal degree of freedom. Creation and annihilation operators c*x and cx anticommute. The Hamilton operator is

[formula]

where î is the unit vector in the i-direction. The model is trivial and can be solved in momentum space. However, when one tries to simulate it with a Monte Carlo algorithm it shows from the algorithmic point of view many of the characteristic features of more complicated quantum spin systems. In addition, the exact solution of this model allows us to test our algorithm. We can express the grand canonical partition function

[formula]

(where N is the particle number operator) with the Suzuki-Trotter formula as explained in [\cite=wiese] [\cite=QM].

In Table 1 we present the results of the Monte Carlo simulations performed with the loop algorithm and with our algorithm and we compare the obtained results with the exact solution. The construction of the clusters in our algorithm can be performed in analogy with the loop algorithm [\cite=wiese], however using a fixed list of points in the d+1-dimensional lattice and a fixed list of random numbers for each mapping g∈G. For our runs we have used a hashing table with Z = 10000 entries. In all our simulations we have not found any collisions in the hashing tables so that the systematic error on the observables is zero.

We have applied the algorithms for various values of β and μ at fixed lattice spacing βε = 1 / 16. The results of both algorithms agree with the exact results within the error bars. It is evident that the sign problem becomes severe for the loop algorithm when the temperature is lowered or the chemical potential is increased. However, the sign remains always positive for our algorithm.

A more exhaustive analysis of the efficiency of our algorithm is under study. Applications of it to more physical interesting models are under way.

I would like to specially thank N. Galli for discussions and help with the hashing technique. I also would like to thank B. Jegerlehner for helpful comments and discussions and P.Weisz for reading the manuscript and helpful comments.