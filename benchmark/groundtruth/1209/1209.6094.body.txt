Efficient determination of the energy landscape of nonlinear Schrödinger-type equations

Nonlinear Schrödinger equations and their variations are used to model a wide variety of physical systems [\cite=tsal] [\cite=rcf], with applications spanning superconductivity [\cite=glt], quantum condensates [\cite=gpe1] [\cite=gpe2], nonlinear acoustics [\cite=som1979coupled], nonlinear optics [\cite=gedalin1997optical], and hydrodynamics [\cite=nore1993numerical]. Typically, the physical models described by these equations contain a set of parameters specifying, e.g., the sample geometry, external fields, or boundary conditions. To understand the physical properties of the system, it is interesting to explore the energy landscape of the steady state solutions as a function of one or more of these parameters. In general, slight perturbations in one of the control parameters can induce changes in the stability properties of the states, causing abrupt transitions in the energy landscape [\cite=PhysRevB.65.104515]. Although the existence of steady states can be proven in certain cases, analytic solutions are hard or impossible to obtain in realistic systems. Numerical methods are hence of particular importance for understanding the physics of the systems modeled by nonlinear Schrödinger equations. The challenge is to develop efficient computational tools to explore the full energy landscape, including minima and saddle-points, of three- and higher-dimensional systems.

In general, the nonlinear Schrödinger equations describing the evolution of a quantum-dynamical system represented by a complex-valued order parameter ψ are written as

[formula]

with a linear, positive-semidefinite (energy) operator [formula], an external potential V, and the coupling parameter g. The term |ψ|2 usually describes a probability density of the model entity, e.g., the locality of quantum particles. Examples include the Gross-Pitaevskii equation where [formula] is the negative Laplacian, and the Ginzburg-Landau (GL) equation, where [formula] is the covariant Laplacian with a given vector potential [formula].

To understand the long-term dynamics, it is essential to compute steady states of the system, i.e., solutions to

[formula]

Solving [\eqref=eq:schroed] in realistic three-dimensional domains is a difficult numerical task: the number of unknowns quickly becomes very large and standard numerical methods become impractical. In addition, the energy landscape of the solutions becomes very complicated and its systematic exploration is prohibitive with current numerical techniques.

This letter describes a numerical approach for the efficient computation of the steady-state landscape as a function of the control parameters. Its central component is a Newton-Krylov algorithm [\cite=kelley1995iterative] [\cite=knoll2004jacobian] to solve the nonlinear problem [\eqref=eq:schroed], combined with numerical parameter continuation [\cite=Krauskopf2007] to explore the solution landscape. Although numerical continuation and Newton-Krylov solvers are well-known methods for large-scale systems, they cannot be applied straightforwardly to [\eqref=eq:schroed]. We will show that, by exploiting the properties of the linearization of the operator S(  ·  ) and devising a specially tailored preconditioner, it is possible to considerably accelerate the convergence of the linear iterations. This opens up the possibility to compute steady states and to systematically explore the energy landscape in three-dimensional problems. The new method scales optimally with the number of unknowns in the system and is fully parallelizable. In particular, we illustrate the power of the method by studying three-dimensional vortex nucleation in an extreme-type-II superconductor in an inhomogeneous magnetic field, described by the GL equation.

Numerical simulations within the GL model are an essential tool for the analysis of superconducting phenomena. In this area, vortex matter has been at the forefront of research in the past two decades. Emphasis has been put on the computation of vortex states with imposed confinement (i.e., the sample shape) and on their dependence upon critical parameters of the superconducting sample. Of particular relevance are unstable states of the system, often called saddle points. These solutions shape the energy landscape as they constitute the connections between families of stable states, thereby providing a unique insight into the dynamic transitions and vortex rearrangements that have been observed experimentally. Notably, with the framework proposed in this letter we can compute both stable and unstable states, which are not accessible with traditional numerical methods. Owing to numerical difficulties, saddle points have been calculated only for radially-symmetric samples such as disks, using a limited-expansion method [\cite=schw1999]. Recently, the full energy landscape (including saddle points) was systematically explored in two-dimensional square samples, using numerical continuation techniques [\cite=SAV:2012:NBS]: in particular, it was possible to build an atlas of the instabilities occurring in the sample, providing a complete classification of the symmetries of observable stable states. In this letter, we address the much more challenging case of three-dimensional samples of arbitrary shape.

Existing methods

The literature on numerical methods for the time-dependent equation [\eqref=eq:tschroed] is rather extensive and mostly concerned with time-stepping schemes [\cite=Taha1984203] [\cite=sanz1984methods] [\cite=Chang1999397]. For example, references [\cite=PhysRevA.51.4704] [\cite=bao2003numerical] leveraged specific properties of certain numerical procedures and settings for dealing with the Gross-Pitaevskii equation. Stationary-states are typically found by applying a (pseudo-)time-stepping scheme until a stationary state is reached [\cite=schwPRL] [\cite=PhysRevLett.79.4653] [\cite=geurts]. There are, however, several disadvantages with this approach. Firstly, iterations converge only for strictly stable states, therefore unstable or saddle point states can not be computed. Secondly, stable solutions may have extremely long (sometimes oscillatory) transients, therefore convergence for three-dimensional domains may be prohibitively slow.

Newton's method

A better approach is to use Newton iterations directly on [\eqref=eq:schroed], starting from a suitable initial guess: Newton's method converges superlinearly in a neighborhood of the solution, irrespectively of the stability properties of the equilibrium. Once a steady state ψ is found, stability is determined by computing the spectrum of the operator obtained by linearizing S around ψ. For the Schrödinger equations, this linear operator is defined via the action

[formula]

where [formula] denotes complex conjugation.

A sequence of approximations ψ(k) to the steady state is computed with Newton's method ψ(k + 1)  =  ψ(k)  +  δψ(k), where the update δψ(k) satisfies

[formula]

Therefore, the solution of a large linear system is required at each Newton step k, which is the most significant difficulty when applying Newton's method to nonlinear Schrödinger equations.

Solving the Jacobian system

Linear systems such as [\eqref=eq:newton] can be solved using Krylov iterative methods and have been widely used in the past decades [\cite=saad2003iterative] [\cite=greenbaum1997iterative]. A property of Krylov subspace methods is that no explicit (matrix) representation of the operator is needed, but only its application to vectors (cf. ([\ref=eq:schroed_J])). The convergence of those methods is highly dependent on the spectrum of the involved linear operator. Principal optimizations can be employed if all eigenvalues of the respective linear operator are real-valued. This is the case if the linear operator is represented by a Hermitian matrix or, in general, if [formula] is self-adjoint with respect to a given inner product. The linear operator ([\ref=eq:schroed_J]) associated with the nonlinear Schrödinger equations is self-adjoint with respect to the inner product

[formula]

This suggests the use of MINRES [\cite=greenbaum1997iterative], a Krylov subspace method suitable for indefinite self-adjoint problems. However, one characteristic of Krylov methods is that a larger number of unknowns increases the number of iterations that are needed to achieve convergence. In addition, the computational cost of a single evaluation of the linear action also grows with the number of unknowns. Therefore, high-resolution discretizations of three-dimensional systems would require a prohibitive computational effort. Indeed, decreasing the number of Krylov iterations is the subject of extensive research efforts in this area.

A popular approach is to use a preconditioner for the linear problem. The main idea is that, instead of solving the discretized version Jx  =  b of [\eqref=eq:newton], one can solve an equivalent, numerically more favorable problem P- 1Jx  =  P- 1b with a linear, invertible preconditioning operator P. If P is appropriately chosen, Krylov methods applied to the new system converge much faster. In the case of the linearization of nonlinear Schrödinger operators ([\ref=eq:schroed_J]), the energy operator [formula] is of particular interest, as it typically dominates the spectral behavior of [formula]. More precisely, we define the symmetric preconditioning operator

[formula]

with 0 < ε  ≪  1 [\cite=SV:2012:OLS]. We note that [formula] is positive-definite except for the uninteresting case of [formula]. This, most importantly, makes the inversion of the discretized [formula], P- 1(ψ), computationally cheap since its positive-definiteness makes it a suitable target for geometric or algebraic multigrid (AMG) solvers that yield optimal convergence [\cite=trottenberg2001multigrid]. As will be shown, even inexact inversions of ([\ref=eq:prec]) used as preconditioners for ([\ref=eq:schroed_J]) make the Krylov convergence independent of the number of unknowns.

Numerical parameter continuation

The efficient linear solver outlined above is an essential building block for the exploration of the energy landscape, which is performed via numerical parameter continuation, a well-established technique for numerical bifurcation analysis of dynamical systems [\cite=keller1987lectures]. Let F(ψ;p) = 0 be a nonlinear system dependent upon a scalar parameter [formula] and let ψ*0 be a solution for a given parameter value p*0. Under generic regularity conditions for F, it is possible to construct a one-parameter family of solutions ψ, parametrized by p, in the neighborhood of (ψ*0,p*0) [\cite=Krauskopf2007]. First, a prediction step (ψ1,p1) is taken in the tangent direction to the one-parameter family, then a correction is done using Newton's method. This leads to a new solution (ψ*1,p*1). The set of points (ψ*k,p*k) form a smooth solution curve. Once again, we remark that the method is oblivious to the stability properties of the solutions.

Application to the Ginzburg-Landau problem

We illustrate the power of this method on a numerically challenging problem: the computation of vortex structures in a three-dimensional superconducting domain with a magnetic core, which establishes an internal and inhomogeneous magnetic field.

Given a bounded superconducting domain Ω, the GL equations

[formula]

describe stationary states of an extreme-type-II superconductor subject to a magnetic field associated with the vector potential [formula] [\cite=schwPRL] [\cite=DGP:1992:AAG]. The equations are presented in dimensionless form: distances are scaled by the superconducting coherence length ξ, the order parameter ψ by its value in the absence of applied magnetic field, and the vector potential by ξHc2, where Hc2 denotes the upper critical magnetic field of a bulk material. Since the kinetic energy operator [formula] is Hermitian and positive semi-definite, equation [\eqref=eq:GL_compact] is of the form [\eqref=eq:schroed] (with [formula], g = 1) and can be solved with our numerical method.

We choose Ω to be a cube with side length 10 and a spherical cavity of radius 1 containing a magnetic dipole with magnetic moment [formula] (see figure [\ref=fig:domain]). The associated magnetic vector potential of such a dipole is [formula]. This example is of great relevance to the field, since the expected loops appear in several physical systems [\cite=ScVort]. Their nucleation, growth, motion, and recombination harbors a vast variety of novel physics. We perform numerical experiments using a finite-volume (tetrahedral) discretization where the complex-valued order parameter ψ is approximated in the grid nodes [\cite=SV:2012:OLS].

The first important result is shown in figure [\ref=fig:prec], and concerns the efficiency of solving the Jacobian systems with preconditioners based on the discretization P(ψ) of [\eqref=eq:prec]. More specifically, we use two preconditioners, the first one being the exact inverse (up to machine precision) of P(ψ) and the second one being an approximate inverse of P(ψ) obtained with just a single AMG step. Preconditioned linear systems are solved for increasing number of unknowns and they are compared to the case without preconditioners. A remarkable result is that, in both preconditioned cases, the number of iterations does not increase with the number of unknowns in the system. This indicates optimal scalability of the solver, which is extremely advantageous compared to the case without preconditioner.

Numerical parameter continuation is then applied to a discretization with [formula] grid points. The magnetic vector potential [formula] (and thus the corresponding magnetic field [formula]) is scaled with the dimensionless magnetic moment μ = m / (Hc2ξ3) which is taken as control parameter. For μ = 0, the homogeneous state [formula] is clearly a solution (independently of the domain) and can be used to start off the parameter continuation. Alternatively, the computation can be started from a solution obtained otherwise (e.g., via time stepping). As shown in figure [\ref=fig:branches], our method automatically generates the energy landscape, parametrized by μ, revealing the existence of several branches with different energy (for a definition of Gibbs free energy see, e.g., [\cite=schwPRL] [\cite=geurts]). Initially, at low μ, the superconducting order parameter is strongly suppressed only around the embedded dipole. For increasing μ, vortex loops emerge from this area, connecting the poles of the dipole. Initially, exactly 4 such loops are present in the stable solution which enjoys the fourfold symmetry of the problem (similar to figure [\ref=subfig:sol4]). A bifurcation occurs at [formula], suppressing three loops towards the dipole and generating a branch of states with just one loop (see supplementary material for the animation, figure [\ref=subfig:sol1] and branch a in figure [\ref=fig:branches]). Similar behavior is found for the state with two loops, with a bifurcation point at [formula] (see the state in figure [\ref=subfig:sol2] and its corresponding energy branch). However, none of these states reaches the ground state of the system: it is actually the three-loops state that prevails at [formula], formed via shrinking one loop along the saddle point and growing three loops until they hit the cube sides. When μ is further increased, these loops follow another saddle point, where they hit the top and bottom surfaces, and then stabilize as three vortices piercing the sample top to bottom (figure [\ref=subfig:sol3]). As we continue the computation for higher values of μ, more bifurcations occur on each energy branch, and new solutions branches emerge. Since this calculation is only intended to illustrate our approach, we do not include details about such branches. The entire solution curves can be obtained from [\cite=schloemer:figshare].

Conclusion and outlook

In this letter, we developed a computational tool that allows the efficient exploration of the steady-state landscape of nonlinear Schrödinger-type equations on a high-resolution three-dimensional grid. It uses a preconditioned Newton-Krylov solver in combination with a numerical parameter continuation method. The main advantage is that the computational cost increases only linearly with the number of grid points in the calculation. This is due to the fact that the number of required iterations is independent of the dimension of the solution space, i.e., the number of unknowns. As a result, it is now possible to efficiently study three-dimensional physical systems described by nonlinear Schrödinger equations even on low-end workstations. Note that our solver is entirely built of existing open-source components. In particular we used the high-performance continuation solver implemented in LOCA [\cite=1089021].

By using Newton's method, our approach gives insight into saddle point states which are essential for understanding the dynamics of the GL system. At the same time, the finite-volume discretization can be used on samples with arbitrary shape. We have employed our solver for a challenging numerical problem, computing several stable and saddle point vortex(-loop) configurations in a three-dimensional superconducting cube encapsulating a magnetic dipole [\cite=mauro].

In conclusion, our method gives access to the dynamics of systems that were to date perceived to be too complex to be tackled with numerical continuation. It is inherently applicable to all physical systems modeled by nonlinear Schrödinger equations [\eqref=eq:tschroed], including the Gross-Pitaevskii equations for Bose-Einstein condensates, nonlinear optics, plasma physics, deep water waves, and even seemingly distant subjects such as cosmology and particle physics. Just as demonstrated for vortices in superconductors, numerical continuation methods can be used for systematic studies of other topological solitons (even three-dimensional knotted ones [\cite=knot1] [\cite=knot2]), solitary waves and breathers, which are common to various equations of nonlinear Schrödinger type (see, e.g., [\cite=nonlin]).

Acknowledgment

This research was supported by Flemish Science Foundation (FWO Vlaanderen) through project G.0174.08N.