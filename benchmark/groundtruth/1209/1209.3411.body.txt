Model

Evolution of Voltage over Time

Consider a group of interacting populations of neurons. Equation [\ref=eq:single_pop_def] describes the evolution over time of the membrane voltages for the i ensemble. Table [\ref=var-explan] explains the remaining variables.

[formula]

To represent n ensembles, we may combine n versions of Equation [\ref=eq:single_pop_def], as Equation [\ref=eq:no-subs] describes.

[formula]

[formula]

If the real part of the eigenvalues of [formula] are less than one, then the system will evolve to the voltage that Equation [\ref=eq:v_steady] describes.

[formula]

Islands of Steady State Behavior

[formula] need not be symmetric. But, if some block matrices within it are, the corresponding subpopulations can approach their own steady state even if the network is still unstable. If, furthermore, the combination of recurrent and feedforward input to those subpopulations is a saturating function, then the system's Lyapunov function is bounded and fixed points for that subpopulation must exist (Cohen and Grossberg, 1983).

One reasonable way to create a symmetric weight matrix for [formula], the block matrix that describes the k ensemble is to assume that it recognizes one of N memory patterns, [formula]. Assume that a subpopulation with n neurons signals its recognition of any memory pattern, [formula], by displaying a voltage vector [formula]. One matrix that accomplishes this is:

[formula]

Longer-term Effects on Neural Population Dynamics

Assume that two additional processes occur as defined by Equations [\ref=eq:oja] and [\ref=eq:godall]. Both are much slower than Equation [\ref=eq:no-subs]. One modifies [formula].

[formula]

[formula]

Replacing [formula]in Equations [\ref=eq:oja] and [\ref=eq:godall] yields Equations [\ref=eq:oja_2] and [\ref=eq:godall_2]. Note the appearance of the autocorrelation matrices for the stimulus, [formula], and network activity, [formula].

[formula]

[formula]

Equations [\ref=eq:oja_2] and [\ref=eq:godall_2] describe somewhat contrasting behaviors. Equation [\ref=eq:oja_2] aligns the correlation structure of the network activity with the strength of its recurrent connections. Equation [\ref=eq:godall_2] urges the outputs to be decorrelated. A faster correlating influence and slower decorrelating one allow oscillations in the correlation of network activity. According to this model, interestingly, those oscillations are dependent on input but not directly on the correlation structure of the input.

Remarks on the Structure of the Model

There is an interesting concordance between [formula] and Equation [\ref=eq:assoc-mem]. If [formula], then [formula]. This further highlights how interrelated Equations [\ref=eq:oja_2] and [\ref=eq:godall_2] are.

Effect of Correlation Structure on the Dynamics of the Feedforward Weights

If the stimulus is random, that is [formula], then the feedforward weights, [formula], stop changing only when [formula]. Combining the definition of [formula] in Equation [\ref=eq:v_steady] with the observation that [formula] must have1 we note that such stimuli prevent this system from recognizing any pattern that requires a distribution of activities over the network. Moreover, considering the rank-nullity theorem and ranks of [formula], one can see that this result holds for any stimulus autocorrelation matrix, [formula], that results from the outer product of a vector with itself.

It is next natural to consider how this system responds to many superimposed stimuli that each have different correlation structures. That is, consider a[formula] that results from the sum of i correlation matrices. Each of those autocorrelation matrices results from the outer product of the i activity pattern with itself, as Equation [\ref=eq:multi-q] describes.

[formula]

If we assume that all the input patterns are pairwise independent, then the rank of [formula] becomes equal to i, whose upper bound we assume to be the number of neurons. This stands in contrast to the result of the previous paragraph.

Effects of Correlation Structure on the Dynamics of Network Connections

By studying Equation [\ref=eq:godall_2] we can gain some insight into how [formula] influence [formula]. If [formula] lies in the nullspace of the columns of [formula], then [formula] approaches the identity matrix. Said another way, when [formula] jam each other,[formula] tries to span the largest basis it can.

The contrary effects of

Nonrandom Constant Stimulus

Consider any brief nonrandom stimulus such that, [formula] but is constant. Then[formula] only stops changing if the columns of [formula] are in the nullspace of the rows of [formula]. Because[formula] results from the tensor product of a vector with itself, it has 1 and so it may lie in the nullspace of [formula].

Brief Pulse

If a stimulus is presented to the system for a brief period of time, it will only cause sustained activity in the system if the activity that it induces is itself a fixed point of the system. That is, for a stimulus, [formula], and its response, [formula], Equation must hold.

Extension to Drug Addiction

Craving

Similar response to variable reinforcement and huge rewards

Let the i subpopulation of Equation [\ref=eq:no-subs], in analogy with a proposed role for the dopaminergic neurons in ventral tegmental area (VTA) represent the positive expecrted reward of a stimulus. Let another population, the j one, in analogy with the GABAergic neurons in the VTA represent the negative expected reward.