Convergence of Expected Utility For Universal AI

Lemma

Corollary

Abstract

We consider a sequence of repeated interactions between an agent and an environment. Uncertainty about the environment is captured by a probability distribution over a space of hypotheses, which includes all computable functions. Given a utility function, we can evaluate the expected utility of any computational policy for interaction with the environment. After making some plausible assumptions (and maybe one not-so-plausible assumption), we show that if the utility function is unbounded, then the expected utility of any policy is undefined.

AI Formalism

We will assume that the interaction between the agent and the environment takes place in discrete time-steps, or cycles. In cycle n, the agent outputs an action yn∈Y, and the environment inputs to the agent a perception xn∈X. Y and X are the sets of possible actions and perceptions, respectively, and are considered as subsets of [formula]. Thus the story of all interaction between agent and environment is captured by the two sequences [formula] and [formula].

Let us introduce a notation for substrings. If s is a sequence or string, and [formula], a  ≤  b, then define [formula].

We will denote the function instantiated by the environment as Q:Y*  →  X, so that [formula], xn  =  Q(yn1). This means that the perception generated by the environment at any given cycle is determined by the agent's actions on that and all previous cycles.

A policy for the agent is a function [formula], so that an agent implementing p at time n will choose an action [formula].

If, at any time, an agent adopts some policy p, and continues to follow that policy forever, then p and Q taken together completely determine the future of the sequences [formula] and [formula]. We are particularly interested in the future sequence of perceptions, so we will define a future function [formula].

Because the precise nature of the environment Q is unknown to the agent, we will let Ω be the set of possible environments. Let F be a σ-algebra on Ω, and P:F  →  [0,1] be a probability measure on F which represents the agent's prior information about the environment.

We will also define a function Γq:Y*  →  X* which represents the perception string output by environment q given some action string. Let [formula].

The agent will compare the quality of different outcomes using a utility function [formula]. We can then judge a policy by calculating the expected utility of the outcome given that policy, which can be written as

[formula]

...where Q is being treated as a random variable. When we write a string next to a sequence, as in [formula], we mean to concatenate them. Here, xn1 represents what the agent has seen in the past, and [formula] represents something the agent may see in the future. By concatenating them, we get a complete sequence of perceptions, which is the input required by the utility function U.

Notice that the expected utility above is a conditional expectation. Except on the very first time-step, the agent will already have some knowledge about the environment. After n cycles, the agent has output the string yn1, and the environment has output the string xn1. Thus the agent's knowledge is given by the equation [formula].

Agents such as AIXI (Hutter, 2007) choose actions by comparing the expected utility of different policies. Thus we will focus, in this paper, on calculating the expected utility of a policy.

Assumptions about the Hypothesis Space

Here we'll make further assumptions about the hypothesis space [formula]. While we could succinctly make strong assumptions that would justify our central claim, we will instead try to give somewhat weaker assumptions, even at the loss of some brevity.

Let ΩC be the set of computable total functions mapping Y* to X. We will assume that Ω  ⊇  ΩC and that [formula] and [formula]. Thus we assume that the agent assigns a nonzero probability to any computable environment function.

Let ΩP be the set of computable partial functions from Y* to X. Then ΩC  ⊂  ΩP. The computable partial functions ΩP can be indexed by natural numbers, using a surjective computable index function [formula]. Since the codomain of φ is a set of partial functions, it may be unclear what we mean when we say that φ is computable. We mean that [formula], whose codomain is X, is a computable partial function. We will also use the notation [formula].

We'll now assume that there exists a computable total function [formula] such that if φi∈ΩC, then [formula]. Intuitively, we are saying that φ is a way of describing computable functions using some sort of language, and that ρ is a way of specifying lower bounds on probabilities based on these descriptions. Note that we make no assumption about [formula] when φi∉ΩC.

To see an example of a hypothesis space satisfying all of our assumptions, let Ω  =  ΩC, let F  =  2ΩP, let φ be any programming language, and let [formula]. Let

[formula]

and for any ω∈Ω, let

[formula]

Assumptions about the Utility Function

Perhaps the most philosophically questionable assumption in this paper has already been made in defining the domain of the utility function U as [formula], the set of perception-sequences. This is like assuming that a person cares not about his or her family and friends, but about his or her perception of his or her family and friends.

Since the utility function [formula] takes as its argument an infinite sequence, we must discuss what it means for such a function to be computable. Obviously any computation which terminates can only look at a finite number of terms. Therefore we will try to approximate [formula] using prefixes of x. We say that U is computable if there exist computable functions [formula] such that, if [formula] and x̄∈X* and [formula], then:

[formula]

[formula] and [formula] as x̄  →  x.

In any case, we will not assume that U is computable, because we do not need such a strong assumption to prove our claims. Instead we will define two possible conditions.

U is computably unbounded from below if - U is computably unbounded from above.

Note in particular that any computable function on [formula] which is unbounded from above is computably unbounded from above, and any computable function which is unbounded from below is computably unbounded from below.

The following lemma will help us find environments which generate large amounts of utility. When considering f in the lemma, think of UL above.

In other words, given an unbounded partial function f, there is a computable function H which finds an input on which f will exceed any given bound.

First we'll index C; let [formula].

If f were a total function, we could simply let [formula]. We would compute this by first computing f(c1), then f(c2), etc. Unfortunately we only have that f is a partial function, so we can not proceed in this way.

Instead, we'll note that for any input on which f halts, it must halt in a specific number of steps. The Cantor pairing function [formula], [formula] is a bijection, so we can use π- 1 to index all pairs of natural numbers. Then we can simulate f on every possible input for every number of steps, which will allow us to evaluate f on every input for which f halts.

Then H is a computable total function and [formula].

Results

Let R be the set of all computable partial functions mapping [formula] to [formula], and let [formula] be a computable index (analogous to our other index function φ).

Let

[formula]

Suppose not. Then B(n)  >  f(n) only finitely many times, so there exists some [formula] such that [formula].

Let C(n,m)  =  f(n)  +  c. By a corollary of the Recursion Theorem, there exists [formula] such that [formula].

By definition, B(m)  ≥  θm(0)  =  C(m,0)  =  f(m)  +  c  >  B(m). So B(m)  >  B(m), which is a contradiction.

Now suppose that at time n + 1, the agent has already taken actions yn1 and made observations xn1, and is considering the expected utility of policy p. Let [formula].

Let [formula] be as in definition [\ref=un_abv]. Then by Lemma [\ref=heav], there exists [formula] such that [formula].

H here is intended to be used to construct sequences with high utility. Since H outputs a string rather than a sequence, we will pad it to get a sequence. Let c∈X be some arbitrary word in the perception alphabet. Then let [formula], where (n) is a sequence beginning with H(n), followed by [formula].

For brevity, let [formula]. [formula] represents the complete sequence of perceptions received by the agent, assuming that it continues to implement policy p in environment q.

We will now break up the expected utility into two terms, depending on whether or not Q∈ΩC.

[formula]

We will show that the series:

has infinitely many terms ≥  1. We will do this by finding a sequence of environments whose utilities grows very quickly - more quickly than their probabilities can shrink.

By equation [\ref=B_def], for each [formula] there exists [formula] such that uj  ≤  j and [formula].

Now we define a map on function indices [formula] such that:

So G takes the θ-index of an [formula] function (say, g), and returns the φ-index of an environment which is compatible with all the data so far, and which is guaranteed to produce utility greater than g(0). We can assume that G is a computable function.

So our sequence of environments will be [formula].

Then [formula]. Now let

[formula]

Then [formula] is a computable, nondecreasing function. Since [formula] is computable, B(j)  ≥  (j) infinitely often. Since uj  ≤  j, then by definition, [formula]. P(ΓQ(yn1)  =  xn1|Q  =  φG(uj))  =  1, so by Bayes' Rule, P({φG(uj)}|ΓQ(yn1)  =  xn1)  ≥  P({φG(uj)}). Since both sides are positive, we take the reciprocal to get [formula]. By transitivity, [formula] infinitely often, so [formula] infinitely often. Since the series contains infinitely many terms ≥  1, its limit is either +    ∞   or nonexistent.

By definition, - U is computably unbounded from above. Thus, by theorem [\ref=big_thm], [formula] is either undefined or +    ∞  . So [formula] is either undefined or -    ∞  .

By theorem [\ref=big_thm], [formula] is either undefined or +    ∞  . By corollary [\ref=from_below], it is either undefined or -    ∞  . Thus it is undefined.

Discussion

Our main result implies that if you have an unbounded, perception determined, computable utility function, and you use a Solomonoff-like prior (Solomonoff, 1964), then you have no way to choose between policies using expected utility. So which of these things should we change?

We could use a non-perception determined utility function. Then our main result would not apply. In this case, the existence of bounded expected utility will depend on the utility function. It may be possible to generalize our argument to some larger class of utility functions which have a different domain.

We could use an uncomputable utility function. For instance, if the utility of any perception-sequence is defined as equal to its Kolmogorov complexity, then the utility function is unbounded but the expected utility of any policy is finite.

We could use a smaller hypothesis space; perhaps not all computable environments should be considered.

The simplest approach may be to use a bounded utility function. Then convergence is guaranteed.