Condition numbers and scale free graphs

Introduction

In the last years several networks were analyzed, like internet routers, biological and metabolic networks, or sexual contacts [\cite=FFF], [\cite=JTAOB], [\cite=LEASA], and the node degree distributions of all of them seem to follow a power law. Also, several models of graph growth were presented in order to explain the emergence of this power law distribution [\cite=AB], [\cite=KR], [\cite=DMS]. However, several critics appeared, mainly focusing on sampling bias [\cite=ACKM], [\cite=LKJ], [\cite=PR], [\cite=CCG], [\cite=CM], [\cite=AAB], [\cite=LBCX], and the quality of data fitting [\cite=HJ], [\cite=KW], [\cite=SMA].

Recently, a simple experiment was presented in [\cite=GMY] studying the linear fit on the log log scale of computationally generated data with a pure power law distribution, and a severe bias error was reported (36%, and 29% with logarithmic bins).

In this work we present an underlying problem which explains those errors: regrettably, the matrix in the least square method is ill conditioned. Let n be the maximum degree of the network, we show that the condition number grows at least as the logarithm of n. Moreover, we introduce a parameter c∈[0,1] and we consider only the node degree distribution on

[formula]

Main Results

Condition Number

For a given matrix A∈Rm  ×  m, and a matrix norm [formula], the condition number is defined as

[formula]

Usually, for the 2-norm the condition is denoted cond(A)2. The 2-norm is an operator type norm, i.e. for v∈Rm, taking the vectorial Euclidean norm

[formula]

we have

[formula]

Concerning the condition number, the following results are well known [\cite=GV]:

[formula]

where λmin and λmax are the minimum and the maximum eigenvalue (in absolute value), and

[formula]

which says that cond(A)2 is the reciprocal of the relative distance of A to the set of singular matrices.

The interest in the condition number for matrices is related to the accuracy of computations, since it gives a bound for the propagation of the relative error in the data when a linear system is solved. If cond(A)  ~  10k, then k is roughly the number of significant figures we can expect to lose in computations.

More precisely, for a general system Ax = b, if we consider a perturbation on the right hand side [formula], then calling [formula] to the exact solution of A  =   it can be shown that

[formula]

A practical rule in statistics is to avoid the least square method when the condition number is greater than or equal to 900 (indeed they define κ(A) = cond(A)1 / 2, and κ  ≥  15 is a strong sign of collinearity, see for example [\cite=CHP]).

Theoretical Results

Let us consider a graph G with k nodes [formula], and d(xi) is the degree of node xi, that is, the number of links emanating from xi. Let us define

[formula]

For each j, 1  ≤  j  ≤  n, let hj be the number of nodes with degree j. The existence of a power law dependence h(d)  =  adγ is usually observed in a log-log plot, and computed with the least square method after a logarithmic change of variables.

First we assume that the degrees span the full integer interval

[formula]

A = ( )

[formula]

cond(A)~ ln(n)

[formula]

Δ = n- ln(j)+4 ln(j).

[formula]

ln(j) ~ n(ln(n)-1))+ O(ln(n))

[formula]

ln(j) ~ n(ln(n)-2ln(n)+2)+ O(ln(n)).

[formula]

lim =1

[formula]

A = ( ) = ( ).

[formula]

cond(A)~ n.

[formula]

=

[formula]

cond(A)= ~ n.

[formula]

Numerical Simulations

In this section we present several numerical computations of matrix conditions.

We computed the condition number of matrix An numerically by using MATLAB. Also, we computed the condition number for the truncated matrix An, for each n we consider the matrix obtained with degree values between cn and n. The results are shown in Figure [\ref=fig:conda] for n  ≤  100000, c = 0 and c = 0.1.

We show the dependence on c in Figure [\ref=fig:asubc3], for n = 104 and n = 105, with c from 0 to 0.5.

In Table [\ref=tab:1] we show the condition numbers for logarithmic bins of the form aej, 1  ≤  j  ≤  n, for n = 103,104,105, and 106; and a = 0.1, a = 1 and a = 2.

Finally, we consider the Linear Preferential Attachment model of Barabasi and Albert. This is a model of network growth, where a new node is added with a link to a previously added node, chosen at random with a probability proportional to its degree.

We generated 5  ×  104 graphs of 104 nodes, 25  ×  103 graphs of 105 nodes, 104 graphs of 106 nodes, and 104 graphs of 107 nodes, and computed the condition of the least square matrix associated with each one. We show the distribution of values of the condition number in Figure [\ref=fig:ce]. Also, in Table [\ref=tab:2] we present the computation of mean values of the condition number for c = 0, c = 0.05 and c = 0.1.

Conclusions

We have studied the condition number of the least square matrix corresponding to scale free networks. We computed theoretical lower bounds of the condition numbers showing that it behaves roughly as the logarithm of the maximum degree of the network, and numerical simulations support this fact. We also showed that neglecting the less connected nodes of the network (a usual practice in fact, since the interest is on the tail) things become even worse. Similar conclusions can be drawn for the logarithmic bin.

Finally, for random networks generated with the Linear Preference Attachment model, numerical computations of the condition numbers showed a severe ill condition of the least square matrices, even for small sized networks (104 nodes). Clearly, in this context it is very difficult to compute the power law exponent by the least square method due to the lost of accuracy expected from the corresponding condition numbers.

Acknowledgements

GA and JPP are partially supported by Fundacion Antorchas and ANPCyT. MG is partially supported by Fundacion Antorchas and CONICET.