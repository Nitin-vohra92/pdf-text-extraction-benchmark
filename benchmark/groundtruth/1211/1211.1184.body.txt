: An Package for Mortality Rates Graduation by Fixed and Adaptive Discrete Beta Kernel Techniques

Introduction

Mortality rates are age-specific indicators commonly used in demography. Historically, they are also widely adopted by actuaries, in the form of mortality tables, to calculate life insurance premiums, annuities, reserves, and so on. Producing these tables from a suitable set of crude (or raw) mortality rates is called graduation, and this subject has been extensively discussed in the actuarial literature (see, e.g., [\citealt=Copa:nonp:1983] and [\citealt=Habe:Rens:Gene:1996]). To be specific, the dx deaths at age x can be seen as arising from a population, initially exposed to the risk of death, of size ex. The situation is commonly summarized via the model [formula], where qx represents the true, but unknown, mortality rate at age x. The crude rate [formula] is the observed counterpart of qx. Graduation is necessary because crude data usually presents abrupt changes, which do not agree to the dependence structure supposedly characterizing the true rates [\citep=Lond:Grad:1985]. In fact, a common prior opinion about their form is that each true mortality rate is closely related to its neighbors. This relationship is expressed by the belief that the true rates progress smoothly from one age to the next. So, the next logical step is to graduate the crude rates to produce smooth estimates, x, of the true rates. This is done by systematically revising the crude rates in order to remove any random fluctuations. Nonparametric models are the natural choice if the aim is to reflect this belief. Furthermore, a nonparametric approach can be used to choose the simplest suitable parametric model, to provide a diagnostic check of a parametric model, or to simply explore the data (see [\citealt=Hard:Appl:1992] for a detailed discussion on the chief motivations that imply their use, and [\citealt=DMSa:acom:2006] for an exhaustive comparison of nonparametric methods in the graduation of mortality rates).

Due to its conceptual simplicity and practical and theoretical properties, kernel smoothing is one of the most popular statistical methods for nonparametric graduation. Among the various alternatives existing in literature (see [\citealt=Copa:nonp:1983], [\citealt=Gavi:Habe:Verr:Movi:1993] [\citealt=GHVe:onth:1994] [\citealt=GHVe:grad:1995] and [\citealt=Peri:Kost:Anev:2005]), the attention is here focused on the discrete beta kernel estimator proposed by [\citet=Mazz:Punz:Disc:2011]. Roughly speaking, the genesis of this model starts with the consideration that, although age X is in principle a continuous variable, it is typically truncated in some way, such as age at last birthday, so that it takes values on the discrete set [formula], ω being the highest age of interest. Discretization of age, from a pragmatical and practical point of view, could also come handy to actuaries that have to produce "discrete" graduated mortality tables starting from the observed counterparts. In the fixed bandwidth estimator proposed in [\citet=Mazz:Punz:Disc:2011], the discrete beta probability mass functions of [\citet=Punz:Zini:Appr:2012], parameterized according to [\citet=Punz:disc:2010], are considered as kernel functions in order to overcome the problem of boundary bias, commonly arising from the use of symmetric kernels [\citep=Chen:beta:2000]. The support X of the discrete beta, in fact, matches the age range and this, when smoothing is made near the boundaries, allows avoiding allocation of weight outside the support (for example negative or unrealistically high ages). Variants of the fixed bandwidth discrete beta kernel estimator, which allow the bandwidth to vary at each age according to the reliability of the data, also exist; in [\citet=Mazz:Punz:Grad:2012], the reliability is expressed by the ex, while in [\citet=Mazz:Punz:Usin:2013] this reliability is measured via the reciprocal of the variation coefficient (VC), with the VC being function of both the amount of exposure and the observed mortality rate.

In this paper we present the [\citep=R] package , available from CRAN (), which offers all the features described above and adds some related functionalities. Although is well-provided with kernel smoothing techniques [\citep=Hayfield:Racine:2008:JSSOBK:v27i05], it does not offer neither discrete beta kernel smoothing, nor application of kernel smoothing techniques in graduation of mortality data. Note that nonparametric smoothing techniques, of the kind found in , are commonly used and often cited exploratory statistical tools; as evidence, consider the number of times in which classical statistical studies use the functions and , both in the package, for kernel smoothing estimation of a density or regression function.

The paper is organized as follows. Section [\ref=sec:Discrete_beta_kernel_graduation] retraces the fixed discrete beta kernel estimator. Its adaptive variants are recalled in Section [\ref=sec:Making_the_bandwidth_adaptive] while some cross-validation approaches for the selection of both the fixed and the adaptive bandwidth is discussed in Section [\ref=sec:CV]. Further related aspects, such as the adoption of a preliminary logit transformation of the rates and the computation of the pointwise confidence intervals, are given in Section [\ref=sec:kernel]. The relevance of the package is shown, via a real data set, in Section [\ref=sec:Package_DBKGrad_in_use], and conclusions are finally given in Section [\ref=sec:conclusions].

Discrete beta kernel graduation

Given the crude rates [formula], y∈X, the Nadaraya-Watson kernel estimator of the true but unknown mortality rate qx, at the evaluation age x, is

[formula]

where [formula] is the discrete kernel function (hereafter simply named kernel), m∈X is the single mode of the kernel, h > 0 is the (fixed) bandwidth (or smoothing parameter) governing the bias-variance trade-off, and [formula] is the normalized kernel. Since we are treating age as being discrete, with equally spaced values, kernel graduation by means of [\eqref=eq:NW_kernel] is equivalent to moving (or local) weighted average graduation [\citep=GHVe:grad:1995].

In [\eqref=eq:NW_kernel], the discrete beta kernels [\citep=Mazz:Punz:Disc:2011]

[formula]

are here adopted. Their normalized version, corresponds to the discrete beta probability mass function defined in [\citet=Punz:Zini:Appr:2012] and parameterized, as in [\citet=Punz:disc:2010], according to the mode m and another parameter h that is closely related to the distribution variability. In particular, for h  →  0+, [formula] tends to a Dirac delta function in x = m, while for h  →    ∞  , [formula] tends to a discrete uniform distribution;  [\ref=fig:beta_h] shows the effect of varying h, maintaining constant ω and m. Thus h can be considered as the smoothing parameter of the estimator [\eqref=eq:NW_kernel]; indeed, as h becomes smaller, the spurious fine structure becomes visible, while as h gets larger, more details are obscured.

Roughly speaking, discrete beta kernels possess two peculiar characteristics. Firstly, their shape, fixed h, automatically changes according to the value of m. The graphical effect of varying m, keep fixed h and ω, is displayed in  [\ref=fig:beta_m]. Secondly, the support of the kernels matches the age range X so that no weight is assigned outside the data support; this means that the order of magnitude of the bias does not increase near the boundaries. Further details are reported in [\citet=Mazz:Punz:Disc:2011]; see also [\citet=Chen:beta:2000] to find out more on the properties of the discrete beta kernel estimator in its continuous counterpart. The discrete beta kernel estimator is obtained with the specification - which represents the default - in the function.

Making the bandwidth adaptive

Rather than restricting h to a fixed value, a more flexible approach is to allow the bandwidth to vary according to the reliability of the data measured in a convenient way. Thus, for ages in which the reliability is relatively larger, a low value for h results in an estimate that more closely reflects the crude rates. For ages in which the reliability is smaller, such as at old ages, a higher value for h allows the estimate of the true mortality rates to progress more smoothly; this means that at older ages we are calculating local averages over a greater number of observations. This technique is often referred to as a variable or adaptive (bandwidth) kernel estimator because it is characterized by an adaptive bandwidth [formula] which depends on the reliability lx and is function of a further sensitive parameter s.

Although the reliability lx can be inserted into the basic model [\eqref=eq:NW_kernel] in a number of ways [\citep=GHVe:grad:1995], here we adopt a natural formulation according to which

[formula]

where h is the global bandwidth and [formula]. Reliability decides the shape of the local factors, while s is necessary to dampen the possible extreme variations in reliability that can arise between young and old ages. Naturally, in the case s = 0, we are ignoring the variation in reliability, which gives a fixed bandwidth estimator.

Using [\eqref=eq:local_bandwidth] we are calculating a different bandwidth for each age x∈X, leading model [\eqref=eq:NW_kernel] to become

[formula]

where the notation hx is used to abbreviate [formula]. Thus, for each evaluation age x, the ω + 1 discrete beta distributions [formula] vary for the placement of the mode as well as for their variability as measured by hx.

In particular, [\citet=Mazz:Punz:Grad:2012] consider the reliability a function only of the amount of exposure, according to the formulation

[formula]

where is the empirical frequency of exposed to the risk of death at age x. This alternative is allowed by the specification in the function.

According to the model [formula], where [formula] is the maximum likelihood estimate of qx, a natural index of reliability is represented by the reciprocal of a relative measure of variability. As relative measure of variability, [\citet=Mazz:Punz:Usin:2013] adopt the variation coefficient (VC) which, in this context, can be computed as It is inserted in [\eqref=eq:local_bandwidth] according to the formulation

[formula]

In [\eqref=eq:VC_local_factor], [formula] is normalized so that [formula]. Note that reliability measured as in [\eqref=eq:VC_local_factor] takes into account the amount of exposure ex, but also the crude rate [formula]. The specification , in the function, allows for this adaptive bandwidth variant.

The Choice of h and s

As regard the fixed bandwidth estimator in [\eqref=eq:NW_kernel], the choice of h is important. Although it is informative to choose the bandwidth by trial and error, it is also convenient to have an objective, risk-based method for selecting h. The literature on data-driven methods for selecting the optimal value for h is vast; however, cross-validation [\citep=Ston:cros:1974] is without doubt the most commonly used and the simplest to understand. Cross-validation simultaneously fits and smooths the data by removing one data point at a time, estimating the value of the function at the missing point, and then comparing the estimate to the omitted, observed value. For a complete description of cross-validation in the context of graduation, see [\citet=GHVe:grad:1995]. The cross-validation statistic to be minimized is

[formula]

where [formula] denotes the residual (at age x) and is the estimated value at age x computed by removing the crude rate [formula] at that age. The bandwidth that minimizes [formula] is referred to as the cross-validation bandwidth. As residuals, [\citet=Mazz:Punz:Disc:2011] [\citet=Mazz:Punz:Grad:2012] consider the classical residuals

[formula]

while [\citet=Mazz:Punz:Usin:2013] adopt the proportional differences

[formula]

which is commonly used in the graduation literature because, since the high differences in mortality rates among ages, we want, in [\eqref=eq:CV_statistic], the mean relative square error to be low [\citep=Heli:Poll:Thea:1980]. Cross-validation, with residuals [\eqref=eq:differences], is obtained with the specification while, with residuals [\eqref=eq:proportional_differences], is obtained with the specification (the default) in the function.

In the adaptive frame, in addition to the global bandwidth h, also the sensitivity parameter needs to be selected. The natural choice consists in minimizing the bidimensional cross-validation statistic [formula] as a function of both h and s where in this case, [formula] is naturally based on [\eqref=eq:adaptive_NW_kernel]. This is obtained via the specifications and in the function. Nevertheless, in literature (see [\citealp=GHVe:grad:1995] and [\citealp=Mazz:Punz:Disc:2011] [\citealp=Mazz:Punz:Grad:2012] [\citealp=Mazz:Punz:Usin:2013]), s is chosen subjectively and cross-validation is still used to select h by minimizing the conditional cross-validation statistic [formula]. This approach can be obtained by posing and , and by specifying a value for the argument of the function. Note that, in the cross-validation routine, minimization is performed using the Levenberg-Marquardt algorithm [\citep=More:TheL:1978] in the package [\citep=minpack.lm].

Further aspects

The smoother matrix

Models [\eqref=eq:NW_kernel] and [\eqref=eq:adaptive_NW_kernel] can be written, for notational and computational convenience, in the following compact (matricial) form where [formula] and [formula] are the [formula]-dimensional vectors of crude and graduated mortality rates, respectively, while [formula] is the so-called [formula] smoother (or hat) matrix - depending on the bandwidth h and eventually also on the sensitivity parameter s - in which the i-th row contains the ω + 1 weights allocated to [formula], x∈X, in order to obtain i - 1. The smoother matrix is one of the values, named , returned by the function.

Transforming mortality rates

Before applying any model, it is always worth considering a transformation of the data into a more tractable form, that better reflects the strengths of the model or that more clearly reveals the structure of the data. In parametric graduation, for example, it may be easier to transform the rates and work with a linear model than to graduate the crude rates using a more mathematically demanding nonlinear model. The same philosophy applies in nonparametric graduation.

Although several transformations t exist (see, e.g., [\citealp=Carr:Rupp:Tran:1988], [\citealp=Cox:Snel:Anal:1989], and [\citealp=Elan:John:Surv:1980]), the most commonly used in binary analysis is the logit (or log-odds) transformation

[formula]

with back-transform, with respect to the more general model [\eqref=eq:adaptive_NW_kernel], By smoothing on a logistic scale and then back-transforming, we are guaranteed that [formula]. This transformation also reflects the fact that small changes when the mortality rate is near zero are as important as larger changes when the mortality rate is much higher. [\citet=Rens:Actu:1991] provides further motivation for this transformation, based on the theory of generalized linear models. The logit transformation [\eqref=eq:logit_transformation] is considered by the function via the argument specification . However, because the choice of a transformation remains subjective, and the relative success of a particular transformation seems to depend on the data set [\citep=GHVe:grad:1995], the default setting of the function is .

Pointwise confidence intervals

In visual inspection and graphical interpretation of the estimated kernel sequence of points, pointwise confidence intervals at the considered ages x∈X provide relevant information, because they indicate the extent to which the estimates are well defined on X. Moreover, they are useful when nonparametric and parametric models are compared. In the following formulas of this section, the bandwidth h, and eventually the sensitivity parameter s, are considered as a priori fixed/selected.

Since x is a linear function of the mortality rates, as can be easily seen from [\eqref=eq:NW_kernel] and [\eqref=eq:adaptive_NW_kernel], and being [formula]

[formula]

The above formula holds if independence of the dys is assumed and requires the knowledge of the number ey of exposed to risk at each age. Substituting qy for y yields the [formula] pointwise confidence intervals

[formula]

where [formula] is such that [formula].

Package in use: the Sicily2008M data

This tutorial uses the Sicily2008M dataset included in the package (also downloadable from ) and already analyzed in [\cite=Mazz:Punz:Grad:2012]. Data consist of values for [formula] and ex, [formula], and are relative to the male population of the Sicily Region (Italy) for the year 2008.

To begin the analysis, data are loaded in the following way The last two commands are only specified to simplify the subsequent notation. For a quick look at data, the following commands can be used The second step consists in creating a object. This step performs the discrete beta kernel graduation and prepares the object for analysis using the available plots. This can be obtained, for example, by the following command Here, the (old) ages of interest are reduced from ω = 100 to ω = 85 via the specification ; this allows to make the graphical inspection of the next plots easier. The function produces, by default, fixed discrete beta kernel graduation in which the bandwidth is estimated by minimizing the cross-validation statistic [\eqref=eq:CV_statistic] with the residuals given in [\eqref=eq:proportional_differences]. The iterations from the cross-validation procedure are printed at video. Also by default, no preliminary transformation of the data is considered.

Once the object is created, plots become available. The function allows for six different plots, that can be chosen by altering the option. The code produces the plot of the crude mortality rates () in  [\ref=fig:FX_CV_obs], while the code produces the plot of the graduated mortality rates () in  [\ref=fig:FX_CV_hat]. As usual in the graduation literature, a logarithmic scale is used. In both the plots, a small but prominent hump, peaking around 18 years of age, is also visible; this "excess mortality rate", known in literature as accidental hump, is typically observed especially in males and it is probably due to an increase in a variety of risky activities, the most notable being to obtain a driver's license. The simultaneous graphical representation of both crude and graduated mortality rates (see  [\ref=fig:FX_CV_hat_obs]) is obtained via the command The histogram of the residuals [\eqref=eq:differences], displayed in  [\ref=fig:residuals], is obtained by the code It could be useful in model diagnostic checking. The histogram of the proportional residuals [\eqref=eq:proportional_differences] can be obtained by specifying .

To improve the graphical inspection of the obtained results, pointwise confidence interval can be added to the plot. However, as said in Section [\ref=subsec:pointwise_confidence_intervals], these intervals require the knowledge of the exposed to risk. Thus, the object needs to be re-created to account for this aspect. The code produces the plot in  [\ref=fig:FX_CV_hat_obs]. By the argument , the exposed to risk are passed to the function. Also in the first row of code, the argument - which is the default - specifies the value of α for the pointwise confidence intervals given in [\eqref=eq:confidence_bands_for_ICRF]. In the plot command, the argument allows to display only the graduated sequence of points, while activates the pointwise confidence intervals, with the confidence level specified in the main function above.

Naturally, the user can specify a value for h if, for example, he prefers an higher smoothness. The code produces the plot in  [\ref=fig:FX_manual_IC_hat_obs] in which, if compared with  [\ref=fig:FX_CV_hat_obs], an higher smothness of the graduated sequence of points can be noted. This is made possible by the (manual) specification , along with the constraint which avoids the cross-validation selection of the bandwidth.

So far, the exposed to risk have been only used to define the pointwise confidence intervals. However, as explained in Section [\ref=sec:Making_the_bandwidth_adaptive], they are also useful to take into account the reliability of the data. The code produces the bar plot of the male population at risk displayed in  [\ref=fig:exposed]. The great variation in exposure, over the age range, shows the usefulness of an adaptive approach. Note that one offhanded change in exposure is visible in the age ranges 60-62, due to the Second World War. The code reproduces the scheme followed in [\citet=Mazz:Punz:Grad:2012] where, the sensitivity parameter is fixed to s  =  0.28, the bandwidth h is selected by minimizing the (conditional) cross-validation statistic [formula] in which the classical residuals in [\eqref=eq:differences] are used via the specification . The corresponding graphical representation in  [\ref=fig:EX_CVcond_IC_hat_obs] is obtained via the code It is easy to note that the estimated points have a more "graduated" behavior, with respect to the observed ones and to the graduated ones displayed in  [\ref=fig:FX_CV_IC_hat_obs], above all for the ages from 0 to 15.

The code allows to further show the package flexibility. The graphical result is displayed in  [\ref=fig:VC_CVjoint_IC_hat_obs]. In particular, a preliminary logit transformation of the mortality rates is applied (), as explained in Section [\ref=subsec:Transforming_mortality_rates] and, via the specifications and , both h and s are automatically selected by minimizing the joint cross-validation score [formula]. An effect of having applied the logit transformation is that, since this time cross-validation selects s = 0, there is no need of using the adaptive variant of the discrete beta kernel estimator.

Finally, the code summarizes to the user, via a dataframe, the table of all the most important quantities for each age. This may be useful when exporting the results.

Conclusions

In this paper we have presented the package for the environment. This package is specifically conceived for nonparametric graduation of discrete finite functions, such are mortality rates. The package is conceptually simple and easy to use; nevertheless several options are available to the user. He may choose among fixed and adaptive bandwidths, the latter being based, via two different formulations, on the exposed to the risk of dying. Furthermore, the bandwidth and/or a dampening factor may be indicated by the user or chosen by cross-validation; the cross-validation score being minimized may be based on the traditional sum of squared residuals or on an alternative formulation used in the graduation literature, that is the squared proportional residuals. Several plots of either types of residuals, as well as of observed data and of fitted data with confidence intervals, are provided. The package also included an illustrative data set, which contains mortality data for the 2008 male population in the Region of Sicily (Italy). We believe that the package may prove useful to actuaries, demographers, and other social scientists, either as a modeling tool or, if parametric models are to be used, it may still be useful for carrying out a diagnosis of parametric models or simply to examine data.