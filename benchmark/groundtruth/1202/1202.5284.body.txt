Elitism Levels Traverse Mechanism For The Derivation of Upper Bounds on Unimodal Functions

Introduction

We analyze an elitist population-based Evolutionary Algorithm with population size μ and recombination pool size λ,(μ  +  λ)EA using a genetic operator 1-Bit-Swap that recombines information between parents (see [\cite=tersarkisov2010]). Most research in theoretical EA community is focused on mutation-based single species algorithms such as [formula] EA (see e.g. [\cite=droste02] [\cite=doerr10] [\cite=doerr113]) with some sharp bounds on runtime obtained for OneMax function such as 0.982n log n in [\cite=doerr113]. Results on population-based algorithms are less abundant, and are restricted to mostly [formula]EA (see [\cite=witt04]) with upper bound O(μn + n log n) and [formula]EA (see [\cite=jansen05] [\cite=he2010]) with upper bound on OneMax O(n log n + nλ) in [\cite=jansen05] and all linear functions [formula] in [\cite=he2010]. Although so far (μ  +  λ) or (N + N) EAs have deserved less attention, they have been the subject of analysis in [\cite=heyao02] [\cite=heyao04] [\cite=chenhe09]. Specifically, in [\cite=chenhe09] it was derived that for a (N + N) EA with mutation and tournament selection solving OneMax the upper bound is O(nN log N  +  n log n) if measured in the number of function evaluations. Unfortunately many of these results are not directly comparable due to the difference in selection functions (fitness-proportional, truncation, elitist, tournament, etc) and elitism settings (save 1 best species or some variable proportion). Even more significantly, it was shown already in [\cite=heyao02] that population effect is generally problem-specific, so it is quite hard to generalize findings to other functions. There is ample evidence though (e.g. [\cite=jansen05] [\cite=witt04]) that for mutation-based algorithms (incl. Randomized Local Search, RLS) optimizing simple functions such as OneMax population is not beneficial and tends to degrade performance.

Algorithms and Problems

Algorithm

Although the mechanism described in this paper is quite universal, we test it on (μ  +  λ)EA1BS solving OneMax problem. This problem is well-known in EA community, recent achievements include [\cite=doerr102] [\cite=doerr113] with some sharp bounds. We selected this problem due to its simplicity and the ability to compare our findings to those available already.

Selection function

Throughout the article we analyze an elitist recombination-driven (μ  +  λ) EA using a variant of tournament selection. It is both simple to implement and analyze. But since we recombine information between parents, we are interested in forming [formula] of species in the recombination pool, and on the construction of these pairs the properties of the algorithm will be derived. This formation occurs in the following way:

Thus it is obvious that better-fit species have higher chances of entering the pool, so we can expect the proportion of α species to be higher in the pool rather than in the population.

1-Bit-Swap Genetic Operator

We apply the 1-Bit-Swap operator that was found to be useful solving a large number of test problems in [\cite=tersarkisov2010] and was analyzed extensively in [\cite=tersarkisov11] [\cite=tersarkisov112] to have outperformed the mainstream RLS algorithm both theoretically and numerically. Another advantage of 1BS is that we can compare it directly to RLS, since both are local search operators that cannot move too far from the current best search point. The operator works in the following way:

Definitions

Fitness levels partition

Basic approach to analyzing elitist EA with a simple 1-bit mutation solving unimodal binary-encoded EAs was introduced by Wegener in [\cite=wegener2003] that is based on fitness partitioning: on a set of binary strings {0,1}n size 2n a partition into a finite number of nonempty subsets [formula] is defined with ordering [formula] s.t. all a∈Am are the global optimum. This approach allows definition and derivation of the lower bound of success probability of transition between states, si(a) = P(Ai + 1|Ai) and the upper bound on expected convergence time of the algorithm, expected first hitting time of the best fitness level, [formula]. This idea can be extended to the situation when we apply non-negative weights w(f) (see [\cite=wegener2003] [\cite=droste02]) and to derive lower bounds (by considering the upper bound on si(a). Another tool used extensively in the analysis of EAs are potential (auxiliary) functions that measure progress (see [\cite=wegener2003]). This is especially useful when working on functions that have fitness plateaus (see e.g. [\cite=jansen01]), in which case we make the difference:

fitness functions decide whether the new binary input (species) is better than the old one

potential function tracks the progress between states of the algorithm (fitness levels)

OneMax (or some simple transformation of it) is used as a potential function for more complicated problems (Royal Roads, Binary Values, Short/Long Path etc).

Elitism Levels Partition

In this article we extend this approach to a population-based elitist algorithm, but rather than tracking the traverse of levels of fitness, we do the same to the levels of elitism, i.e., number of elite species in the population. We focus on species that can either evolve to the currently-best over 1 iteration or are already best. Therefore, the population is broken down into three disjoint subsets:

[formula]

Since 1BS swaps exactly 1 bit between two parents, this partition in combination with the assumptions made above enables construction of a very precise model, since the value of α cannot 'jump' more than 1 level of fitness and only α-species can breed better population, but only β1-species may evolve into α and change the probability of evolution.

α-levels subpartition

This additional partition is necessary for functions with plateaus for which we use potential functions explained above. The need for it becomes evident in the next section, when probabilities of evolving elite species on two types of functions are compared. In addition to the elitism levels partition, for functions with plateaus we need to subpartition the α-level. In slight abuse of notation in the rest of this article, we denote A the set of chromosomes in the population with the highest fitness. Also γ is the length of the plateau of fitness. Therefore the set A can be partitioned into where each subset Am has equal fitness. In order to differentiate between Am, we assign each elite species an additional auxiliary function, Vm that tracks progress to the next level by counting the number of 1-bits in the fitness level:[formula] with corresponding auxiliary values [formula], i.e. OneMax is used as an auxiliary function. Species with both highest fitness and auxiliary values can be viewed as super-elite or [formula]. In the next section we use the notation [formula] to denote the set of elite or super-elite species, an element of that set and the size of it. This is done to reduce notational clutter.

Elitism Levels Traverse Mechanism for Upper Bounds

In this section we present the main result of the article on a general function that is later confirmed by further application to OneMax Test Function. We are interested in the upper bounds on optimization time (for explanation of Landau notation see e.g. Chapter 9 in [\cite=knuth95]). The working of the Elitism Levels Traverse Mechanism can be illustrated by an example from immunology. There exists a population of species size N, which is susceptible to M types of infection, which are mutually exclusive, i.e. a species cannot be infected by more than one infection. The size of each set of infected species cannot be larger than mj. We denote [formula] an event that there are 1  ≤  r  ≤  mj infected species of type j, of which exactly one spawns an infected offspring that destroys a healthy member of the population. Since the sets of infected species are mutually exclusive, by additivity we obtain the probability that any of the infected species adds exactly one infected offspring:

This expression is quite complicated for a number of reasons, e.g. the knowledge of mj. Although we can find bounds on the partial sum of rows of Pascal triangle, it is guaranteed to make the derivation quite messy. Therefore we need to lower-bound this probability. We do this by considering only one infected species of each type rather than r and the event of spawning exactly one infected species by Ej. This gives us the lower bound on the total probability of adding exactly one infected offspring, which is proven in Appendix [\ref=sec:main_eq]:

[formula]

In the notation of EA, [formula], the number of pairs of parents in the recombination pool with parents that are able to produce exactly one elite offspring. δμ (for 0 < δ < 1) is the number of elite individuals in the population that, once it is reached, the probability to generate an offspring with higher fitness is arbitrarily close to one, i.e. 1 - o(1). We also have n - 1 levels of fitness. Combining this with the upper bound on the probability of adding elite offsprings to the population, we obtain the upper bound (worst-case) on the optimization time of the algorithm:

[formula]

Derivation of the upper bound from Equation [\ref=eq:main_eq] is rather versatile. We need to identify pairs of possible parents < p1,p2  >   such that there exists some probability of swapping bits between parents φj(k) > 0 that as a results of applying a genetic operator to this pair either a new α species evolves from lower-ranked ones or an existing α is preserved after the recombination. Intuitively, for the functions with plateaus both the population size and the number of elite species are more important than for those without plateaus. In the remainder of this section we show that the probability to add a super-elite offspring when solving a function with plateaus is less than the probability to add an elite offspring when solving functions without plateaus. For the rest of this section we denote f1 function without plateaus and f2 function with plateaus. What we show is that P(Ef1j(α,k))  ≥  P(Ef2j(α,k)).

Functions without plateaus

For this type of unimodal functions (e.g. OneMax) intuitively it is easier to add an elite offspring and thus reduce the optimization time, but we need to show it rigorously. The probability to select a pair with an α-parent can be bounded by where ξ1 is the probability to select a non-elite species to be paired with the elite one. Also bound the probability to flip the bits [formula]. So the probability of an event Ej that includes pairs with elite species is The probability to select a pair without the the currently-elite species is lower-bounded by [formula]. By breaking down the set of parents Mf1 in the recombination pool into those including α  -   parents, [formula] and those that do not, [formula], we can find the lower bound on the probability of adding another elite species:

Functions with plateaus

As noted in [\cite=chenhe09], algorithms with well-chosen population size perform similar to, and best individuals evolve along the same path as (1 + 1)EA. The difference between ([formula] lies in the cost of traversing plateau. For this type of functions the length of plateau γ > 1. So we have K plateaus w.l.o.g. of the same length [formula]. Also we assume that at the start of the algorithm each 'bin' (plateau) starts with an equal number of 1's and 0's uniformly distributed, therefore fitness of the best species at the beginning of the run is 0. To track progress between jumps in fitness values we use OneMax as an auxiliary function (roughly along the lines of using potential or distance functions, see e.g. [\cite=he2010]) that sums bits in the plateau. The tricky part in this analysis is that the selection is based on fitness of the string rather than auxiliary function, but the progress towards the next level of fitness plateau depends on the number of parents with highest auxiliary value, [formula]. By denoting the subset of α with highest auxiliary function [formula], we notice that [formula]. Also trivially [formula] (for the case of functions without plateaus these functions are identical and last two expressions are equalities). As shown before, for a unimodal function without plateaus regardless of fitness function, the probability that one of the parents is elite is [formula], since if two elite species are selected for breeding, parent is chosen randomly. Obviously [formula]. Additionally, Obviously, unlike f1, for the evolution process on f2 only a small subset of parents are of use, these having the highest and next-highest auxiliary values. Therefore pairs that do not include at least 1 of these parents can't add an [formula] offspring. Similar to [formula] and clearly [formula]. Along the lines of arguments in the previous subsection, [formula] s.t. probability to select a non super-elite parent in addition to the super-elite one is upper-bounded by it. We get: so the probability of an event that an [formula] parent is added to a pool and a new [formula] offspring evolves is upper-bounded by where η is the lower bound on the probability of swapping bits. Therefore the probability to add one more [formula] species to the population is Combining the inequalities above, and taking [formula], we compare the values in the first and second fractions in the expressions for [formula]. It is easy to see that [formula]

[formula]

Upper Bound on Runtime of (μ  +  λ)EA1BS on OneMax test function Using Elitism Levels Traverse Mechanism

In this section we present our findings on the upper bounds on runtime of (μ  +  λ)EA with 1-Bit-Swap operator optimizing OneMax function using the Elitism Levels Traverse Mechanism. We distinguish four pairs of parents that make possible evolution of currently-elite species:

[formula]

We do not consider the obvious pair <  α,α  >   as it either adds two elite offsprings, of generates an offspring with higher fitness, something we do not use in the Mechanism. For the upper bound on optimization time we only consider increase of the number of elite species by at most one. Increase by two or more is ignored, or otherwise transformed into any of the lower-ranked species. Similar approach was used in [\cite=chenhe09] in bounding the takeover time.

Simple upper bound

Of these four cases we start analysis with the first two. Main reason is that the other two cases involve cubic function, which becomes quite complicated to solve (see next subsection). For the cases E1,E2 we get the following probabilities of success:

[formula]

[formula]

The probability of at least 1 of these events is

[formula]

and, since P(S) is minimal, the upper bound on expected time to traverse levels of elitism large enough to get a 1 - o(1) probability of evolution is The expression for the expected first hitting time we obtain as a result of this setup is

[formula]

where

[formula]

At this point we set β1 pessimistically to 1 to simplify the derivation. This a quadratic equation in α. The full solution to Equation [\ref=fht1] is in Appendix [\ref=sec:eq2]. The optimization time is

[formula]

for some constant ε2(μ). For the second option of [formula] the upper bound becomes

[formula]

or, in the number of function evaluations

[formula]

Refined upper bound

We add the other two cases to obtain a sharper upper bound on optimization time, we set β1 = 1:

[formula]

The probability to evolve one more elite species is (P(E1),P(E2) are the same as in the previous derivation):

[formula]

and the expected time until there are δμ elite strings in the population:

[formula]

where

[formula]

Full solution of Equation [\ref=eq:fht2] is in Appendix [\ref=sec:eq6]. The upper bound on expected optimization time is (for [formula] is a constant):

[formula]

for 0  <  ε(μ) < 1 and if [formula], in the number of function evaluations:

[formula]

This bound is sharper than the one obtained using simpler arguments earlier in this paper up to the order λ (since more possibilities of adding elite species are considered). It is also comparable to the results in [\cite=chenhe09] [\cite=jansen05] [\cite=he2010] (see below). Such a result likely means that population has positive effect for some relatively small μ, but as it keeps increasing it either levels out (at best) or starts to degrade performance.

Generations vs Function evaluations

Tournament selection has a property that you do not need to evaluate every species, but we need to make 2λ evaluations (since two species compete for 1 slot in the recombination pool, so the number of evaluations each generation is O(λ). Therefore, in terms of the number of functions evaluations the rough bound becomes O(μλn log n) and the refined one O(μn log n). If μ  =  λ = O(1) this reduces to the well-known result of O(n log n) for OneMax function. The λ term in the denominator means that for the algorithm run on parallel computers the increase in the recombination pool size improves the performance.

Comparison to earlier results

The closest comparison we can draw is to (N + N)EA with mutation and tournament selection function in [\cite=chenhe09], O(nN log N  +  n log n) if measured in the number of function evaluations (Proposition 4). By setting N = O(1) = c  ≥  1 this bound becomes n log n + O(n), which is larger than just O(n log n). If instead we set [formula] the result in [\cite=chenhe09] is sharper than in this paper. For populations [formula] though the bound in this article becomes sharper again, e.g., for [formula] it is [formula], and in [\cite=chenhe09] it is [formula].

Discussion

We presented a new tool to analyze population-based elitist EAs, Elitism Levels Traverse Mechanism, which we used to derive a new upper bound on (μ  +  λ) EAs with a recombination operator and a variant of tournament selection solving OneMax problem. We derived and proved the lower bound on the probability of evolving exactly 1 new currently-elite species, which helped us obtain the upper bound on the expected optimization time. We showed that for a function with fitness plateaus it is harder to add a super-elite offspring to the population than an elite offspring for a function without plateaus. This means that the very number of super-elite species in the population is more important in the former case than the number of elite species in the latter. It may seem from the derived equations that population generally degrades performance (since μ is in the numerator), but for small size of population, when the cost of functions evaluations is not much different from 1, population brings about some positive effect. As it keeps increasing, the effect levels out, at the same time the costs of evaluating functions grows and population loses its benefit. For other algorithms, s.a. RLS the effect even of small-sized population is usually negative, which makes EA+1BS (and, possibly, other recombination-based algorithms) stand out. At the same time the recombination pool improves performance (at least when measured in terms of the number of generations), since λ is in the denominator. This means there is a benefit from increasing recombination pool size when the algorithm is run on parallel computers. The Mechanism we have designed in this article proved to be quite efficient in deriving upper bounds for OneMax function and we are confident it can also yield tight upper bounds on other population-driven algorithms and more complicated problems.

Conclusions and Future Work

There are many reasons to use population in evolutionary computing rather than just [formula] algorithms, that includes higher diversity and shorter evolutionary path (see [\cite=chenhe09]). We intend to expand the results in this article by considering the following extensions to the upper bound tool:

Analysis of functions with fitness plateaus. Apparently for functions with fitness plateaus (e.g. Royal roads) both large populations and large number of elite parents are crucial compared to functions without one, so we will extend our findings to these functions as well.

Typical runtime analysis. It is fairly obvious that the actual number of elite species grows every generation at some rate that realistically lies between the upper and lower bounds. We need to find an approximation on the expected number of α added to the population every generation and thus estimate the typical runtime.

Elitism rates analysis. In this article we never really considered the rate of elitism, i.e. the actual number of species saved in the population each generation, although numerical computation shows that it has a strong effect on the runtime. So far we only said that all the elite species are saved each generation, thus accumulating over time till δμ. It would be interesting to compare elitism level 1 to 50%, i.e. if there is any difference if only 1 species is saved compared to half of the population.

Derivation of δμ to find the proportion of elite species that yields a high enough probability of evolution. Quite obviously it is different for functions with plateaus and without.

Derivation of the optimal population size. We will do this by comparing the number of functions evaluations necessary of [formula] algorithms.

Proof of Equations [\ref=eq:main_ineq]-[\ref=eq:main_eq]

Main idea and logic of the lower bound on the probability of adding an elite offspring and the upper bound on runtime following from this is presented in Section [\ref=sec:main_sec]. Here we present the derivation of this bound. We prove this lower bound inequality for an arbitrary subset (it is not to be confused with at trivial one of the form [formula]):

[formula]

In this expression Pswap is not necessarily the probability to swap bits < 0,1 > . It is the probability to swap bits such that an elite offspring evolves. Since all the terms in the sum are positive, we use the lower bound on this expression:

[formula]

Canceling out φj(k) and moving the term [formula] on the other side, LHS of the inequality becomes

[formula]

and the RHS is upper-bounded by LHS is lower-bounded by (using Bernoulli inequality for [formula]):

[formula]

Since we can select Psel = o(λc) and [formula], the expression is

[formula]

thus proving the upper bound on the probability of evolving 1 more elite species for an arbitrary subset. This logic applies for each of the M subsets (types of pairs) of the recombination pool, and the inequality becomes

[formula]

The upper bound in Equation [\ref=eq:main_eq] follows directly.

Solution of Equation [\ref=fht1]

We have a quadratic equation with

[formula]

In order to simplify the already complicated derivation, we want the expression above in the form for some r, not necessarily rational. From equating coefficients it becomes clear that and so, using the first root

[formula]

For large b0 these expressions involving digamma function can be expanded asymptotically in Taylor series (we use only the first two terms):

[formula]

and therefore the expected time to traverse enough levels of elitism to improve 1 bit of the string is (plugging this expression into Equation [\ref=fht1])

[formula]

To improve the pair <  β1,β1  >   we need to either swap 1 from the first parent and 0 from the second, or the other way around (any other outcome just keeps the current number of bits in each parent): Plugging this into the expression for [formula], we obtain the expected optimization time of the algorithm, pessimistically assuming that at the beginning of the run the best species has only 2 1-bit and finishes at n - 2, since if the fitness of β1  =  n - 1 implies the fitness of α  =  n.

[formula]

The second step is due to partial fraction expansion. Although this seems quite a loose bound given cubic in μ, we take μ = O(λ) so all we need to establish is δ to reduce the power. Obviously 0  <  δ < 1, but we need to select it s.t. summation over α makes sense. We set δ  =  μ-  ε1 for an arbitrary [formula]. Then δμ2  =  μ2 - ε1  =  μ1 + ε2. For example, [formula]. Therefore, the upper bound on the expected convergence time is

[formula]

In fact if (similar to [\cite=chenhe09]) we set [formula], so the expectation becomes linear in μ:

[formula]

Solution to Equation [\ref=eq:fht2]

We need a solution to the cubic equation of the form

[formula]

where

[formula]

Solution to S(μ,k) is of the form Equating the coefficients we obtain three roots ρ:

[formula]

To simplify the increasingly hard notation, we select only the last root:

[formula]

The second line in the derivation was obtained by expanding both second-order polygamma functions in Taylor series as b'0  →    ∞   and taking two first terms of each function. We now combine the front term in Equation [\ref=eq:fht2] with this derivation to obtain the expression on the upper bound on achieving the number of elite species in the population δμ: since

[formula]

We are now ready to find the upper bound on the expected optimization time of the algorithm:

[formula]

Here again we pessimistically assume that the best species at the start of the run has fitness 3, since in such case fitness of β- 1 has minimal fitness of 1, otherwise we obtain inconsistencies s.a. [formula]. We have two probabilities to consider for the two new types of pairs:

[formula]

We need to preserve the better parent in order to get it added to the population, so need to either select 1-bits in each parent or 0-bits in each parent. for the last swap probability, φ4(k), we need only to select a 0 in the β1 parent and 1 in β- 1 parent, other options either degrade the better parent or leave the current fitness. We continue with manipulating with the summand over k:

[formula]

We leave out the first fraction, and factor the denominator in the form (k - s)(k - r), s.t. s,r are solutions to the set of equations: The resulting solution (we only use one of the roots, which are symmetric) is: The value under the root can be bounded by So the expression becomes upper-bounded by Expanding this in partial fractions, we obtain

[formula]

We obtain two sums over k:

[formula]

The result of - O(1) is due to the fact that we can select any n, for which the values of digamma function are small negative constants (see Appendix [\ref=sec:math] for details on Taylor series expansion of ψ0(n) for n < 0). For the second sum, we notice the upper bound on the value in the denominator, since [formula]:

[formula]

the minus sign in front of the expression cancels out and we obtain the upper bound for S(μ,n): and the upper bound on the expected first hitting time:

[formula]

with [formula] the expression becomes (measured in the number of generations, for c > 0)

[formula]

or, in the number of function evaluations,

[formula]

Mathematical Expressions

There is a number of important mathematical expression used throughout the article, we present some of them here: Digamma function: For [formula] we use the largest term of Taylor series for asymptotic expansion: The values for cot (πn) for integer n, such as in this article, are infinity. Therefore for expressions for [formula] we have selected some constants, e.g. [formula], s.t. the resulting values are constants. Since n is arbitrarily large, we can find such n that the difference between them is negative, hence we obtain term - O(1).