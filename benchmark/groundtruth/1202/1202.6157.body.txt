Definition Proposition Conjecture Corollary

9.311.5

Distributed Power Allocation with SINR Constraints Using Trial and Error Learning

Introduction

In this paper, we consider a network where several transmitter-receiver pairs communicate through a common bandwidth divided into several orthogonal sub-bands, thus, subject to mutual interference. All devices must guarantee certain quality of service (QoS), expressed in terms of signal to interference plus noise ratio (SINR). The behaviour of the devices is designed for achieving a stable network operating point (equilibrium) where the maximum number of communicating pairs satisfy their QoS with the minimum global power consumption. Network operating point must be achieved by the radio devices in a fully decentralized way by selecting their power allocation policy, i.e., selecting a sub-band and a power level for each transmission. In this scenario, all communications take place in absence of a centralized controller and neither cooperation nor exchange of information between different pairs are considered. For instance, this scenario may model the case of tactical radios and ad hoc networks, where, in order to set power and channel, current solutions require a certain level of cooperation with exchange of information between the devices or a manual setting.

The closest works to ours are [\cite=Iiduka-2010], [\cite=Altman-Altman-2003] and [\cite=PangScutari-IT-08]. In [\cite=Iiduka-2010], variational inequality theory is used to design a centralized power control algorithm for this scenario, in [\cite=Altman-Altman-2003] the authors show that, if the assumption of S-modularity holds for the corresponding game, then best response dynamics [\cite=Rose-CommMag-2011] converges to a generalized Nash equilibrium (GNE); in [\cite=PangScutari-IT-08], the authors provide, under the assumption of low interference, a sufficient condition for the convergence of the iterative water-filling algorithm to a GNE. It is worth noting that the works in [\cite=Iiduka-2010], [\cite=Altman-Altman-2003] and [\cite=PangScutari-IT-08] assume a compact and convex set of actions, i.e, the possible power allocation (PA) vectors may take any value in the corresponding simplex. Conversely, in our work, we consider a finite action set by quantizing the possible available powers into a certain amount of levels. Basically, this is because in practice power levels must be expressed in a finite amount of bits. Moreover, several authors have pointed out that better global performance (e.g. spectral efficiency) is achieved when the set of PA vectors is substantially reduced [\cite=Popescu-Rose-03], [\cite=Rose-Perlaza-2011], [\cite=Altman-BraessParadox], [\cite=Perlaza-Crowncom-09]. Indeed, this effect has been reported as a Braess kind paradox [\cite=Braess-eng]. In this paper, our contribution is twofold: first, we present a fully decentralized learning algorithm able to keep the SINR level above a certain threshold a high proportion of the time, by means of only one bit feedback and relying only on local information [\cite=Rose-CommMag-2011]; second, we analytically study the convergence properties and the convergence point, which is shown to be an efficient Nash equilibrium (NE) in terms of global performance. The paper is organized as follows. In Sec. [\ref=System_Model], we describe the wireless scenario and we formalize the problem; in Sec. [\ref=Game_formulation], we model the system as a game in normal form and in satisfaction form; in Sec. [\ref=Trial_and_error] we present the trial and error algorithm as introduced in [\cite=PaytonYoung-Trial-Error]; in Sec. [\ref=Algo_properties], we present a formal analytical study of the convergence properties (i.e., expected number of iterations to reach the NE and the satisfaction equilibrium (SE)), as well as, the expected fraction of time the system is at the NE and at the SE; in Sec. [\ref=Numerical_results] we validate our analysis through numerical simulations; the paper is concluded in Sec. [\ref=conclusion].

System model

Let us consider the system described in Fig. [\ref=system_m]. Here, a set [formula] of transmitter-receiver pairs share a set [formula] of orthogonal sub-bands. Transmitter k is allowed to transmit over one sub-band at a time at a given power level. We denote by pk∈P, with [formula], |P|  =  Q, and bk∈C, the power level and the frequency sub-band chosen by transmitter k respectively. We denote by [formula] the network power allocation vector, by [formula] the spectrum occupation vector and by [formula] a network configuration vector, where ak  =  (pk,bk). To communicate, pairs have to achieve a sufficient SINR level, i.e., SINRk  >  Γ where we denote by Γ the minimum SINR threshold allowing transmission. Receivers treat interference as Gaussian noise, thus:

[formula]

where g(b)k,l represents the channel power gain between transmitter l and receiver k over sub-band b, σ2 is the power of the thermal noise assumed constant over the whole spectrum and [formula] represents the indicator function. In our scenario, we assume block-fading channels, i.e., channel realizations are time invariant for the whole transmission. Our objective is the satisfaction of the SINR constraints for the largest possible set of pairs by using the lowest global energy consumption. Formally, we want the network configuration vector [formula] to be a solution of the following optimization problem

[formula]

where we denote by K*  ⊆  K the largest subset of links able to simultaneously achieve a sufficient SINR level. Generally, to achieve this goal a central controller knowing all the network's parameters is required. In the following sections, we propose a decentralized algorithm demanding no information on the network which will steer the system to a solution of [\eqref=Opt_problem].

Game Formulation

In this section, we model the scenario presented in Sec [\ref=system_m] in two different formulations: a normal-form game and a satisfaction-form [\cite=Perlaza-JSTSP-2012] game.

Normal form formulation

We model the network described above by the game in normal form

[formula]

Here, K represents the set of players, A is the joint set of actions, that is, A  =  A1  ×  A2  ×  ...  ×  AK where Ak  =  C  ×  P and we introduce the utility function [formula] defined by:

[formula]

where β is a design parameter discussed in Sec [\ref=Algo_properties]. This function has been designed to be monotonically decreasing with the power consumption, and monotonically increasing with the number of players who achieve the minimum SINR. In the following, we show that, with this utility function, the NE of the game G can solve the problem stated in [\eqref=Opt_problem]. Moreover, note that to evaluate [\eqref=ut_function] each transmitter only requires local information, since [formula] can easily be fed back by the receiver with 1 bit.

(Interdependent game). G is said to be interdependent if for every non-empty subset K+  ⊂  K and every action profile [formula] such that [formula] is the action profile of all players in K+, it holds that:

[formula]

In the following, we assume that game G is interdependent. This is a reasonable assumption, since, physically, this means that no link is isolated from the others. The solution concept used under this formulation is the Nash equilibrium, which we define as follows:

(Nash equilibrium in pure strategies). An action profile [formula] is a NE of game G if [formula] k∈K and [formula]

[formula]

To measure the efficiency of each NE, we introduce the social welfare function, defined by the sum of all individual utilities: [formula].

Satisfaction form

The satisfaction form is a game theoretical formulation modelling scenarios where players are exclusively interested in the satisfaction of their individual QoS constraints. Let us define the game as

[formula]

where K, A follow the previous definitions and the satisfaction correspondence [formula] is defined by

[formula]

The solution concept used under this formulation is the satisfaction equilibrium (SE) defined as:

(Satisfaction equilibrium). A satisfaction equilibrium of game G' is an action profile [formula] such that [formula],

[formula]

Moreover, we measure the effort of player k due to the use of a particular action [formula] by using the effort function [\cite=Perlaza-JSTSP-2012] [formula]. We can, then, define an efficient satisfaction equilibrium (ESE) as:

(Efficient satisfaction equilibrium). A satisfaction equilibrium [formula] is said to be efficient, if [formula]

[formula]

In brief, an ESE is an action profile where all players are satisfied and no player may decrease its individual effort by unilateral deviation. Since our optimization problem is to minimize the overall transmit power, we identify the effort by the function: Φk(ak) = pk.

Algorithm Description

In this section, we briefly describe the trial and error (TE) algorithm introduced in [\cite=PaytonYoung-Trial-Error], [\cite=pradelsky]. Later, we characterize the degrees of freedom of the system to fit in our scenario. In TE learning, each player k locally implements a state machine, at each iteration n, a state is defined by the triplet:

[formula]

where [formula] represents a "mood", i.e., a characteristic that defines the machine reaction to its experience of the environment, āk∈A and ūk∈[0,1] represents a benchmark action and benchmark utility, respectively. There are four possible moods: content (C), watchful (C - ), hopeful (C + ), discontent (D). In the following, we characterize the behaviour of each player in every possible mood.

Content

If at stage n player k is content, it uses the benchmarked action āk(n) with probability (1 - ε) and experiments a new action a'k(n) with probability ε. If at stage n the player decided to experiment, at stage (n + 1) it evaluates the utility uk'(n + 1) associated with a'k(n) as follows: if u'k(n + 1)  <  ūk(n) then Zk(n + 1) = Zk(n), otherwise if u'k(n + 1)  >  ūk(n), then, with probability εG(u'k(n + 1) - ūk(n)), a new action and utility benchmark are set out, i.e., ūk(n + 1) = u'k(n + 1) and āk(n + 1) = a'k(n), respectively. Here, G(  ·  ) must be such that:

[formula]

we opt for a linear formulation: G(Δu)  =   - 0.2Δu  +  0.2.

Hopeful-Watchful

If player k achieves an increment or a decrement in its utility without having experimented at the previous stage, then the mood become hopeful or watchful, according to the following rule: (i) if u'k(n + 1)  >  ūk(n) then, mk(n + 1)  =  C + , āk(n + 1) = āk(n) and ūk(n + 1) = ūk(n); (ii) if mk(n + 1)  =  C - , then āk(n + 1) = āk(n) and ūk(n + 1) = ūk(n). If player k observes an improvement also at the next stage (i.e., u'k(n + 2)  >  ūk(n + 1)), then the mood switches to content and the benchmark utility is updated with the new one: mk(n + 2) = C and ūk(n + 2) = u'k(n + 1). On the contrary, if a loss is observed also at the next stage (i.e., u'k(n + 2)  <  ūk(n + 1)), then the mood switches to discontent mk(n + 2) = D.

Discontent

If player k is discontent, it experiments a new action (a'k(n)) at each step n. We refer to this behaviour as noisy search. When the corresponding utility uk'(n + 1) is observed, with probability p = εF(uk'(n + 1) the mood turns to content mk(n + 1) = C, a new action and utility benchmark are set up, ūk(n + 1)  =  uk'(n + 1) and āk(n + 1)  =  ak'(n + 1), while, with probability (1 - p) it continues the noisy search. Note that function F must be such that

[formula]

we opt for a linear formulation: [formula].

Algorithm properties

Hereunder, we restate Theorem 1 in [\cite=PaytonYoung-Trial-Error] and Theorem 1 in [\cite=pradelsky] using our notation.

Let G have at least one pure Nash equilibrium and let ε be small enough. Then, a pure Nash equilibrium is played at least (1 - δ) of the time.

This theorem introduces a different notion of convergence. Generally [\cite=Rose-CommMag-2011], we say that an algorithm converges when it approaches a certain solution as n  →    ∞   while, here, it means that this solution is played with a high probability an high proportion of the total time.

Let G have at least one pure Nash equilibrium and let each player employ TE, then a Nash equilibrium that maximizes the sum utility among all equilibrium states is played a large proportion of the time.

Note that, generally, different equilibria are associated with different social welfare values. Learning algorithms available in the literature [\cite=Rose-CommMag-2011], [\cite=Scutari-Algorithms-2008], do not always take into consideration the problem of equilibrium selection, which is a central issue when aiming at global performance.

Main results

Working point properties

In this section, we present our results based on the previous analysis. Proofs are omitted due to space constraints. Based on the game theoretical formulation in Sec. [\ref=Game_formulation] and the algorithm properties in Sec. [\ref=Trial_and_error] we state the following:

Let [formula] be the set of NE of G, let β  >  K and let us denote by Kl the number of players satisfied at the l-th NE. Then, TE converges to the NE where Kl is maximized.

This theorem states that, if β  >  K, then TE converges to a state where the largest possible number of players are satisfied and are at the NE. Here, β represents the interest a network designer has in satisfying the largest set of players over the minimization of the network power consumption. The next two theorems allow us to link this result with the original global design problem expressed in [\eqref=Opt_problem].

Let (i) [formula] be the set of solutions of [\eqref=Opt_problem] with K*  =  K, (ii) [formula] be the set of NE of G and [formula] and let β  >  K. Then, TE learning converges to an action profile [formula] such that [formula] and is an ESE.

This theorem links together the concept of ESE of game G', the NE of game G and the solutions of [\eqref=Opt_problem]. Indeed, when the assumptions are met, the TE algorithm will reach a network state where: (i) all players are satisfied, (ii) the network power consumption is minimized. Note that, generally, it is possible for [\eqref=Opt_problem] to have a solution that is not a NE of G.

Let [\eqref=Opt_problem] have no solution for K*  =  K and fix β  >  K. Let K* be the largest number of players that can be simultaneously satisfied and let K*m be the m-th set, such that |K*m|  =  K*, where [\eqref=Opt_problem] has a solution; let also be A*m the corresponding set of solutions. Let us define [formula] and [formula] the set of NE. Then, TE learning converges to an action profile [formula] such that [formula].

The previous theorem states that, when some players cannot satisfy their SINR condition, the TE algorithm selects the subset K*m among all possible K* such that: (i) the highest number of players are satisfied, (ii) the network power consumption is minimized (with the unsatisfied players employing 0 power).

Let [formula] and [formula] be [formula], let C  ≥  K and fix β  >  K. Then, TE converges to a solution of [\eqref=Opt_problem].

Basically, this corollary means that, if transmitters and receivers are satisfiable on each channel (high SNR regime), then TE converges to an optimal working point.

Convergence analysis

TE algorithm defines a discrete time Markov chain (DTMC) on the set of the states. Studying the behaviour of the algorithm on the complete chain is an intractable problem due to the number of states, transitions and parameters. In the following, we provide an approximated DTMC that allows us to estimate: (a) the expected converging time at the NE and at the SE, (b) the expected fraction of time the system is at the NE and at the SE. Under the light of the description made in Sec. [\ref=Trial_and_error], we state the following: (i) the fraction of time spent in the watchful or hopeful states is negligible compared to the one in discontent or content one; (ii) at any time, the probability of having more than one player discontent is negligible. In the following, we assume C > K and a simplified channel model, defined as

[formula]

In Sec. [\ref=Numerical_results] we will show that these results are good approximations also under less restrictive conditions. The resulting DTMC for studying TE behaviour is represented in Fig. [\ref=MC]. When interested in convergence time and occupancy frequency of the NE, state Eq represents the NE, and CK - k a state where K - k players are using an individually optimal action and D a state where one player is discontent. The transition probabilities we evaluate are listed hereunder, the detailed description is omitted due to space constraints.

[formula]

The analysis of this DTMC allows us to state the following theorems:

The expected number of iterations needed before reaching the NE for the first time NE is bounded as follows:

[formula]

where, γ≃0.577 is the Euler-Mascheroni constant.

Note that, the time demanded to converge is directly proportional to the degree of freedom (i.e., |Ak|  =  CQ) and inversely to the experimentation probability ε. Nonetheless, as we shall see, choosing a large ε increases the instability of the NE and, consequentially, the network performance.

The expected fraction of time the system is at a NE (1 - δ) is:

[formula]

where

[formula]

Here, (1 - δ) depends on [formula] as in [\eqref=NE->D]. This means that, the larger the ε the shorter the time the system is at a NE. To evaluate convergence time and occupancy frequency of the SE we, again, make use of Fig. [\ref=MC]. In this case, state Eq represents the SE, CK - k is a state where K - k players are satisfied and D a state where one user is discontent. The corresponding transition probabilities are listed hereunder.

[formula]

Given the model in [\eqref=chan_model] and C > K, the term QS  <  Q represents the number of power quantization levels that a player can employ to successfully achieve SINRk  >  Γ on any free channel. We can, then, state the following theorems:

The expected number of iterations needed before reaching the SE for the first time SE is bounded as follows:

[formula]

Under assumption [\eqref=chan_model], being satisfied is a weaker condition than being at the NE, thus, it results that TNE  ≥  TSE. Predictably, larger PMAX and lower Γ increasing QS, are able to improve the converging speed.

The expected fraction of time the system is at a SE FSE is:

[formula]

where

[formula]

Simulation results

The purpose of this section is threefold. First, we run simulations to numerically validate the DTMCs introduced in Sec. [\ref=Algo_properties], second, we validate the results on more general channel models, then, we evaluate the performance of the algorithm in terms of satisfaction and power employed. The first two experiments have been run for two different sets of parameters. The first set is composed by: K = 3, C = 4, ε = 0.02 and 6  ≤  Q  ≤  10. The second set is composed by K = 4, C = 5, ε = 0.02 and 6  ≤  Q  ≤  10. In our first experiment, we run 107 iterations to estimate (1 - δ) under two different channel models: the simple channels expressed in [\eqref=chan_model] and a Rayleigh channel. The results are summarized in Figure [\ref=NE_frac]. As we can see, the analysis, brought on particular channel model, proves to be sufficiently precise also under more general formulations. In our second experiment, we estimated the converging time and compared with the analytical results in Figure [\ref=rising_time]. As we can see, increasing the action set dimension, i.e., increasing C or Q, brings slower convergence rate since the algorithm requires more time to explore all the possibilities. Note that, here, convergence time means the time needed by the system to work at the NE for the first time. The third experiment's parameter set is composed as follows: K = 4, C = 5, ε = 0.02 Q = 8 with the simplified channel model as in [\eqref=chan_model]. Here, we have run 103 tests, each one composed by 6000 iteration of TE. The results are showed in Fig [\ref=FIG_sat_vs_power], where the upper curve represents the fraction of players satisfied, while the lower curve represents the ratio between the average power employed by the network and the optimal power that should be employed to satisfy all the players. In average, in accordance with Figure [\ref=NE_frac], the system reaches an optimal equilibrium (all players satisfied and minimum amount of power employed) after around 2200 iterations. Note that, even though, for some specific scenarios, this number may be too high, the configurations selected by the algorithm before the convergence are just slightly inefficient. Indeed, a configuration where all the players are able to satisfy their SINR constraints is averagely reached after 600 iterations. Moreover, before this, we observe that only a fraction of satisfiable players is satisfied, in spite of the amount of power used.

conclusion

In this paper, we have studied a power control problem in a self configuring decentralized network. We presented a new decentralized algorithm able to steer the network into a working point where the maximum number of transmitter-receiver pairs achieves a sufficient SINR while minimizing the network power consumption. The algorithm does not assume any prior knowledge of the network and can learn an efficient equilibrium with only one bit of feedback. By assuming a particular channel realization, we have analytically estimated the expected performance of the algorithm through a Markov chain description of the algorithm behaviour. Finally we have shown through Monte-Carlo simulations that the analysis is approximatively correct also for general channel models.

Acknowledgement

This research work was carried out in the framework of the CORASMA – EDA Project B-0781-IAP4-GC.