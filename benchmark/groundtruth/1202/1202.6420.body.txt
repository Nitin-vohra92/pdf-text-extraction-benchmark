MAXIMUM-ENTROPY SURROGATION IN NETWORK SIGNAL DETECTION

Introduction

Established methods in coherent multiple-channel signal detection typically assume that data from all sensors is collected at a single location for processing. In particular, this view is implicit in the generalized coherence (GC) approach introduced in [\cite=Gish87] and elaborated and extended in numerous other works (e.g., [\cite=Cochran95] [\cite=Clausen97] [\cite=Clausen01] [\cite=Ramirez10] [\cite=Songsri12]). In signal processing for sensor networks, it is frequently desirable to process data locally at (or in local neighborhoods of) the nodes and reduce, or even eliminate, the need for aggregation of data at a "fusion center."

In GC-based detection and related methods, such as those using multiple coherence [\cite=Trueblood78], processing entails computing inner products (correlations) between segments of time series data collected at each pair of nodes in the network. When all data are collected at a fusion center, this is not an issue. This paper proposes an approach for implementing a GC detector that incorporates a high degree of local data reduction by using only inner products of time series segments collected at pairs of nodes that are adjacent in the topology of the network. This is equivalent to traditional GC detection only when the network is fully connected. Otherwise, the detector must operate without using the inner products associated with pairs of nodes that do not share an edge in the network graph.

The approach introduced here replaces each missing inner product datum by a surrogate value obtained via a maximum entropy method, and then proceeds to apply a standard GC detector as though all data were available. The paper begins in Section [\ref=sec:GC_background] by summarizing the basics of GC detection, and proceeds in Section [\ref=sec:max_ent] to describe the maximum entropy procedure that allows surrogation for missing data in networks that are not fully connected. Section [\ref=sec:results] shows simulation results for small networks that illustrate the performance of the approach in such settings. The paper concludes in Section [\ref=sec:conclusion] with a discussion of further work needed to make this technique viable for larger sensor networks and also how this approach suggests a point of view about quantifying the value of information in network signal processing.

The generalized coherence detector

The GC estimate is an established statistic for detection of a common signal on several noisy channels [\cite=Cochran95]. Its properties and applications have been well documented, and it continues to be extended and studied in various contexts [\cite=Ramirez10] [\cite=Songsri12]. A crucial drawback of GC-based methods in the sensor network setting is that standard implementations require all the raw sensor data to be collected in one place (i.e., a "fusion center") to perform the processing.

Given M measurements [formula] at the nodes of a network with each [formula], define normalized measurement vectors Um = Xm / ||Xm|| for [formula]. The GC estimate obtained from these measurements is [formula], where the matrix [formula] is the M  ×  M Gram matrix

[formula]

formed from the normalized data vectors. In typical multiple-channel detection applications, the value of 2 is compared to a threshold to decide between signal-present (H1) and signal-absent (H0) hypotheses.

In a completely connected network, such as those depicted in Figures [\ref=fig:3node](a) and [\ref=fig:4node](a), all of the inner products comprising the Gram matrix may be computed locally; i.e., by exchange of data between nodes that share an edge in the network graph. This enables dramatic reduction in the amount of data necessary to communicate to the fusion center in order to implement a GC detector for the network. When the network graph is not complete, however, inner products of data vectors corresponding to nodes that do not share an edge cannot be computed locally and transmission of these scalar values corresponding to each edge in the network graph is not sufficient to enable the fusion center to compute the GC estimate.

Considering the three-node case depicted in Figure [\ref=fig:3node](b), note that the value of [formula] is generally not determined by the values of [formula] and [formula]. But it is not independent of these values either; e.g., G must be non-negative definite. In the approach described in Sec. [\ref=sec:max_ent], the values of the "missing" inner products ( i.e., those corresponding to pairs of nodes that do not share an edge) will be replaced by surrogate values obtained via a maximum entropy technique, thereby enabling a GC test to be performed despite the missing data. Sec. [\ref=sec:results] considers the detection performance of GC detectors implemented in this way.

Maximum-entropy surrogation

Assume that there is a complex random variable [formula] associated with each network node m, modeling data samples collected at that node. Collected samples at node m are hence realizations of [formula] and can be used to estimated the mean and variance of [formula] in standard ways [\cite=Papoulis02]. The ability to communicate between nodes m and j linked by an edge permits estimation of the covariance [formula] by similar methods. For a complete graph ( i.e., one in which each pair of nodes shares an edge), it is thus possible to estimate the full M  ×  M covariance matrix C of the variables [formula]. Indeed, assuming the Xm have mean zero, if N independent samples of [formula] are collected at node m for each m and are assimilated into complex N-vectors [formula] of sample values, then the standard estimator Ĉ of C is proportional to the Gram matrix [formula]. The GC detector can thus be viewed as a test on the estimated covariance matrix of the variates [formula]. If each [formula] is further assumed to be normalized to unit variance, using the true variance in place of an estimate on the main diagonal gives a test matrix of the form ([\ref=eq:normalized_Gram]).

The maximum-entropy method [\cite=jaynes79] holds that missing values in C should be surrogated in such a way as to introduce no new assumptions about the nature of the random variables or of the network. The joint distribution of the random variables [formula] that best describes current knowledge ( i.e., the covariance estimates for all pairs of directly connected nodes) with no further assumptions is the maximum entropy distribution constrained by the available data.

The problem of finding the maximum-entropy completion of a covariance matrix has been studied in prior literature (see, e.g., [\cite=Vandenberghe98] and references cited therein). The maximum-entropy probability density [formula] consistent with the estimated covariances must be of the form

[formula]

In this expression λm for [formula] and μm,j  =  μj,m for values of (m,j) corresponding to the edge set E of the network graph are Lagrange parameters in the constrained optimization problem that arises in maximization of entropy subject to the constraints imposed by knowledge of the covariance values estimated from available measurements. For complex random variables, this will be a complex normal density and hence completely specified by its mean and covariance matrix.

It follows from ([\ref=eq:maxent]), and is also noted in past literature [\cite=Vandenberghe98], that the covariance matrix A of this maximum-entropy distribution will have the property that its inverse will has zeros in positions corresponding to the missing covariance values. This observation gives a direct means for calculating the needed surrogate values in small networks.

Example: Consider the three node network depicted in Fig. [\ref=fig:3node](b). Writing the estimated covariance matrix as the value of the covariance estimate â is assumed to be obtained by exchange of data between nodes 1 and 3 and the value [formula] is obtained by exchange of data between nodes 2 and 3. A maximum-entropy surrogate value for s is obtained by noting where D =  det   Ĉ. The 1-2 entry of Ĉ- 1 will be zero when s assumes the desired value. Hence, s = â* and the maximum-entropy completion of Ĉ is

This direct calculation method was used to find surrogate values in the small network examples discussed above and evaluated in Sec. [\ref=sec:results]. In general, a necessary and sufficient condition for the existence of the maximum entropy distribution as a (normalizable) probability distribution is Ĉ is invertible as a symbolic matrix. Finding k surrogate values in this way requires solving k equations in k unknowns, which becomes prohibitively cumbersome for even small networks ( e.g., M > 5). Fortunately, maximum-entropy covariance matrix completion problems [\cite=Gohberg95] fall into a class of determinant maximization problems (entropy in this setting is log  det   Ĉ) that can be efficiently solved by convex programming techniques [\cite=Boyd04] [\cite=Vandenberghe98].

The GC statistic in invariant to re-indexing of the M channels [\cite=Cochran95]. This is in contrast to the multiple coherence statistic [\cite=Trueblood78], which distinguishes a reference channel. Consequently, networks that are topologically isomorphic will have identical detection performance characteristics under the approach introduced here. For example, for a network having four nodes and five edges, it suffices to analyze the case depicted in Fig. [\ref=fig:4node](b) since all other cases are topologically equivalent to this one (and similarly for all M-node networks whose graphs are one edge short of being complete). Fig. [\ref=fig:4node_2] shows that there are topologically distinct cases of four-node networks with four edges. In general, it will be necessary to analyze the performance of each such equivalence class separately, and it is anticipated that different topologies will provide distinct detection performance characteristics. While further study of this aspect of the approach is beyond the scope of this paper, it is expected that comparison of network topologies based on the detection performance they support when completed via a maximum-entropy method will provide insight into sensor network design and optimization.

Results for small networks of sensors

Figure [\ref=fig:4node_results] shows receiver operating characteristic (ROC) curves for detection of a white complex Gaussian signal vector in white complex Gaussian noise in a 4-node sensor network. The vectors are of length N=64. The signal-to-noise ratio is identical at each sensor, with the top set of curves at -3 dB, the center set at -4.5 dB, and the bottom set at -6 dB. Within each set, the top curve is for the complete network (Figure [\ref=fig:4node](a)), the middle curve for the network with no link between nodes 1 and 2 (Figure [\ref=fig:4node](b)), and the bottom curve for the network with no links between nodes 1 and 2 or nodes 2 and 3 (Figure [\ref=fig:4node_2](a)).

These curves indicate that the equal-channel SNR detection performance lost when network connectivity is reduced by the removal of one or two links is modest - much less significant than the detection performance would be diminished by 1 dB of SNR at each node. While this experimental finding with such a small network is only relevant to a small application regime, it indicates that further study with larger networks is warranted.

Discussion and conclusions

A maximum entropy method to enable the implementation of generalized coherence detectors on incompletely connected sensor networks without aggregation of raw data at a fusion center has been described and demonstrated with small networks. Performance degradation in the cases studied was modest, though more compete evaluation of the method with larger and sparser networks, unequal signal-to-noise ratios at the sensor nodes, and signals of rank greater than one is essential to establish a comprehensive understanding of this approach in detection of signals spread across a sensor network. It is anticipated that known methods for covariance matrix completion by optimization algorithms will be essential for applying the approach to sensor networks of even moderate size ( e.g., more than ten nodes) because direct calculation of maximum-entropy surrogate values becomes formidable even for a small number of nodes.

It is noteworthy that the use of maximum entropy baselines in this application provides a mechanism for quantifying the value of information sharing within the sensor network; i.e., in this setting, a link is precisely as valuable as the performance gain it enables over the use of a maximum entropy surrogate in place of its datum.