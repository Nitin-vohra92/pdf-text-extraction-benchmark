Explicit computation of cusp forms via Hecke action on cohomology and its complexity

Introduction

When working in the field of modular forms it is often extremely useful to be able to work explicitly with spaces of modular forms, for instance in working with elliptic curves, testing conjectures, etc.

To the author's knowledge, every available software package uses modular symbols to compute bases of spaces of modular forms, and in the literature this is the standard approach as well. A good reference for the computational aspects of this is Stein [\cite=Stein].

In this paper we look at another way of determining bases of spaces of cusp forms, by using a cohomological approach, based on the Eichler-Shimura isomorphism, as done in Wang [\cite=Wang]. The theory behind this algorithm is worked through in [\cite=Wang], and what we do here is take an explicit implementation of this algorithm and analyze its complexity.

Our main result is the following:

An upper bound on the theoretical complexity of determining a basis for Sk(Γ0(N),χ) via the cohomological approach described below is

[formula]

for ε  >  0.

Finally we give two examples, where we work through the main steps of the algorithm. The first of these examples is the easier case of trivial character, while the second example with non-trivial character showcases some other aspects of the algorithm.

Notation

Let Δ denote all 2  ×  2 matrices with coefficients in [formula], and let [formula] be the matrices herein with determinant 1. We also define

[formula]

We wish to determine a basis for the space of cusp forms of weight k  ≥  2 on Γ0(N) with character χ (a Dirichlet character on [formula]). We denote by μ the index of Γ0(N) in Γ.

For [formula], we define χ(δ0)  =  χ(d).

As in [\cite=Wang], we let [formula] denote

[formula]

modulo the relation

[formula]

and we see that [formula] is just [formula] if χ is the trivial character.

For [formula] we put

[formula]

and it is easily checked that [formula] for γ0∈Γ0(N) and γ∈Γ.

We have an operation of Δ on

[formula]

given by

[formula]

and we get an action of Δ0(N) on Mχ (where the coefficient ring of M is extended with the values of χ) by setting δ0.m  =  χ(δ0)(δ0m).

We also look at the coinduced module Wχ of Mχ on Γ:

[formula]

We get an action of δ∈Δ on w∈Wχ by setting

[formula]

for γ∈Γ.

For a matrix δ∈Δ, we denote by Wδχ the submodule of Wχ invariant under the action of δ.

We reserve I, S, Q and ε for the following matrices:

[formula]

Algorithm and implementation

Coset representatives

We start out by getting coset representatives for Γ0(N) in Γ. Besides the N representatives [formula], we also have [formula] (if N is prime these are all of them).

As shown in Cremona [\cite=Cremona], there is a bijection between coset representatives [formula] of Γ0(N) in Γ and elements [formula]. To get the remaining representatives we simply take the remaining elements (c,d) of [formula] and lift these to a matrix [formula] in Γ via the Euclidean algorithm.

It is described in Section 2.2 of [\cite=Cremona] how to efficiently determine [formula]. One starts out with the obvious elements (1,0), [formula], and then look at elements (c,d), where c|N and [formula], and add it to the list if it is not equivalent to an element already on the list (one uses that two elements (c1,d1) and (c2,d2) are equivalent if and only if [formula]). See also Section 8.7 of [\cite=Stein].

We will denote the coset representatives by [formula].

From p. 103 of [\cite=Wang] we have the exact sequence (of complex vector spaces)

[formula]

where [formula].

By p. 105 of [\cite=Wang] we have that [formula], which is Wχ modulo the relations

[formula]

Therefore we need to be able determine a matrix representation of the action of a matrix in Δ on Wχ.

An element of Wχ is determined by its values on the μ coset representatives, and since Mχ is generated by the k - 1 homogenous monomials of degree k - 2, the space Wχ has μ(k - 1) generators.

As a basis for Wχ we thus have the elements

[formula]

with [formula] and [formula].

To determine the action of δ∈Δ on Wχ, we only need the action of δ.wij on the coset representatives. If γrδ∉Δ0(N)Γ the action is 0, so we now assume that we can write γrδ  =  δ0γ for some δ0∈Δ0(N) and γ∈Γ. Since we have γ  =  γ0γs for some γ0∈Γ0(N) and a coset representative γs, we replace δ0 with δ0γ0∈Δ0(N), so that the action is given by

[formula]

To get the action of δ on wij we need to run through the coset representatives γr, get the corresponding δ0∈Δ0(N) such that γrδ  =  δ0γs, and then compute the coefficients [formula] of the polynomial

[formula]

for [formula]. These coefficients are then placed in the (s + jμ)'th row and the (i + tμ)'th columns ([formula]) of a μ(k - 1)  ×  μ(k - 1)-matrix.

This way we get matrix representations of the actions of I + S, I + Q + Q2 and I + ε on Wχ, and Wχ / (WSχ + WQχ + Wεχ) is then the nullspace of the resulting relations matrix (the relations matrix is the above three matrix representations stacked on top one another).

Dimension

To determine the dimension of the space of cusp forms, we need the dimension of H1(〈T〉,Wχ)+, that is the dimension of the subspace of H1(〈T〉,Wχ) invariant under the action of ε.

By Lemma 6 of [\cite=Wang] we have an isomorphism (of [formula]-vector spaces)

[formula]

and the action of ε on [formula] is shown to be given by

[formula]

with [formula].

Let us write ε.{s}  =  c{s'}. Since ε is an involution, we have ε.{s'}  =  c- 1{s}. If {s}  =  {s'}, we have ε.{s}  =    ±  {s}, showing that {s} is in the corresponding ±  -space. If {s}  ≠  {s'}, we have {s}  ±  c{s'} in the corresponding ±  -space.

Thus, if {s}  ≠  {s'} we get elements of both ±  -spaces, but when {s}  =  {s'} we get an element of only one of these spaces - the space corresponding to the sign of -  χ(δ0), i.e. we get at element of the +  -space if and only if χ(δ0)  =   - 1 when {s}  =  {s'}.

We therefore need to determine when two cusps {γ- 1m  ∞  } and {γ- 1n  ∞  } are equivalent, and this happens exactly when γmTu  =  γ0γn for some γ0∈Γ0(N) and [formula]. This groups the coset representatives into ν∞ classes (one for each cusp equivalence class).

Thus ε maps a cusp {s} to ±  {s} (with s  =  γ- 1i  ∞  ) if and only if the coset representatives γi and γj, satisfying γjε  =  δ0γi, are in the same equivalence class, which is exactly when γiTu  =  γ0γj for some γ0∈Γ0(N) and [formula].

Since we only need one representative for each equivalence class, we choose for a given γi, the unique representative γj satisfying γiT  =  γ0γj for some γ0∈Γ0(N), and write γjε  =  δ0γi, checking the sign of χ(δ0).

This way we find the part of the ±  -spaces coming from the case where ε maps {s} to ±  {s}. When this does not happen, we get elements of both ±  -spaces, and since the sum of the dimensions is ν∞ we get the dimension of the +  -space.

The dimension of Sk(Γ0(N),χ) is the difference between the dimension of the nullspace of the relations matrix and the dimension just found.

Hecke action and basis

Since Sk(Γ0(N),χ) is the kernel of the homomorphism

[formula]

we take elements in the kernel of this map and compute the corresponding q-expansions until we have enough forms to generate Sk(Γ0(N),χ).

It is described in [\cite=Wang] how to choose elements in the kernel, and we will briefly recount this here.

By Lemmas 3 and 4 in [\cite=Wang] we get that [formula] via the map

[formula]

Since [formula], Lemma 6 of [\cite=Wang] gives an isomorphism (of [formula]-vector spaces) [formula] induced by the map [formula] given by

[formula]

Thus, the homomorphism H1(Γ,Wχ)  →  H1(〈T〉,Wχ) becomes a homomorphism [formula], and with the above isomorphisms this map is on [formula] given by

[formula]

For [formula] to be in the kernel, we can use any [formula] with m any (non-empty) linear combination of the monomials [formula] if k > 2, and m = 1 if k = 2 (in the weight-2 case we have to have χ(c)  =  χ(d) as well).

Since elements [formula] correspond bijectively to coset representatives [formula] of Γ0(N) in Γ, we can therefore represent elements of the kernel as [formula] with [formula] and m as above.

We use the Heilbronn-Merel matrices (see Proposition 20 of Merel [\cite=Merel])

[formula]

to determine the action of the Hecke operator Tn on the elements of the kernel found above.

The action of the Hecke operator Tn on Wχ / (WSχ + WQχ) is given by

[formula]

Translating this through the isomorphisms above, the action on a kernel element [formula] is

[formula]

where we for each A∈Hn write γrA  =  δ0,AγrA with δ0,A∈Δ0(N) (terms where it is not possible to write γrA in this way are ignored).

The coefficients of the polynomial χ(δ0,A)(A.m) are then saved in a vector tn, where the coefficient of xjyk - 2 - j is added to the rA(k - 1) - (k - 2 - j)'th entry, as A runs through Hn.

If we wish to compute the basis up to exponent qM, we compute tn for [formula], where we note that M has to be at least [formula], and we let t be the matrix whose n'th column is tn.

We then multiply the nullspace matrix of the relations matrix found earlier with the matrix whose n'th column is tn, and denote the resulting matrix by B. If B has rank equal to the dimension of Sk(Γ0(N),χ), we have found a basis (the leading rows of B).

If B has rank less than the dimension, we choose another element [formula] in the kernel, compute the Hecke action [formula] on this, multiply the nullspace matrix of the relations matrix with the resulting matrix, and get a matrix whose rows are concatenated to B, and we again compute the rank of B. This procedure continues until we get as many linearly independent rows in B as the dimension of Sk(Γ0(N),χ).

Experimentation indicates that if we choose [formula] (for k  >  2) this procedure is likely to give a basis using just the first few γr's.

Determining the kernel

In the implementation described, we choose certain kernel elements and generate Fourier coefficients from these until we have enough forms to generate the space of cusp forms.

However, there is no certainty that this will work, that is there is no guarantee that this approach will give enough linearly independent forms (even though the author has yet to see an example of this).

Another approach (which is certain to work every time) is the following. From the nullspace of the relations matrix we have a basis for Wχ / (WSχ + WQχ + Wεχ). By using the isomorphism [formula] given by ([\ref=iso]), we can get the image of this basis on a quotient of [formula], expressed in terms of the standard basis of [formula].

We use this basis to write up a matrix representation of the map ([\ref=map]) on this quotient, and determine its nullspace (which has dimension equal to the dimension of Sk(Γ0(N),χ)). From the nullspace matrix we read off a basis, and we then write the kernel elements as linear combinations of the [formula]. We now compute the Hecke action on these elements, which we know will generate enough forms to give a basis for Sk(Γ0(N),χ).

Complexity of implementation

We always assume that the level is given via its prime factorization, i.e. no work is needed to find the divisors of N.

We also use that a Dirichlet character on [formula] is defined via a lookup table, which takes O(N) to create, but we do not then need to worry about the cost of evaluating the character.

Coset representatives

The number of coset representatives is

[formula]

Let n be the number of prime divisors of N, and let [formula] be the first n primes. By using Landau [\cite=Landau], p. 139, we find that

[formula]

since N  ≥  2n. We therefore have μ  =  O(N log  log N).

We determine the coset representatives by looking at elements (c,d), where c|N and [formula]. By Theorem 315 of Hardy-Wright [\cite=Hardy-Wright], the number of divisors of N is O(Nδ) for δ  >  0, and we therefore look at O(N1 + δ) elements (c,d).

Everytime we look at an element we check if it is equivalent to something already found, and this takes O( log 2N) each time. Whenever we find a new element we lift it to a matrix in Γ via the Euclidean algorithm, which also takes O( log 2N). This gives a total complexity of O(N1 + δ log 2N).

All it takes to get γrδ on the form δ0γs is to compute some greatest common divisors and run through the coset representatives to see which one works. All in all the complexity for this is O(μ log 2N).

The hardest part of computing the action on a matrix on a polynomial is the binomial coefficients that shows up when computing polynomial coefficients. The cost of computing [formula] is O(m2 log 2n), and so a rough estimate for computing the action of δ0 on the k - 1 monomials xjyk - 2 - j is O(k4 log 2k). This needs to be done for every γr, i.e. μ times, giving a total complexity of O(μ2 log 2N + μk4 log 2k) for determining the matrix representation of δ on Wχ.

In can be noted that if we work over the finite field [formula] instead of the integers, one can use a congruence first proved by Lucas [\cite=Lucas] to obtain the complexity O(p2 log 2p log k) for the binomial coefficient computations. A more modern reference for the Lucas congruence is Stanley [\cite=Stanley], p. 44.

The relations matrix consists of the matrix representations of the actions of I + S, I + Q + Q2 and I + ε, and so is a matrix of size 3μ(k - 1)  ×  μ(k - 1). To compute the nullspace therefore takes O(μ3k3), and this is really the time-consuming function of this part.

Dimension

We first build an array whose i'th entry is the index j of the coset representative satisfying γiT  =  γ0γj, as well as a similar array giving the index j of the coset representative satisfying γiε  =  δ0γj. Doing this takes O(μ2 log 2N).

Next we determine to which cusp equivalence class each coset representative belong, and computing ν∞ along the way. The work needed is already done in the first array we created.

We then choose a representative γi of a cusp equivalence class and use the second array to find an equivalent representative γj satisfying γjε  =  δ0γi for some δ0∈Δ0(N). We then compute χ(δ0) and add 1 to the count of the corresponding ±  -variable d±.

The dimension of the +  -space is then d+ + (ν∞ - d+ - d-) / 2, and the dimension of Sk(Γ0(N),χ) is the difference between the dimension of the nullspace of the relations matrix and the dimension of the +  -space.

The work in creating the arrays is by far the most work in this, so the complexity of this algorithm is O(μ2 log 2N).

Hecke action and basis

Even though we use the Heilbronn-Merel matrices in the implementation, we turn to [\cite=Merel] for the complexity analysis, since this paper gives another class of matrices which can be used instead of the Heilbronn-Merel matrices, and we have estimates on the size of these classes.

In Section 3 of [\cite=Merel], Merel defines a set Sn, where a matrix [formula] is in Sn if it has determinant n and at least one of the following conditions are satisfied:

a  >  |b|, d  >  |c|, bc  >  0,

b = 0, |c|  <  d / 2,

c = 0, |b|  <  a / 2.

He also defines a set Sn', where [formula] is in Sn' if it has determinant n and one of the two following conditions are satisfied:

b = 0, |c|  =  d / 2,

c = 0, |b|  =  a / 2.

It is easily seen that an upper bound for |Sn'| is 2σ(n), where σ(n) is the sum of the positive divisors of n, and from p. 85 of [\cite=Merel] we have, as n  →    ∞  ,

[formula]

By Theorem 322 of [\cite=Hardy-Wright] we have σ(n)  =  O(n1 + δ) for δ  >  0, so that we have

[formula]

for ε  >  0, since log n  =  O(nδ') for δ'  >  0.

We need to compute Sn and Sn' for [formula] (or more n if we want higher precision), so O(μ2 + εk2 + ε) matrices are needed to compute the Hecke action.

We want to compute the action of Tn on [formula], for m a linear combination of the monomials [formula] if k > 2 and m = 1 if k = 2. To do this we write, for each [formula], γrA  =  δ0,AγrA, with δ0,A∈Δ0(N), and this can be done in O(μ log 2N) for each A. We then have

[formula]

and as mentioned earlier, the complexity of determining the action of A on a linear combination of all possible monomials is O(k4 log 2k).

The coefficients of χ(δ0,A)(A.m) are added for each A and saved in a vector tn, with indices depending on the monomial xjyk - 2 - j and index rA. Determining all necessary tn are done in O(μ2 + εk2 + ε(μ log 2N + k4 log 2k)).

Multiplying the nullspace matrix of the relations matrix with the matrix whose n'th column is tn, takes O(μ3k3), which is less than the complexity of determining the Hecke action.

The resulting matrix is the basis matrix if it has rank equal to the dimension of Sk(Γ0(N),χ). We therefore do Gaussian elimination and compute the rank to see if we are done. If not, we choose another coset representative γr, get the resulting tn's of the Hecke action on [formula], multiply the nullspace matrix of the relations matrix with the resulting matrix, and get a matrix whose rows are concatenated to B. We again do Gaussian elimination and compute the rank, and this is repeated until we get the right rank. If we run through all the coset representatives without getting the right rank, we can try with another m.

Gaussian elimination is done in O(μ3k3), and is therefore insignificant compared to the computation of the Hecke action.

For a given m, this procedure is repeated at most μ times, but experimentation indicates that it is likely to finish much sooner if m is chosen to be the sum of all possible monomials (in the case of k  >  2). We see that the computation of the Hecke action is by far the hardest part of this basis determination, and we therefore get a total theoretical complexity of O(μ3 + εk2 + ε(μ log 2N + k4 log 2k)).

Since μ  =  O(N log  log N), and hence με  =  O(Nε), we find that

[formula]

using that log 2α  =  O(αε') for ε'  >  0 (and α either N or k), and this is Theorem [\ref=thm] after replacing ε  +  ε' with ε.

Examples

We use this implementation to determine bases for two spaces of cusp forms, one with trivial character and one with non-trivial character.

The first example gives more detail, while the second highlights an aspect which only happens in the case of non-trivial character.

We start out by getting the coset representatives, and we do this by determining [formula] in the way we described earlier. Thus we get the 30 elements

[formula]

and these are lifted to matrices in Γ via the Euclidean algorithm:

[formula]

We denote the representatives by [formula], e.g. γ26  =  I.

Next we determine the nullspace of the relations matrix. Since the matrix representations of I + S, I + Q + Q2 and I + ε all are 90  ×  90-matrices, we do not write these up here. After bringing the matrix on echelon form and deleting zero rows, the nullspace matrix of the relations matrix is a 7  ×  90-matrix.

Next we compute the dimension of the +  -space. We therefore build an array whose i'th entry is the index j of the coset representative γj satisfying γiT  =  γ0γj for some γ0∈Γ0. This becomes

This array shows that [formula] are in the same cusp equivalence class, and the rest are in their own class. All in all, we see that Γ0(25) has 6 cusps, represented by γ1, γ26, γ27, γ28, γ29 and γ30.

We also build an array whose i'th entry is the index j of the coset representative γj satisfying γjε  =  δ0γi for some δ0∈Δ0(N). This becomes:

We now take each of the six representatives γi, match them with the corresponding γj from this table (checking that γj is in the same equivalence class). We do not need to compute the δ0's since we have trivial character, and therefore always will get elements of the -  -space.

From the table we see that only γ1 and γ26 give rise to γj's in the same cusp equivalence class, and we therefore get 2 elements of the -  -space.

Since there are 6 cusps, this means that the remaining 4 are split evenly between the +  - and -  -spaces, giving that the dimension of the +  -space is 2.

From this we get that the dimension of S4(Γ0(25)) is 7 - 2  =  5 (nullspace dimension minus +  -space dimension).

Finally we compute the Hecke action [formula] for [formula].

Each coset representative γr gives rise to a kernel element [formula], and to compute tn for [formula] we compute A.xy for all A∈Hn, keeping track of the index rA of γrA  =  δ0,AγAr.

In the case of n = 3 we have

[formula]

and we denote these [formula].

We need to compute up to r = 4 since the forms generated by using r  ≤  3 only spans a 4-dimensional space. As a matter of fact, the forms generated by using just [formula] span the whole space, and we write a table of indices ri with respect to γ4, as well as the action of Ai on xy:

Thus we get that

[formula]

and we put in the coefficients in a vector t3 (where (t3)3(ri - 1) + j is the coefficient of xjy2 - j in Ai.xy).

We do this for all [formula], and build a matrix with the tn as columns. We then multiply the nullspace matrix with this matrix, and get (after removing zero rows and putting the matrix on echelon form)

[formula]

which has rank 5, and the rows therefore form a basis for S4(Γ0(25)). Thus the standard basis (up to q10) of this space is

[formula]

We start out by getting the coset representatives, and we again do this by determining [formula]. We get the 24 elements

[formula]

and these are lifted to matrices in Γ via the Euclidean algorithm:

[formula]

We denote the representatives by [formula].

We again determine the relations matrix (of size 184  ×  96) and its nullspace, which in this case has dimension 8.

Just as in the last example we choose a coset representative from each cusp equivalence class, and we get 6 cusps represented by γ1, γ13, γ14, γ17, γ21 and γ24.

We now take each of these γi, match them with the corresponding γj satisfying γjε  =  δ0γi (checking that γj is in the same equivalence class as γi, which they all are in this case), and compute χ(δ0) to see to which of the ±  -spaces they correspond. We summarize the results in the follwing table:

From this we get that the dimension of [formula] is 8 - 3  =  5 (nullspace dimension minus +  -space dimension).

As before we compute the Hecke action [formula] for [formula], and in this case it is enough to use the kernel element [formula] to generate a basis.

The matrix we get after multiplying the nullspace matrix with the matrix having the tn as columns (and removing zero rows and putting it on echelon form) is

[formula]

We thus get that the standard basis (up to q10) of [formula] is

[formula]